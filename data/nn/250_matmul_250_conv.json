{"linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_0": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 773753}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_1": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 38251668}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_2": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 53415221}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_3": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2311828}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>_4": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n  return %ret : tensor<32x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x1024xf32>\n    memref.copy %2, %alloc : memref<32x1024xf32> to memref<32x1024xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x1024xf32>\n    return %3 : tensor<32x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15112447}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>_5": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123990930}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_6": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 53750799}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_7": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3517093}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_8": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123683074}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_9": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 128391345}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>_10": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 59001924}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>_11": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14015166}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>_12": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 61947738}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>_13": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3476092}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_14": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 28549735}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>_15": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14976819}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_16": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2060508083}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>_17": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 9605943}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>_18": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 48545966}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_19": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 579113}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>_20": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2306416}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_21": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 32035841}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_22": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15921899}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>_23": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 61947566}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>_24": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 245361070}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>_25": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n  return %ret : tensor<64x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32xf32>\n    memref.copy %2, %alloc : memref<64x32xf32> to memref<64x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32xf32>\n    return %3 : tensor<64x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 148184}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>_26": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 513728106}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>_27": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 577728}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_28": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 230735243}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>_29": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3795105}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_30": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7910509}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_31": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4809888}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_32": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 11983075}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>_33": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 56372100}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>_34": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7723724}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_35": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 509879734}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_36": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1496697}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_37": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 579146}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>_38": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 127646498}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_39": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 500855213}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_40": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1513767}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_41": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1151312}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_42": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15711671}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_43": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 11986101}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>_44": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1941680}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>_45": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 508698868}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_46": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6335426}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>_47": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n  return %ret : tensor<64x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32xf32>\n    memref.copy %2, %alloc : memref<64x32xf32> to memref<64x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32xf32>\n    return %3 : tensor<64x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1859904}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_48": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15363277}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_49": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15979730}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_50": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 13146091}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>_51": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 210549328}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_52": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15449959}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_53": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 106847897}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_54": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3747489}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_55": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15698661}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_56": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 375903}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>_57": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 13907660}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>_58": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 127863983}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_59": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63755827}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_60": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 32051511}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_61": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 573038}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>_62": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n  return %ret : tensor<32x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512xf32>\n    memref.copy %2, %alloc : memref<32x512xf32> to memref<32x512xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512xf32>\n    return %3 : tensor<32x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15632805}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>_63": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2304549}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>_64": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 514692155}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_65": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 286555}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>_66": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 116359878}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_67": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 28045125}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>_68": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 12141895}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>_69": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7048277}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>_70": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 126081907}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_71": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15263217}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_72": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 766192}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>_73": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n  return %ret : tensor<32x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x1024xf32>\n    memref.copy %2, %alloc : memref<32x1024xf32> to memref<32x1024xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x1024xf32>\n    return %3 : tensor<32x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 128790758}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>_74": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 247280285}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>_75": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n  return %ret : tensor<32x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x1024xf32>\n    memref.copy %2, %alloc : memref<32x1024xf32> to memref<32x1024xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x1024xf32>\n    return %3 : tensor<32x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2414158}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_76": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31978495}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_77": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1679676}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_78": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 257557803}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>_79": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 215132769}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>_80": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 508880270}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_81": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63338026}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_82": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 870553}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_83": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14963400}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_84": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 28592832}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_85": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6058172}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_86": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 120498335}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_87": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 250547281}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_88": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7847989}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_89": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 62211845}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_90": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 143638}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_91": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3892431}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>_92": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n  return %ret : tensor<64x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32xf32>\n    memref.copy %2, %alloc : memref<64x32xf32> to memref<64x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32xf32>\n    return %3 : tensor<64x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 143441}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>_93": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 62690481}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>_94": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 257264891}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_95": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 573208}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>_96": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30871233}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_97": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7818823}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_98": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7490809}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>_99": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 29246676}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_100": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15635434}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_101": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 51350509}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_102": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 296267}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_103": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31749989}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>_104": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3794240}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>_105": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 56086258}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_106": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14055371}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_107": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1030080701}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_108": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6054539}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>_109": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1189269}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_110": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63687955}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_111": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 125660106}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_112": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7486436}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_113": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3506577}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>_114": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7483799}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_115": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4614121}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_116": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1515850}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>_117": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 112588806}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>_118": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n  return %ret : tensor<32x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512xf32>\n    memref.copy %2, %alloc : memref<32x512xf32> to memref<32x512xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512xf32>\n    return %3 : tensor<32x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15615909}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_119": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2967912}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>_120": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15561692}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_121": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123686151}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>_122": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 926461}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_123": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 750970}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_124": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 32078360}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>_125": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31709734}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>_126": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 5990513}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>_127": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31575561}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_128": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3506673}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>_129": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31572551}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_130": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 62192572}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_131": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30187528}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>_132": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 60440547}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_133": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6954291}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>_134": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123025464}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>_135": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 210939669}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_136": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7907738}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_137": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1019404792}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_138": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 253286633}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_139": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15215735}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_140": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7521772}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>_141": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 56242843}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>_142": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 62888595}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>_143": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 125335550}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>_144": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n  return %ret : tensor<64x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512xf32>\n    memref.copy %2, %alloc : memref<64x512xf32> to memref<64x512xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512xf32>\n    return %3 : tensor<64x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63648632}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>_145": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 12144608}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_146": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31927801}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_147": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63707465}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_148": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 286758}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_149": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2062204188}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_150": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 32051301}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_151": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2311836}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_152": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31565876}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_153": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3719965}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_154": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15685206}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>_155": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n  return %ret : tensor<64x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512xf32>\n    memref.copy %2, %alloc : memref<64x512xf32> to memref<64x512xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512xf32>\n    return %3 : tensor<64x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6071379}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_156": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 60119933}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_157": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 11981578}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_158": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 234808616}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_159": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 250748686}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_160": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 286559}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>_161": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15816586}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_162": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 253156145}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_163": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2322884}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_164": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1020425692}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>_165": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 9545972}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_166": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 255164634}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_167": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1160065}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_168": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63340765}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_169": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 13298230}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_170": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 127527501}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_171": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2965810}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_172": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 286552}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_173": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 97069965}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>_174": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 26223937}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>_175": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n  return %ret : tensor<32x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x1024xf32>\n    memref.copy %2, %alloc : memref<32x1024xf32> to memref<32x1024xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x1024xf32>\n    return %3 : tensor<32x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2408249}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>_176": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14986412}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_177": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 585716}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_178": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 19209653}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_179": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 253102365}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_180": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6147741}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>_181": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31039772}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_182": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 52837629}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>_183": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 204473684}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_184": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30281164}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_185": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1762161}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>_186": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 508400573}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_187": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15514758}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>_188": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123609434}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>_189": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15805596}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>_190": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63752843}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>_191": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 510102927}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_192": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 28227494}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>_193": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 5993395}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_194": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3029850}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_195": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15175722}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_196": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63230692}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_197": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 97108561}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_198": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7489454}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>_199": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6158701}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>_200": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 286599}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>_201": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63088253}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_202": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7720522}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_203": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1030684247}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>_204": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1933384}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>_205": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14022868}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_206": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15695460}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>_207": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 125035626}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>_208": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7723655}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>_209": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 71745}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_210": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30879233}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>_211": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 13539736}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>_212": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 305452}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_213": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 120993854}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_214": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 97300689}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_215": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1760905}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_216": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123861290}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_217": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123683683}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_218": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 255018086}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_219": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1513306}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_220": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 375841}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_221": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7024256}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>_222": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 509687044}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>_223": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7486449}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>_224": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 257121649}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>_225": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 125417450}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>_226": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 213232485}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>_227": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 64239466}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_228": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 869817}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>_229": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 212503467}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>_230": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 27988415}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>_231": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 32066452}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_232": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2061072579}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>_233": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 61752791}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>_234": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 125221756}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>_235": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 143466}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_236": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 97243387}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>_237": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 29462900}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_238": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3748062}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>_239": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1026703495}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>_240": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 501182149}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>_241": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14977283}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>_242": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30494484}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>_243": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4124682017}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>_244": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3718350}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>_245": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 256946073}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>_246": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30880218}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>_247": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 28166049}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>_248": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3500175}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>_249": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2058379855}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<64x8x39x39xf32>) -> tensor<64x8x39x39xf32>_1": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<64x8x39x39xf32>) -> tensor<64x8x39x39xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x64x128x128xf32>, %filter: tensor<8x64x7x7xf32>, %init: tensor<64x8x39x39xf32>) -> tensor<64x8x39x39xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<64x8x39x39xf32>) -> tensor<64x8x39x39xf32>\n  return %ret : tensor<64x8x39x39xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x64x128x128xf32>, %arg1: tensor<8x64x7x7xf32>, %arg2: tensor<64x8x39x39xf32>) -> tensor<64x8x39x39xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x39x39xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x39x39xf32>\n    memref.copy %2, %alloc : memref<64x8x39x39xf32> to memref<64x8x39x39xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 39 {\n          affine.for %arg6 = 0 to 39 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x64x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x39x39xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x39x39xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x39x39xf32>\n    return %3 : tensor<64x8x39x39xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x39x39xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x64x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x64x128x128xf32>) -> tensor<64x64x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x7x7xf32>) -> tensor<8x64x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x39x39xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x39x39xf32>) -> tensor<64x8x39x39xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<64x8x39x39xf32>) -> tensor<64x8x39x39xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x39x39xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x39x39xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 39, 1], ["%arg6", 0, 39, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 9259214118}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>_2": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x16x256x256xf32>, %filter: tensor<32x16x1x1xf32>, %init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>\n  return %ret : tensor<16x32x256x256xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x16x256x256xf32>, %arg1: tensor<32x16x1x1xf32>, %arg2: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x16x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x256x256xf32>\n    memref.copy %2, %alloc : memref<16x32x256x256xf32> to memref<16x32x256x256xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          affine.for %arg6 = 0 to 256 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x16x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x256x256xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x256x256xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x256x256xf32>\n    return %3 : tensor<16x32x256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x16x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x16x256x256xf32>) -> tensor<16x16x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x16x1x1xf32>) -> tensor<32x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x256x256xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1], ["%arg6", 0, 256, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 3", "%arg6 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1556000014}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<4x256x64x128xf32>) -> tensor<4x256x64x128xf32>_3": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<4x256x64x128xf32>) -> tensor<4x256x64x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x8x64x128xf32>, %filter: tensor<256x8x1x1xf32>, %init: tensor<4x256x64x128xf32>) -> tensor<4x256x64x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<4x256x64x128xf32>) -> tensor<4x256x64x128xf32>\n  return %ret : tensor<4x256x64x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x8x64x128xf32>, %arg1: tensor<256x8x1x1xf32>, %arg2: tensor<4x256x64x128xf32>) -> tensor<4x256x64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x8x64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x256x64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x256x64x128xf32>\n    memref.copy %2, %alloc : memref<4x256x64x128xf32> to memref<4x256x64x128xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x8x64x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x256x64x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x256x64x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x256x64x128xf32>\n    return %3 : tensor<4x256x64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x256x64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x8x64x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x8x64x128xf32>) -> tensor<4x8x64x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x8x1x1xf32>) -> tensor<256x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x256x64x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x256x64x128xf32>) -> tensor<4x256x64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<4x256x64x128xf32>) -> tensor<4x256x64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x256x64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x256x64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 98596874}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<4x16x32x256xf32>) -> tensor<4x16x32x256xf32>_6": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<4x16x32x256xf32>) -> tensor<4x16x32x256xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x256x32x256xf32>, %filter: tensor<16x256x1x1xf32>, %init: tensor<4x16x32x256xf32>) -> tensor<4x16x32x256xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<4x16x32x256xf32>) -> tensor<4x16x32x256xf32>\n  return %ret : tensor<4x16x32x256xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x256x32x256xf32>, %arg1: tensor<16x256x1x1xf32>, %arg2: tensor<4x16x32x256xf32>) -> tensor<4x16x32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x256x32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x16x32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x16x32x256xf32>\n    memref.copy %2, %alloc : memref<4x16x32x256xf32> to memref<4x16x32x256xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 256 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x256x32x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x16x32x256xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x16x32x256xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x16x32x256xf32>\n    return %3 : tensor<4x16x32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x16x32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x256x32x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x256x32x256xf32>) -> tensor<4x256x32x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x256x1x1xf32>) -> tensor<16x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x16x32x256xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x16x32x256xf32>) -> tensor<4x16x32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<4x16x32x256xf32>) -> tensor<4x16x32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x16x32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x16x32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 256, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 509809900}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x64xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<8x256x26x58xf32>) -> tensor<8x256x26x58xf32>_8": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x64xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<8x256x26x58xf32>) -> tensor<8x256x26x58xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x32x32x64xf32>, %filter: tensor<256x32x3x3xf32>, %init: tensor<8x256x26x58xf32>) -> tensor<8x256x26x58xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x64xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<8x256x26x58xf32>) -> tensor<8x256x26x58xf32>\n  return %ret : tensor<8x256x26x58xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x32x32x64xf32>, %arg1: tensor<256x32x3x3xf32>, %arg2: tensor<8x256x26x58xf32>) -> tensor<8x256x26x58xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x32x32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x256x26x58xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x256x26x58xf32>\n    memref.copy %2, %alloc : memref<8x256x26x58xf32> to memref<8x256x26x58xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 58 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x32x32x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x26x58xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x26x58xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x256x26x58xf32>\n    return %3 : tensor<8x256x26x58xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x256x26x58xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x32x32x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x32x32x64xf32>) -> tensor<8x32x32x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x32x3x3xf32>) -> tensor<256x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x256x26x58xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x256x26x58xf32>) -> tensor<8x256x26x58xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x64xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<8x256x26x58xf32>) -> tensor<8x256x26x58xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x256x26x58xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x256x26x58xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 26, 1], ["%arg6", 0, 58, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 3", "%arg6 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3328165635}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x32xf32>, tensor<16x8x3x3xf32>) outs (%init: tensor<16x16x253x13xf32>) -> tensor<16x16x253x13xf32>_9": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x32xf32>, tensor<16x8x3x3xf32>) outs (%init: tensor<16x16x253x13xf32>) -> tensor<16x16x253x13xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x512x32xf32>, %filter: tensor<16x8x3x3xf32>, %init: tensor<16x16x253x13xf32>) -> tensor<16x16x253x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x32xf32>, tensor<16x8x3x3xf32>) outs (%init: tensor<16x16x253x13xf32>) -> tensor<16x16x253x13xf32>\n  return %ret : tensor<16x16x253x13xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x512x32xf32>, %arg1: tensor<16x8x3x3xf32>, %arg2: tensor<16x16x253x13xf32>) -> tensor<16x16x253x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x16x253x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x16x253x13xf32>\n    memref.copy %2, %alloc : memref<16x16x253x13xf32> to memref<16x16x253x13xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 253 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x512x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x253x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x253x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x16x253x13xf32>\n    return %3 : tensor<16x16x253x13xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x16x253x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x512x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x512x32xf32>) -> tensor<16x8x512x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x8x3x3xf32>) -> tensor<16x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x16x253x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x16x253x13xf32>) -> tensor<16x16x253x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x32xf32>, tensor<16x8x3x3xf32>) outs (%init: tensor<16x16x253x13xf32>) -> tensor<16x16x253x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x16x253x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x16x253x13xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 253, 1], ["%arg6", 0, 13, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 212773885}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x64x64xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<32x32x22x22xf32>) -> tensor<32x32x22x22xf32>_10": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x64x64xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<32x32x22x22xf32>) -> tensor<32x32x22x22xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x128x64x64xf32>, %filter: tensor<32x128x1x1xf32>, %init: tensor<32x32x22x22xf32>) -> tensor<32x32x22x22xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x64x64xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<32x32x22x22xf32>) -> tensor<32x32x22x22xf32>\n  return %ret : tensor<32x32x22x22xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x128x64x64xf32>, %arg1: tensor<32x128x1x1xf32>, %arg2: tensor<32x32x22x22xf32>) -> tensor<32x32x22x22xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32x22x22xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32x22x22xf32>\n    memref.copy %2, %alloc : memref<32x32x22x22xf32> to memref<32x32x22x22xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 22 {\n          affine.for %arg6 = 0 to 22 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x128x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x22x22xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x22x22xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32x22x22xf32>\n    return %3 : tensor<32x32x22x22xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32x22x22xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x128x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x128x64x64xf32>) -> tensor<32x128x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x1x1xf32>) -> tensor<32x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x32x22x22xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x32x22x22xf32>) -> tensor<32x32x22x22xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x64x64xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<32x32x22x22xf32>) -> tensor<32x32x22x22xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32x22x22xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32x22x22xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 22, 1], ["%arg6", 0, 22, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 227059812}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x64xf32>, tensor<128x16x7x7xf32>) outs (%init: tensor<8x128x41x20xf32>) -> tensor<8x128x41x20xf32>_11": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x64xf32>, tensor<128x16x7x7xf32>) outs (%init: tensor<8x128x41x20xf32>) -> tensor<8x128x41x20xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x128x64xf32>, %filter: tensor<128x16x7x7xf32>, %init: tensor<8x128x41x20xf32>) -> tensor<8x128x41x20xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x64xf32>, tensor<128x16x7x7xf32>) outs (%init: tensor<8x128x41x20xf32>) -> tensor<8x128x41x20xf32>\n  return %ret : tensor<8x128x41x20xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x128x64xf32>, %arg1: tensor<128x16x7x7xf32>, %arg2: tensor<8x128x41x20xf32>) -> tensor<8x128x41x20xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x16x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x41x20xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x41x20xf32>\n    memref.copy %2, %alloc : memref<8x128x41x20xf32> to memref<8x128x41x20xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 41 {\n          affine.for %arg6 = 0 to 20 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x128x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x16x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x41x20xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x41x20xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x41x20xf32>\n    return %3 : tensor<8x128x41x20xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x41x20xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x128x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x128x64xf32>) -> tensor<8x16x128x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x16x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x16x7x7xf32>) -> tensor<128x16x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x41x20xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x41x20xf32>) -> tensor<8x128x41x20xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x64xf32>, tensor<128x16x7x7xf32>) outs (%init: tensor<8x128x41x20xf32>) -> tensor<8x128x41x20xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x41x20xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x41x20xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 41, 1], ["%arg6", 0, 20, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2481524345}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x32xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<16x16x62x14xf32>) -> tensor<16x16x62x14xf32>_14": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x32xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<16x16x62x14xf32>) -> tensor<16x16x62x14xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x64x128x32xf32>, %filter: tensor<16x64x3x3xf32>, %init: tensor<16x16x62x14xf32>) -> tensor<16x16x62x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x32xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<16x16x62x14xf32>) -> tensor<16x16x62x14xf32>\n  return %ret : tensor<16x16x62x14xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x64x128x32xf32>, %arg1: tensor<16x64x3x3xf32>, %arg2: tensor<16x16x62x14xf32>) -> tensor<16x16x62x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x64x128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x16x62x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x16x62x14xf32>\n    memref.copy %2, %alloc : memref<16x16x62x14xf32> to memref<16x16x62x14xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x64x128x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x62x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x62x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x16x62x14xf32>\n    return %3 : tensor<16x16x62x14xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x16x62x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x64x128x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x64x128x32xf32>) -> tensor<16x64x128x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x3x3xf32>) -> tensor<16x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x16x62x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x16x62x14xf32>) -> tensor<16x16x62x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x32xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<16x16x62x14xf32>) -> tensor<16x16x62x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x16x62x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x16x62x14xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 62, 1], ["%arg6", 0, 14, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 486803810}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x32x64xf32>, tensor<32x8x5x5xf32>) outs (%init: tensor<256x32x28x60xf32>) -> tensor<256x32x28x60xf32>_18": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x32x64xf32>, tensor<32x8x5x5xf32>) outs (%init: tensor<256x32x28x60xf32>) -> tensor<256x32x28x60xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x8x32x64xf32>, %filter: tensor<32x8x5x5xf32>, %init: tensor<256x32x28x60xf32>) -> tensor<256x32x28x60xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x32x64xf32>, tensor<32x8x5x5xf32>) outs (%init: tensor<256x32x28x60xf32>) -> tensor<256x32x28x60xf32>\n  return %ret : tensor<256x32x28x60xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x8x32x64xf32>, %arg1: tensor<32x8x5x5xf32>, %arg2: tensor<256x32x28x60xf32>) -> tensor<256x32x28x60xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x8x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x8x32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x28x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x28x60xf32>\n    memref.copy %2, %alloc : memref<256x32x28x60xf32> to memref<256x32x28x60xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x8x32x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x8x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x28x60xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x28x60xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x28x60xf32>\n    return %3 : tensor<256x32x28x60xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x28x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x8x32x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x8x32x64xf32>) -> tensor<256x8x32x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x8x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x8x5x5xf32>) -> tensor<32x8x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x28x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x28x60xf32>) -> tensor<256x32x28x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x32x64xf32>, tensor<32x8x5x5xf32>) outs (%init: tensor<256x32x28x60xf32>) -> tensor<256x32x28x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x28x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x28x60xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 28, 1], ["%arg6", 0, 60, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 10074143348}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x512x256xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<32x256x171x86xf32>) -> tensor<32x256x171x86xf32>_19": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x512x256xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<32x256x171x86xf32>) -> tensor<32x256x171x86xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x32x512x256xf32>, %filter: tensor<256x32x1x1xf32>, %init: tensor<32x256x171x86xf32>) -> tensor<32x256x171x86xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x512x256xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<32x256x171x86xf32>) -> tensor<32x256x171x86xf32>\n  return %ret : tensor<32x256x171x86xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x32x512x256xf32>, %arg1: tensor<256x32x1x1xf32>, %arg2: tensor<32x256x171x86xf32>) -> tensor<32x256x171x86xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32x512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256x171x86xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256x171x86xf32>\n    memref.copy %2, %alloc : memref<32x256x171x86xf32> to memref<32x256x171x86xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 171 {\n          affine.for %arg6 = 0 to 86 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x32x512x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x256x171x86xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x256x171x86xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256x171x86xf32>\n    return %3 : tensor<32x256x171x86xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256x171x86xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x32x512x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x32x512x256xf32>) -> tensor<32x32x512x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x32x1x1xf32>) -> tensor<256x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x256x171x86xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x256x171x86xf32>) -> tensor<32x256x171x86xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x512x256xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<32x256x171x86xf32>) -> tensor<32x256x171x86xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256x171x86xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256x171x86xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 171, 1], ["%arg6", 0, 86, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 11769993779}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x256xf32>, tensor<128x16x3x3xf32>) outs (%init: tensor<4x128x85x85xf32>) -> tensor<4x128x85x85xf32>_21": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x256xf32>, tensor<128x16x3x3xf32>) outs (%init: tensor<4x128x85x85xf32>) -> tensor<4x128x85x85xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x256x256xf32>, %filter: tensor<128x16x3x3xf32>, %init: tensor<4x128x85x85xf32>) -> tensor<4x128x85x85xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x256xf32>, tensor<128x16x3x3xf32>) outs (%init: tensor<4x128x85x85xf32>) -> tensor<4x128x85x85xf32>\n  return %ret : tensor<4x128x85x85xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x256x256xf32>, %arg1: tensor<128x16x3x3xf32>, %arg2: tensor<4x128x85x85xf32>) -> tensor<4x128x85x85xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x128x85x85xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x128x85x85xf32>\n    memref.copy %2, %alloc : memref<4x128x85x85xf32> to memref<4x128x85x85xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 85 {\n          affine.for %arg6 = 0 to 85 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x128x85x85xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x128x85x85xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x128x85x85xf32>\n    return %3 : tensor<4x128x85x85xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x128x85x85xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x256x256xf32>) -> tensor<4x16x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x16x3x3xf32>) -> tensor<128x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x128x85x85xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x128x85x85xf32>) -> tensor<4x128x85x85xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x256xf32>, tensor<128x16x3x3xf32>) outs (%init: tensor<4x128x85x85xf32>) -> tensor<4x128x85x85xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x128x85x85xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x128x85x85xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 85, 1], ["%arg6", 0, 85, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1999430505}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x64xf32>, tensor<512x256x5x5xf32>) outs (%init: tensor<4x512x7x18xf32>) -> tensor<4x512x7x18xf32>_22": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x64xf32>, tensor<512x256x5x5xf32>) outs (%init: tensor<4x512x7x18xf32>) -> tensor<4x512x7x18xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x256x32x64xf32>, %filter: tensor<512x256x5x5xf32>, %init: tensor<4x512x7x18xf32>) -> tensor<4x512x7x18xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x64xf32>, tensor<512x256x5x5xf32>) outs (%init: tensor<4x512x7x18xf32>) -> tensor<4x512x7x18xf32>\n  return %ret : tensor<4x512x7x18xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x256x32x64xf32>, %arg1: tensor<512x256x5x5xf32>, %arg2: tensor<4x512x7x18xf32>) -> tensor<4x512x7x18xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x256x32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x512x7x18xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x512x7x18xf32>\n    memref.copy %2, %alloc : memref<4x512x7x18xf32> to memref<4x512x7x18xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 18 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x256x32x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x256x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x7x18xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x7x18xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x512x7x18xf32>\n    return %3 : tensor<4x512x7x18xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x512x7x18xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x256x32x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x256x32x64xf32>) -> tensor<4x256x32x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x256x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x256x5x5xf32>) -> tensor<512x256x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x512x7x18xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x512x7x18xf32>) -> tensor<4x512x7x18xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x32x64xf32>, tensor<512x256x5x5xf32>) outs (%init: tensor<4x512x7x18xf32>) -> tensor<4x512x7x18xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x512x7x18xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x512x7x18xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 7, 1], ["%arg6", 0, 18, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 6276660394}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x64xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<16x32x58x26xf32>) -> tensor<16x32x58x26xf32>_23": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x64xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<16x32x58x26xf32>) -> tensor<16x32x58x26xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x32x128x64xf32>, %filter: tensor<32x32x5x5xf32>, %init: tensor<16x32x58x26xf32>) -> tensor<16x32x58x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x64xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<16x32x58x26xf32>) -> tensor<16x32x58x26xf32>\n  return %ret : tensor<16x32x58x26xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x32x128x64xf32>, %arg1: tensor<32x32x5x5xf32>, %arg2: tensor<16x32x58x26xf32>) -> tensor<16x32x58x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x32x128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x58x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x58x26xf32>\n    memref.copy %2, %alloc : memref<16x32x58x26xf32> to memref<16x32x58x26xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 58 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x32x128x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x58x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x58x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x58x26xf32>\n    return %3 : tensor<16x32x58x26xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x58x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x32x128x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x32x128x64xf32>) -> tensor<16x32x128x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x5x5xf32>) -> tensor<32x32x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x58x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x58x26xf32>) -> tensor<16x32x58x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x64xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<16x32x58x26xf32>) -> tensor<16x32x58x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x58x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x58x26xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 58, 1], ["%arg6", 0, 26, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2347549385}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x64xf32>, tensor<256x16x1x1xf32>) outs (%init: tensor<8x256x86x22xf32>) -> tensor<8x256x86x22xf32>_31": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x64xf32>, tensor<256x16x1x1xf32>) outs (%init: tensor<8x256x86x22xf32>) -> tensor<8x256x86x22xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x256x64xf32>, %filter: tensor<256x16x1x1xf32>, %init: tensor<8x256x86x22xf32>) -> tensor<8x256x86x22xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x64xf32>, tensor<256x16x1x1xf32>) outs (%init: tensor<8x256x86x22xf32>) -> tensor<8x256x86x22xf32>\n  return %ret : tensor<8x256x86x22xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x256x64xf32>, %arg1: tensor<256x16x1x1xf32>, %arg2: tensor<8x256x86x22xf32>) -> tensor<8x256x86x22xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x256x86x22xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x256x86x22xf32>\n    memref.copy %2, %alloc : memref<8x256x86x22xf32> to memref<8x256x86x22xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 86 {\n          affine.for %arg6 = 0 to 22 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x256x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x86x22xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x86x22xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x256x86x22xf32>\n    return %3 : tensor<8x256x86x22xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x256x86x22xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x256x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x256x64xf32>) -> tensor<8x16x256x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x16x1x1xf32>) -> tensor<256x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x256x86x22xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x256x86x22xf32>) -> tensor<8x256x86x22xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x64xf32>, tensor<256x16x1x1xf32>) outs (%init: tensor<8x256x86x22xf32>) -> tensor<8x256x86x22xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x256x86x22xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x256x86x22xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 86, 1], ["%arg6", 0, 22, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 149611461}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x32x32xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>_37": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x32x32xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x64x32x32xf32>, %filter: tensor<8x64x3x3xf32>, %init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x32x32xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>\n  return %ret : tensor<16x8x28x28xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x64x32x32xf32>, %arg1: tensor<8x64x3x3xf32>, %arg2: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x28x28xf32>\n    memref.copy %2, %alloc : memref<16x8x28x28xf32> to memref<16x8x28x28xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x28x28xf32>\n    return %3 : tensor<16x8x28x28xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x64x32x32xf32>) -> tensor<16x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x3x3xf32>) -> tensor<8x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x32x32xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x28x28xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 28, 1], ["%arg6", 0, 28, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 218421180}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x256xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<4x512x29x125xf32>) -> tensor<4x512x29x125xf32>_39": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x256xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<4x512x29x125xf32>) -> tensor<4x512x29x125xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x8x64x256xf32>, %filter: tensor<512x8x3x3xf32>, %init: tensor<4x512x29x125xf32>) -> tensor<4x512x29x125xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x256xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<4x512x29x125xf32>) -> tensor<4x512x29x125xf32>\n  return %ret : tensor<4x512x29x125xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x8x64x256xf32>, %arg1: tensor<512x8x3x3xf32>, %arg2: tensor<4x512x29x125xf32>) -> tensor<4x512x29x125xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x8x64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x512x29x125xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x512x29x125xf32>\n    memref.copy %2, %alloc : memref<4x512x29x125xf32> to memref<4x512x29x125xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 29 {\n          affine.for %arg6 = 0 to 125 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x8x64x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x29x125xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x29x125xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x512x29x125xf32>\n    return %3 : tensor<4x512x29x125xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x512x29x125xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x8x64x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x8x64x256xf32>) -> tensor<4x8x64x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x8x3x3xf32>) -> tensor<512x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x512x29x125xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x512x29x125xf32>) -> tensor<4x512x29x125xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x256xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<4x512x29x125xf32>) -> tensor<4x512x29x125xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x512x29x125xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x512x29x125xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 29, 1], ["%arg6", 0, 125, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1875182235}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<64x8x58x122xf32>) -> tensor<64x8x58x122xf32>_45": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<64x8x58x122xf32>) -> tensor<64x8x58x122xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x64x128xf32>, %filter: tensor<8x8x7x7xf32>, %init: tensor<64x8x58x122xf32>) -> tensor<64x8x58x122xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<64x8x58x122xf32>) -> tensor<64x8x58x122xf32>\n  return %ret : tensor<64x8x58x122xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x64x128xf32>, %arg1: tensor<8x8x7x7xf32>, %arg2: tensor<64x8x58x122xf32>) -> tensor<64x8x58x122xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x58x122xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x58x122xf32>\n    memref.copy %2, %alloc : memref<64x8x58x122xf32> to memref<64x8x58x122xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 58 {\n          affine.for %arg6 = 0 to 122 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x64x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x58x122xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x58x122xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x58x122xf32>\n    return %3 : tensor<64x8x58x122xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x58x122xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x64x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x64x128xf32>) -> tensor<64x8x64x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x7x7xf32>) -> tensor<8x8x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x58x122xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x58x122xf32>) -> tensor<64x8x58x122xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<64x8x58x122xf32>) -> tensor<64x8x58x122xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x58x122xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x58x122xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 58, 1], ["%arg6", 0, 122, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 5291222222}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x32x128xf32>, tensor<32x128x7x7xf32>) outs (%init: tensor<64x32x5x37xf32>) -> tensor<64x32x5x37xf32>_46": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x32x128xf32>, tensor<32x128x7x7xf32>) outs (%init: tensor<64x32x5x37xf32>) -> tensor<64x32x5x37xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x128x32x128xf32>, %filter: tensor<32x128x7x7xf32>, %init: tensor<64x32x5x37xf32>) -> tensor<64x32x5x37xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x32x128xf32>, tensor<32x128x7x7xf32>) outs (%init: tensor<64x32x5x37xf32>) -> tensor<64x32x5x37xf32>\n  return %ret : tensor<64x32x5x37xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x128x32x128xf32>, %arg1: tensor<32x128x7x7xf32>, %arg2: tensor<64x32x5x37xf32>) -> tensor<64x32x5x37xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128x32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32x5x37xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32x5x37xf32>\n    memref.copy %2, %alloc : memref<64x32x5x37xf32> to memref<64x32x5x37xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 37 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x128x32x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x5x37xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x5x37xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32x5x37xf32>\n    return %3 : tensor<64x32x5x37xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32x5x37xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x128x32x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x128x32x128xf32>) -> tensor<64x128x32x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x7x7xf32>) -> tensor<32x128x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x32x5x37xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x32x5x37xf32>) -> tensor<64x32x5x37xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x32x128xf32>, tensor<32x128x7x7xf32>) outs (%init: tensor<64x32x5x37xf32>) -> tensor<64x32x5x37xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32x5x37xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32x5x37xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 5, 1], ["%arg6", 0, 37, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 9070266823}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x126x62xf32>) -> tensor<32x32x126x62xf32>_51": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x126x62xf32>) -> tensor<32x32x126x62xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x32x128x64xf32>, %filter: tensor<32x32x3x3xf32>, %init: tensor<32x32x126x62xf32>) -> tensor<32x32x126x62xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x126x62xf32>) -> tensor<32x32x126x62xf32>\n  return %ret : tensor<32x32x126x62xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x32x128x64xf32>, %arg1: tensor<32x32x3x3xf32>, %arg2: tensor<32x32x126x62xf32>) -> tensor<32x32x126x62xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32x128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32x126x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32x126x62xf32>\n    memref.copy %2, %alloc : memref<32x32x126x62xf32> to memref<32x32x126x62xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 126 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x32x128x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x126x62xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x126x62xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32x126x62xf32>\n    return %3 : tensor<32x32x126x62xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32x126x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x32x128x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x32x128x64xf32>) -> tensor<32x32x128x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x3x3xf32>) -> tensor<32x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x32x126x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x32x126x62xf32>) -> tensor<32x32x126x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x126x62xf32>) -> tensor<32x32x126x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32x126x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32x126x62xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 126, 1], ["%arg6", 0, 62, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 8819224833}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>_52": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x256x256xf32>, %filter: tensor<32x8x1x1xf32>, %init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>\n  return %ret : tensor<16x32x128x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x256x256xf32>, %arg1: tensor<32x8x1x1xf32>, %arg2: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x128x128xf32>\n    memref.copy %2, %alloc : memref<16x32x128x128xf32> to memref<16x32x128x128xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x128x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x128x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x128x128xf32>\n    return %3 : tensor<16x32x128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x256x256xf32>) -> tensor<16x8x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x8x1x1xf32>) -> tensor<32x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x128x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 103538440}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x512x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<4x512x171x11xf32>) -> tensor<4x512x171x11xf32>_55": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x512x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<4x512x171x11xf32>) -> tensor<4x512x171x11xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x256x512x32xf32>, %filter: tensor<512x256x1x1xf32>, %init: tensor<4x512x171x11xf32>) -> tensor<4x512x171x11xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x512x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<4x512x171x11xf32>) -> tensor<4x512x171x11xf32>\n  return %ret : tensor<4x512x171x11xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x256x512x32xf32>, %arg1: tensor<512x256x1x1xf32>, %arg2: tensor<4x512x171x11xf32>) -> tensor<4x512x171x11xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x256x512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x512x171x11xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x512x171x11xf32>\n    memref.copy %2, %alloc : memref<4x512x171x11xf32> to memref<4x512x171x11xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 171 {\n          affine.for %arg6 = 0 to 11 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x256x512x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x171x11xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x171x11xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x512x171x11xf32>\n    return %3 : tensor<4x512x171x11xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x512x171x11xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x256x512x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x256x512x32xf32>) -> tensor<4x256x512x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x256x1x1xf32>) -> tensor<512x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x512x171x11xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x512x171x11xf32>) -> tensor<4x512x171x11xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x512x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<4x512x171x11xf32>) -> tensor<4x512x171x11xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x512x171x11xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x512x171x11xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 171, 1], ["%arg6", 0, 11, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3760476569}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x256x512xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<32x8x127x255xf32>) -> tensor<32x8x127x255xf32>_58": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x256x512xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<32x8x127x255xf32>) -> tensor<32x8x127x255xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x16x256x512xf32>, %filter: tensor<8x16x3x3xf32>, %init: tensor<32x8x127x255xf32>) -> tensor<32x8x127x255xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x256x512xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<32x8x127x255xf32>) -> tensor<32x8x127x255xf32>\n  return %ret : tensor<32x8x127x255xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x16x256x512xf32>, %arg1: tensor<8x16x3x3xf32>, %arg2: tensor<32x8x127x255xf32>) -> tensor<32x8x127x255xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x16x256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x8x127x255xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x8x127x255xf32>\n    memref.copy %2, %alloc : memref<32x8x127x255xf32> to memref<32x8x127x255xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 127 {\n          affine.for %arg6 = 0 to 255 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x16x256x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x127x255xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x127x255xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x8x127x255xf32>\n    return %3 : tensor<32x8x127x255xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x8x127x255xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x16x256x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x16x256x512xf32>) -> tensor<32x16x256x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x3x3xf32>) -> tensor<8x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x8x127x255xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x8x127x255xf32>) -> tensor<32x8x127x255xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x256x512xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<32x8x127x255xf32>) -> tensor<32x8x127x255xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x8x127x255xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x8x127x255xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 127, 1], ["%arg6", 0, 255, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4551109670}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x32x32xf32>, tensor<8x1024x7x7xf32>) outs (%init: tensor<4x8x26x26xf32>) -> tensor<4x8x26x26xf32>_59": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x32x32xf32>, tensor<8x1024x7x7xf32>) outs (%init: tensor<4x8x26x26xf32>) -> tensor<4x8x26x26xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x1024x32x32xf32>, %filter: tensor<8x1024x7x7xf32>, %init: tensor<4x8x26x26xf32>) -> tensor<4x8x26x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x32x32xf32>, tensor<8x1024x7x7xf32>) outs (%init: tensor<4x8x26x26xf32>) -> tensor<4x8x26x26xf32>\n  return %ret : tensor<4x8x26x26xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x1024x32x32xf32>, %arg1: tensor<8x1024x7x7xf32>, %arg2: tensor<4x8x26x26xf32>) -> tensor<4x8x26x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x1024x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x1024x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x26x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x26x26xf32>\n    memref.copy %2, %alloc : memref<4x8x26x26xf32> to memref<4x8x26x26xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 1024 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x1024x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x1024x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x26x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x26x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x26x26xf32>\n    return %3 : tensor<4x8x26x26xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x26x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x1024x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x1024x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x1024x7x7xf32>) -> tensor<8x1024x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x26x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x26x26xf32>) -> tensor<4x8x26x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x32x32xf32>, tensor<8x1024x7x7xf32>) outs (%init: tensor<4x8x26x26xf32>) -> tensor<4x8x26x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x26x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x26x26xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 26, 1], ["%arg6", 0, 26, 1], ["%arg7", 0, 1024, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4168181343}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x64xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x171x22xf32>) -> tensor<16x8x171x22xf32>_60": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x64xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x171x22xf32>) -> tensor<16x8x171x22xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x512x64xf32>, %filter: tensor<8x8x1x1xf32>, %init: tensor<16x8x171x22xf32>) -> tensor<16x8x171x22xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x64xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x171x22xf32>) -> tensor<16x8x171x22xf32>\n  return %ret : tensor<16x8x171x22xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x512x64xf32>, %arg1: tensor<8x8x1x1xf32>, %arg2: tensor<16x8x171x22xf32>) -> tensor<16x8x171x22xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x171x22xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x171x22xf32>\n    memref.copy %2, %alloc : memref<16x8x171x22xf32> to memref<16x8x171x22xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 171 {\n          affine.for %arg6 = 0 to 22 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x512x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x171x22xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x171x22xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x171x22xf32>\n    return %3 : tensor<16x8x171x22xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x171x22xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x512x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x512x64xf32>) -> tensor<16x8x512x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x1x1xf32>) -> tensor<8x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x171x22xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x171x22xf32>) -> tensor<16x8x171x22xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x64xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x171x22xf32>) -> tensor<16x8x171x22xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x171x22xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x171x22xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 171, 1], ["%arg6", 0, 22, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 6754393}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x32x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<16x64x9x84xf32>) -> tensor<16x64x9x84xf32>_61": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x32x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<16x64x9x84xf32>) -> tensor<16x64x9x84xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x256x32x256xf32>, %filter: tensor<64x256x3x3xf32>, %init: tensor<16x64x9x84xf32>) -> tensor<16x64x9x84xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x32x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<16x64x9x84xf32>) -> tensor<16x64x9x84xf32>\n  return %ret : tensor<16x64x9x84xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x256x32x256xf32>, %arg1: tensor<64x256x3x3xf32>, %arg2: tensor<16x64x9x84xf32>) -> tensor<16x64x9x84xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x256x32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x64x9x84xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x64x9x84xf32>\n    memref.copy %2, %alloc : memref<16x64x9x84xf32> to memref<16x64x9x84xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 9 {\n          affine.for %arg6 = 0 to 84 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x256x32x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x256x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x9x84xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x9x84xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x64x9x84xf32>\n    return %3 : tensor<16x64x9x84xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x64x9x84xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x256x32x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x256x32x256xf32>) -> tensor<16x256x32x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x256x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x256x3x3xf32>) -> tensor<64x256x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x64x9x84xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x64x9x84xf32>) -> tensor<16x64x9x84xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x32x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<16x64x9x84xf32>) -> tensor<16x64x9x84xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x64x9x84xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x64x9x84xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 9, 1], ["%arg6", 0, 84, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 6851299382}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<1024x8x7x7xf32>) outs (%init: tensor<64x1024x7x7xf32>) -> tensor<64x1024x7x7xf32>_64": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<1024x8x7x7xf32>) outs (%init: tensor<64x1024x7x7xf32>) -> tensor<64x1024x7x7xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x32x32xf32>, %filter: tensor<1024x8x7x7xf32>, %init: tensor<64x1024x7x7xf32>) -> tensor<64x1024x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<1024x8x7x7xf32>) outs (%init: tensor<64x1024x7x7xf32>) -> tensor<64x1024x7x7xf32>\n  return %ret : tensor<64x1024x7x7xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x32x32xf32>, %arg1: tensor<1024x8x7x7xf32>, %arg2: tensor<64x1024x7x7xf32>) -> tensor<64x1024x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x8x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024x7x7xf32>\n    memref.copy %2, %alloc : memref<64x1024x7x7xf32> to memref<64x1024x7x7xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x8x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x1024x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x1024x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024x7x7xf32>\n    return %3 : tensor<64x1024x7x7xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x32x32xf32>) -> tensor<64x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x8x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x8x7x7xf32>) -> tensor<1024x8x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x1024x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x1024x7x7xf32>) -> tensor<64x1024x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<1024x8x7x7xf32>) outs (%init: tensor<64x1024x7x7xf32>) -> tensor<64x1024x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024x7x7xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 7, 1], ["%arg6", 0, 7, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4723833781}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x32x64xf32>) -> tensor<64x512x32x64xf32>_66": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x32x64xf32>) -> tensor<64x512x32x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x32x64xf32>, %filter: tensor<512x8x1x1xf32>, %init: tensor<64x512x32x64xf32>) -> tensor<64x512x32x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x32x64xf32>) -> tensor<64x512x32x64xf32>\n  return %ret : tensor<64x512x32x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x32x64xf32>, %arg1: tensor<512x8x1x1xf32>, %arg2: tensor<64x512x32x64xf32>) -> tensor<64x512x32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512x32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512x32x64xf32>\n    memref.copy %2, %alloc : memref<64x512x32x64xf32> to memref<64x512x32x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x32x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x512x32x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x512x32x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512x32x64xf32>\n    return %3 : tensor<64x512x32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512x32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x32x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x32x64xf32>) -> tensor<64x8x32x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x8x1x1xf32>) -> tensor<512x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x512x32x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x512x32x64xf32>) -> tensor<64x512x32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x32x64xf32>) -> tensor<64x512x32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512x32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512x32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 801262317}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x64x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<256x16x22x86xf32>) -> tensor<256x16x22x86xf32>_68": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x64x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<256x16x22x86xf32>) -> tensor<256x16x22x86xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x256x64x256xf32>, %filter: tensor<16x256x1x1xf32>, %init: tensor<256x16x22x86xf32>) -> tensor<256x16x22x86xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x64x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<256x16x22x86xf32>) -> tensor<256x16x22x86xf32>\n  return %ret : tensor<256x16x22x86xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x64x256xf32>, %arg1: tensor<16x256x1x1xf32>, %arg2: tensor<256x16x22x86xf32>) -> tensor<256x16x22x86xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256x64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x16x22x86xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x16x22x86xf32>\n    memref.copy %2, %alloc : memref<256x16x22x86xf32> to memref<256x16x22x86xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 22 {\n          affine.for %arg6 = 0 to 86 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x256x64x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x16x22x86xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x16x22x86xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x16x22x86xf32>\n    return %3 : tensor<256x16x22x86xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x16x22x86xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x64x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x64x256xf32>) -> tensor<256x256x64x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x256x1x1xf32>) -> tensor<16x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x16x22x86xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x16x22x86xf32>) -> tensor<256x16x22x86xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x64x256xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<256x16x22x86xf32>) -> tensor<256x16x22x86xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x16x22x86xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x16x22x86xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 22, 1], ["%arg6", 0, 86, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 8162945898}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<16x32x7x7xf32>) outs (%init: tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>_69": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<16x32x7x7xf32>) outs (%init: tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x32x32x32xf32>, %filter: tensor<16x32x7x7xf32>, %init: tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<16x32x7x7xf32>) outs (%init: tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>\n  return %ret : tensor<8x16x7x7xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x32x32x32xf32>, %arg1: tensor<16x32x7x7xf32>, %arg2: tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x32x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x16x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x16x7x7xf32>\n    memref.copy %2, %alloc : memref<8x16x7x7xf32> to memref<8x16x7x7xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x32x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x16x7x7xf32>\n    return %3 : tensor<8x16x7x7xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x16x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x32x32x32xf32>) -> tensor<8x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x32x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x32x7x7xf32>) -> tensor<16x32x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x16x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<16x32x7x7xf32>) outs (%init: tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x16x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x16x7x7xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 7, 1], ["%arg6", 0, 7, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 37530907}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x128x32xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<8x16x64x16xf32>) -> tensor<8x16x64x16xf32>_70": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x128x32xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<8x16x64x16xf32>) -> tensor<8x16x64x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x128x128x32xf32>, %filter: tensor<16x128x1x1xf32>, %init: tensor<8x16x64x16xf32>) -> tensor<8x16x64x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x128x32xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<8x16x64x16xf32>) -> tensor<8x16x64x16xf32>\n  return %ret : tensor<8x16x64x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x128x128x32xf32>, %arg1: tensor<16x128x1x1xf32>, %arg2: tensor<8x16x64x16xf32>) -> tensor<8x16x64x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x128x128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x16x64x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x16x64x16xf32>\n    memref.copy %2, %alloc : memref<8x16x64x16xf32> to memref<8x16x64x16xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x128x128x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x64x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x64x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x16x64x16xf32>\n    return %3 : tensor<8x16x64x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x16x64x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x128x128x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x128x128x32xf32>) -> tensor<8x128x128x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x128x1x1xf32>) -> tensor<16x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x16x64x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x16x64x16xf32>) -> tensor<8x16x64x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x128x32xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<8x16x64x16xf32>) -> tensor<8x16x64x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x16x64x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x16x64x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 60204965}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x64x32xf32>, tensor<32x256x5x5xf32>) outs (%init: tensor<8x32x56x24xf32>) -> tensor<8x32x56x24xf32>_71": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x64x32xf32>, tensor<32x256x5x5xf32>) outs (%init: tensor<8x32x56x24xf32>) -> tensor<8x32x56x24xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x256x64x32xf32>, %filter: tensor<32x256x5x5xf32>, %init: tensor<8x32x56x24xf32>) -> tensor<8x32x56x24xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x64x32xf32>, tensor<32x256x5x5xf32>) outs (%init: tensor<8x32x56x24xf32>) -> tensor<8x32x56x24xf32>\n  return %ret : tensor<8x32x56x24xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x256x64x32xf32>, %arg1: tensor<32x256x5x5xf32>, %arg2: tensor<8x32x56x24xf32>) -> tensor<8x32x56x24xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x256x64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x32x56x24xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x32x56x24xf32>\n    memref.copy %2, %alloc : memref<8x32x56x24xf32> to memref<8x32x56x24xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 24 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x256x64x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x256x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x56x24xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x56x24xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x32x56x24xf32>\n    return %3 : tensor<8x32x56x24xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x32x56x24xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x256x64x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x256x64x32xf32>) -> tensor<8x256x64x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x256x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x256x5x5xf32>) -> tensor<32x256x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x32x56x24xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x32x56x24xf32>) -> tensor<8x32x56x24xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x64x32xf32>, tensor<32x256x5x5xf32>) outs (%init: tensor<8x32x56x24xf32>) -> tensor<8x32x56x24xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x32x56x24xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x32x56x24xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 56, 1], ["%arg6", 0, 24, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 8414943409}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x512xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<4x64x84x170xf32>) -> tensor<4x64x84x170xf32>_79": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x512xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<4x64x84x170xf32>) -> tensor<4x64x84x170xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x256x512xf32>, %filter: tensor<64x64x3x3xf32>, %init: tensor<4x64x84x170xf32>) -> tensor<4x64x84x170xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x512xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<4x64x84x170xf32>) -> tensor<4x64x84x170xf32>\n  return %ret : tensor<4x64x84x170xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x256x512xf32>, %arg1: tensor<64x64x3x3xf32>, %arg2: tensor<4x64x84x170xf32>) -> tensor<4x64x84x170xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x64x84x170xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x64x84x170xf32>\n    memref.copy %2, %alloc : memref<4x64x84x170xf32> to memref<4x64x84x170xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 84 {\n          affine.for %arg6 = 0 to 170 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x256x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x84x170xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x84x170xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x64x84x170xf32>\n    return %3 : tensor<4x64x84x170xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x64x84x170xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x256x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x256x512xf32>) -> tensor<4x64x256x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x64x3x3xf32>) -> tensor<64x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x64x84x170xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x64x84x170xf32>) -> tensor<4x64x84x170xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x512xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<4x64x84x170xf32>) -> tensor<4x64x84x170xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x64x84x170xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x64x84x170xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 84, 1], ["%arg6", 0, 170, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 8450744075}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<16x32x10x10xf32>) -> tensor<16x32x10x10xf32>_83": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<16x32x10x10xf32>) -> tensor<16x32x10x10xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x32x32xf32>, %filter: tensor<32x8x3x3xf32>, %init: tensor<16x32x10x10xf32>) -> tensor<16x32x10x10xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<16x32x10x10xf32>) -> tensor<16x32x10x10xf32>\n  return %ret : tensor<16x32x10x10xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x32x32xf32>, %arg1: tensor<32x8x3x3xf32>, %arg2: tensor<16x32x10x10xf32>) -> tensor<16x32x10x10xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x10x10xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x10x10xf32>\n    memref.copy %2, %alloc : memref<16x32x10x10xf32> to memref<16x32x10x10xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 10 {\n          affine.for %arg6 = 0 to 10 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x10x10xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x10x10xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x10x10xf32>\n    return %3 : tensor<16x32x10x10xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x10x10xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x32x32xf32>) -> tensor<16x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x8x3x3xf32>) -> tensor<32x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x10x10xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x10x10xf32>) -> tensor<16x32x10x10xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<16x32x10x10xf32>) -> tensor<16x32x10x10xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x10x10xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x10x10xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 10, 1], ["%arg6", 0, 10, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 12769445}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<32x512x5x5xf32>) outs (%init: tensor<4x32x8x8xf32>) -> tensor<4x32x8x8xf32>_86": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<32x512x5x5xf32>) outs (%init: tensor<4x32x8x8xf32>) -> tensor<4x32x8x8xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x512x32x32xf32>, %filter: tensor<32x512x5x5xf32>, %init: tensor<4x32x8x8xf32>) -> tensor<4x32x8x8xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<32x512x5x5xf32>) outs (%init: tensor<4x32x8x8xf32>) -> tensor<4x32x8x8xf32>\n  return %ret : tensor<4x32x8x8xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x512x32x32xf32>, %arg1: tensor<32x512x5x5xf32>, %arg2: tensor<4x32x8x8xf32>) -> tensor<4x32x8x8xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x512x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x32x8x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x32x8x8xf32>\n    memref.copy %2, %alloc : memref<4x32x8x8xf32> to memref<4x32x8x8xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x512x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x512x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x8x8xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x8x8xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x32x8x8xf32>\n    return %3 : tensor<4x32x8x8xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x32x8x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x512x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x512x32x32xf32>) -> tensor<4x512x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x512x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x512x5x5xf32>) -> tensor<32x512x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x32x8x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x32x8x8xf32>) -> tensor<4x32x8x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<32x512x5x5xf32>) outs (%init: tensor<4x32x8x8xf32>) -> tensor<4x32x8x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x32x8x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x32x8x8xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 8, 1], ["%arg6", 0, 8, 1], ["%arg7", 0, 512, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 401694075}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x64xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x64xf32>) -> tensor<8x256x128x64xf32>_92": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x64xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x64xf32>) -> tensor<8x256x128x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x128x64xf32>, %filter: tensor<256x64x1x1xf32>, %init: tensor<8x256x128x64xf32>) -> tensor<8x256x128x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x64xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x64xf32>) -> tensor<8x256x128x64xf32>\n  return %ret : tensor<8x256x128x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x128x64xf32>, %arg1: tensor<256x64x1x1xf32>, %arg2: tensor<8x256x128x64xf32>) -> tensor<8x256x128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x256x128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x256x128x64xf32>\n    memref.copy %2, %alloc : memref<8x256x128x64xf32> to memref<8x256x128x64xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x128x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x128x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x128x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x256x128x64xf32>\n    return %3 : tensor<8x256x128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x256x128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x128x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x128x64xf32>) -> tensor<8x64x128x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x64x1x1xf32>) -> tensor<256x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x256x128x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x256x128x64xf32>) -> tensor<8x256x128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x64xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x64xf32>) -> tensor<8x256x128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x256x128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x256x128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3575193159}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<64x8x32x16xf32>) -> tensor<64x8x32x16xf32>_99": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<64x8x32x16xf32>) -> tensor<64x8x32x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x64x32xf32>, %filter: tensor<8x8x1x1xf32>, %init: tensor<64x8x32x16xf32>) -> tensor<64x8x32x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<64x8x32x16xf32>) -> tensor<64x8x32x16xf32>\n  return %ret : tensor<64x8x32x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x64x32xf32>, %arg1: tensor<8x8x1x1xf32>, %arg2: tensor<64x8x32x16xf32>) -> tensor<64x8x32x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x32x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x32x16xf32>\n    memref.copy %2, %alloc : memref<64x8x32x16xf32> to memref<64x8x32x16xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x64x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x32x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x32x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x32x16xf32>\n    return %3 : tensor<64x8x32x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x32x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x64x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x64x32xf32>) -> tensor<64x8x64x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x1x1xf32>) -> tensor<8x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x32x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x32x16xf32>) -> tensor<64x8x32x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<64x8x32x16xf32>) -> tensor<64x8x32x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x32x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x32x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3242972}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x256x64xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<16x8x128x32xf32>) -> tensor<16x8x128x32xf32>_100": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x256x64xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<16x8x128x32xf32>) -> tensor<16x8x128x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x64x256x64xf32>, %filter: tensor<8x64x1x1xf32>, %init: tensor<16x8x128x32xf32>) -> tensor<16x8x128x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x256x64xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<16x8x128x32xf32>) -> tensor<16x8x128x32xf32>\n  return %ret : tensor<16x8x128x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x64x256x64xf32>, %arg1: tensor<8x64x1x1xf32>, %arg2: tensor<16x8x128x32xf32>) -> tensor<16x8x128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x64x256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x128x32xf32>\n    memref.copy %2, %alloc : memref<16x8x128x32xf32> to memref<16x8x128x32xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x64x256x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x128x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x128x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x128x32xf32>\n    return %3 : tensor<16x8x128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x64x256x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x64x256x64xf32>) -> tensor<16x64x256x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x1x1xf32>) -> tensor<8x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x128x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x128x32xf32>) -> tensor<16x8x128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x256x64xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<16x8x128x32xf32>) -> tensor<16x8x128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 119062668}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x16x64xf32>) -> tensor<16x256x16x64xf32>_101": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x16x64xf32>) -> tensor<16x256x16x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x32x128xf32>, %filter: tensor<256x8x1x1xf32>, %init: tensor<16x256x16x64xf32>) -> tensor<16x256x16x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x16x64xf32>) -> tensor<16x256x16x64xf32>\n  return %ret : tensor<16x256x16x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x32x128xf32>, %arg1: tensor<256x8x1x1xf32>, %arg2: tensor<16x256x16x64xf32>) -> tensor<16x256x16x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x256x16x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x256x16x64xf32>\n    memref.copy %2, %alloc : memref<16x256x16x64xf32> to memref<16x256x16x64xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 16 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x32x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x256x16x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x256x16x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x256x16x64xf32>\n    return %3 : tensor<16x256x16x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x256x16x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x32x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x32x128xf32>) -> tensor<16x8x32x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x8x1x1xf32>) -> tensor<256x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x256x16x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x256x16x64xf32>) -> tensor<16x256x16x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x128xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x16x64xf32>) -> tensor<16x256x16x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x256x16x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x256x16x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 16, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 51030596}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x43x86xf32>) -> tensor<8x128x43x86xf32>_103": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x43x86xf32>) -> tensor<8x128x43x86xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x128x256xf32>, %filter: tensor<128x16x1x1xf32>, %init: tensor<8x128x43x86xf32>) -> tensor<8x128x43x86xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x43x86xf32>) -> tensor<8x128x43x86xf32>\n  return %ret : tensor<8x128x43x86xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x128x256xf32>, %arg1: tensor<128x16x1x1xf32>, %arg2: tensor<8x128x43x86xf32>) -> tensor<8x128x43x86xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x43x86xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x43x86xf32>\n    memref.copy %2, %alloc : memref<8x128x43x86xf32> to memref<8x128x43x86xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 43 {\n          affine.for %arg6 = 0 to 86 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x128x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x43x86xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x43x86xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x43x86xf32>\n    return %3 : tensor<8x128x43x86xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x43x86xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x128x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x128x256xf32>) -> tensor<8x16x128x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x16x1x1xf32>) -> tensor<128x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x43x86xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x43x86xf32>) -> tensor<8x128x43x86xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x43x86xf32>) -> tensor<8x128x43x86xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x43x86xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x43x86xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 43, 1], ["%arg6", 0, 86, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 150634947}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x32x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<32x64x11x43xf32>) -> tensor<32x64x11x43xf32>_104": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x32x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<32x64x11x43xf32>) -> tensor<32x64x11x43xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x128x32x128xf32>, %filter: tensor<64x128x1x1xf32>, %init: tensor<32x64x11x43xf32>) -> tensor<32x64x11x43xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x32x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<32x64x11x43xf32>) -> tensor<32x64x11x43xf32>\n  return %ret : tensor<32x64x11x43xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x128x32x128xf32>, %arg1: tensor<64x128x1x1xf32>, %arg2: tensor<32x64x11x43xf32>) -> tensor<32x64x11x43xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128x32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64x11x43xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64x11x43xf32>\n    memref.copy %2, %alloc : memref<32x64x11x43xf32> to memref<32x64x11x43xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 11 {\n          affine.for %arg6 = 0 to 43 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x128x32x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x64x11x43xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x64x11x43xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64x11x43xf32>\n    return %3 : tensor<32x64x11x43xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64x11x43xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x128x32x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x128x32x128xf32>) -> tensor<32x128x32x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x128x1x1xf32>) -> tensor<64x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x64x11x43xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x64x11x43xf32>) -> tensor<32x64x11x43xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x32x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<32x64x11x43xf32>) -> tensor<32x64x11x43xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64x11x43xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64x11x43xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 11, 1], ["%arg6", 0, 43, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 450659563}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x64x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<32x8x28x12xf32>) -> tensor<32x8x28x12xf32>_107": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x64x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<32x8x28x12xf32>) -> tensor<32x8x28x12xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x16x64x32xf32>, %filter: tensor<8x16x5x5xf32>, %init: tensor<32x8x28x12xf32>) -> tensor<32x8x28x12xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x64x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<32x8x28x12xf32>) -> tensor<32x8x28x12xf32>\n  return %ret : tensor<32x8x28x12xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x16x64x32xf32>, %arg1: tensor<8x16x5x5xf32>, %arg2: tensor<32x8x28x12xf32>) -> tensor<32x8x28x12xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x16x64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x8x28x12xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x8x28x12xf32>\n    memref.copy %2, %alloc : memref<32x8x28x12xf32> to memref<32x8x28x12xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 12 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x16x64x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x28x12xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x28x12xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x8x28x12xf32>\n    return %3 : tensor<32x8x28x12xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x8x28x12xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x16x64x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x16x64x32xf32>) -> tensor<32x16x64x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x5x5xf32>) -> tensor<8x16x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x8x28x12xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x8x28x12xf32>) -> tensor<32x8x28x12xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x16x64x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<32x8x28x12xf32>) -> tensor<32x8x28x12xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x8x28x12xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x8x28x12xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 28, 1], ["%arg6", 0, 12, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 129253657}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>_108": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x8x64x64xf32>, %filter: tensor<1024x8x1x1xf32>, %init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>\n  return %ret : tensor<4x1024x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x8x64x64xf32>, %arg1: tensor<1024x8x1x1xf32>, %arg2: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x1024x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x1024x32x32xf32>\n    memref.copy %2, %alloc : memref<4x1024x32x32xf32> to memref<4x1024x32x32xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x1024x32x32xf32>\n    return %3 : tensor<4x1024x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x1024x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x8x1x1xf32>) -> tensor<1024x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x1024x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x1024x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x1024x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 51145169}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x128x256xf32>, tensor<64x32x1x1xf32>) outs (%init: tensor<4x64x64x128xf32>) -> tensor<4x64x64x128xf32>_110": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x128x256xf32>, tensor<64x32x1x1xf32>) outs (%init: tensor<4x64x64x128xf32>) -> tensor<4x64x64x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x32x128x256xf32>, %filter: tensor<64x32x1x1xf32>, %init: tensor<4x64x64x128xf32>) -> tensor<4x64x64x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x128x256xf32>, tensor<64x32x1x1xf32>) outs (%init: tensor<4x64x64x128xf32>) -> tensor<4x64x64x128xf32>\n  return %ret : tensor<4x64x64x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x32x128x256xf32>, %arg1: tensor<64x32x1x1xf32>, %arg2: tensor<4x64x64x128xf32>) -> tensor<4x64x64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x32x128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x64x64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x64x64x128xf32>\n    memref.copy %2, %alloc : memref<4x64x64x128xf32> to memref<4x64x64x128xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x32x128x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x64x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x64x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x64x64x128xf32>\n    return %3 : tensor<4x64x64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x64x64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x32x128x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x32x128x256xf32>) -> tensor<4x32x128x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x32x1x1xf32>) -> tensor<64x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x64x64x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x64x64x128xf32>) -> tensor<4x64x64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x128x256xf32>, tensor<64x32x1x1xf32>) outs (%init: tensor<4x64x64x128xf32>) -> tensor<4x64x64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x64x64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x64x64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 201369341}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x256x64xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<256x32x128x32xf32>) -> tensor<256x32x128x32xf32>_124": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x256x64xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<256x32x128x32xf32>) -> tensor<256x32x128x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x8x256x64xf32>, %filter: tensor<32x8x1x1xf32>, %init: tensor<256x32x128x32xf32>) -> tensor<256x32x128x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x256x64xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<256x32x128x32xf32>) -> tensor<256x32x128x32xf32>\n  return %ret : tensor<256x32x128x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x8x256x64xf32>, %arg1: tensor<32x8x1x1xf32>, %arg2: tensor<256x32x128x32xf32>) -> tensor<256x32x128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x8x256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x128x32xf32>\n    memref.copy %2, %alloc : memref<256x32x128x32xf32> to memref<256x32x128x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x8x256x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x128x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x128x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x128x32xf32>\n    return %3 : tensor<256x32x128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x8x256x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x8x256x64xf32>) -> tensor<256x8x256x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x8x1x1xf32>) -> tensor<32x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x128x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x128x32xf32>) -> tensor<256x32x128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x8x256x64xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<256x32x128x32xf32>) -> tensor<256x32x128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 416789768}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x512x128xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x256x64xf32>) -> tensor<4x1024x256x64xf32>_125": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x512x128xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x256x64xf32>) -> tensor<4x1024x256x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x8x512x128xf32>, %filter: tensor<1024x8x1x1xf32>, %init: tensor<4x1024x256x64xf32>) -> tensor<4x1024x256x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x512x128xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x256x64xf32>) -> tensor<4x1024x256x64xf32>\n  return %ret : tensor<4x1024x256x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x8x512x128xf32>, %arg1: tensor<1024x8x1x1xf32>, %arg2: tensor<4x1024x256x64xf32>) -> tensor<4x1024x256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x8x512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x1024x256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x1024x256x64xf32>\n    memref.copy %2, %alloc : memref<4x1024x256x64xf32> to memref<4x1024x256x64xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x8x512x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x256x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x256x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x1024x256x64xf32>\n    return %3 : tensor<4x1024x256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x1024x256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x8x512x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x8x512x128xf32>) -> tensor<4x8x512x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x8x1x1xf32>) -> tensor<1024x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x1024x256x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x1024x256x64xf32>) -> tensor<4x1024x256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x512x128xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<4x1024x256x64xf32>) -> tensor<4x1024x256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x1024x256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x1024x256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 831004249}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x128xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<8x32x11x43xf32>) -> tensor<8x32x11x43xf32>_126": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x128xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<8x32x11x43xf32>) -> tensor<8x32x11x43xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x32x32x128xf32>, %filter: tensor<32x32x1x1xf32>, %init: tensor<8x32x11x43xf32>) -> tensor<8x32x11x43xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x128xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<8x32x11x43xf32>) -> tensor<8x32x11x43xf32>\n  return %ret : tensor<8x32x11x43xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x32x32x128xf32>, %arg1: tensor<32x32x1x1xf32>, %arg2: tensor<8x32x11x43xf32>) -> tensor<8x32x11x43xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x32x32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x32x11x43xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x32x11x43xf32>\n    memref.copy %2, %alloc : memref<8x32x11x43xf32> to memref<8x32x11x43xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 11 {\n          affine.for %arg6 = 0 to 43 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x32x32x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x11x43xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x11x43xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x32x11x43xf32>\n    return %3 : tensor<8x32x11x43xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x32x11x43xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x32x32x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x32x32x128xf32>) -> tensor<8x32x32x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x1x1xf32>) -> tensor<32x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x32x11x43xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x32x11x43xf32>) -> tensor<8x32x11x43xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x128xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<8x32x11x43xf32>) -> tensor<8x32x11x43xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x32x11x43xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x32x11x43xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 11, 1], ["%arg6", 0, 43, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 10798231}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<1024x512x7x7xf32>) outs (%init: tensor<4x1024x5x5xf32>) -> tensor<4x1024x5x5xf32>_134": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<1024x512x7x7xf32>) outs (%init: tensor<4x1024x5x5xf32>) -> tensor<4x1024x5x5xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x512x32x32xf32>, %filter: tensor<1024x512x7x7xf32>, %init: tensor<4x1024x5x5xf32>) -> tensor<4x1024x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<1024x512x7x7xf32>) outs (%init: tensor<4x1024x5x5xf32>) -> tensor<4x1024x5x5xf32>\n  return %ret : tensor<4x1024x5x5xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x512x32x32xf32>, %arg1: tensor<1024x512x7x7xf32>, %arg2: tensor<4x1024x5x5xf32>) -> tensor<4x1024x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x512x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x1024x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x1024x5x5xf32>\n    memref.copy %2, %alloc : memref<4x1024x5x5xf32> to memref<4x1024x5x5xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x512x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x512x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x1024x5x5xf32>\n    return %3 : tensor<4x1024x5x5xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x1024x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x512x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x512x32x32xf32>) -> tensor<4x512x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x512x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x512x7x7xf32>) -> tensor<1024x512x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x1024x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x1024x5x5xf32>) -> tensor<4x1024x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x512x32x32xf32>, tensor<1024x512x7x7xf32>) outs (%init: tensor<4x1024x5x5xf32>) -> tensor<4x1024x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x1024x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x1024x5x5xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 5, 1], ["%arg6", 0, 5, 1], ["%arg7", 0, 512, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 9972103181}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x128x256xf32>, tensor<32x32x7x7xf32>) outs (%init: tensor<8x32x39x82xf32>) -> tensor<8x32x39x82xf32>_137": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x128x256xf32>, tensor<32x32x7x7xf32>) outs (%init: tensor<8x32x39x82xf32>) -> tensor<8x32x39x82xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x32x128x256xf32>, %filter: tensor<32x32x7x7xf32>, %init: tensor<8x32x39x82xf32>) -> tensor<8x32x39x82xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x128x256xf32>, tensor<32x32x7x7xf32>) outs (%init: tensor<8x32x39x82xf32>) -> tensor<8x32x39x82xf32>\n  return %ret : tensor<8x32x39x82xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x32x128x256xf32>, %arg1: tensor<32x32x7x7xf32>, %arg2: tensor<8x32x39x82xf32>) -> tensor<8x32x39x82xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x32x128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x32x39x82xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x32x39x82xf32>\n    memref.copy %2, %alloc : memref<8x32x39x82xf32> to memref<8x32x39x82xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 39 {\n          affine.for %arg6 = 0 to 82 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x32x128x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x39x82xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x39x82xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x32x39x82xf32>\n    return %3 : tensor<8x32x39x82xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x32x39x82xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x32x128x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x32x128x256xf32>) -> tensor<8x32x128x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x7x7xf32>) -> tensor<32x32x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x32x39x82xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x32x39x82xf32>) -> tensor<8x32x39x82xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x128x256xf32>, tensor<32x32x7x7xf32>) outs (%init: tensor<8x32x39x82xf32>) -> tensor<8x32x39x82xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x32x39x82xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x32x39x82xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 39, 1], ["%arg6", 0, 82, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4899224749}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x512xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<8x1024x86x171xf32>) -> tensor<8x1024x86x171xf32>_138": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x512xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<8x1024x86x171xf32>) -> tensor<8x1024x86x171xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x8x256x512xf32>, %filter: tensor<1024x8x1x1xf32>, %init: tensor<8x1024x86x171xf32>) -> tensor<8x1024x86x171xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x512xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<8x1024x86x171xf32>) -> tensor<8x1024x86x171xf32>\n  return %ret : tensor<8x1024x86x171xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x8x256x512xf32>, %arg1: tensor<1024x8x1x1xf32>, %arg2: tensor<8x1024x86x171xf32>) -> tensor<8x1024x86x171xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x8x256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x1024x86x171xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x1024x86x171xf32>\n    memref.copy %2, %alloc : memref<8x1024x86x171xf32> to memref<8x1024x86x171xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 86 {\n          affine.for %arg6 = 0 to 171 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x8x256x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x1024x86x171xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x1024x86x171xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x1024x86x171xf32>\n    return %3 : tensor<8x1024x86x171xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x1024x86x171xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x8x256x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x8x256x512xf32>) -> tensor<8x8x256x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x8x1x1xf32>) -> tensor<1024x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x1024x86x171xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x1024x86x171xf32>) -> tensor<8x1024x86x171xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x512xf32>, tensor<1024x8x1x1xf32>) outs (%init: tensor<8x1024x86x171xf32>) -> tensor<8x1024x86x171xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x1024x86x171xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x1024x86x171xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 86, 1], ["%arg6", 0, 171, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1525443849}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x64x64xf32>) -> tensor<64x16x64x64xf32>_139": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x64x64xf32>) -> tensor<64x16x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x256x64x64xf32>, %filter: tensor<16x256x1x1xf32>, %init: tensor<64x16x64x64xf32>) -> tensor<64x16x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x64x64xf32>) -> tensor<64x16x64x64xf32>\n  return %ret : tensor<64x16x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x256x64x64xf32>, %arg1: tensor<16x256x1x1xf32>, %arg2: tensor<64x16x64x64xf32>) -> tensor<64x16x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x64x64xf32>\n    memref.copy %2, %alloc : memref<64x16x64x64xf32> to memref<64x16x64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x256x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x64x64xf32>\n    return %3 : tensor<64x16x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x256x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x256x64x64xf32>) -> tensor<64x256x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x256x1x1xf32>) -> tensor<16x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x64x64xf32>) -> tensor<64x16x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x64x64xf32>) -> tensor<64x16x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 3", "%arg6 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4542480467}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x512x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<32x32x171x43xf32>) -> tensor<32x32x171x43xf32>_143": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x512x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<32x32x171x43xf32>) -> tensor<32x32x171x43xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x64x512x128xf32>, %filter: tensor<32x64x1x1xf32>, %init: tensor<32x32x171x43xf32>) -> tensor<32x32x171x43xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x512x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<32x32x171x43xf32>) -> tensor<32x32x171x43xf32>\n  return %ret : tensor<32x32x171x43xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x64x512x128xf32>, %arg1: tensor<32x64x1x1xf32>, %arg2: tensor<32x32x171x43xf32>) -> tensor<32x32x171x43xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64x512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32x171x43xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32x171x43xf32>\n    memref.copy %2, %alloc : memref<32x32x171x43xf32> to memref<32x32x171x43xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 171 {\n          affine.for %arg6 = 0 to 43 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x64x512x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x171x43xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x171x43xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32x171x43xf32>\n    return %3 : tensor<32x32x171x43xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32x171x43xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x64x512x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x64x512x128xf32>) -> tensor<32x64x512x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x64x1x1xf32>) -> tensor<32x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x32x171x43xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x32x171x43xf32>) -> tensor<32x32x171x43xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x512x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<32x32x171x43xf32>) -> tensor<32x32x171x43xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32x171x43xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32x171x43xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 171, 1], ["%arg6", 0, 43, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1802333075}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x128xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x13x61xf32>) -> tensor<4x512x13x61xf32>_144": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x128xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x13x61xf32>) -> tensor<4x512x13x61xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x32x32x128xf32>, %filter: tensor<512x32x3x3xf32>, %init: tensor<4x512x13x61xf32>) -> tensor<4x512x13x61xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x128xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x13x61xf32>) -> tensor<4x512x13x61xf32>\n  return %ret : tensor<4x512x13x61xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x32x32x128xf32>, %arg1: tensor<512x32x3x3xf32>, %arg2: tensor<4x512x13x61xf32>) -> tensor<4x512x13x61xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x32x32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x512x13x61xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x512x13x61xf32>\n    memref.copy %2, %alloc : memref<4x512x13x61xf32> to memref<4x512x13x61xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 61 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x32x32x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x13x61xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x13x61xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x512x13x61xf32>\n    return %3 : tensor<4x512x13x61xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x512x13x61xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x32x32x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x32x32x128xf32>) -> tensor<4x32x32x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x32x3x3xf32>) -> tensor<512x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x512x13x61xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x512x13x61xf32>) -> tensor<4x512x13x61xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x128xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x13x61xf32>) -> tensor<4x512x13x61xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x512x13x61xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x512x13x61xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 13, 1], ["%arg6", 0, 61, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1796028793}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<4x64x23x23xf32>) -> tensor<4x64x23x23xf32>_146": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<4x64x23x23xf32>) -> tensor<4x64x23x23xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x8x64x64xf32>, %filter: tensor<64x8x7x7xf32>, %init: tensor<4x64x23x23xf32>) -> tensor<4x64x23x23xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<4x64x23x23xf32>) -> tensor<4x64x23x23xf32>\n  return %ret : tensor<4x64x23x23xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x8x64x64xf32>, %arg1: tensor<64x8x7x7xf32>, %arg2: tensor<4x64x23x23xf32>) -> tensor<4x64x23x23xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x8x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x64x23x23xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x64x23x23xf32>\n    memref.copy %2, %alloc : memref<4x64x23x23xf32> to memref<4x64x23x23xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 23 {\n          affine.for %arg6 = 0 to 23 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x8x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x23x23xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x23x23xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x64x23x23xf32>\n    return %3 : tensor<4x64x23x23xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x64x23x23xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x8x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x8x7x7xf32>) -> tensor<64x8x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x64x23x23xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x64x23x23xf32>) -> tensor<4x64x23x23xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x64x64xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<4x64x23x23xf32>) -> tensor<4x64x23x23xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x64x23x23xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x64x23x23xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 23, 1], ["%arg6", 0, 23, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 200747740}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<4x64x42x84xf32>) -> tensor<4x64x42x84xf32>_149": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<4x64x42x84xf32>) -> tensor<4x64x42x84xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x256x128x256xf32>, %filter: tensor<64x256x3x3xf32>, %init: tensor<4x64x42x84xf32>) -> tensor<4x64x42x84xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<4x64x42x84xf32>) -> tensor<4x64x42x84xf32>\n  return %ret : tensor<4x64x42x84xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x256x128x256xf32>, %arg1: tensor<64x256x3x3xf32>, %arg2: tensor<4x64x42x84xf32>) -> tensor<4x64x42x84xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x256x128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x64x42x84xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x64x42x84xf32>\n    memref.copy %2, %alloc : memref<4x64x42x84xf32> to memref<4x64x42x84xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 42 {\n          affine.for %arg6 = 0 to 84 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x256x128x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x256x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x42x84xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x42x84xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x64x42x84xf32>\n    return %3 : tensor<4x64x42x84xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x64x42x84xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x256x128x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x256x128x256xf32>) -> tensor<4x256x128x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x256x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x256x3x3xf32>) -> tensor<64x256x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x64x42x84xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x64x42x84xf32>) -> tensor<4x64x42x84xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x256xf32>, tensor<64x256x3x3xf32>) outs (%init: tensor<4x64x42x84xf32>) -> tensor<4x64x42x84xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x64x42x84xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x64x42x84xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 42, 1], ["%arg6", 0, 84, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 12976284865}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x32xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x126x30xf32>) -> tensor<4x128x126x30xf32>_152": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x32xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x126x30xf32>) -> tensor<4x128x126x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x128x32xf32>, %filter: tensor<128x64x3x3xf32>, %init: tensor<4x128x126x30xf32>) -> tensor<4x128x126x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x32xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x126x30xf32>) -> tensor<4x128x126x30xf32>\n  return %ret : tensor<4x128x126x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x128x32xf32>, %arg1: tensor<128x64x3x3xf32>, %arg2: tensor<4x128x126x30xf32>) -> tensor<4x128x126x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x128x126x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x128x126x30xf32>\n    memref.copy %2, %alloc : memref<4x128x126x30xf32> to memref<4x128x126x30xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 126 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x128x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x128x126x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x128x126x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x128x126x30xf32>\n    return %3 : tensor<4x128x126x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x128x126x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x128x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x128x32xf32>) -> tensor<4x64x128x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x64x3x3xf32>) -> tensor<128x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x128x126x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x128x126x30xf32>) -> tensor<4x128x126x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x32xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x126x30xf32>) -> tensor<4x128x126x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x128x126x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x128x126x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 126, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4248824654}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x128x32xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x64x16xf32>) -> tensor<64x512x64x16xf32>_153": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x128x32xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x64x16xf32>) -> tensor<64x512x64x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x128x32xf32>, %filter: tensor<512x8x1x1xf32>, %init: tensor<64x512x64x16xf32>) -> tensor<64x512x64x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x128x32xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x64x16xf32>) -> tensor<64x512x64x16xf32>\n  return %ret : tensor<64x512x64x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x128x32xf32>, %arg1: tensor<512x8x1x1xf32>, %arg2: tensor<64x512x64x16xf32>) -> tensor<64x512x64x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512x64x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512x64x16xf32>\n    memref.copy %2, %alloc : memref<64x512x64x16xf32> to memref<64x512x64x16xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x128x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x512x64x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x512x64x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512x64x16xf32>\n    return %3 : tensor<64x512x64x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512x64x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x128x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x128x32xf32>) -> tensor<64x8x128x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x8x1x1xf32>) -> tensor<512x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x512x64x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x512x64x16xf32>) -> tensor<64x512x64x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x128x32xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<64x512x64x16xf32>) -> tensor<64x512x64x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512x64x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512x64x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 420098930}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x64x32xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<64x32x64x32xf32>) -> tensor<64x32x64x32xf32>_161": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x64x32xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<64x32x64x32xf32>) -> tensor<64x32x64x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x64x64x32xf32>, %filter: tensor<32x64x1x1xf32>, %init: tensor<64x32x64x32xf32>) -> tensor<64x32x64x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x64x32xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<64x32x64x32xf32>) -> tensor<64x32x64x32xf32>\n  return %ret : tensor<64x32x64x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x64x64x32xf32>, %arg1: tensor<32x64x1x1xf32>, %arg2: tensor<64x32x64x32xf32>) -> tensor<64x32x64x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64x64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32x64x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32x64x32xf32>\n    memref.copy %2, %alloc : memref<64x32x64x32xf32> to memref<64x32x64x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x64x64x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x64x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x64x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32x64x32xf32>\n    return %3 : tensor<64x32x64x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32x64x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x64x64x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x64x64x32xf32>) -> tensor<64x64x64x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x64x1x1xf32>) -> tensor<32x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x32x64x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x32x64x32xf32>) -> tensor<64x32x64x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x64x32xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<64x32x64x32xf32>) -> tensor<64x32x64x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32x64x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32x64x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1018036357}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x61x13xf32>) -> tensor<16x8x61x13xf32>_163": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x61x13xf32>) -> tensor<16x8x61x13xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x128x128x32xf32>, %filter: tensor<8x128x3x3xf32>, %init: tensor<16x8x61x13xf32>) -> tensor<16x8x61x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x61x13xf32>) -> tensor<16x8x61x13xf32>\n  return %ret : tensor<16x8x61x13xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x128x128x32xf32>, %arg1: tensor<8x128x3x3xf32>, %arg2: tensor<16x8x61x13xf32>) -> tensor<16x8x61x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x128x128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x61x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x61x13xf32>\n    memref.copy %2, %alloc : memref<16x8x61x13xf32> to memref<16x8x61x13xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 61 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x128x128x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x61x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x61x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x61x13xf32>\n    return %3 : tensor<16x8x61x13xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x61x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x128x128x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x128x128x32xf32>) -> tensor<16x128x128x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x128x3x3xf32>) -> tensor<8x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x61x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x61x13xf32>) -> tensor<16x8x61x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x61x13xf32>) -> tensor<16x8x61x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x61x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x61x13xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 61, 1], ["%arg6", 0, 13, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 461851202}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x256x512xf32>, tensor<64x8x3x3xf32>) outs (%init: tensor<32x64x85x170xf32>) -> tensor<32x64x85x170xf32>_164": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x256x512xf32>, tensor<64x8x3x3xf32>) outs (%init: tensor<32x64x85x170xf32>) -> tensor<32x64x85x170xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x8x256x512xf32>, %filter: tensor<64x8x3x3xf32>, %init: tensor<32x64x85x170xf32>) -> tensor<32x64x85x170xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x256x512xf32>, tensor<64x8x3x3xf32>) outs (%init: tensor<32x64x85x170xf32>) -> tensor<32x64x85x170xf32>\n  return %ret : tensor<32x64x85x170xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x8x256x512xf32>, %arg1: tensor<64x8x3x3xf32>, %arg2: tensor<32x64x85x170xf32>) -> tensor<32x64x85x170xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x8x256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64x85x170xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64x85x170xf32>\n    memref.copy %2, %alloc : memref<32x64x85x170xf32> to memref<32x64x85x170xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 85 {\n          affine.for %arg6 = 0 to 170 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x8x256x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x64x85x170xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x64x85x170xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64x85x170xf32>\n    return %3 : tensor<32x64x85x170xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64x85x170xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x8x256x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x8x256x512xf32>) -> tensor<32x8x256x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x8x3x3xf32>) -> tensor<64x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x64x85x170xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x64x85x170xf32>) -> tensor<32x64x85x170xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x256x512xf32>, tensor<64x8x3x3xf32>) outs (%init: tensor<32x64x85x170xf32>) -> tensor<32x64x85x170xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64x85x170xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64x85x170xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 85, 1], ["%arg6", 0, 170, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 7452715573}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<64x16x128x256xf32>) -> tensor<64x16x128x256xf32>_167": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<64x16x128x256xf32>) -> tensor<64x16x128x256xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x64x128x256xf32>, %filter: tensor<16x64x1x1xf32>, %init: tensor<64x16x128x256xf32>) -> tensor<64x16x128x256xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<64x16x128x256xf32>) -> tensor<64x16x128x256xf32>\n  return %ret : tensor<64x16x128x256xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x64x128x256xf32>, %arg1: tensor<16x64x1x1xf32>, %arg2: tensor<64x16x128x256xf32>) -> tensor<64x16x128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64x128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x128x256xf32>\n    memref.copy %2, %alloc : memref<64x16x128x256xf32> to memref<64x16x128x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 256 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x64x128x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x128x256xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x128x256xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x128x256xf32>\n    return %3 : tensor<64x16x128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x64x128x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x64x128x256xf32>) -> tensor<64x64x128x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x1x1xf32>) -> tensor<16x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x128x256xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x128x256xf32>) -> tensor<64x16x128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<64x16x128x256xf32>) -> tensor<64x16x128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 256, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 3", "%arg6 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 7993359162}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x512xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<4x8x244x500xf32>) -> tensor<4x8x244x500xf32>_169": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x512xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<4x8x244x500xf32>) -> tensor<4x8x244x500xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x256x512xf32>, %filter: tensor<8x16x7x7xf32>, %init: tensor<4x8x244x500xf32>) -> tensor<4x8x244x500xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x512xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<4x8x244x500xf32>) -> tensor<4x8x244x500xf32>\n  return %ret : tensor<4x8x244x500xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x256x512xf32>, %arg1: tensor<8x16x7x7xf32>, %arg2: tensor<4x8x244x500xf32>) -> tensor<4x8x244x500xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x244x500xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x244x500xf32>\n    memref.copy %2, %alloc : memref<4x8x244x500xf32> to memref<4x8x244x500xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 244 {\n          affine.for %arg6 = 0 to 500 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x256x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x244x500xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x244x500xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x244x500xf32>\n    return %3 : tensor<4x8x244x500xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x244x500xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x256x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x256x512xf32>) -> tensor<4x16x256x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x244x500xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x244x500xf32>) -> tensor<4x8x244x500xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x512xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<4x8x244x500xf32>) -> tensor<4x8x244x500xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x244x500xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x244x500xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 244, 1], ["%arg6", 0, 500, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 11622387558}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x256xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x14x126xf32>) -> tensor<8x16x14x126xf32>_173": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x256xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x14x126xf32>) -> tensor<8x16x14x126xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x32x256xf32>, %filter: tensor<16x16x3x3xf32>, %init: tensor<8x16x14x126xf32>) -> tensor<8x16x14x126xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x256xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x14x126xf32>) -> tensor<8x16x14x126xf32>\n  return %ret : tensor<8x16x14x126xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x32x256xf32>, %arg1: tensor<16x16x3x3xf32>, %arg2: tensor<8x16x14x126xf32>) -> tensor<8x16x14x126xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x16x14x126xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x16x14x126xf32>\n    memref.copy %2, %alloc : memref<8x16x14x126xf32> to memref<8x16x14x126xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 126 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x32x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x14x126xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x14x126xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x16x14x126xf32>\n    return %3 : tensor<8x16x14x126xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x16x14x126xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x32x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x32x256xf32>) -> tensor<8x16x32x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x16x3x3xf32>) -> tensor<16x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x16x14x126xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x16x14x126xf32>) -> tensor<8x16x14x126xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x256xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x14x126xf32>) -> tensor<8x16x14x126xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x16x14x126xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x16x14x126xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 126, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 124834658}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x64xf32>, tensor<512x64x5x5xf32>) outs (%init: tensor<8x512x10x20xf32>) -> tensor<8x512x10x20xf32>_176": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x64xf32>, tensor<512x64x5x5xf32>) outs (%init: tensor<8x512x10x20xf32>) -> tensor<8x512x10x20xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x32x64xf32>, %filter: tensor<512x64x5x5xf32>, %init: tensor<8x512x10x20xf32>) -> tensor<8x512x10x20xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x64xf32>, tensor<512x64x5x5xf32>) outs (%init: tensor<8x512x10x20xf32>) -> tensor<8x512x10x20xf32>\n  return %ret : tensor<8x512x10x20xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x32x64xf32>, %arg1: tensor<512x64x5x5xf32>, %arg2: tensor<8x512x10x20xf32>) -> tensor<8x512x10x20xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x512x10x20xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x512x10x20xf32>\n    memref.copy %2, %alloc : memref<8x512x10x20xf32> to memref<8x512x10x20xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 10 {\n          affine.for %arg6 = 0 to 20 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x32x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x64x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x512x10x20xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x512x10x20xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x512x10x20xf32>\n    return %3 : tensor<8x512x10x20xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x512x10x20xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x32x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x32x64xf32>) -> tensor<8x64x32x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x64x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x64x5x5xf32>) -> tensor<512x64x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x512x10x20xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x512x10x20xf32>) -> tensor<8x512x10x20xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x64xf32>, tensor<512x64x5x5xf32>) outs (%init: tensor<8x512x10x20xf32>) -> tensor<8x512x10x20xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x512x10x20xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x512x10x20xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 10, 1], ["%arg6", 0, 20, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 5008429361}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x512x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x170x10xf32>) -> tensor<64x8x170x10xf32>_177": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x512x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x170x10xf32>) -> tensor<64x8x170x10xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x32x512x32xf32>, %filter: tensor<8x32x3x3xf32>, %init: tensor<64x8x170x10xf32>) -> tensor<64x8x170x10xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x512x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x170x10xf32>) -> tensor<64x8x170x10xf32>\n  return %ret : tensor<64x8x170x10xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x32x512x32xf32>, %arg1: tensor<8x32x3x3xf32>, %arg2: tensor<64x8x170x10xf32>) -> tensor<64x8x170x10xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32x512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x170x10xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x170x10xf32>\n    memref.copy %2, %alloc : memref<64x8x170x10xf32> to memref<64x8x170x10xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 170 {\n          affine.for %arg6 = 0 to 10 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x32x512x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x170x10xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x170x10xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x170x10xf32>\n    return %3 : tensor<64x8x170x10xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x170x10xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x32x512x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x32x512x32xf32>) -> tensor<64x32x512x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x32x3x3xf32>) -> tensor<8x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x170x10xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x170x10xf32>) -> tensor<64x8x170x10xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x512x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x170x10xf32>) -> tensor<64x8x170x10xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x170x10xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x170x10xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 170, 1], ["%arg6", 0, 10, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 962697841}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x30x30xf32>) -> tensor<4x128x30x30xf32>_189": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x30x30xf32>) -> tensor<4x128x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x64x64xf32>, %filter: tensor<128x64x3x3xf32>, %init: tensor<4x128x30x30xf32>) -> tensor<4x128x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x30x30xf32>) -> tensor<4x128x30x30xf32>\n  return %ret : tensor<4x128x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x64x64xf32>, %arg1: tensor<128x64x3x3xf32>, %arg2: tensor<4x128x30x30xf32>) -> tensor<4x128x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x128x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x128x30x30xf32>\n    memref.copy %2, %alloc : memref<4x128x30x30xf32> to memref<4x128x30x30xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x128x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x128x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x128x30x30xf32>\n    return %3 : tensor<4x128x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x128x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x64x64xf32>) -> tensor<4x64x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x64x3x3xf32>) -> tensor<128x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x128x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x128x30x30xf32>) -> tensor<4x128x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<4x128x30x30xf32>) -> tensor<4x128x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x128x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x128x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1019667550}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x256x512xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<64x8x86x171xf32>) -> tensor<64x8x86x171xf32>_194": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x256x512xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<64x8x86x171xf32>) -> tensor<64x8x86x171xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x64x256x512xf32>, %filter: tensor<8x64x1x1xf32>, %init: tensor<64x8x86x171xf32>) -> tensor<64x8x86x171xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x256x512xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<64x8x86x171xf32>) -> tensor<64x8x86x171xf32>\n  return %ret : tensor<64x8x86x171xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x64x256x512xf32>, %arg1: tensor<8x64x1x1xf32>, %arg2: tensor<64x8x86x171xf32>) -> tensor<64x8x86x171xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64x256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x86x171xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x86x171xf32>\n    memref.copy %2, %alloc : memref<64x8x86x171xf32> to memref<64x8x86x171xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 86 {\n          affine.for %arg6 = 0 to 171 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x64x256x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x86x171xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x86x171xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x86x171xf32>\n    return %3 : tensor<64x8x86x171xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x86x171xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x64x256x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x64x256x512xf32>) -> tensor<64x64x256x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x1x1xf32>) -> tensor<8x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x86x171xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x86x171xf32>) -> tensor<64x8x86x171xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x256x512xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<64x8x86x171xf32>) -> tensor<64x8x86x171xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x86x171xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x86x171xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 86, 1], ["%arg6", 0, 171, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1932039426}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<8x8x256x64xf32>) -> tensor<8x8x256x64xf32>_195": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<8x8x256x64xf32>) -> tensor<8x8x256x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x512x128xf32>, %filter: tensor<8x16x1x1xf32>, %init: tensor<8x8x256x64xf32>) -> tensor<8x8x256x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<8x8x256x64xf32>) -> tensor<8x8x256x64xf32>\n  return %ret : tensor<8x8x256x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x512x128xf32>, %arg1: tensor<8x16x1x1xf32>, %arg2: tensor<8x8x256x64xf32>) -> tensor<8x8x256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x256x64xf32>\n    memref.copy %2, %alloc : memref<8x8x256x64xf32> to memref<8x8x256x64xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 256 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x512x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x256x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x256x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x256x64xf32>\n    return %3 : tensor<8x8x256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x512x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x512x128xf32>) -> tensor<8x16x512x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x1x1xf32>) -> tensor<8x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x256x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x256x64xf32>) -> tensor<8x8x256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<8x8x256x64xf32>) -> tensor<8x8x256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 256, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 3", "%arg6 * 2 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 42829052}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x32xf32>, tensor<1024x16x3x3xf32>) outs (%init: tensor<16x1024x20x9xf32>) -> tensor<16x1024x20x9xf32>_196": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x32xf32>, tensor<1024x16x3x3xf32>) outs (%init: tensor<16x1024x20x9xf32>) -> tensor<16x1024x20x9xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x16x64x32xf32>, %filter: tensor<1024x16x3x3xf32>, %init: tensor<16x1024x20x9xf32>) -> tensor<16x1024x20x9xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x32xf32>, tensor<1024x16x3x3xf32>) outs (%init: tensor<16x1024x20x9xf32>) -> tensor<16x1024x20x9xf32>\n  return %ret : tensor<16x1024x20x9xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x16x64x32xf32>, %arg1: tensor<1024x16x3x3xf32>, %arg2: tensor<16x1024x20x9xf32>) -> tensor<16x1024x20x9xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x16x64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x1024x20x9xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x1024x20x9xf32>\n    memref.copy %2, %alloc : memref<16x1024x20x9xf32> to memref<16x1024x20x9xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 20 {\n          affine.for %arg6 = 0 to 9 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x16x64x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x1024x20x9xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x1024x20x9xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x1024x20x9xf32>\n    return %3 : tensor<16x1024x20x9xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x1024x20x9xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x16x64x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x16x64x32xf32>) -> tensor<16x16x64x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x16x3x3xf32>) -> tensor<1024x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x1024x20x9xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x1024x20x9xf32>) -> tensor<16x1024x20x9xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x32xf32>, tensor<1024x16x3x3xf32>) outs (%init: tensor<16x1024x20x9xf32>) -> tensor<16x1024x20x9xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x1024x20x9xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x1024x20x9xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 20, 1], ["%arg6", 0, 9, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1576997437}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<32x32x122x26xf32>) -> tensor<32x32x122x26xf32>_204": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<32x32x122x26xf32>) -> tensor<32x32x122x26xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x8x128x32xf32>, %filter: tensor<32x8x3x3xf32>, %init: tensor<32x32x122x26xf32>) -> tensor<32x32x122x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<32x32x122x26xf32>) -> tensor<32x32x122x26xf32>\n  return %ret : tensor<32x32x122x26xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x8x128x32xf32>, %arg1: tensor<32x8x3x3xf32>, %arg2: tensor<32x32x122x26xf32>) -> tensor<32x32x122x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x8x128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32x122x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32x122x26xf32>\n    memref.copy %2, %alloc : memref<32x32x122x26xf32> to memref<32x32x122x26xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 122 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x8x128x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x122x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x122x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32x122x26xf32>\n    return %3 : tensor<32x32x122x26xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32x122x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x8x128x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x8x128x32xf32>) -> tensor<32x8x128x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x8x3x3xf32>) -> tensor<32x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x32x122x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x32x122x26xf32>) -> tensor<32x32x122x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<32x32x122x26xf32>) -> tensor<32x32x122x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32x122x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32x122x26xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 122, 1], ["%arg6", 0, 26, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 3", "%arg6 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 829239003}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x64x256xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<16x128x20x84xf32>) -> tensor<16x128x20x84xf32>_206": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x64x256xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<16x128x20x84xf32>) -> tensor<16x128x20x84xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x64x64x256xf32>, %filter: tensor<128x64x3x3xf32>, %init: tensor<16x128x20x84xf32>) -> tensor<16x128x20x84xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x64x256xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<16x128x20x84xf32>) -> tensor<16x128x20x84xf32>\n  return %ret : tensor<16x128x20x84xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x64x64x256xf32>, %arg1: tensor<128x64x3x3xf32>, %arg2: tensor<16x128x20x84xf32>) -> tensor<16x128x20x84xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x64x64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x128x20x84xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x128x20x84xf32>\n    memref.copy %2, %alloc : memref<16x128x20x84xf32> to memref<16x128x20x84xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 20 {\n          affine.for %arg6 = 0 to 84 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x64x64x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x128x20x84xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x128x20x84xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x128x20x84xf32>\n    return %3 : tensor<16x128x20x84xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x128x20x84xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x64x64x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x64x64x256xf32>) -> tensor<16x64x64x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x64x3x3xf32>) -> tensor<128x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x128x20x84xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x128x20x84xf32>) -> tensor<16x128x20x84xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x64x256xf32>, tensor<128x64x3x3xf32>) outs (%init: tensor<16x128x20x84xf32>) -> tensor<16x128x20x84xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x128x20x84xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x128x20x84xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 20, 1], ["%arg6", 0, 84, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 7640220860}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x512x32xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<8x64x171x11xf32>) -> tensor<8x64x171x11xf32>_210": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x512x32xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<8x64x171x11xf32>) -> tensor<8x64x171x11xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x256x512x32xf32>, %filter: tensor<64x256x1x1xf32>, %init: tensor<8x64x171x11xf32>) -> tensor<8x64x171x11xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x512x32xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<8x64x171x11xf32>) -> tensor<8x64x171x11xf32>\n  return %ret : tensor<8x64x171x11xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x256x512x32xf32>, %arg1: tensor<64x256x1x1xf32>, %arg2: tensor<8x64x171x11xf32>) -> tensor<8x64x171x11xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x256x512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x64x171x11xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x64x171x11xf32>\n    memref.copy %2, %alloc : memref<8x64x171x11xf32> to memref<8x64x171x11xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 171 {\n          affine.for %arg6 = 0 to 11 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x256x512x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x64x171x11xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x64x171x11xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x64x171x11xf32>\n    return %3 : tensor<8x64x171x11xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x64x171x11xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x256x512x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x256x512x32xf32>) -> tensor<8x256x512x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x256x1x1xf32>) -> tensor<64x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x64x171x11xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x64x171x11xf32>) -> tensor<8x64x171x11xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x512x32xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<8x64x171x11xf32>) -> tensor<8x64x171x11xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x64x171x11xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x64x171x11xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 171, 1], ["%arg6", 0, 11, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1079431549}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x512xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<16x8x506x506xf32>) -> tensor<16x8x506x506xf32>_213": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x512xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<16x8x506x506xf32>) -> tensor<16x8x506x506xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x512x512xf32>, %filter: tensor<8x8x3x3xf32>, %init: tensor<16x8x506x506xf32>) -> tensor<16x8x506x506xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x512xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<16x8x506x506xf32>) -> tensor<16x8x506x506xf32>\n  return %ret : tensor<16x8x506x506xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x512x512xf32>, %arg1: tensor<8x8x3x3xf32>, %arg2: tensor<16x8x506x506xf32>) -> tensor<16x8x506x506xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x506x506xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x506x506xf32>\n    memref.copy %2, %alloc : memref<16x8x506x506xf32> to memref<16x8x506x506xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 506 {\n          affine.for %arg6 = 0 to 506 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x512x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x506x506xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x506x506xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x506x506xf32>\n    return %3 : tensor<16x8x506x506xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x506x506xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x512x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x512x512xf32>) -> tensor<16x8x512x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x3x3xf32>) -> tensor<8x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x506x506xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x506x506xf32>) -> tensor<16x8x506x506xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x512x512xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<16x8x506x506xf32>) -> tensor<16x8x506x506xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x506x506xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x506x506xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 506, 1], ["%arg6", 0, 506, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 3", "%arg6 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 8479646947}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x32xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x58x26xf32>) -> tensor<32x8x58x26xf32>_216": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x32xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x58x26xf32>) -> tensor<32x8x58x26xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x8x64x32xf32>, %filter: tensor<8x8x3x3xf32>, %init: tensor<32x8x58x26xf32>) -> tensor<32x8x58x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x32xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x58x26xf32>) -> tensor<32x8x58x26xf32>\n  return %ret : tensor<32x8x58x26xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x8x64x32xf32>, %arg1: tensor<8x8x3x3xf32>, %arg2: tensor<32x8x58x26xf32>) -> tensor<32x8x58x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x8x64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x8x58x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x8x58x26xf32>\n    memref.copy %2, %alloc : memref<32x8x58x26xf32> to memref<32x8x58x26xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 58 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x8x64x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x58x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x58x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x8x58x26xf32>\n    return %3 : tensor<32x8x58x26xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x8x58x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x8x64x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x8x64x32xf32>) -> tensor<32x8x64x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x3x3xf32>) -> tensor<8x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x8x58x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x8x58x26xf32>) -> tensor<32x8x58x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x32xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x58x26xf32>) -> tensor<32x8x58x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x8x58x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x8x58x26xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 58, 1], ["%arg6", 0, 26, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 3", "%arg6 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 98717124}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x512x32x64xf32>, tensor<8x512x5x5xf32>) outs (%init: tensor<16x8x14x30xf32>) -> tensor<16x8x14x30xf32>_222": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x512x32x64xf32>, tensor<8x512x5x5xf32>) outs (%init: tensor<16x8x14x30xf32>) -> tensor<16x8x14x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x512x32x64xf32>, %filter: tensor<8x512x5x5xf32>, %init: tensor<16x8x14x30xf32>) -> tensor<16x8x14x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x512x32x64xf32>, tensor<8x512x5x5xf32>) outs (%init: tensor<16x8x14x30xf32>) -> tensor<16x8x14x30xf32>\n  return %ret : tensor<16x8x14x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x512x32x64xf32>, %arg1: tensor<8x512x5x5xf32>, %arg2: tensor<16x8x14x30xf32>) -> tensor<16x8x14x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x512x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x512x32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x14x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x14x30xf32>\n    memref.copy %2, %alloc : memref<16x8x14x30xf32> to memref<16x8x14x30xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x512x32x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x512x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x14x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x14x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x14x30xf32>\n    return %3 : tensor<16x8x14x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x14x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x512x32x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x512x32x64xf32>) -> tensor<16x512x32x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x512x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x512x5x5xf32>) -> tensor<8x512x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x14x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x14x30xf32>) -> tensor<16x8x14x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x512x32x64xf32>, tensor<8x512x5x5xf32>) outs (%init: tensor<16x8x14x30xf32>) -> tensor<16x8x14x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x14x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x14x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 512, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2727660176}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x128x64xf32>) -> tensor<4x8x128x64xf32>_223": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x128x64xf32>) -> tensor<4x8x128x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x256x128xf32>, %filter: tensor<8x16x1x1xf32>, %init: tensor<4x8x128x64xf32>) -> tensor<4x8x128x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x128x64xf32>) -> tensor<4x8x128x64xf32>\n  return %ret : tensor<4x8x128x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x256x128xf32>, %arg1: tensor<8x16x1x1xf32>, %arg2: tensor<4x8x128x64xf32>) -> tensor<4x8x128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x128x64xf32>\n    memref.copy %2, %alloc : memref<4x8x128x64xf32> to memref<4x8x128x64xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x256x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x128x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x128x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x128x64xf32>\n    return %3 : tensor<4x8x128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x256x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x256x128xf32>) -> tensor<4x16x256x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x1x1xf32>) -> tensor<8x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x128x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x128x64xf32>) -> tensor<4x8x128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x256x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x128x64xf32>) -> tensor<4x8x128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8 * 2", "%arg6 * 2 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 10476453}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x64x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<4x32x22x86xf32>) -> tensor<4x32x22x86xf32>_225": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x64x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<4x32x22x86xf32>) -> tensor<4x32x22x86xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x128x64x256xf32>, %filter: tensor<32x128x1x1xf32>, %init: tensor<4x32x22x86xf32>) -> tensor<4x32x22x86xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x64x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<4x32x22x86xf32>) -> tensor<4x32x22x86xf32>\n  return %ret : tensor<4x32x22x86xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x128x64x256xf32>, %arg1: tensor<32x128x1x1xf32>, %arg2: tensor<4x32x22x86xf32>) -> tensor<4x32x22x86xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x128x64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x32x22x86xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x32x22x86xf32>\n    memref.copy %2, %alloc : memref<4x32x22x86xf32> to memref<4x32x22x86xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 22 {\n          affine.for %arg6 = 0 to 86 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x128x64x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x22x86xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x22x86xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x32x22x86xf32>\n    return %3 : tensor<4x32x22x86xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x32x22x86xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x128x64x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x128x64x256xf32>) -> tensor<4x128x64x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x1x1xf32>) -> tensor<32x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x32x22x86xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x32x22x86xf32>) -> tensor<4x32x22x86xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x64x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<4x32x22x86xf32>) -> tensor<4x32x22x86xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x32x22x86xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x32x22x86xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 22, 1], ["%arg6", 0, 86, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 121852531}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<16x8x7x7xf32>) outs (%init: tensor<64x16x20x20xf32>) -> tensor<64x16x20x20xf32>_229": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<16x8x7x7xf32>) outs (%init: tensor<64x16x20x20xf32>) -> tensor<64x16x20x20xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x64x64xf32>, %filter: tensor<16x8x7x7xf32>, %init: tensor<64x16x20x20xf32>) -> tensor<64x16x20x20xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<16x8x7x7xf32>) outs (%init: tensor<64x16x20x20xf32>) -> tensor<64x16x20x20xf32>\n  return %ret : tensor<64x16x20x20xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x64x64xf32>, %arg1: tensor<16x8x7x7xf32>, %arg2: tensor<64x16x20x20xf32>) -> tensor<64x16x20x20xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x8x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x20x20xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x20x20xf32>\n    memref.copy %2, %alloc : memref<64x16x20x20xf32> to memref<64x16x20x20xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 20 {\n          affine.for %arg6 = 0 to 20 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x8x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x20x20xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x20x20xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x20x20xf32>\n    return %3 : tensor<64x16x20x20xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x20x20xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x64x64xf32>) -> tensor<64x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x8x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x8x7x7xf32>) -> tensor<16x8x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x20x20xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x20x20xf32>) -> tensor<64x16x20x20xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<16x8x7x7xf32>) outs (%init: tensor<64x16x20x20xf32>) -> tensor<64x16x20x20xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x20x20xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x20x20xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 20, 1], ["%arg6", 0, 20, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8", "%arg6 * 3 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 614382417}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x64xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<16x16x128x64xf32>) -> tensor<16x16x128x64xf32>_230": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x64xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<16x16x128x64xf32>) -> tensor<16x16x128x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x128x128x64xf32>, %filter: tensor<16x128x1x1xf32>, %init: tensor<16x16x128x64xf32>) -> tensor<16x16x128x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x64xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<16x16x128x64xf32>) -> tensor<16x16x128x64xf32>\n  return %ret : tensor<16x16x128x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x128x128x64xf32>, %arg1: tensor<16x128x1x1xf32>, %arg2: tensor<16x16x128x64xf32>) -> tensor<16x16x128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x128x128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x16x128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x16x128x64xf32>\n    memref.copy %2, %alloc : memref<16x16x128x64xf32> to memref<16x16x128x64xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x128x128x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x128x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x128x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x16x128x64xf32>\n    return %3 : tensor<16x16x128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x16x128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x128x128x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x128x128x64xf32>) -> tensor<16x128x128x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x128x1x1xf32>) -> tensor<16x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x16x128x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x16x128x64xf32>) -> tensor<16x16x128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x128x64xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<16x16x128x64xf32>) -> tensor<16x16x128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x16x128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x16x128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1089050732}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<4x16x84x20xf32>) -> tensor<4x16x84x20xf32>_232": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<4x16x84x20xf32>) -> tensor<4x16x84x20xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x256x64xf32>, %filter: tensor<16x64x3x3xf32>, %init: tensor<4x16x84x20xf32>) -> tensor<4x16x84x20xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<4x16x84x20xf32>) -> tensor<4x16x84x20xf32>\n  return %ret : tensor<4x16x84x20xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x256x64xf32>, %arg1: tensor<16x64x3x3xf32>, %arg2: tensor<4x16x84x20xf32>) -> tensor<4x16x84x20xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x16x84x20xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x16x84x20xf32>\n    memref.copy %2, %alloc : memref<4x16x84x20xf32> to memref<4x16x84x20xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 84 {\n          affine.for %arg6 = 0 to 20 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x256x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x16x84x20xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x16x84x20xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x16x84x20xf32>\n    return %3 : tensor<4x16x84x20xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x16x84x20xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x256x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x256x64xf32>) -> tensor<4x64x256x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x3x3xf32>) -> tensor<16x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x16x84x20xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x16x84x20xf32>) -> tensor<4x16x84x20xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x256x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<4x16x84x20xf32>) -> tensor<4x16x84x20xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x16x84x20xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x16x84x20xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 84, 1], ["%arg6", 0, 20, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 494249615}, "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x128x128xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<32x16x43x43xf32>) -> tensor<32x16x43x43xf32>_233": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x128x128xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<32x16x43x43xf32>) -> tensor<32x16x43x43xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x128x128x128xf32>, %filter: tensor<16x128x1x1xf32>, %init: tensor<32x16x43x43xf32>) -> tensor<32x16x43x43xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x128x128xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<32x16x43x43xf32>) -> tensor<32x16x43x43xf32>\n  return %ret : tensor<32x16x43x43xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 3)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x128x128x128xf32>, %arg1: tensor<16x128x1x1xf32>, %arg2: tensor<32x16x43x43xf32>) -> tensor<32x16x43x43xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x16x43x43xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x16x43x43xf32>\n    memref.copy %2, %alloc : memref<32x16x43x43xf32> to memref<32x16x43x43xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 43 {\n          affine.for %arg6 = 0 to 43 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x128x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x43x43xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x43x43xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x16x43x43xf32>\n    return %3 : tensor<32x16x43x43xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x16x43x43xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x128x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x128x128x128xf32>) -> tensor<32x128x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x128x1x1xf32>) -> tensor<16x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x16x43x43xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x16x43x43xf32>) -> tensor<32x16x43x43xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<3> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<32x128x128x128xf32>, tensor<16x128x1x1xf32>) outs (%init: tensor<32x16x43x43xf32>) -> tensor<32x16x43x43xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x16x43x43xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x16x43x43xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 43, 1], ["%arg6", 0, 43, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 3", "%arg6 * 3 + %arg9 * 3"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 481967491}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x43x43xf32>) -> tensor<16x64x43x43xf32>_236": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x43x43xf32>) -> tensor<16x64x43x43xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x128x128xf32>, %filter: tensor<64x8x1x1xf32>, %init: tensor<16x64x43x43xf32>) -> tensor<16x64x43x43xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x43x43xf32>) -> tensor<16x64x43x43xf32>\n  return %ret : tensor<16x64x43x43xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x128x128xf32>, %arg1: tensor<64x8x1x1xf32>, %arg2: tensor<16x64x43x43xf32>) -> tensor<16x64x43x43xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x64x43x43xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x64x43x43xf32>\n    memref.copy %2, %alloc : memref<16x64x43x43xf32> to memref<16x64x43x43xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 43 {\n          affine.for %arg6 = 0 to 43 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x43x43xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x43x43xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x64x43x43xf32>\n    return %3 : tensor<16x64x43x43xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x64x43x43xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x128x128xf32>) -> tensor<16x8x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x8x1x1xf32>) -> tensor<64x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x64x43x43xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x64x43x43xf32>) -> tensor<16x64x43x43xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x43x43xf32>) -> tensor<16x64x43x43xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x64x43x43xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x64x43x43xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 43, 1], ["%arg6", 0, 43, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 25389253}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x128xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<256x32x32x128xf32>) -> tensor<256x32x32x128xf32>_238": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x128xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<256x32x32x128xf32>) -> tensor<256x32x32x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x16x32x128xf32>, %filter: tensor<32x16x1x1xf32>, %init: tensor<256x32x32x128xf32>) -> tensor<256x32x32x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x128xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<256x32x32x128xf32>) -> tensor<256x32x32x128xf32>\n  return %ret : tensor<256x32x32x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x16x32x128xf32>, %arg1: tensor<32x16x1x1xf32>, %arg2: tensor<256x32x32x128xf32>) -> tensor<256x32x32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x16x32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x32x128xf32>\n    memref.copy %2, %alloc : memref<256x32x32x128xf32> to memref<256x32x32x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x16x32x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x32x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x32x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x32x128xf32>\n    return %3 : tensor<256x32x32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x16x32x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x16x32x128xf32>) -> tensor<256x16x32x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x16x1x1xf32>) -> tensor<32x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x32x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x32x128xf32>) -> tensor<256x32x32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x128xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<256x32x32x128xf32>) -> tensor<256x32x32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1480820595}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x512xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<256x8x7x167xf32>) -> tensor<256x8x7x167xf32>_240": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x512xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<256x8x7x167xf32>) -> tensor<256x8x7x167xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x32x32x512xf32>, %filter: tensor<8x32x7x7xf32>, %init: tensor<256x8x7x167xf32>) -> tensor<256x8x7x167xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x512xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<256x8x7x167xf32>) -> tensor<256x8x7x167xf32>\n  return %ret : tensor<256x8x7x167xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x32x512xf32>, %arg1: tensor<8x32x7x7xf32>, %arg2: tensor<256x8x7x167xf32>) -> tensor<256x8x7x167xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x32x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x8x7x167xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x8x7x167xf32>\n    memref.copy %2, %alloc : memref<256x8x7x167xf32> to memref<256x8x7x167xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 167 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x32x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x32x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x8x7x167xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x8x7x167xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x8x7x167xf32>\n    return %3 : tensor<256x8x7x167xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x8x7x167xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x32x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x32x512xf32>) -> tensor<256x32x32x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x32x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x32x7x7xf32>) -> tensor<8x32x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x8x7x167xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x8x7x167xf32>) -> tensor<256x8x7x167xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x512xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<256x8x7x167xf32>) -> tensor<256x8x7x167xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x8x7x167xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x8x7x167xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 7, 1], ["%arg6", 0, 167, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 14360322416}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x128xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<8x16x56x120xf32>) -> tensor<8x16x56x120xf32>_246": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x128xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<8x16x56x120xf32>) -> tensor<8x16x56x120xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x8x64x128xf32>, %filter: tensor<16x8x5x5xf32>, %init: tensor<8x16x56x120xf32>) -> tensor<8x16x56x120xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x128xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<8x16x56x120xf32>) -> tensor<8x16x56x120xf32>\n  return %ret : tensor<8x16x56x120xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x8x64x128xf32>, %arg1: tensor<16x8x5x5xf32>, %arg2: tensor<8x16x56x120xf32>) -> tensor<8x16x56x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x8x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x8x64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x16x56x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x16x56x120xf32>\n    memref.copy %2, %alloc : memref<8x16x56x120xf32> to memref<8x16x56x120xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 120 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x8x64x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x8x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x56x120xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x56x120xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x16x56x120xf32>\n    return %3 : tensor<8x16x56x120xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x16x56x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x8x64x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x8x64x128xf32>) -> tensor<8x8x64x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x8x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x8x5x5xf32>) -> tensor<16x8x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x16x56x120xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x16x56x120xf32>) -> tensor<8x16x56x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x128xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<8x16x56x120xf32>) -> tensor<8x16x56x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x16x56x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x16x56x120xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 56, 1], ["%arg6", 0, 120, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8 * 2", "%arg6 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 649501680}, "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<64x8x10x20xf32>) -> tensor<64x8x10x20xf32>_249": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<64x8x10x20xf32>) -> tensor<64x8x10x20xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x32x64xf32>, %filter: tensor<8x8x3x3xf32>, %init: tensor<64x8x10x20xf32>) -> tensor<64x8x10x20xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<64x8x10x20xf32>) -> tensor<64x8x10x20xf32>\n  return %ret : tensor<64x8x10x20xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 3 + d1 * 2)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x32x64xf32>, %arg1: tensor<8x8x3x3xf32>, %arg2: tensor<64x8x10x20xf32>) -> tensor<64x8x10x20xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x10x20xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x10x20xf32>\n    memref.copy %2, %alloc : memref<64x8x10x20xf32> to memref<64x8x10x20xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 10 {\n          affine.for %arg6 = 0 to 20 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x32x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x10x20xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x10x20xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x10x20xf32>\n    return %3 : tensor<64x8x10x20xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x10x20xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x32x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x32x64xf32>) -> tensor<64x8x32x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x3x3xf32>) -> tensor<8x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x10x20xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x10x20xf32>) -> tensor<64x8x10x20xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<2> : tensor<2xi64>, strides = dense<3> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<64x8x10x20xf32>) -> tensor<64x8x10x20xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x10x20xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x10x20xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 10, 1], ["%arg6", 0, 20, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 3 + %arg8 * 2", "%arg6 * 3 + %arg9 * 2"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 51651115}}