{"linalg.add ins(%arg0, %arg1: tensor<128x32x64xf32>, tensor<128x32x64xf32>) outs(%arg2: tensor<128x32x64xf32>) -> tensor<128x32x64xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<128x32x64xf32>, tensor<128x32x64xf32>) outs(%arg2: tensor<128x32x64xf32>) -> tensor<128x32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32x64xf32>, %arg1: tensor<128x32x64xf32>, %arg2: tensor<128x32x64xf32>) -> tensor<128x32x64xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<128x32x64xf32>, tensor<128x32x64xf32>) outs(%arg2: tensor<128x32x64xf32>) -> tensor<128x32x64xf32>\n  return %ret : tensor<128x32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x64xf32>, %arg1: tensor<128x32x64xf32>, %arg2: tensor<128x32x64xf32>) -> tensor<128x32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %3 = affine.load %1[%arg3, %arg4, %arg5] : memref<128x32x64xf32>\n          %4 = affine.load %0[%arg3, %arg4, %arg5] : memref<128x32x64xf32>\n          %5 = arith.addf %3, %4 : f32\n          affine.store %5, %alloc[%arg3, %arg4, %arg5] : memref<128x32x64xf32>\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x64xf32>\n    return %2 : tensor<128x32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32x64xf32>) -> tensor<128x32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x32x64xf32>) -> tensor<128x32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32x64xf32>) -> tensor<128x32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<128x32x64xf32>, tensor<128x32x64xf32>) outs(%arg2: tensor<128x32x64xf32>) -> tensor<128x32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg4", "%arg5"], ["%arg3", "%arg4", "%arg5"]], "store_data": []}, "execution_time": 246147}, "linalg.add ins(%arg0, %arg1: tensor<512xf32>, tensor<512xf32>) outs(%arg2: tensor<512xf32>) -> tensor<512xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<512xf32>, tensor<512xf32>) outs(%arg2: tensor<512xf32>) -> tensor<512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512xf32>, %arg1: tensor<512xf32>, %arg2: tensor<512xf32>) -> tensor<512xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<512xf32>, tensor<512xf32>) outs(%arg2: tensor<512xf32>) -> tensor<512xf32>\n  return %ret : tensor<512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512xf32>, %arg1: tensor<512xf32>, %arg2: tensor<512xf32>) -> tensor<512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512xf32>\n    affine.for %arg3 = 0 to 512 {\n      %3 = affine.load %1[%arg3] : memref<512xf32>\n      %4 = affine.load %0[%arg3] : memref<512xf32>\n      %5 = arith.addf %3, %4 : f32\n      affine.store %5, %alloc[%arg3] : memref<512xf32>\n    }\n    %2 = bufferization.to_tensor %alloc : memref<512xf32>\n    return %2 : tensor<512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512xf32>) -> tensor<512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512xf32>) -> tensor<512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512xf32>) -> tensor<512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<512xf32>, tensor<512xf32>) outs(%arg2: tensor<512xf32>) -> tensor<512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3"], ["%arg3"]], "store_data": []}, "execution_time": 477}, "linalg.add ins(%arg0, %arg1: tensor<64x256xf32>, tensor<64x256xf32>) outs(%arg2: tensor<64x256xf32>) -> tensor<64x256xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<64x256xf32>, tensor<64x256xf32>) outs(%arg2: tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<64x256xf32>, tensor<64x256xf32>) outs(%arg2: tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        %3 = affine.load %1[%arg3, %arg4] : memref<64x256xf32>\n        %4 = affine.load %0[%arg3, %arg4] : memref<64x256xf32>\n        %5 = arith.addf %3, %4 : f32\n        affine.store %5, %alloc[%arg3, %arg4] : memref<64x256xf32>\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %2 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<64x256xf32>, tensor<64x256xf32>) outs(%arg2: tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 12656}, "linalg.add ins(%arg0, %arg1: tensor<64x512x512xf32>, tensor<64x512x512xf32>) outs(%arg2: tensor<64x512x512xf32>) -> tensor<64x512x512xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<64x512x512xf32>, tensor<64x512x512xf32>) outs(%arg2: tensor<64x512x512xf32>) -> tensor<64x512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512x512xf32>, %arg1: tensor<64x512x512xf32>, %arg2: tensor<64x512x512xf32>) -> tensor<64x512x512xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<64x512x512xf32>, tensor<64x512x512xf32>) outs(%arg2: tensor<64x512x512xf32>) -> tensor<64x512x512xf32>\n  return %ret : tensor<64x512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512x512xf32>, %arg1: tensor<64x512x512xf32>, %arg2: tensor<64x512x512xf32>) -> tensor<64x512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512x512xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %3 = affine.load %1[%arg3, %arg4, %arg5] : memref<64x512x512xf32>\n          %4 = affine.load %0[%arg3, %arg4, %arg5] : memref<64x512x512xf32>\n          %5 = arith.addf %3, %4 : f32\n          affine.store %5, %alloc[%arg3, %arg4, %arg5] : memref<64x512x512xf32>\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<64x512x512xf32>\n    return %2 : tensor<64x512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512x512xf32>) -> tensor<64x512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512x512xf32>) -> tensor<64x512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x512x512xf32>) -> tensor<64x512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<64x512x512xf32>, tensor<64x512x512xf32>) outs(%arg2: tensor<64x512x512xf32>) -> tensor<64x512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg4", "%arg5"], ["%arg3", "%arg4", "%arg5"]], "store_data": []}, "execution_time": 20606760}, "linalg.add ins(%arg0, %arg1: tensor<512x256x64xf32>, tensor<512x256x64xf32>) outs(%arg2: tensor<512x256x64xf32>) -> tensor<512x256x64xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<512x256x64xf32>, tensor<512x256x64xf32>) outs(%arg2: tensor<512x256x64xf32>) -> tensor<512x256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256x64xf32>, %arg1: tensor<512x256x64xf32>, %arg2: tensor<512x256x64xf32>) -> tensor<512x256x64xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<512x256x64xf32>, tensor<512x256x64xf32>) outs(%arg2: tensor<512x256x64xf32>) -> tensor<512x256x64xf32>\n  return %ret : tensor<512x256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256x64xf32>, %arg1: tensor<512x256x64xf32>, %arg2: tensor<512x256x64xf32>) -> tensor<512x256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %3 = affine.load %1[%arg3, %arg4, %arg5] : memref<512x256x64xf32>\n          %4 = affine.load %0[%arg3, %arg4, %arg5] : memref<512x256x64xf32>\n          %5 = arith.addf %3, %4 : f32\n          affine.store %5, %alloc[%arg3, %arg4, %arg5] : memref<512x256x64xf32>\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<512x256x64xf32>\n    return %2 : tensor<512x256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256x64xf32>) -> tensor<512x256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256x64xf32>) -> tensor<512x256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256x64xf32>) -> tensor<512x256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<512x256x64xf32>, tensor<512x256x64xf32>) outs(%arg2: tensor<512x256x64xf32>) -> tensor<512x256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg4", "%arg5"], ["%arg3", "%arg4", "%arg5"]], "store_data": []}, "execution_time": 10603283}, "linalg.add ins(%arg0, %arg1: tensor<32xf32>, tensor<32xf32>) outs(%arg2: tensor<32xf32>) -> tensor<32xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<32xf32>, tensor<32xf32>) outs(%arg2: tensor<32xf32>) -> tensor<32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32xf32>, %arg1: tensor<32xf32>, %arg2: tensor<32xf32>) -> tensor<32xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<32xf32>, tensor<32xf32>) outs(%arg2: tensor<32xf32>) -> tensor<32xf32>\n  return %ret : tensor<32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32xf32>, %arg1: tensor<32xf32>, %arg2: tensor<32xf32>) -> tensor<32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32xf32>\n    affine.for %arg3 = 0 to 32 {\n      %3 = affine.load %1[%arg3] : memref<32xf32>\n      %4 = affine.load %0[%arg3] : memref<32xf32>\n      %5 = arith.addf %3, %4 : f32\n      affine.store %5, %alloc[%arg3] : memref<32xf32>\n    }\n    %2 = bufferization.to_tensor %alloc : memref<32xf32>\n    return %2 : tensor<32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32xf32>) -> tensor<32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32xf32>) -> tensor<32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32xf32>) -> tensor<32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<32xf32>, tensor<32xf32>) outs(%arg2: tensor<32xf32>) -> tensor<32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3"], ["%arg3"]], "store_data": []}, "execution_time": 112}, "linalg.add ins(%arg0, %arg1: tensor<32x256xf32>, tensor<32x256xf32>) outs(%arg2: tensor<32x256xf32>) -> tensor<32x256xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<32x256xf32>, tensor<32x256xf32>) outs(%arg2: tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<32x256xf32>, tensor<32x256xf32>) outs(%arg2: tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        %3 = affine.load %1[%arg3, %arg4] : memref<32x256xf32>\n        %4 = affine.load %0[%arg3, %arg4] : memref<32x256xf32>\n        %5 = arith.addf %3, %4 : f32\n        affine.store %5, %alloc[%arg3, %arg4] : memref<32x256xf32>\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %2 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<32x256xf32>, tensor<32x256xf32>) outs(%arg2: tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6037}, "linalg.add ins(%arg0, %arg1: tensor<256x128x512xf32>, tensor<256x128x512xf32>) outs(%arg2: tensor<256x128x512xf32>) -> tensor<256x128x512xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<256x128x512xf32>, tensor<256x128x512xf32>) outs(%arg2: tensor<256x128x512xf32>) -> tensor<256x128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128x512xf32>, %arg1: tensor<256x128x512xf32>, %arg2: tensor<256x128x512xf32>) -> tensor<256x128x512xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x128x512xf32>, tensor<256x128x512xf32>) outs(%arg2: tensor<256x128x512xf32>) -> tensor<256x128x512xf32>\n  return %ret : tensor<256x128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128x512xf32>, %arg1: tensor<256x128x512xf32>, %arg2: tensor<256x128x512xf32>) -> tensor<256x128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %3 = affine.load %1[%arg3, %arg4, %arg5] : memref<256x128x512xf32>\n          %4 = affine.load %0[%arg3, %arg4, %arg5] : memref<256x128x512xf32>\n          %5 = arith.addf %3, %4 : f32\n          affine.store %5, %alloc[%arg3, %arg4, %arg5] : memref<256x128x512xf32>\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x512xf32>\n    return %2 : tensor<256x128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128x512xf32>) -> tensor<256x128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128x512xf32>) -> tensor<256x128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128x512xf32>) -> tensor<256x128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x128x512xf32>, tensor<256x128x512xf32>) outs(%arg2: tensor<256x128x512xf32>) -> tensor<256x128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg4", "%arg5"], ["%arg3", "%arg4", "%arg5"]], "store_data": []}, "execution_time": 20773398}, "linalg.add ins(%arg0, %arg1: tensor<128xf32>, tensor<128xf32>) outs(%arg2: tensor<128xf32>) -> tensor<128xf32>": {"operation": "linalg.add ins(%arg0, %arg1: tensor<128xf32>, tensor<128xf32>) outs(%arg2: tensor<128xf32>) -> tensor<128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128xf32>, %arg1: tensor<128xf32>, %arg2: tensor<128xf32>) -> tensor<128xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<128xf32>, tensor<128xf32>) outs(%arg2: tensor<128xf32>) -> tensor<128xf32>\n  return %ret : tensor<128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128xf32>, %arg1: tensor<128xf32>, %arg2: tensor<128xf32>) -> tensor<128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128xf32>\n    affine.for %arg3 = 0 to 128 {\n      %3 = affine.load %1[%arg3] : memref<128xf32>\n      %4 = affine.load %0[%arg3] : memref<128xf32>\n      %5 = arith.addf %3, %4 : f32\n      affine.store %5, %alloc[%arg3] : memref<128xf32>\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128xf32>\n    return %2 : tensor<128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128xf32>) -> tensor<128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128xf32>) -> tensor<128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128xf32>) -> tensor<128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<128xf32>, tensor<128xf32>) outs(%arg2: tensor<128xf32>) -> tensor<128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 0, "/": 0, "exp": 0}, "load_data": [["%arg3"], ["%arg3"]], "store_data": []}, "execution_time": 173}}