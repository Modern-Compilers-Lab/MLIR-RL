{"linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1732365}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n  return %ret : tensor<32x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512xf32>\n    memref.copy %2, %alloc : memref<32x512xf32> to memref<32x512xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512xf32>\n    return %3 : tensor<32x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7314749}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 125349713}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3026926}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 125058338}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14060672}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 97259448}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 56203184}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n  return %ret : tensor<64x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512xf32>\n    memref.copy %2, %alloc : memref<64x512xf32> to memref<64x512xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512xf32>\n    return %3 : tensor<64x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31411110}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 6925500}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7758659}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 62615080}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 12103825}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2325354}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 5948544}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 11884765}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 19101680}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 5998566}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14965617}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 18558159}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 71822}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n  return %ret : tensor<512x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<512x32xf32>) -> tensor<512x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x32xf32>\n    memref.copy %2, %alloc : memref<512x32xf32> to memref<512x32xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x32xf32>\n    return %3 : tensor<512x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2976229}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n  return %ret : tensor<64x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32xf32>\n    memref.copy %2, %alloc : memref<64x32xf32> to memref<64x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32xf32>\n    return %3 : tensor<64x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 880361}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 77039700}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 127325911}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 10175187}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4650177}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 395303}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 118306446}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n  return %ret : tensor<32x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x1024xf32>\n    memref.copy %2, %alloc : memref<32x1024xf32> to memref<32x1024xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x1024xf32>\n    return %3 : tensor<32x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 128782654}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 241857370}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 28045685}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1020164236}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 592184}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7489265}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 62650985}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15945290}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 60028762}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 38266863}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 510139249}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 293224}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3745208}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 53501272}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 514344392}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15688405}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 286912}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 253094736}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 579089}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4805208}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 9554934}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4124892024}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14995436}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n  return %ret : tensor<256x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<256x64xf32>) -> tensor<256x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64xf32>\n    memref.copy %2, %alloc : memref<256x64xf32> to memref<256x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64xf32>\n    return %3 : tensor<256x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7326672}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15404391}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4606896}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 4907121}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n  return %ret : tensor<64x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512xf32>\n    memref.copy %2, %alloc : memref<64x512xf32> to memref<64x512xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512xf32>\n    return %3 : tensor<64x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63648296}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2058732248}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 13900662}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n  return %ret : tensor<32x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512xf32>\n    memref.copy %2, %alloc : memref<32x512xf32> to memref<32x512xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512xf32>\n    return %3 : tensor<32x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1197130}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 257180779}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 127469618}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 5946466}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30799499}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31663824}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 250680657}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63812987}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 64233157}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 126614627}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n  return %ret : tensor<64x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<64x256xf32>) -> tensor<64x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256xf32>\n    memref.copy %2, %alloc : memref<64x256xf32> to memref<64x256xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256xf32>\n    return %3 : tensor<64x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7030523}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 32237239}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 255168586}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 501120114}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 61947991}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 937481}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 127499075}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n  return %ret : tensor<1024x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<1024x32xf32>) -> tensor<1024x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x32xf32>\n    memref.copy %2, %alloc : memref<1024x32xf32> to memref<1024x32xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x32xf32>\n    return %3 : tensor<1024x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 29938302}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3863694}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 12171145}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n  return %ret : tensor<1024x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<1024x64xf32>) -> tensor<1024x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x64xf32>\n    memref.copy %2, %alloc : memref<1024x64xf32> to memref<1024x64xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x64xf32>\n    return %3 : tensor<1024x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 28762107}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 120096476}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15829473}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 500996784}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 515128302}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 255152881}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 579086}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7911333}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31865761}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 255078916}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1749545}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 509069696}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 25909236}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30360337}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n  return %ret : tensor<64x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512xf32>\n    memref.copy %2, %alloc : memref<64x512xf32> to memref<64x512xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512xf32>\n    return %3 : tensor<64x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2387612}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 121055686}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 287604}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 150270}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 112563646}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2060738571}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2040907149}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 12199945}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 258335238}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7253214}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 63521686}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n  return %ret : tensor<64x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32xf32>\n    memref.copy %2, %alloc : memref<64x32xf32> to memref<64x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32xf32>\n    return %3 : tensor<64x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3887650}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n  return %ret : tensor<32x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512xf32>\n    memref.copy %2, %alloc : memref<32x512xf32> to memref<32x512xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512xf32>\n    return %3 : tensor<32x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 64390054}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n  return %ret : tensor<32x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x1024xf32>\n    memref.copy %2, %alloc : memref<32x1024xf32> to memref<32x1024xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x1024xf32>\n    return %3 : tensor<32x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2404894}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 510691183}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 59922014}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 24154670}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2996019}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 234525962}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7488473}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n  return %ret : tensor<64x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<64x512xf32>) -> tensor<64x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x512xf32>\n    memref.copy %2, %alloc : memref<64x512xf32> to memref<64x512xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x512xf32>\n    return %3 : tensor<64x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 128634241}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15504971}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 48538100}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n  return %ret : tensor<32x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<32x128xf32>) -> tensor<32x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128xf32>\n    memref.copy %2, %alloc : memref<32x128xf32> to memref<32x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128xf32>\n    return %3 : tensor<32x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7871592}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7917596}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 250643359}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3501184}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2449662}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3516892}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 191618}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 513842152}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 247431895}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 483787441}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14047378}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 254395205}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n  return %ret : tensor<32x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512xf32>\n    memref.copy %2, %alloc : memref<32x512xf32> to memref<32x512xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512xf32>\n    return %3 : tensor<32x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31861770}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 62728572}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 123270021}, "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 1024, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1001878147}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 2306687}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n  return %ret : tensor<64x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x32xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<64x32xf32>) -> tensor<64x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32xf32>\n    memref.copy %2, %alloc : memref<64x32xf32> to memref<64x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32xf32>\n    return %3 : tensor<64x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x32xf32>, tensor<32x32xf32>) outs(%arg2 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 148298}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x256xf32>) -> tensor<64x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1515111}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 7712893}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 128505784}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n  return %ret : tensor<32x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<32x512xf32>) -> tensor<32x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512xf32>\n    memref.copy %2, %alloc : memref<32x512xf32> to memref<32x512xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512xf32>\n    return %3 : tensor<32x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3040358}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n  return %ret : tensor<32x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x1024xf32>, %arg1: tensor<1024x32xf32>, %arg2: tensor<32x32xf32>) -> tensor<32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32xf32>\n    memref.copy %2, %alloc : memref<32x32xf32> to memref<32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32xf32>\n    return %3 : tensor<32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x32xf32>) -> tensor<1024x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x1024xf32>, tensor<1024x32xf32>) outs(%arg2 : tensor<32x32xf32>) -> tensor<32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3937474}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 9646823}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n  return %ret : tensor<64x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x64xf32>, %arg1: tensor<64x128xf32>, %arg2: tensor<64x128xf32>) -> tensor<64x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x128xf32>\n    memref.copy %2, %alloc : memref<64x128xf32> to memref<64x128xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x128xf32>\n    return %3 : tensor<64x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x64xf32>, tensor<64x128xf32>) outs(%arg2 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1497711}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32xf32>, %arg1: tensor<32x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x32xf32>, tensor<32x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 574128}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n  return %ret : tensor<32x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<32x256xf32>) -> tensor<32x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x256xf32>\n    memref.copy %2, %alloc : memref<32x256xf32> to memref<32x256xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x256xf32>\n    return %3 : tensor<32x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x512xf32>) -> tensor<32x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15898708}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n  return %ret : tensor<512x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x64xf32>, %arg2: tensor<512x64xf32>) -> tensor<512x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x64xf32>\n    memref.copy %2, %alloc : memref<512x64xf32> to memref<512x64xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x64xf32>\n    return %3 : tensor<512x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x64xf32>) outs(%arg2 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 61944291}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x64xf32>) -> tensor<256x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1671972}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64xf32>, %arg1: tensor<64x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x32xf32>) -> tensor<64x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x64xf32>, tensor<64x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 747467}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x32xf32>, %arg1: tensor<32x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x256xf32>) -> tensor<32x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x32xf32>, tensor<32x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 9490711}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n  return %ret : tensor<64x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<64x1024xf32>) -> tensor<64x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x1024xf32>\n    memref.copy %2, %alloc : memref<64x1024xf32> to memref<64x1024xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x1024xf32>\n    return %3 : tensor<64x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<64x1024xf32>) -> tensor<64x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 30188004}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n  return %ret : tensor<128x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x64xf32>, %arg2: tensor<128x64xf32>) -> tensor<128x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64xf32>\n    memref.copy %2, %alloc : memref<128x64xf32> to memref<128x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64xf32>\n    return %3 : tensor<128x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x64xf32>) -> tensor<1024x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x64xf32>) outs(%arg2 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 1024, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 31738824}, "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n  return %ret : tensor<32x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<32x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<32x64xf32>) -> tensor<32x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x64xf32>\n    memref.copy %2, %alloc : memref<32x64xf32> to memref<32x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<32x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<32x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<32x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x64xf32>\n    return %3 : tensor<32x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<32x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<32x128xf32>) -> tensor<32x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<32x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<32x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<32x64xf32>) -> tensor<32x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 870430}, "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n  return %ret : tensor<64x64xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<64x128xf32>, %arg1: tensor<128x64xf32>, %arg2: tensor<64x64xf32>) -> tensor<64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64xf32>\n    memref.copy %2, %alloc : memref<64x64xf32> to memref<64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<64x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x64xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<64x64xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<64x64xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64xf32>\n    return %3 : tensor<64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<64x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<64x128xf32>) -> tensor<64x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x64xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x64xf32>) -> tensor<128x64xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<64x64xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<64x128xf32>, tensor<128x64xf32>) outs(%arg2 : tensor<64x64xf32>) -> tensor<64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 1739668}, "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n  return %ret : tensor<128x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x32xf32>, %arg2: tensor<128x32xf32>) -> tensor<128x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32xf32>\n    memref.copy %2, %alloc : memref<128x32xf32> to memref<128x32xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32xf32>\n    return %3 : tensor<128x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x32xf32>) outs(%arg2 : tensor<128x32xf32>) -> tensor<128x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 128, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 3746782}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n  return %ret : tensor<256x32xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x32xf32>, %arg2: tensor<256x32xf32>) -> tensor<256x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32xf32>\n    memref.copy %2, %alloc : memref<256x32xf32> to memref<256x32xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x32xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x32xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x32xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32xf32>\n    return %3 : tensor<256x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x32xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x32xf32>) -> tensor<512x32xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x32xf32>) outs(%arg2 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 512, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 15698825}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32xf32>, %arg1: tensor<32x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x32xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<32x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x32xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x32xf32>) -> tensor<256x32xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<32x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<32x1024xf32>) -> tensor<32x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x32xf32>, tensor<32x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 19217727}, "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x64xf32>, %arg1: tensor<64x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 64 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x64xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<64x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x64xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x64xf32>) -> tensor<512x64xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<64x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<64x512xf32>) -> tensor<64x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x64xf32>, tensor<64x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 512, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 64, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 48550313}, "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {"operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>", "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}", "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 128, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg5"], ["%arg5", "%arg4"], ["%arg3", "%arg4"]], "store_data": []}, "execution_time": 14209249}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x128x128xf32>, tensor<8x256x1x1xf32>) outs (%init: tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x128x128xf32>, tensor<8x256x1x1xf32>) outs (%init: tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x256x128x128xf32>, %filter: tensor<8x256x1x1xf32>, %init: tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x128x128xf32>, tensor<8x256x1x1xf32>) outs (%init: tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32>\n  return %ret : tensor<32x8x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x256x128x128xf32>, %arg1: tensor<8x256x1x1xf32>, %arg2: tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x8x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x8x64x64xf32>\n    memref.copy %2, %alloc : memref<32x8x64x64xf32> to memref<32x8x64x64xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x256x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x8x64x64xf32>\n    return %3 : tensor<32x8x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x8x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x256x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x256x128x128xf32>) -> tensor<32x256x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x256x1x1xf32>) -> tensor<8x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x8x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x128x128xf32>, tensor<8x256x1x1xf32>) outs (%init: tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x8x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x8x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1030713465}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x256x64x64xf32>, %filter: tensor<16x256x1x1xf32>, %init: tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32>\n  return %ret : tensor<64x16x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x256x64x64xf32>, %arg1: tensor<16x256x1x1xf32>, %arg2: tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x256x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x32x32xf32>\n    memref.copy %2, %alloc : memref<64x16x32x32xf32> to memref<64x16x32x32xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x256x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x32x32xf32>\n    return %3 : tensor<64x16x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x256x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x256x64x64xf32>) -> tensor<64x256x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x256x1x1xf32>) -> tensor<16x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x256x64x64xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1006070770}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x28x28xf32>) -> tensor<64x16x28x28xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x28x28xf32>) -> tensor<64x16x28x28xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x32x32x32xf32>, %filter: tensor<16x32x5x5xf32>, %init: tensor<64x16x28x28xf32>) -> tensor<64x16x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x28x28xf32>) -> tensor<64x16x28x28xf32>\n  return %ret : tensor<64x16x28x28xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x32x32x32xf32>, %arg1: tensor<16x32x5x5xf32>, %arg2: tensor<64x16x28x28xf32>) -> tensor<64x16x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x32x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x28x28xf32>\n    memref.copy %2, %alloc : memref<64x16x28x28xf32> to memref<64x16x28x28xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x32x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x28x28xf32>\n    return %3 : tensor<64x16x28x28xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x32x32x32xf32>) -> tensor<64x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x32x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x32x5x5xf32>) -> tensor<16x32x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x28x28xf32>) -> tensor<64x16x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x28x28xf32>) -> tensor<64x16x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x28x28xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 28, 1], ["%arg6", 0, 28, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2417292235}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x32x32xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x32x32xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x32x32xf32>, %filter: tensor<32x16x1x1xf32>, %init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x32x32xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n  return %ret : tensor<4x32x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x32x32xf32>, %arg1: tensor<32x16x1x1xf32>, %arg2: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x32x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x32x32x32xf32>\n    memref.copy %2, %alloc : memref<4x32x32x32xf32> to memref<4x32x32x32xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x32x32x32xf32>\n    return %3 : tensor<4x32x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x32x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x32x32xf32>) -> tensor<4x16x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x16x1x1xf32>) -> tensor<32x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x32x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x32x32xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x32x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x32x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4092169}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x1024x64x64xf32>, %filter: tensor<32x1024x1x1xf32>, %init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n  return %ret : tensor<4x32x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x1024x64x64xf32>, %arg1: tensor<32x1024x1x1xf32>, %arg2: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x1024x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x32x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x32x32x32xf32>\n    memref.copy %2, %alloc : memref<4x32x32x32xf32> to memref<4x32x32x32xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 1024 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x1024x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x1024x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x32x32x32xf32>\n    return %3 : tensor<4x32x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x32x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x1024x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x1024x64x64xf32>) -> tensor<4x1024x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x1024x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x1024x1x1xf32>) -> tensor<32x1024x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x32x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x32x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x32x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 1024, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 530832532}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x128xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x63x63xf32>) -> tensor<32x32x63x63xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x128xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x63x63xf32>) -> tensor<32x32x63x63xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x32x128x128xf32>, %filter: tensor<32x32x3x3xf32>, %init: tensor<32x32x63x63xf32>) -> tensor<32x32x63x63xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x128xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x63x63xf32>) -> tensor<32x32x63x63xf32>\n  return %ret : tensor<32x32x63x63xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x32x128x128xf32>, %arg1: tensor<32x32x3x3xf32>, %arg2: tensor<32x32x63x63xf32>) -> tensor<32x32x63x63xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32x63x63xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32x63x63xf32>\n    memref.copy %2, %alloc : memref<32x32x63x63xf32> to memref<32x32x63x63xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 63 {\n          affine.for %arg6 = 0 to 63 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x32x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x63x63xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x63x63xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32x63x63xf32>\n    return %3 : tensor<32x32x63x63xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32x63x63xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x32x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x32x128x128xf32>) -> tensor<32x32x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x3x3xf32>) -> tensor<32x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x32x63x63xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x32x63x63xf32>) -> tensor<32x32x63x63xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x128x128xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<32x32x63x63xf32>) -> tensor<32x32x63x63xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32x63x63xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32x63x63xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 63, 1], ["%arg6", 0, 63, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4462808550}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x128x64x64xf32>, %filter: tensor<64x128x1x1xf32>, %init: tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>\n  return %ret : tensor<8x64x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x128x64x64xf32>, %arg1: tensor<64x128x1x1xf32>, %arg2: tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x128x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x64x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x64x32x32xf32>\n    memref.copy %2, %alloc : memref<8x64x32x32xf32> to memref<8x64x32x32xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x128x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x64x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x64x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x64x32x32xf32>\n    return %3 : tensor<8x64x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x64x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x128x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x128x1x1xf32>) -> tensor<64x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x64x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x64x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x64x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 239866244}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x64x64xf32>, %filter: tensor<8x16x1x1xf32>, %init: tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32>\n  return %ret : tensor<4x8x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x64x64xf32>, %arg1: tensor<8x16x1x1xf32>, %arg2: tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x32x32xf32>\n    memref.copy %2, %alloc : memref<4x8x32x32xf32> to memref<4x8x32x32xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x32x32xf32>\n    return %3 : tensor<4x8x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x64x64xf32>) -> tensor<4x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x1x1xf32>) -> tensor<8x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1074385}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<16x16x61x61xf32>) -> tensor<16x16x61x61xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<16x16x61x61xf32>) -> tensor<16x16x61x61xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x64x128x128xf32>, %filter: tensor<16x64x7x7xf32>, %init: tensor<16x16x61x61xf32>) -> tensor<16x16x61x61xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<16x16x61x61xf32>) -> tensor<16x16x61x61xf32>\n  return %ret : tensor<16x16x61x61xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x64x128x128xf32>, %arg1: tensor<16x64x7x7xf32>, %arg2: tensor<16x16x61x61xf32>) -> tensor<16x16x61x61xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x64x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x16x61x61xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x16x61x61xf32>\n    memref.copy %2, %alloc : memref<16x16x61x61xf32> to memref<16x16x61x61xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 61 {\n          affine.for %arg6 = 0 to 61 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x64x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x61x61xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x61x61xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x16x61x61xf32>\n    return %3 : tensor<16x16x61x61xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x16x61x61xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x64x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x64x128x128xf32>) -> tensor<16x64x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x7x7xf32>) -> tensor<16x64x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x16x61x61xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x16x61x61xf32>) -> tensor<16x16x61x61xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<16x16x61x61xf32>) -> tensor<16x16x61x61xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x16x61x61xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x16x61x61xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 61, 1], ["%arg6", 0, 61, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 11357510366}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x64x64xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x64x64xf32>) -> tensor<16x64x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x64x64xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x64x64xf32>) -> tensor<16x64x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x64x64xf32>, %filter: tensor<64x8x1x1xf32>, %init: tensor<16x64x64x64xf32>) -> tensor<16x64x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x64x64xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x64x64xf32>) -> tensor<16x64x64x64xf32>\n  return %ret : tensor<16x64x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x64x64xf32>, %arg1: tensor<64x8x1x1xf32>, %arg2: tensor<16x64x64x64xf32>) -> tensor<16x64x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x64x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x64x64x64xf32>\n    memref.copy %2, %alloc : memref<16x64x64x64xf32> to memref<16x64x64x64xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x64x64x64xf32>\n    return %3 : tensor<16x64x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x64x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x64x64xf32>) -> tensor<16x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x8x1x1xf32>) -> tensor<64x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x64x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x64x64x64xf32>) -> tensor<16x64x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x64x64xf32>, tensor<64x8x1x1xf32>) outs (%init: tensor<16x64x64x64xf32>) -> tensor<16x64x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x64x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x64x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 49751692}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x1024x64x64xf32>, %filter: tensor<32x1024x1x1xf32>, %init: tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32>\n  return %ret : tensor<32x32x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x1024x64x64xf32>, %arg1: tensor<32x1024x1x1xf32>, %arg2: tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x1024x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x1024x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x32x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x32x32x32xf32>\n    memref.copy %2, %alloc : memref<32x32x32x32xf32> to memref<32x32x32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 1024 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x1024x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x1024x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x32x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x32x32x32xf32>\n    return %3 : tensor<32x32x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x32x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x1024x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x1024x64x64xf32>) -> tensor<32x1024x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x1024x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x1024x1x1xf32>) -> tensor<32x1024x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x32x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x1024x64x64xf32>, tensor<32x1024x1x1xf32>) outs (%init: tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x32x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x32x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 1024, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4353349666}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x256x256xf32>, %filter: tensor<128x16x1x1xf32>, %init: tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32>\n  return %ret : tensor<8x128x256x256xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x256x256xf32>, %arg1: tensor<128x16x1x1xf32>, %arg2: tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x256x256xf32>\n    memref.copy %2, %alloc : memref<8x128x256x256xf32> to memref<8x128x256x256xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          affine.for %arg6 = 0 to 256 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x256x256xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x256x256xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x256x256xf32>\n    return %3 : tensor<8x128x256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x256x256xf32>) -> tensor<8x16x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x16x1x1xf32>) -> tensor<128x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x256x256xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x256x256xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 256, 1], ["%arg6", 0, 256, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3137511479}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<4x64x16x16xf32>) -> tensor<4x64x16x16xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<4x64x16x16xf32>) -> tensor<4x64x16x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x128x32x32xf32>, %filter: tensor<64x128x1x1xf32>, %init: tensor<4x64x16x16xf32>) -> tensor<4x64x16x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<4x64x16x16xf32>) -> tensor<4x64x16x16xf32>\n  return %ret : tensor<4x64x16x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x128x32x32xf32>, %arg1: tensor<64x128x1x1xf32>, %arg2: tensor<4x64x16x16xf32>) -> tensor<4x64x16x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x128x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x64x16x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x64x16x16xf32>\n    memref.copy %2, %alloc : memref<4x64x16x16xf32> to memref<4x64x16x16xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 16 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x128x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x16x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x16x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x64x16x16xf32>\n    return %3 : tensor<4x64x16x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x64x16x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x128x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x128x32x32xf32>) -> tensor<4x128x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x128x1x1xf32>) -> tensor<64x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x64x16x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x64x16x16xf32>) -> tensor<4x64x16x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<4x64x16x16xf32>) -> tensor<4x64x16x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x64x16x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x64x16x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 16, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 30308270}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x62x62xf32>) -> tensor<4x8x62x62xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x62x62xf32>) -> tensor<4x8x62x62xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x64x64xf32>, %filter: tensor<8x16x3x3xf32>, %init: tensor<4x8x62x62xf32>) -> tensor<4x8x62x62xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x62x62xf32>) -> tensor<4x8x62x62xf32>\n  return %ret : tensor<4x8x62x62xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x64x64xf32>, %arg1: tensor<8x16x3x3xf32>, %arg2: tensor<4x8x62x62xf32>) -> tensor<4x8x62x62xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x62x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x62x62xf32>\n    memref.copy %2, %alloc : memref<4x8x62x62xf32> to memref<4x8x62x62xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x62x62xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x62x62xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x62x62xf32>\n    return %3 : tensor<4x8x62x62xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x62x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x64x64xf32>) -> tensor<4x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x3x3xf32>) -> tensor<8x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x62x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x62x62xf32>) -> tensor<4x8x62x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x62x62xf32>) -> tensor<4x8x62x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x62x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x62x62xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 62, 1], ["%arg6", 0, 62, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 65807895}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x32x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x32x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x16x32x32xf32>, %filter: tensor<8x16x5x5xf32>, %init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x32x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>\n  return %ret : tensor<16x8x28x28xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x16x32x32xf32>, %arg1: tensor<8x16x5x5xf32>, %arg2: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x16x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x28x28xf32>\n    memref.copy %2, %alloc : memref<16x8x28x28xf32> to memref<16x8x28x28xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x16x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x28x28xf32>\n    return %3 : tensor<16x8x28x28xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x16x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x16x32x32xf32>) -> tensor<16x16x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x5x5xf32>) -> tensor<8x16x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x32x32xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x28x28xf32>) -> tensor<16x8x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x28x28xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 28, 1], ["%arg6", 0, 28, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 150321154}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<4x32x30x30xf32>) -> tensor<4x32x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<4x32x30x30xf32>) -> tensor<4x32x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x8x32x32xf32>, %filter: tensor<32x8x3x3xf32>, %init: tensor<4x32x30x30xf32>) -> tensor<4x32x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<4x32x30x30xf32>) -> tensor<4x32x30x30xf32>\n  return %ret : tensor<4x32x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x8x32x32xf32>, %arg1: tensor<32x8x3x3xf32>, %arg2: tensor<4x32x30x30xf32>) -> tensor<4x32x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x32x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x32x30x30xf32>\n    memref.copy %2, %alloc : memref<4x32x30x30xf32> to memref<4x32x30x30xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x32x30x30xf32>\n    return %3 : tensor<4x32x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x32x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x8x32x32xf32>) -> tensor<4x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x8x3x3xf32>) -> tensor<32x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x32x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x32x30x30xf32>) -> tensor<4x32x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x8x32x32xf32>, tensor<32x8x3x3xf32>) outs (%init: tensor<4x32x30x30xf32>) -> tensor<4x32x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x32x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x32x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 29044243}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x256x256xf32>, %filter: tensor<8x64x5x5xf32>, %init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>\n  return %ret : tensor<8x8x126x126xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x256x256xf32>, %arg1: tensor<8x64x5x5xf32>, %arg2: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x126x126xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x126x126xf32>\n    memref.copy %2, %alloc : memref<8x8x126x126xf32> to memref<8x8x126x126xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 126 {\n          affine.for %arg6 = 0 to 126 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x126x126xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x126x126xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x126x126xf32>\n    return %3 : tensor<8x8x126x126xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x126x126xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x256x256xf32>) -> tensor<8x64x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x5x5xf32>) -> tensor<8x64x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x126x126xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x126x126xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x126x126xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 126, 1], ["%arg6", 0, 126, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 6209141295}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<8x32x14x14xf32>) -> tensor<8x32x14x14xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<8x32x14x14xf32>) -> tensor<8x32x14x14xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x32x32xf32>, %filter: tensor<32x64x5x5xf32>, %init: tensor<8x32x14x14xf32>) -> tensor<8x32x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<8x32x14x14xf32>) -> tensor<8x32x14x14xf32>\n  return %ret : tensor<8x32x14x14xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x32x32xf32>, %arg1: tensor<32x64x5x5xf32>, %arg2: tensor<8x32x14x14xf32>) -> tensor<8x32x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x32x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x32x14x14xf32>\n    memref.copy %2, %alloc : memref<8x32x14x14xf32> to memref<8x32x14x14xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x64x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x32x14x14xf32>\n    return %3 : tensor<8x32x14x14xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x32x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x64x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x64x5x5xf32>) -> tensor<32x64x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x32x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x32x14x14xf32>) -> tensor<8x32x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<8x32x14x14xf32>) -> tensor<8x32x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x32x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x32x14x14xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 14, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 304619307}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x32x32x32xf32>, %filter: tensor<8x32x3x3xf32>, %init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>\n  return %ret : tensor<8x8x15x15xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x32x32x32xf32>, %arg1: tensor<8x32x3x3xf32>, %arg2: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x15x15xf32>\n    memref.copy %2, %alloc : memref<8x8x15x15xf32> to memref<8x8x15x15xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x15x15xf32>\n    return %3 : tensor<8x8x15x15xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x32x32x32xf32>) -> tensor<8x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x32x3x3xf32>) -> tensor<8x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x15x15xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 15, 1], ["%arg6", 0, 15, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 15492038}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<8x32x64x64xf32>) -> tensor<8x32x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<8x32x64x64xf32>) -> tensor<8x32x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x8x128x128xf32>, %filter: tensor<32x8x1x1xf32>, %init: tensor<8x32x64x64xf32>) -> tensor<8x32x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<8x32x64x64xf32>) -> tensor<8x32x64x64xf32>\n  return %ret : tensor<8x32x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x8x128x128xf32>, %arg1: tensor<32x8x1x1xf32>, %arg2: tensor<8x32x64x64xf32>) -> tensor<8x32x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x8x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x32x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x32x64x64xf32>\n    memref.copy %2, %alloc : memref<8x32x64x64xf32> to memref<8x32x64x64xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x8x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x32x64x64xf32>\n    return %3 : tensor<8x32x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x32x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x8x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x8x128x128xf32>) -> tensor<8x8x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x8x1x1xf32>) -> tensor<32x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x32x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x32x64x64xf32>) -> tensor<8x32x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<32x8x1x1xf32>) outs (%init: tensor<8x32x64x64xf32>) -> tensor<8x32x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x32x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x32x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 13079117}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x32x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x15x15xf32>) -> tensor<16x8x15x15xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x32x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x15x15xf32>) -> tensor<16x8x15x15xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x128x32x32xf32>, %filter: tensor<8x128x3x3xf32>, %init: tensor<16x8x15x15xf32>) -> tensor<16x8x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x32x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x15x15xf32>) -> tensor<16x8x15x15xf32>\n  return %ret : tensor<16x8x15x15xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x128x32x32xf32>, %arg1: tensor<8x128x3x3xf32>, %arg2: tensor<16x8x15x15xf32>) -> tensor<16x8x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x128x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x15x15xf32>\n    memref.copy %2, %alloc : memref<16x8x15x15xf32> to memref<16x8x15x15xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x128x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x15x15xf32>\n    return %3 : tensor<16x8x15x15xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x128x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x128x32x32xf32>) -> tensor<16x128x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x128x3x3xf32>) -> tensor<8x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x15x15xf32>) -> tensor<16x8x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x128x32x32xf32>, tensor<8x128x3x3xf32>) outs (%init: tensor<16x8x15x15xf32>) -> tensor<16x8x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x15x15xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 15, 1], ["%arg6", 0, 15, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 127364549}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x32xf32>, tensor<256x16x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x32xf32>, tensor<256x16x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x32x32xf32>, %filter: tensor<256x16x7x7xf32>, %init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x32xf32>, tensor<256x16x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>\n  return %ret : tensor<8x256x13x13xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x32x32xf32>, %arg1: tensor<256x16x7x7xf32>, %arg2: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x16x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x256x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x256x13x13xf32>\n    memref.copy %2, %alloc : memref<8x256x13x13xf32> to memref<8x256x13x13xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x16x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x256x13x13xf32>\n    return %3 : tensor<8x256x13x13xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x256x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x16x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x16x7x7xf32>) -> tensor<256x16x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x256x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x32x32xf32>, tensor<256x16x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x256x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x256x13x13xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 13, 1], ["%arg6", 0, 13, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1020783434}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<256x64x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<256x64x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x32x32xf32>, %filter: tensor<256x64x7x7xf32>, %init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<256x64x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>\n  return %ret : tensor<8x256x13x13xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x32x32xf32>, %arg1: tensor<256x64x7x7xf32>, %arg2: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x256x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x256x13x13xf32>\n    memref.copy %2, %alloc : memref<8x256x13x13xf32> to memref<8x256x13x13xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x64x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x256x13x13xf32>\n    return %3 : tensor<8x256x13x13xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x256x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x64x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x256x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<256x64x7x7xf32>) outs (%init: tensor<8x256x13x13xf32>) -> tensor<8x256x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x256x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x256x13x13xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 13, 1], ["%arg6", 0, 13, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4104830793}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x3x3xf32>) outs (%init: tensor<64x16x30x30xf32>) -> tensor<64x16x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x3x3xf32>) outs (%init: tensor<64x16x30x30xf32>) -> tensor<64x16x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x32x32x32xf32>, %filter: tensor<16x32x3x3xf32>, %init: tensor<64x16x30x30xf32>) -> tensor<64x16x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x3x3xf32>) outs (%init: tensor<64x16x30x30xf32>) -> tensor<64x16x30x30xf32>\n  return %ret : tensor<64x16x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x32x32x32xf32>, %arg1: tensor<16x32x3x3xf32>, %arg2: tensor<64x16x30x30xf32>) -> tensor<64x16x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x30x30xf32>\n    memref.copy %2, %alloc : memref<64x16x30x30xf32> to memref<64x16x30x30xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x30x30xf32>\n    return %3 : tensor<64x16x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x32x32x32xf32>) -> tensor<64x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x32x3x3xf32>) -> tensor<16x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x30x30xf32>) -> tensor<64x16x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<16x32x3x3xf32>) outs (%init: tensor<64x16x30x30xf32>) -> tensor<64x16x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 991818273}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x128xf32>, tensor<64x32x5x5xf32>) outs (%init: tensor<16x64x62x62xf32>) -> tensor<16x64x62x62xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x128xf32>, tensor<64x32x5x5xf32>) outs (%init: tensor<16x64x62x62xf32>) -> tensor<16x64x62x62xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x32x128x128xf32>, %filter: tensor<64x32x5x5xf32>, %init: tensor<16x64x62x62xf32>) -> tensor<16x64x62x62xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x128xf32>, tensor<64x32x5x5xf32>) outs (%init: tensor<16x64x62x62xf32>) -> tensor<16x64x62x62xf32>\n  return %ret : tensor<16x64x62x62xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x32x128x128xf32>, %arg1: tensor<64x32x5x5xf32>, %arg2: tensor<16x64x62x62xf32>) -> tensor<16x64x62x62xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x32x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x64x62x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x64x62x62xf32>\n    memref.copy %2, %alloc : memref<16x64x62x62xf32> to memref<16x64x62x62xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x32x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x32x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x62x62xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x64x62x62xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x64x62x62xf32>\n    return %3 : tensor<16x64x62x62xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x64x62x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x32x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x32x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x32x5x5xf32>) -> tensor<64x32x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x64x62x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x64x62x62xf32>) -> tensor<16x64x62x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x128x128xf32>, tensor<64x32x5x5xf32>) outs (%init: tensor<16x64x62x62xf32>) -> tensor<16x64x62x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x64x62x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x64x62x62xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 62, 1], ["%arg6", 0, 62, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 11973881575}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x62x62xf32>) -> tensor<32x8x62x62xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x62x62xf32>) -> tensor<32x8x62x62xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x8x64x64xf32>, %filter: tensor<8x8x3x3xf32>, %init: tensor<32x8x62x62xf32>) -> tensor<32x8x62x62xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x62x62xf32>) -> tensor<32x8x62x62xf32>\n  return %ret : tensor<32x8x62x62xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x8x64x64xf32>, %arg1: tensor<8x8x3x3xf32>, %arg2: tensor<32x8x62x62xf32>) -> tensor<32x8x62x62xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x8x62x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x8x62x62xf32>\n    memref.copy %2, %alloc : memref<32x8x62x62xf32> to memref<32x8x62x62xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x62x62xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x62x62xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x8x62x62xf32>\n    return %3 : tensor<32x8x62x62xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x8x62x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x8x64x64xf32>) -> tensor<32x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x3x3xf32>) -> tensor<8x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x8x62x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x8x62x62xf32>) -> tensor<32x8x62x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x64x64xf32>, tensor<8x8x3x3xf32>) outs (%init: tensor<32x8x62x62xf32>) -> tensor<32x8x62x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x8x62x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x8x62x62xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 62, 1], ["%arg6", 0, 62, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 248567332}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<1024x16x7x7xf32>) outs (%init: tensor<4x1024x29x29xf32>) -> tensor<4x1024x29x29xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<1024x16x7x7xf32>) outs (%init: tensor<4x1024x29x29xf32>) -> tensor<4x1024x29x29xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x64x64xf32>, %filter: tensor<1024x16x7x7xf32>, %init: tensor<4x1024x29x29xf32>) -> tensor<4x1024x29x29xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<1024x16x7x7xf32>) outs (%init: tensor<4x1024x29x29xf32>) -> tensor<4x1024x29x29xf32>\n  return %ret : tensor<4x1024x29x29xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x64x64xf32>, %arg1: tensor<1024x16x7x7xf32>, %arg2: tensor<4x1024x29x29xf32>) -> tensor<4x1024x29x29xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x16x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x1024x29x29xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x1024x29x29xf32>\n    memref.copy %2, %alloc : memref<4x1024x29x29xf32> to memref<4x1024x29x29xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 29 {\n          affine.for %arg6 = 0 to 29 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x16x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x29x29xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x29x29xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x1024x29x29xf32>\n    return %3 : tensor<4x1024x29x29xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x1024x29x29xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x64x64xf32>) -> tensor<4x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x16x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x16x7x7xf32>) -> tensor<1024x16x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x1024x29x29xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x1024x29x29xf32>) -> tensor<4x1024x29x29xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<1024x16x7x7xf32>) outs (%init: tensor<4x1024x29x29xf32>) -> tensor<4x1024x29x29xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x1024x29x29xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x1024x29x29xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 29, 1], ["%arg6", 0, 29, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 10202090850}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x512x64x64xf32>, tensor<8x512x3x3xf32>) outs (%init: tensor<8x8x31x31xf32>) -> tensor<8x8x31x31xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x512x64x64xf32>, tensor<8x512x3x3xf32>) outs (%init: tensor<8x8x31x31xf32>) -> tensor<8x8x31x31xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x512x64x64xf32>, %filter: tensor<8x512x3x3xf32>, %init: tensor<8x8x31x31xf32>) -> tensor<8x8x31x31xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x512x64x64xf32>, tensor<8x512x3x3xf32>) outs (%init: tensor<8x8x31x31xf32>) -> tensor<8x8x31x31xf32>\n  return %ret : tensor<8x8x31x31xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x512x64x64xf32>, %arg1: tensor<8x512x3x3xf32>, %arg2: tensor<8x8x31x31xf32>) -> tensor<8x8x31x31xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x512x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x512x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x31x31xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x31x31xf32>\n    memref.copy %2, %alloc : memref<8x8x31x31xf32> to memref<8x8x31x31xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 31 {\n          affine.for %arg6 = 0 to 31 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x512x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x512x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x31x31xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x31x31xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x31x31xf32>\n    return %3 : tensor<8x8x31x31xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x31x31xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x512x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x512x64x64xf32>) -> tensor<8x512x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x512x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x512x3x3xf32>) -> tensor<8x512x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x31x31xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x31x31xf32>) -> tensor<8x8x31x31xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x512x64x64xf32>, tensor<8x512x3x3xf32>) outs (%init: tensor<8x8x31x31xf32>) -> tensor<8x8x31x31xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x31x31xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x31x31xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 31, 1], ["%arg6", 0, 31, 1], ["%arg7", 0, 512, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1116243519}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x16x16xf32>) -> tensor<16x8x16x16xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x16x16xf32>) -> tensor<16x8x16x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x32x32xf32>, %filter: tensor<8x8x1x1xf32>, %init: tensor<16x8x16x16xf32>) -> tensor<16x8x16x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x16x16xf32>) -> tensor<16x8x16x16xf32>\n  return %ret : tensor<16x8x16x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x32x32xf32>, %arg1: tensor<8x8x1x1xf32>, %arg2: tensor<16x8x16x16xf32>) -> tensor<16x8x16x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x16x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x16x16xf32>\n    memref.copy %2, %alloc : memref<16x8x16x16xf32> to memref<16x8x16x16xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 16 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x16x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x16x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x16x16xf32>\n    return %3 : tensor<16x8x16x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x16x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x32x32xf32>) -> tensor<16x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x1x1xf32>) -> tensor<8x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x16x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x16x16xf32>) -> tensor<16x8x16x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<8x8x1x1xf32>) outs (%init: tensor<16x8x16x16xf32>) -> tensor<16x8x16x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x16x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x16x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 16, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 396476}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x128x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<64x64x64x64xf32>) -> tensor<64x64x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x128x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<64x64x64x64xf32>) -> tensor<64x64x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x128x128x128xf32>, %filter: tensor<64x128x1x1xf32>, %init: tensor<64x64x64x64xf32>) -> tensor<64x64x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x128x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<64x64x64x64xf32>) -> tensor<64x64x64x64xf32>\n  return %ret : tensor<64x64x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x128x128x128xf32>, %arg1: tensor<64x128x1x1xf32>, %arg2: tensor<64x64x64x64xf32>) -> tensor<64x64x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x128x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64x64x64xf32>\n    memref.copy %2, %alloc : memref<64x64x64x64xf32> to memref<64x64x64x64xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x128x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x64x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x64x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64x64x64xf32>\n    return %3 : tensor<64x64x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x128x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x128x128x128xf32>) -> tensor<64x128x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x128x1x1xf32>) -> tensor<64x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x64x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x64x64x64xf32>) -> tensor<64x64x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x128x128x128xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<64x64x64x64xf32>) -> tensor<64x64x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 7855480825}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x64x64xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x64x64xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x256x64x64xf32>, %filter: tensor<32x256x1x1xf32>, %init: tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x64x64xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32>\n  return %ret : tensor<16x32x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x256x64x64xf32>, %arg1: tensor<32x256x1x1xf32>, %arg2: tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x256x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x32x32xf32>\n    memref.copy %2, %alloc : memref<16x32x32x32xf32> to memref<16x32x32x32xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x256x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x32x32xf32>\n    return %3 : tensor<16x32x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x256x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x256x64x64xf32>) -> tensor<16x256x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x256x1x1xf32>) -> tensor<32x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x256x64x64xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 508838802}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x256xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x256xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x8x256x256xf32>, %filter: tensor<8x8x5x5xf32>, %init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x256xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>\n  return %ret : tensor<8x8x126x126xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x8x256x256xf32>, %arg1: tensor<8x8x5x5xf32>, %arg2: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x8x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x126x126xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x126x126xf32>\n    memref.copy %2, %alloc : memref<8x8x126x126xf32> to memref<8x8x126x126xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 126 {\n          affine.for %arg6 = 0 to 126 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x8x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x126x126xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x126x126xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x126x126xf32>\n    return %3 : tensor<8x8x126x126xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x126x126xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x8x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x8x256x256xf32>) -> tensor<8x8x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x5x5xf32>) -> tensor<8x8x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x126x126xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x256x256xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<8x8x126x126xf32>) -> tensor<8x8x126x126xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x126x126xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x126x126xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 126, 1], ["%arg6", 0, 126, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 754326919}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<64x16x63x63xf32>) -> tensor<64x16x63x63xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<64x16x63x63xf32>) -> tensor<64x16x63x63xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x64x128x128xf32>, %filter: tensor<16x64x3x3xf32>, %init: tensor<64x16x63x63xf32>) -> tensor<64x16x63x63xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<64x16x63x63xf32>) -> tensor<64x16x63x63xf32>\n  return %ret : tensor<64x16x63x63xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x64x128x128xf32>, %arg1: tensor<16x64x3x3xf32>, %arg2: tensor<64x16x63x63xf32>) -> tensor<64x16x63x63xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x64x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x63x63xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x63x63xf32>\n    memref.copy %2, %alloc : memref<64x16x63x63xf32> to memref<64x16x63x63xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 63 {\n          affine.for %arg6 = 0 to 63 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x64x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x63x63xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x63x63xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x63x63xf32>\n    return %3 : tensor<64x16x63x63xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x63x63xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x64x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x64x128x128xf32>) -> tensor<64x64x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x3x3xf32>) -> tensor<16x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x63x63xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x63x63xf32>) -> tensor<64x16x63x63xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x64x128x128xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<64x16x63x63xf32>) -> tensor<64x16x63x63xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x63x63xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x63x63xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 63, 1], ["%arg6", 0, 63, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 8981388688}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x32x32xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x32x32xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x64x32x32xf32>, %filter: tensor<512x64x1x1xf32>, %init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x32x32xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>\n  return %ret : tensor<32x512x16x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x64x32x32xf32>, %arg1: tensor<512x64x1x1xf32>, %arg2: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512x16x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512x16x16xf32>\n    memref.copy %2, %alloc : memref<32x512x16x16xf32> to memref<32x512x16x16xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 16 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x512x16x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x512x16x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512x16x16xf32>\n    return %3 : tensor<32x512x16x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512x16x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x64x32x32xf32>) -> tensor<32x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x64x1x1xf32>) -> tensor<512x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x512x16x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x32x32xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512x16x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512x16x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 16, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 814586333}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<64x32x14x14xf32>) -> tensor<64x32x14x14xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<64x32x14x14xf32>) -> tensor<64x32x14x14xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x32x32x32xf32>, %filter: tensor<32x32x5x5xf32>, %init: tensor<64x32x14x14xf32>) -> tensor<64x32x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<64x32x14x14xf32>) -> tensor<64x32x14x14xf32>\n  return %ret : tensor<64x32x14x14xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x32x32x32xf32>, %arg1: tensor<32x32x5x5xf32>, %arg2: tensor<64x32x14x14xf32>) -> tensor<64x32x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32x14x14xf32>\n    memref.copy %2, %alloc : memref<64x32x14x14xf32> to memref<64x32x14x14xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32x14x14xf32>\n    return %3 : tensor<64x32x14x14xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x32x32x32xf32>) -> tensor<64x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x5x5xf32>) -> tensor<32x32x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x32x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x32x14x14xf32>) -> tensor<64x32x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x32x32xf32>, tensor<32x32x5x5xf32>) outs (%init: tensor<64x32x14x14xf32>) -> tensor<64x32x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32x14x14xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 14, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1216939850}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<64x1024x3x3xf32>) outs (%init: tensor<4x64x31x31xf32>) -> tensor<4x64x31x31xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<64x1024x3x3xf32>) outs (%init: tensor<4x64x31x31xf32>) -> tensor<4x64x31x31xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x1024x64x64xf32>, %filter: tensor<64x1024x3x3xf32>, %init: tensor<4x64x31x31xf32>) -> tensor<4x64x31x31xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<64x1024x3x3xf32>) outs (%init: tensor<4x64x31x31xf32>) -> tensor<4x64x31x31xf32>\n  return %ret : tensor<4x64x31x31xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x1024x64x64xf32>, %arg1: tensor<64x1024x3x3xf32>, %arg2: tensor<4x64x31x31xf32>) -> tensor<4x64x31x31xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x1024x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x1024x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x64x31x31xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x64x31x31xf32>\n    memref.copy %2, %alloc : memref<4x64x31x31xf32> to memref<4x64x31x31xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 31 {\n          affine.for %arg6 = 0 to 31 {\n            affine.for %arg7 = 0 to 1024 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x1024x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x1024x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x31x31xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x31x31xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x64x31x31xf32>\n    return %3 : tensor<4x64x31x31xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x64x31x31xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x1024x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x1024x64x64xf32>) -> tensor<4x1024x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x1024x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x1024x3x3xf32>) -> tensor<64x1024x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x64x31x31xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x64x31x31xf32>) -> tensor<4x64x31x31xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x1024x64x64xf32>, tensor<64x1024x3x3xf32>) outs (%init: tensor<4x64x31x31xf32>) -> tensor<4x64x31x31xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x64x31x31xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x64x31x31xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 31, 1], ["%arg6", 0, 31, 1], ["%arg7", 0, 1024, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 9357699985}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<256x32x31x31xf32>) -> tensor<256x32x31x31xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<256x32x31x31xf32>) -> tensor<256x32x31x31xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x16x64x64xf32>, %filter: tensor<32x16x3x3xf32>, %init: tensor<256x32x31x31xf32>) -> tensor<256x32x31x31xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<256x32x31x31xf32>) -> tensor<256x32x31x31xf32>\n  return %ret : tensor<256x32x31x31xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x16x64x64xf32>, %arg1: tensor<32x16x3x3xf32>, %arg2: tensor<256x32x31x31xf32>) -> tensor<256x32x31x31xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x31x31xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x31x31xf32>\n    memref.copy %2, %alloc : memref<256x32x31x31xf32> to memref<256x32x31x31xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 31 {\n          affine.for %arg6 = 0 to 31 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x31x31xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x31x31xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x31x31xf32>\n    return %3 : tensor<256x32x31x31xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x31x31xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x16x64x64xf32>) -> tensor<256x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x16x3x3xf32>) -> tensor<32x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x31x31xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x31x31xf32>) -> tensor<256x32x31x31xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<256x32x31x31xf32>) -> tensor<256x32x31x31xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x31x31xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x31x31xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 31, 1], ["%arg6", 0, 31, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4554549626}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<256x8x5x5xf32>) outs (%init: tensor<16x256x14x14xf32>) -> tensor<16x256x14x14xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<256x8x5x5xf32>) outs (%init: tensor<16x256x14x14xf32>) -> tensor<16x256x14x14xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x32x32xf32>, %filter: tensor<256x8x5x5xf32>, %init: tensor<16x256x14x14xf32>) -> tensor<16x256x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<256x8x5x5xf32>) outs (%init: tensor<16x256x14x14xf32>) -> tensor<16x256x14x14xf32>\n  return %ret : tensor<16x256x14x14xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x32x32xf32>, %arg1: tensor<256x8x5x5xf32>, %arg2: tensor<16x256x14x14xf32>) -> tensor<16x256x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x8x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x256x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x256x14x14xf32>\n    memref.copy %2, %alloc : memref<16x256x14x14xf32> to memref<16x256x14x14xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x8x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x256x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x256x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x256x14x14xf32>\n    return %3 : tensor<16x256x14x14xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x256x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x32x32xf32>) -> tensor<16x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x8x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x8x5x5xf32>) -> tensor<256x8x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x256x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x256x14x14xf32>) -> tensor<16x256x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<256x8x5x5xf32>) outs (%init: tensor<16x256x14x14xf32>) -> tensor<16x256x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x256x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x256x14x14xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 14, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 685129803}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x32x32x32xf32>, %filter: tensor<32x32x1x1xf32>, %init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n  return %ret : tensor<4x32x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x32x32x32xf32>, %arg1: tensor<32x32x1x1xf32>, %arg2: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x32x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x32x32x32xf32>\n    memref.copy %2, %alloc : memref<4x32x32x32xf32> to memref<4x32x32x32xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x32x32x32xf32>\n    return %3 : tensor<4x32x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x32x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x1x1xf32>) -> tensor<32x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x32x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x32x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x32x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 9998141}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x128xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x128xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x256x128x128xf32>, %filter: tensor<256x256x1x1xf32>, %init: tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x128xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32>\n  return %ret : tensor<4x256x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x256x128x128xf32>, %arg1: tensor<256x256x1x1xf32>, %arg2: tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x256x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x256x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x256x64x64xf32>\n    memref.copy %2, %alloc : memref<4x256x64x64xf32> to memref<4x256x64x64xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x256x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x256x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x256x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x256x64x64xf32>\n    return %3 : tensor<4x256x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x256x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x256x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x256x128x128xf32>) -> tensor<4x256x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x256x1x1xf32>) -> tensor<256x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x256x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x128x128xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x256x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x256x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4310940580}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<16x8x1x1xf32>) outs (%init: tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<16x8x1x1xf32>) outs (%init: tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x8x64x64xf32>, %filter: tensor<16x8x1x1xf32>, %init: tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<16x8x1x1xf32>) outs (%init: tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32>\n  return %ret : tensor<8x16x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x8x64x64xf32>, %arg1: tensor<16x8x1x1xf32>, %arg2: tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x16x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x16x32x32xf32>\n    memref.copy %2, %alloc : memref<8x16x32x32xf32> to memref<8x16x32x32xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x16x32x32xf32>\n    return %3 : tensor<8x16x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x16x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x8x64x64xf32>) -> tensor<8x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x8x1x1xf32>) -> tensor<16x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x16x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<16x8x1x1xf32>) outs (%init: tensor<8x16x32x32xf32>) -> tensor<8x16x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x16x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x16x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1620586}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<64x64x13x13xf32>) -> tensor<64x64x13x13xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<64x64x13x13xf32>) -> tensor<64x64x13x13xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x32x32xf32>, %filter: tensor<64x8x7x7xf32>, %init: tensor<64x64x13x13xf32>) -> tensor<64x64x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<64x64x13x13xf32>) -> tensor<64x64x13x13xf32>\n  return %ret : tensor<64x64x13x13xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x32x32xf32>, %arg1: tensor<64x8x7x7xf32>, %arg2: tensor<64x64x13x13xf32>) -> tensor<64x64x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x8x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x64x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x64x13x13xf32>\n    memref.copy %2, %alloc : memref<64x64x13x13xf32> to memref<64x64x13x13xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x8x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x64x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x64x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x64x13x13xf32>\n    return %3 : tensor<64x64x13x13xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x64x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x32x32xf32>) -> tensor<64x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x8x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x8x7x7xf32>) -> tensor<64x8x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x64x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x64x13x13xf32>) -> tensor<64x64x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<64x8x7x7xf32>) outs (%init: tensor<64x64x13x13xf32>) -> tensor<64x64x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x64x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x64x13x13xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 13, 1], ["%arg6", 0, 13, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1017516091}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x32x32xf32>, tensor<128x32x7x7xf32>) outs (%init: tensor<32x128x13x13xf32>) -> tensor<32x128x13x13xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x32x32xf32>, tensor<128x32x7x7xf32>) outs (%init: tensor<32x128x13x13xf32>) -> tensor<32x128x13x13xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x32x32x32xf32>, %filter: tensor<128x32x7x7xf32>, %init: tensor<32x128x13x13xf32>) -> tensor<32x128x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x32x32xf32>, tensor<128x32x7x7xf32>) outs (%init: tensor<32x128x13x13xf32>) -> tensor<32x128x13x13xf32>\n  return %ret : tensor<32x128x13x13xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x32x32x32xf32>, %arg1: tensor<128x32x7x7xf32>, %arg2: tensor<32x128x13x13xf32>) -> tensor<32x128x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128x13x13xf32>\n    memref.copy %2, %alloc : memref<32x128x13x13xf32> to memref<32x128x13x13xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x32x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x128x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x128x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128x13x13xf32>\n    return %3 : tensor<32x128x13x13xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x32x32x32xf32>) -> tensor<32x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x32x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x32x7x7xf32>) -> tensor<128x32x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x128x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x128x13x13xf32>) -> tensor<32x128x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x32x32x32xf32>, tensor<128x32x7x7xf32>) outs (%init: tensor<32x128x13x13xf32>) -> tensor<32x128x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128x13x13xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 13, 1], ["%arg6", 0, 13, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4111051548}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x128x128xf32>) -> tensor<16x256x128x128xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x128x128xf32>) -> tensor<16x256x128x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x256x256xf32>, %filter: tensor<256x8x1x1xf32>, %init: tensor<16x256x128x128xf32>) -> tensor<16x256x128x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x128x128xf32>) -> tensor<16x256x128x128xf32>\n  return %ret : tensor<16x256x128x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x256x256xf32>, %arg1: tensor<256x8x1x1xf32>, %arg2: tensor<16x256x128x128xf32>) -> tensor<16x256x128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x256x128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x256x128x128xf32>\n    memref.copy %2, %alloc : memref<16x256x128x128xf32> to memref<16x256x128x128xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x256x128x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x256x128x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x256x128x128xf32>\n    return %3 : tensor<16x256x128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x256x128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x256x256xf32>) -> tensor<16x8x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x8x1x1xf32>) -> tensor<256x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x256x128x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x256x128x128xf32>) -> tensor<16x256x128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x256x256xf32>, tensor<256x8x1x1xf32>) outs (%init: tensor<16x256x128x128xf32>) -> tensor<16x256x128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x256x128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x256x128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 833792661}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<512x16x3x3xf32>) outs (%init: tensor<4x512x31x31xf32>) -> tensor<4x512x31x31xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<512x16x3x3xf32>) outs (%init: tensor<4x512x31x31xf32>) -> tensor<4x512x31x31xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x64x64xf32>, %filter: tensor<512x16x3x3xf32>, %init: tensor<4x512x31x31xf32>) -> tensor<4x512x31x31xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<512x16x3x3xf32>) outs (%init: tensor<4x512x31x31xf32>) -> tensor<4x512x31x31xf32>\n  return %ret : tensor<4x512x31x31xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x64x64xf32>, %arg1: tensor<512x16x3x3xf32>, %arg2: tensor<4x512x31x31xf32>) -> tensor<4x512x31x31xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x512x31x31xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x512x31x31xf32>\n    memref.copy %2, %alloc : memref<4x512x31x31xf32> to memref<4x512x31x31xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 31 {\n          affine.for %arg6 = 0 to 31 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x31x31xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x31x31xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x512x31x31xf32>\n    return %3 : tensor<4x512x31x31xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x512x31x31xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x64x64xf32>) -> tensor<4x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x16x3x3xf32>) -> tensor<512x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x512x31x31xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x512x31x31xf32>) -> tensor<4x512x31x31xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x64x64xf32>, tensor<512x16x3x3xf32>) outs (%init: tensor<4x512x31x31xf32>) -> tensor<4x512x31x31xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x512x31x31xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x512x31x31xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 31, 1], ["%arg6", 0, 31, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1050295538}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<4x16x26x26xf32>) -> tensor<4x16x26x26xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<4x16x26x26xf32>) -> tensor<4x16x26x26xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x32x32xf32>, %filter: tensor<16x64x7x7xf32>, %init: tensor<4x16x26x26xf32>) -> tensor<4x16x26x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<4x16x26x26xf32>) -> tensor<4x16x26x26xf32>\n  return %ret : tensor<4x16x26x26xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x32x32xf32>, %arg1: tensor<16x64x7x7xf32>, %arg2: tensor<4x16x26x26xf32>) -> tensor<4x16x26x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x16x26x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x16x26x26xf32>\n    memref.copy %2, %alloc : memref<4x16x26x26xf32> to memref<4x16x26x26xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x16x26x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x16x26x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x16x26x26xf32>\n    return %3 : tensor<4x16x26x26xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x16x26x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x32x32xf32>) -> tensor<4x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x7x7xf32>) -> tensor<16x64x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x16x26x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x16x26x26xf32>) -> tensor<4x16x26x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<16x64x7x7xf32>) outs (%init: tensor<4x16x26x26xf32>) -> tensor<4x16x26x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x16x26x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x16x26x26xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 26, 1], ["%arg6", 0, 26, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 515949248}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<32x16x32x32xf32>) -> tensor<32x16x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<32x16x32x32xf32>) -> tensor<32x16x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x256x32x32xf32>, %filter: tensor<16x256x1x1xf32>, %init: tensor<32x16x32x32xf32>) -> tensor<32x16x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<32x16x32x32xf32>) -> tensor<32x16x32x32xf32>\n  return %ret : tensor<32x16x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x256x32x32xf32>, %arg1: tensor<16x256x1x1xf32>, %arg2: tensor<32x16x32x32xf32>) -> tensor<32x16x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x16x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x16x32x32xf32>\n    memref.copy %2, %alloc : memref<32x16x32x32xf32> to memref<32x16x32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x256x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x16x32x32xf32>\n    return %3 : tensor<32x16x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x16x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x256x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x256x32x32xf32>) -> tensor<32x256x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x256x1x1xf32>) -> tensor<16x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x16x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x16x32x32xf32>) -> tensor<32x16x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<16x256x1x1xf32>) outs (%init: tensor<32x16x32x32xf32>) -> tensor<32x16x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x16x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x16x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 535222116}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<32x16x28x28xf32>) -> tensor<32x16x28x28xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<32x16x28x28xf32>) -> tensor<32x16x28x28xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x8x32x32xf32>, %filter: tensor<16x8x5x5xf32>, %init: tensor<32x16x28x28xf32>) -> tensor<32x16x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<32x16x28x28xf32>) -> tensor<32x16x28x28xf32>\n  return %ret : tensor<32x16x28x28xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x8x32x32xf32>, %arg1: tensor<16x8x5x5xf32>, %arg2: tensor<32x16x28x28xf32>) -> tensor<32x16x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x8x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x16x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x16x28x28xf32>\n    memref.copy %2, %alloc : memref<32x16x28x28xf32> to memref<32x16x28x28xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x8x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x16x28x28xf32>\n    return %3 : tensor<32x16x28x28xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x16x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x8x32x32xf32>) -> tensor<32x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x8x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x8x5x5xf32>) -> tensor<16x8x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x16x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x16x28x28xf32>) -> tensor<32x16x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<16x8x5x5xf32>) outs (%init: tensor<32x16x28x28xf32>) -> tensor<32x16x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x16x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x16x28x28xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 28, 1], ["%arg6", 0, 28, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 297292291}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x64x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<16x32x62x62xf32>) -> tensor<16x32x62x62xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x64x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<16x32x62x62xf32>) -> tensor<16x32x62x62xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x32x64x64xf32>, %filter: tensor<32x32x3x3xf32>, %init: tensor<16x32x62x62xf32>) -> tensor<16x32x62x62xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x64x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<16x32x62x62xf32>) -> tensor<16x32x62x62xf32>\n  return %ret : tensor<16x32x62x62xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x32x64x64xf32>, %arg1: tensor<32x32x3x3xf32>, %arg2: tensor<16x32x62x62xf32>) -> tensor<16x32x62x62xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x32x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x62x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x62x62xf32>\n    memref.copy %2, %alloc : memref<16x32x62x62xf32> to memref<16x32x62x62xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x32x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x62x62xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x62x62xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x62x62xf32>\n    return %3 : tensor<16x32x62x62xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x62x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x32x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x3x3xf32>) -> tensor<32x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x62x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x62x62xf32>) -> tensor<16x32x62x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x64x64xf32>, tensor<32x32x3x3xf32>) outs (%init: tensor<16x32x62x62xf32>) -> tensor<16x32x62x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x62x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x62x62xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 62, 1], ["%arg6", 0, 62, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2174526697}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x32x32xf32>, tensor<8x256x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x32x32xf32>, tensor<8x256x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x256x32x32xf32>, %filter: tensor<8x256x3x3xf32>, %init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x32x32xf32>, tensor<8x256x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>\n  return %ret : tensor<8x8x15x15xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x256x32x32xf32>, %arg1: tensor<8x256x3x3xf32>, %arg2: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x256x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x256x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x15x15xf32>\n    memref.copy %2, %alloc : memref<8x8x15x15xf32> to memref<8x8x15x15xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x256x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x256x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x15x15xf32>\n    return %3 : tensor<8x8x15x15xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x256x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x256x32x32xf32>) -> tensor<8x256x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x256x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x256x3x3xf32>) -> tensor<8x256x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x256x32x32xf32>, tensor<8x256x3x3xf32>) outs (%init: tensor<8x8x15x15xf32>) -> tensor<8x8x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x15x15xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 15, 1], ["%arg6", 0, 15, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 129054182}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x7x7xf32>) outs (%init: tensor<8x16x61x61xf32>) -> tensor<8x16x61x61xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x7x7xf32>) outs (%init: tensor<8x16x61x61xf32>) -> tensor<8x16x61x61xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x128x128xf32>, %filter: tensor<16x16x7x7xf32>, %init: tensor<8x16x61x61xf32>) -> tensor<8x16x61x61xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x7x7xf32>) outs (%init: tensor<8x16x61x61xf32>) -> tensor<8x16x61x61xf32>\n  return %ret : tensor<8x16x61x61xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x128x128xf32>, %arg1: tensor<16x16x7x7xf32>, %arg2: tensor<8x16x61x61xf32>) -> tensor<8x16x61x61xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x16x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x16x61x61xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x16x61x61xf32>\n    memref.copy %2, %alloc : memref<8x16x61x61xf32> to memref<8x16x61x61xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 61 {\n          affine.for %arg6 = 0 to 61 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x16x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x61x61xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x61x61xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x16x61x61xf32>\n    return %3 : tensor<8x16x61x61xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x16x61x61xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x128x128xf32>) -> tensor<8x16x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x16x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x16x7x7xf32>) -> tensor<16x16x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x16x61x61xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x16x61x61xf32>) -> tensor<8x16x61x61xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x7x7xf32>) outs (%init: tensor<8x16x61x61xf32>) -> tensor<8x16x61x61xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x16x61x61xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x16x61x61xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 61, 1], ["%arg6", 0, 61, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1416323092}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<1024x8x3x3xf32>) outs (%init: tensor<32x1024x30x30xf32>) -> tensor<32x1024x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<1024x8x3x3xf32>) outs (%init: tensor<32x1024x30x30xf32>) -> tensor<32x1024x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x8x32x32xf32>, %filter: tensor<1024x8x3x3xf32>, %init: tensor<32x1024x30x30xf32>) -> tensor<32x1024x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<1024x8x3x3xf32>) outs (%init: tensor<32x1024x30x30xf32>) -> tensor<32x1024x30x30xf32>\n  return %ret : tensor<32x1024x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x8x32x32xf32>, %arg1: tensor<1024x8x3x3xf32>, %arg2: tensor<32x1024x30x30xf32>) -> tensor<32x1024x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x1024x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x1024x30x30xf32>\n    memref.copy %2, %alloc : memref<32x1024x30x30xf32> to memref<32x1024x30x30xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x1024x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x1024x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x1024x30x30xf32>\n    return %3 : tensor<32x1024x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x1024x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x8x32x32xf32>) -> tensor<32x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x8x3x3xf32>) -> tensor<1024x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x1024x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x1024x30x30xf32>) -> tensor<32x1024x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x32x32xf32>, tensor<1024x8x3x3xf32>) outs (%init: tensor<32x1024x30x30xf32>) -> tensor<32x1024x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x1024x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x1024x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 7982133604}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x32x32xf32>, %filter: tensor<8x64x1x1xf32>, %init: tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32>\n  return %ret : tensor<8x8x16x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x32x32xf32>, %arg1: tensor<8x64x1x1xf32>, %arg2: tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x16x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x16x16xf32>\n    memref.copy %2, %alloc : memref<8x8x16x16xf32> to memref<8x8x16x16xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 16 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x16x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x16x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x16x16xf32>\n    return %3 : tensor<8x8x16x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x16x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x1x1xf32>) -> tensor<8x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x16x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<8x64x1x1xf32>) outs (%init: tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x16x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x16x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 16, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3431631}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<256x8x30x30xf32>) -> tensor<256x8x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<256x8x30x30xf32>) -> tensor<256x8x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x16x64x64xf32>, %filter: tensor<8x16x5x5xf32>, %init: tensor<256x8x30x30xf32>) -> tensor<256x8x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<256x8x30x30xf32>) -> tensor<256x8x30x30xf32>\n  return %ret : tensor<256x8x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x16x64x64xf32>, %arg1: tensor<8x16x5x5xf32>, %arg2: tensor<256x8x30x30xf32>) -> tensor<256x8x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x8x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x8x30x30xf32>\n    memref.copy %2, %alloc : memref<256x8x30x30xf32> to memref<256x8x30x30xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x8x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x8x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x8x30x30xf32>\n    return %3 : tensor<256x8x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x8x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x16x64x64xf32>) -> tensor<256x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x5x5xf32>) -> tensor<8x16x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x8x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x8x30x30xf32>) -> tensor<256x8x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<256x8x30x30xf32>) -> tensor<256x8x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x8x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x8x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2780988903}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<32x8x61x61xf32>) -> tensor<32x8x61x61xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<32x8x61x61xf32>) -> tensor<32x8x61x61xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x8x128x128xf32>, %filter: tensor<8x8x7x7xf32>, %init: tensor<32x8x61x61xf32>) -> tensor<32x8x61x61xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<32x8x61x61xf32>) -> tensor<32x8x61x61xf32>\n  return %ret : tensor<32x8x61x61xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x8x128x128xf32>, %arg1: tensor<8x8x7x7xf32>, %arg2: tensor<32x8x61x61xf32>) -> tensor<32x8x61x61xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x8x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x8x61x61xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x8x61x61xf32>\n    memref.copy %2, %alloc : memref<32x8x61x61xf32> to memref<32x8x61x61xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 61 {\n          affine.for %arg6 = 0 to 61 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x8x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x61x61xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x8x61x61xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x8x61x61xf32>\n    return %3 : tensor<32x8x61x61xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x8x61x61xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x8x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x8x128x128xf32>) -> tensor<32x8x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x7x7xf32>) -> tensor<8x8x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x8x61x61xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x8x61x61xf32>) -> tensor<32x8x61x61xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<32x8x61x61xf32>) -> tensor<32x8x61x61xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x8x61x61xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x8x61x61xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 61, 1], ["%arg6", 0, 61, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1575967765}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<16x512x30x30xf32>) -> tensor<16x512x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<16x512x30x30xf32>) -> tensor<16x512x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x32x32xf32>, %filter: tensor<512x8x3x3xf32>, %init: tensor<16x512x30x30xf32>) -> tensor<16x512x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<16x512x30x30xf32>) -> tensor<16x512x30x30xf32>\n  return %ret : tensor<16x512x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x32x32xf32>, %arg1: tensor<512x8x3x3xf32>, %arg2: tensor<16x512x30x30xf32>) -> tensor<16x512x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x512x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x512x30x30xf32>\n    memref.copy %2, %alloc : memref<16x512x30x30xf32> to memref<16x512x30x30xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x512x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x512x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x512x30x30xf32>\n    return %3 : tensor<16x512x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x512x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x32x32xf32>) -> tensor<16x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x8x3x3xf32>) -> tensor<512x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x512x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x512x30x30xf32>) -> tensor<16x512x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x32x32xf32>, tensor<512x8x3x3xf32>) outs (%init: tensor<16x512x30x30xf32>) -> tensor<16x512x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x512x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x512x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2100262223}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x64x128x128xf32>, %filter: tensor<32x64x1x1xf32>, %init: tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32>\n  return %ret : tensor<16x32x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x64x128x128xf32>, %arg1: tensor<32x64x1x1xf32>, %arg2: tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x64x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x64x64xf32>\n    memref.copy %2, %alloc : memref<16x32x64x64xf32> to memref<16x32x64x64xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x64x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x64x64xf32>\n    return %3 : tensor<16x32x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x64x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x64x128x128xf32>) -> tensor<16x64x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x64x1x1xf32>) -> tensor<32x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x64x128x128xf32>, tensor<32x64x1x1xf32>) outs (%init: tensor<16x32x64x64xf32>) -> tensor<16x32x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 458490342}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x128x128xf32>, %filter: tensor<8x16x1x1xf32>, %init: tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32>\n  return %ret : tensor<4x8x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x128x128xf32>, %arg1: tensor<8x16x1x1xf32>, %arg2: tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x64x64xf32>\n    memref.copy %2, %alloc : memref<4x8x64x64xf32> to memref<4x8x64x64xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x64x64xf32>\n    return %3 : tensor<4x8x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x128x128xf32>) -> tensor<4x16x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x1x1xf32>) -> tensor<8x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x1x1xf32>) outs (%init: tensor<4x8x64x64xf32>) -> tensor<4x8x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4828389}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x64x64xf32>, tensor<128x64x1x1xf32>) outs (%init: tensor<32x128x32x32xf32>) -> tensor<32x128x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x64x64xf32>, tensor<128x64x1x1xf32>) outs (%init: tensor<32x128x32x32xf32>) -> tensor<32x128x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x64x64x64xf32>, %filter: tensor<128x64x1x1xf32>, %init: tensor<32x128x32x32xf32>) -> tensor<32x128x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x64x64xf32>, tensor<128x64x1x1xf32>) outs (%init: tensor<32x128x32x32xf32>) -> tensor<32x128x32x32xf32>\n  return %ret : tensor<32x128x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x64x64x64xf32>, %arg1: tensor<128x64x1x1xf32>, %arg2: tensor<32x128x32x32xf32>) -> tensor<32x128x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x128x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x128x32x32xf32>\n    memref.copy %2, %alloc : memref<32x128x32x32xf32> to memref<32x128x32x32xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x64x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x128x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x128x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x128x32x32xf32>\n    return %3 : tensor<32x128x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x128x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x64x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x64x64x64xf32>) -> tensor<32x64x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x64x1x1xf32>) -> tensor<128x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x128x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x128x32x32xf32>) -> tensor<32x128x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x64x64xf32>, tensor<128x64x1x1xf32>) outs (%init: tensor<32x128x32x32xf32>) -> tensor<32x128x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x128x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x128x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 883795147}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<512x128x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<512x128x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x128x32x32xf32>, %filter: tensor<512x128x3x3xf32>, %init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<512x128x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>\n  return %ret : tensor<4x512x15x15xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x128x32x32xf32>, %arg1: tensor<512x128x3x3xf32>, %arg2: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x128x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x512x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x512x15x15xf32>\n    memref.copy %2, %alloc : memref<4x512x15x15xf32> to memref<4x512x15x15xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x128x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x512x15x15xf32>\n    return %3 : tensor<4x512x15x15xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x512x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x128x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x128x32x32xf32>) -> tensor<4x128x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x128x3x3xf32>) -> tensor<512x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x512x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x128x32x32xf32>, tensor<512x128x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x512x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x512x15x15xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 15, 1], ["%arg6", 0, 15, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2050515541}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x512x512xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x512x512xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x32x512x512xf32>, %filter: tensor<32x32x1x1xf32>, %init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x512x512xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>\n  return %ret : tensor<16x32x256x256xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x32x512x512xf32>, %arg1: tensor<32x32x1x1xf32>, %arg2: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x32x512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x256x256xf32>\n    memref.copy %2, %alloc : memref<16x32x256x256xf32> to memref<16x32x256x256xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 256 {\n          affine.for %arg6 = 0 to 256 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x32x512x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x256x256xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x256x256xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x256x256xf32>\n    return %3 : tensor<16x32x256x256xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x32x512x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x32x512x512xf32>) -> tensor<16x32x512x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x32x1x1xf32>) -> tensor<32x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x256x256xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x512x512xf32>, tensor<32x32x1x1xf32>) outs (%init: tensor<16x32x256x256xf32>) -> tensor<16x32x256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x256x256xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 256, 1], ["%arg6", 0, 256, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3521208272}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x256x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<32x16x128x128xf32>) -> tensor<32x16x128x128xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x256x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<32x16x128x128xf32>) -> tensor<32x16x128x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x64x256x256xf32>, %filter: tensor<16x64x1x1xf32>, %init: tensor<32x16x128x128xf32>) -> tensor<32x16x128x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x256x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<32x16x128x128xf32>) -> tensor<32x16x128x128xf32>\n  return %ret : tensor<32x16x128x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x64x256x256xf32>, %arg1: tensor<16x64x1x1xf32>, %arg2: tensor<32x16x128x128xf32>) -> tensor<32x16x128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x64x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x16x128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x16x128x128xf32>\n    memref.copy %2, %alloc : memref<32x16x128x128xf32> to memref<32x16x128x128xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x64x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x128x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x16x128x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x16x128x128xf32>\n    return %3 : tensor<32x16x128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x16x128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x64x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x64x256x256xf32>) -> tensor<32x64x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x1x1xf32>) -> tensor<16x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x16x128x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x16x128x128xf32>) -> tensor<32x16x128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x64x256x256xf32>, tensor<16x64x1x1xf32>) outs (%init: tensor<32x16x128x128xf32>) -> tensor<32x16x128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x16x128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x16x128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1982575511}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<16x8x61x61xf32>) -> tensor<16x8x61x61xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<16x8x61x61xf32>) -> tensor<16x8x61x61xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x8x128x128xf32>, %filter: tensor<8x8x7x7xf32>, %init: tensor<16x8x61x61xf32>) -> tensor<16x8x61x61xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<16x8x61x61xf32>) -> tensor<16x8x61x61xf32>\n  return %ret : tensor<16x8x61x61xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x8x128x128xf32>, %arg1: tensor<8x8x7x7xf32>, %arg2: tensor<16x8x61x61xf32>) -> tensor<16x8x61x61xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x8x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x61x61xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x61x61xf32>\n    memref.copy %2, %alloc : memref<16x8x61x61xf32> to memref<16x8x61x61xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 61 {\n          affine.for %arg6 = 0 to 61 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x8x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x61x61xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x61x61xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x61x61xf32>\n    return %3 : tensor<16x8x61x61xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x61x61xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x8x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x8x128x128xf32>) -> tensor<16x8x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x7x7xf32>) -> tensor<8x8x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x61x61xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x61x61xf32>) -> tensor<16x8x61x61xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x8x128x128xf32>, tensor<8x8x7x7xf32>) outs (%init: tensor<16x8x61x61xf32>) -> tensor<16x8x61x61xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x61x61xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x61x61xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 61, 1], ["%arg6", 0, 61, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 697394065}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x128xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x128xf32>) -> tensor<8x256x128x128xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x128xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x128xf32>) -> tensor<8x256x128x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x128x128xf32>, %filter: tensor<256x64x1x1xf32>, %init: tensor<8x256x128x128xf32>) -> tensor<8x256x128x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x128xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x128xf32>) -> tensor<8x256x128x128xf32>\n  return %ret : tensor<8x256x128x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x128x128xf32>, %arg1: tensor<256x64x1x1xf32>, %arg2: tensor<8x256x128x128xf32>) -> tensor<8x256x128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x256x128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x256x128x128xf32>\n    memref.copy %2, %alloc : memref<8x256x128x128xf32> to memref<8x256x128x128xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x128x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x256x128x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x256x128x128xf32>\n    return %3 : tensor<8x256x128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x256x128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x128x128xf32>) -> tensor<8x64x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x64x1x1xf32>) -> tensor<256x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x256x128x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x256x128x128xf32>) -> tensor<8x256x128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x128x128xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<8x256x128x128xf32>) -> tensor<8x256x128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x256x128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x256x128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 7931792127}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x256x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<8x32x128x128xf32>) -> tensor<8x32x128x128xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x256x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<8x32x128x128xf32>) -> tensor<8x32x128x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x128x256x256xf32>, %filter: tensor<32x128x1x1xf32>, %init: tensor<8x32x128x128xf32>) -> tensor<8x32x128x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x256x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<8x32x128x128xf32>) -> tensor<8x32x128x128xf32>\n  return %ret : tensor<8x32x128x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x128x256x256xf32>, %arg1: tensor<32x128x1x1xf32>, %arg2: tensor<8x32x128x128xf32>) -> tensor<8x32x128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x128x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x32x128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x32x128x128xf32>\n    memref.copy %2, %alloc : memref<8x32x128x128xf32> to memref<8x32x128x128xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x128x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x128x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x32x128x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x32x128x128xf32>\n    return %3 : tensor<8x32x128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x32x128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x128x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x128x256x256xf32>) -> tensor<8x128x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x1x1xf32>) -> tensor<32x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x32x128x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x32x128x128xf32>) -> tensor<8x32x128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x256x256xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<8x32x128x128xf32>) -> tensor<8x32x128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x32x128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x32x128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2606097345}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<8x8x254x254xf32>) -> tensor<8x8x254x254xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<8x8x254x254xf32>) -> tensor<8x8x254x254xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x256x256xf32>, %filter: tensor<8x64x3x3xf32>, %init: tensor<8x8x254x254xf32>) -> tensor<8x8x254x254xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<8x8x254x254xf32>) -> tensor<8x8x254x254xf32>\n  return %ret : tensor<8x8x254x254xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x256x256xf32>, %arg1: tensor<8x64x3x3xf32>, %arg2: tensor<8x8x254x254xf32>) -> tensor<8x8x254x254xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x254x254xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x254x254xf32>\n    memref.copy %2, %alloc : memref<8x8x254x254xf32> to memref<8x8x254x254xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 254 {\n          affine.for %arg6 = 0 to 254 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x254x254xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x254x254xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x254x254xf32>\n    return %3 : tensor<8x8x254x254xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x254x254xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x256x256xf32>) -> tensor<8x64x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x3x3xf32>) -> tensor<8x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x254x254xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x254x254xf32>) -> tensor<8x8x254x254xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x256x256xf32>, tensor<8x64x3x3xf32>) outs (%init: tensor<8x8x254x254xf32>) -> tensor<8x8x254x254xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x254x254xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x254x254xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 254, 1], ["%arg6", 0, 254, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 9119956107}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x32x32x32xf32>, %filter: tensor<512x32x3x3xf32>, %init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>\n  return %ret : tensor<4x512x15x15xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x32x32x32xf32>, %arg1: tensor<512x32x3x3xf32>, %arg2: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x512x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x512x15x15xf32>\n    memref.copy %2, %alloc : memref<4x512x15x15xf32> to memref<4x512x15x15xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x512x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x512x15x15xf32>\n    return %3 : tensor<4x512x15x15xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x512x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x32x32x32xf32>) -> tensor<4x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x32x3x3xf32>) -> tensor<512x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x512x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x32x32x32xf32>, tensor<512x32x3x3xf32>) outs (%init: tensor<4x512x15x15xf32>) -> tensor<4x512x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x512x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x512x15x15xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 15, 1], ["%arg6", 0, 15, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 498694412}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<8x512x128x128xf32>) -> tensor<8x512x128x128xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<8x512x128x128xf32>) -> tensor<8x512x128x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x8x128x128xf32>, %filter: tensor<512x8x1x1xf32>, %init: tensor<8x512x128x128xf32>) -> tensor<8x512x128x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<8x512x128x128xf32>) -> tensor<8x512x128x128xf32>\n  return %ret : tensor<8x512x128x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x8x128x128xf32>, %arg1: tensor<512x8x1x1xf32>, %arg2: tensor<8x512x128x128xf32>) -> tensor<8x512x128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x8x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x8x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x512x128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x512x128x128xf32>\n    memref.copy %2, %alloc : memref<8x512x128x128xf32> to memref<8x512x128x128xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x8x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x8x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x512x128x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x512x128x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x512x128x128xf32>\n    return %3 : tensor<8x512x128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x512x128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x8x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x8x128x128xf32>) -> tensor<8x8x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x8x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x8x1x1xf32>) -> tensor<512x8x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x512x128x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x512x128x128xf32>) -> tensor<8x512x128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x128x128xf32>, tensor<512x8x1x1xf32>) outs (%init: tensor<8x512x128x128xf32>) -> tensor<8x512x128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x512x128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x512x128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 809545190}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<16x16x5x5xf32>) outs (%init: tensor<16x16x126x126xf32>) -> tensor<16x16x126x126xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<16x16x5x5xf32>) outs (%init: tensor<16x16x126x126xf32>) -> tensor<16x16x126x126xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x16x256x256xf32>, %filter: tensor<16x16x5x5xf32>, %init: tensor<16x16x126x126xf32>) -> tensor<16x16x126x126xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<16x16x5x5xf32>) outs (%init: tensor<16x16x126x126xf32>) -> tensor<16x16x126x126xf32>\n  return %ret : tensor<16x16x126x126xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x16x256x256xf32>, %arg1: tensor<16x16x5x5xf32>, %arg2: tensor<16x16x126x126xf32>) -> tensor<16x16x126x126xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x16x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x16x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x16x126x126xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x16x126x126xf32>\n    memref.copy %2, %alloc : memref<16x16x126x126xf32> to memref<16x16x126x126xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 126 {\n          affine.for %arg6 = 0 to 126 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x16x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x16x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x126x126xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x16x126x126xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x16x126x126xf32>\n    return %3 : tensor<16x16x126x126xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x16x126x126xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x16x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x16x256x256xf32>) -> tensor<16x16x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x16x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x16x5x5xf32>) -> tensor<16x16x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x16x126x126xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x16x126x126xf32>) -> tensor<16x16x126x126xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<16x16x5x5xf32>) outs (%init: tensor<16x16x126x126xf32>) -> tensor<16x16x126x126xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x16x126x126xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x16x126x126xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 126, 1], ["%arg6", 0, 126, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 6211680244}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x128x128xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x63x63xf32>) -> tensor<64x8x63x63xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x128x128xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x63x63xf32>) -> tensor<64x8x63x63xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x32x128x128xf32>, %filter: tensor<8x32x3x3xf32>, %init: tensor<64x8x63x63xf32>) -> tensor<64x8x63x63xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x128x128xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x63x63xf32>) -> tensor<64x8x63x63xf32>\n  return %ret : tensor<64x8x63x63xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x32x128x128xf32>, %arg1: tensor<8x32x3x3xf32>, %arg2: tensor<64x8x63x63xf32>) -> tensor<64x8x63x63xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x63x63xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x63x63xf32>\n    memref.copy %2, %alloc : memref<64x8x63x63xf32> to memref<64x8x63x63xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 63 {\n          affine.for %arg6 = 0 to 63 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x32x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x63x63xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x63x63xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x63x63xf32>\n    return %3 : tensor<64x8x63x63xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x63x63xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x32x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x32x128x128xf32>) -> tensor<64x32x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x32x3x3xf32>) -> tensor<8x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x63x63xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x63x63xf32>) -> tensor<64x8x63x63xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x128x128xf32>, tensor<8x32x3x3xf32>) outs (%init: tensor<64x8x63x63xf32>) -> tensor<64x8x63x63xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x63x63xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x63x63xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 63, 1], ["%arg6", 0, 63, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 2243601392}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<8x8x26x26xf32>) -> tensor<8x8x26x26xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<8x8x26x26xf32>) -> tensor<8x8x26x26xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x32x32x32xf32>, %filter: tensor<8x32x7x7xf32>, %init: tensor<8x8x26x26xf32>) -> tensor<8x8x26x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<8x8x26x26xf32>) -> tensor<8x8x26x26xf32>\n  return %ret : tensor<8x8x26x26xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x32x32x32xf32>, %arg1: tensor<8x32x7x7xf32>, %arg2: tensor<8x8x26x26xf32>) -> tensor<8x8x26x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x32x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x8x26x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x8x26x26xf32>\n    memref.copy %2, %alloc : memref<8x8x26x26xf32> to memref<8x8x26x26xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x32x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x26x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x8x26x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x8x26x26xf32>\n    return %3 : tensor<8x8x26x26xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x8x26x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x32x32x32xf32>) -> tensor<8x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x32x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x32x7x7xf32>) -> tensor<8x32x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x8x26x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x8x26x26xf32>) -> tensor<8x8x26x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x32x32x32xf32>, tensor<8x32x7x7xf32>) outs (%init: tensor<8x8x26x26xf32>) -> tensor<8x8x26x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x8x26x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x8x26x26xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 26, 1], ["%arg6", 0, 26, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 257643119}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x32xf32>, tensor<64x16x3x3xf32>) outs (%init: tensor<256x64x30x30xf32>) -> tensor<256x64x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x32xf32>, tensor<64x16x3x3xf32>) outs (%init: tensor<256x64x30x30xf32>) -> tensor<256x64x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<256x16x32x32xf32>, %filter: tensor<64x16x3x3xf32>, %init: tensor<256x64x30x30xf32>) -> tensor<256x64x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x32xf32>, tensor<64x16x3x3xf32>) outs (%init: tensor<256x64x30x30xf32>) -> tensor<256x64x30x30xf32>\n  return %ret : tensor<256x64x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x16x32x32xf32>, %arg1: tensor<64x16x3x3xf32>, %arg2: tensor<256x64x30x30xf32>) -> tensor<256x64x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x16x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x30x30xf32>\n    memref.copy %2, %alloc : memref<256x64x30x30xf32> to memref<256x64x30x30xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x16x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x30x30xf32>\n    return %3 : tensor<256x64x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x16x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x16x32x32xf32>) -> tensor<256x16x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x16x3x3xf32>) -> tensor<64x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x30x30xf32>) -> tensor<256x64x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x32x32xf32>, tensor<64x16x3x3xf32>) outs (%init: tensor<256x64x30x30xf32>) -> tensor<256x64x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 256, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 7852361468}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<256x8x3x3xf32>) outs (%init: tensor<64x256x30x30xf32>) -> tensor<64x256x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<256x8x3x3xf32>) outs (%init: tensor<64x256x30x30xf32>) -> tensor<64x256x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x32x32xf32>, %filter: tensor<256x8x3x3xf32>, %init: tensor<64x256x30x30xf32>) -> tensor<64x256x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<256x8x3x3xf32>) outs (%init: tensor<64x256x30x30xf32>) -> tensor<64x256x30x30xf32>\n  return %ret : tensor<64x256x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x32x32xf32>, %arg1: tensor<256x8x3x3xf32>, %arg2: tensor<64x256x30x30xf32>) -> tensor<64x256x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x256x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x256x30x30xf32>\n    memref.copy %2, %alloc : memref<64x256x30x30xf32> to memref<64x256x30x30xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x256x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x256x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x256x30x30xf32>\n    return %3 : tensor<64x256x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x256x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x32x32xf32>) -> tensor<64x8x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x8x3x3xf32>) -> tensor<256x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x256x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x256x30x30xf32>) -> tensor<64x256x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x32x32xf32>, tensor<256x8x3x3xf32>) outs (%init: tensor<64x256x30x30xf32>) -> tensor<64x256x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x256x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x256x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 256, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3739411339}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<4x8x122x122xf32>) -> tensor<4x8x122x122xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<4x8x122x122xf32>) -> tensor<4x8x122x122xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x128x128xf32>, %filter: tensor<8x64x7x7xf32>, %init: tensor<4x8x122x122xf32>) -> tensor<4x8x122x122xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<4x8x122x122xf32>) -> tensor<4x8x122x122xf32>\n  return %ret : tensor<4x8x122x122xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x128x128xf32>, %arg1: tensor<8x64x7x7xf32>, %arg2: tensor<4x8x122x122xf32>) -> tensor<4x8x122x122xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x122x122xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x122x122xf32>\n    memref.copy %2, %alloc : memref<4x8x122x122xf32> to memref<4x8x122x122xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 122 {\n          affine.for %arg6 = 0 to 122 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x122x122xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x122x122xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x122x122xf32>\n    return %3 : tensor<4x8x122x122xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x122x122xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x128x128xf32>) -> tensor<4x64x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x7x7xf32>) -> tensor<8x64x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x122x122xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x122x122xf32>) -> tensor<4x8x122x122xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<8x64x7x7xf32>) outs (%init: tensor<4x8x122x122xf32>) -> tensor<4x8x122x122xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x122x122xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x122x122xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 122, 1], ["%arg6", 0, 122, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 5678994342}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<32x256x32x32xf32>, %filter: tensor<512x256x1x1xf32>, %init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>\n  return %ret : tensor<32x512x16x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<32x256x32x32xf32>, %arg1: tensor<512x256x1x1xf32>, %arg2: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<32x256x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<32x512x16x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<32x512x16x16xf32>\n    memref.copy %2, %alloc : memref<32x512x16x16xf32> to memref<32x512x16x16xf32>\n    affine.for %arg3 = 0 to 32 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 16 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<32x256x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x512x16x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<32x512x16x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<32x512x16x16xf32>\n    return %3 : tensor<32x512x16x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<32x512x16x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<32x256x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<32x256x32x32xf32>) -> tensor<32x256x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x256x1x1xf32>) -> tensor<512x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<32x512x16x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<32x256x32x32xf32>, tensor<512x256x1x1xf32>) outs (%init: tensor<32x512x16x16xf32>) -> tensor<32x512x16x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<32x512x16x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<32x512x16x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 32, 1], ["%arg4", 0, 512, 1], ["%arg5", 0, 16, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4043025788}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x64x64xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x64x64xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x256x64x64xf32>, %filter: tensor<1024x256x1x1xf32>, %init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x64x64xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>\n  return %ret : tensor<4x1024x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x256x64x64xf32>, %arg1: tensor<1024x256x1x1xf32>, %arg2: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x256x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x1024x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x1024x32x32xf32>\n    memref.copy %2, %alloc : memref<4x1024x32x32xf32> to memref<4x1024x32x32xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x256x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x1024x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x1024x32x32xf32>\n    return %3 : tensor<4x1024x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x1024x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x256x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x256x64x64xf32>) -> tensor<4x256x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x256x1x1xf32>) -> tensor<1024x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x1024x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x256x64x64xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<4x1024x32x32xf32>) -> tensor<4x1024x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x1024x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x1024x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 1024, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 256, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4147863178}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<128x8x3x3xf32>) outs (%init: tensor<8x128x31x31xf32>) -> tensor<8x128x31x31xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<128x8x3x3xf32>) outs (%init: tensor<8x128x31x31xf32>) -> tensor<8x128x31x31xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x8x64x64xf32>, %filter: tensor<128x8x3x3xf32>, %init: tensor<8x128x31x31xf32>) -> tensor<8x128x31x31xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<128x8x3x3xf32>) outs (%init: tensor<8x128x31x31xf32>) -> tensor<8x128x31x31xf32>\n  return %ret : tensor<8x128x31x31xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x8x64x64xf32>, %arg1: tensor<128x8x3x3xf32>, %arg2: tensor<8x128x31x31xf32>) -> tensor<8x128x31x31xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x8x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x31x31xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x31x31xf32>\n    memref.copy %2, %alloc : memref<8x128x31x31xf32> to memref<8x128x31x31xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 31 {\n          affine.for %arg6 = 0 to 31 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x8x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x31x31xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x31x31xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x31x31xf32>\n    return %3 : tensor<8x128x31x31xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x31x31xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x8x64x64xf32>) -> tensor<8x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x8x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x8x3x3xf32>) -> tensor<128x8x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x31x31xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x31x31xf32>) -> tensor<8x128x31x31xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x8x64x64xf32>, tensor<128x8x3x3xf32>) outs (%init: tensor<8x128x31x31xf32>) -> tensor<8x128x31x31xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x31x31xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x31x31xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 31, 1], ["%arg6", 0, 31, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 249114544}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<16x8x58x58xf32>) -> tensor<16x8x58x58xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<16x8x58x58xf32>) -> tensor<16x8x58x58xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x16x64x64xf32>, %filter: tensor<8x16x7x7xf32>, %init: tensor<16x8x58x58xf32>) -> tensor<16x8x58x58xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<16x8x58x58xf32>) -> tensor<16x8x58x58xf32>\n  return %ret : tensor<16x8x58x58xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x16x64x64xf32>, %arg1: tensor<8x16x7x7xf32>, %arg2: tensor<16x8x58x58xf32>) -> tensor<16x8x58x58xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x58x58xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x58x58xf32>\n    memref.copy %2, %alloc : memref<16x8x58x58xf32> to memref<16x8x58x58xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 58 {\n          affine.for %arg6 = 0 to 58 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x58x58xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x58x58xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x58x58xf32>\n    return %3 : tensor<16x8x58x58xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x58x58xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x16x64x64xf32>) -> tensor<16x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x58x58xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x58x58xf32>) -> tensor<16x8x58x58xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<16x8x58x58xf32>) -> tensor<16x8x58x58xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x58x58xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x58x58xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 58, 1], ["%arg6", 0, 58, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1275451405}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x32x32xf32>, tensor<128x32x1x1xf32>) outs (%init: tensor<16x128x16x16xf32>) -> tensor<16x128x16x16xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x32x32xf32>, tensor<128x32x1x1xf32>) outs (%init: tensor<16x128x16x16xf32>) -> tensor<16x128x16x16xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x32x32x32xf32>, %filter: tensor<128x32x1x1xf32>, %init: tensor<16x128x16x16xf32>) -> tensor<16x128x16x16xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x32x32xf32>, tensor<128x32x1x1xf32>) outs (%init: tensor<16x128x16x16xf32>) -> tensor<16x128x16x16xf32>\n  return %ret : tensor<16x128x16x16xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x32x32x32xf32>, %arg1: tensor<128x32x1x1xf32>, %arg2: tensor<16x128x16x16xf32>) -> tensor<16x128x16x16xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x128x16x16xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x128x16x16xf32>\n    memref.copy %2, %alloc : memref<16x128x16x16xf32> to memref<16x128x16x16xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 16 {\n          affine.for %arg6 = 0 to 16 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x128x16x16xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x128x16x16xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x128x16x16xf32>\n    return %3 : tensor<16x128x16x16xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x128x16x16xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x32x32x32xf32>) -> tensor<16x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x32x1x1xf32>) -> tensor<128x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x128x16x16xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x128x16x16xf32>) -> tensor<16x128x16x16xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x32x32x32xf32>, tensor<128x32x1x1xf32>) outs (%init: tensor<16x128x16x16xf32>) -> tensor<16x128x16x16xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x128x16x16xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x128x16x16xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 16, 1], ["%arg6", 0, 16, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 39841379}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<4x8x60x60xf32>) -> tensor<4x8x60x60xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<4x8x60x60xf32>) -> tensor<4x8x60x60xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x64x64xf32>, %filter: tensor<8x64x5x5xf32>, %init: tensor<4x8x60x60xf32>) -> tensor<4x8x60x60xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<4x8x60x60xf32>) -> tensor<4x8x60x60xf32>\n  return %ret : tensor<4x8x60x60xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x64x64xf32>, %arg1: tensor<8x64x5x5xf32>, %arg2: tensor<4x8x60x60xf32>) -> tensor<4x8x60x60xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x64x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x60x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x60x60xf32>\n    memref.copy %2, %alloc : memref<4x8x60x60xf32> to memref<4x8x60x60xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x64x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x60x60xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x60x60xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x60x60xf32>\n    return %3 : tensor<4x8x60x60xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x60x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x64x64xf32>) -> tensor<4x64x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x64x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x64x5x5xf32>) -> tensor<8x64x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x60x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x60x60xf32>) -> tensor<4x8x60x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x64x64xf32>, tensor<8x64x5x5xf32>) outs (%init: tensor<4x8x60x60xf32>) -> tensor<4x8x60x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x60x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x60x60xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 60, 1], ["%arg6", 0, 60, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 700872547}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x63x63xf32>) -> tensor<4x8x63x63xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x63x63xf32>) -> tensor<4x8x63x63xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x16x128x128xf32>, %filter: tensor<8x16x3x3xf32>, %init: tensor<4x8x63x63xf32>) -> tensor<4x8x63x63xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x63x63xf32>) -> tensor<4x8x63x63xf32>\n  return %ret : tensor<4x8x63x63xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x16x128x128xf32>, %arg1: tensor<8x16x3x3xf32>, %arg2: tensor<4x8x63x63xf32>) -> tensor<4x8x63x63xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x16x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x8x63x63xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x8x63x63xf32>\n    memref.copy %2, %alloc : memref<4x8x63x63xf32> to memref<4x8x63x63xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 63 {\n          affine.for %arg6 = 0 to 63 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x16x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x63x63xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x8x63x63xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x8x63x63xf32>\n    return %3 : tensor<4x8x63x63xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x8x63x63xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x16x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x16x128x128xf32>) -> tensor<4x16x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x3x3xf32>) -> tensor<8x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x8x63x63xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x8x63x63xf32>) -> tensor<4x8x63x63xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x16x128x128xf32>, tensor<8x16x3x3xf32>) outs (%init: tensor<4x8x63x63xf32>) -> tensor<4x8x63x63xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x8x63x63xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x8x63x63xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 63, 1], ["%arg6", 0, 63, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 69475732}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x1024x32x32xf32>, tensor<8x1024x5x5xf32>) outs (%init: tensor<64x8x14x14xf32>) -> tensor<64x8x14x14xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x1024x32x32xf32>, tensor<8x1024x5x5xf32>) outs (%init: tensor<64x8x14x14xf32>) -> tensor<64x8x14x14xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x1024x32x32xf32>, %filter: tensor<8x1024x5x5xf32>, %init: tensor<64x8x14x14xf32>) -> tensor<64x8x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x1024x32x32xf32>, tensor<8x1024x5x5xf32>) outs (%init: tensor<64x8x14x14xf32>) -> tensor<64x8x14x14xf32>\n  return %ret : tensor<64x8x14x14xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x1024x32x32xf32>, %arg1: tensor<8x1024x5x5xf32>, %arg2: tensor<64x8x14x14xf32>) -> tensor<64x8x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x1024x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x1024x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x14x14xf32>\n    memref.copy %2, %alloc : memref<64x8x14x14xf32> to memref<64x8x14x14xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 1024 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x1024x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x1024x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x14x14xf32>\n    return %3 : tensor<64x8x14x14xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x1024x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x1024x32x32xf32>) -> tensor<64x1024x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x1024x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x1024x5x5xf32>) -> tensor<8x1024x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x14x14xf32>) -> tensor<64x8x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x1024x32x32xf32>, tensor<8x1024x5x5xf32>) outs (%init: tensor<64x8x14x14xf32>) -> tensor<64x8x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x14x14xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 14, 1], ["%arg7", 0, 1024, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 10437084048}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x16x256x256xf32>, %filter: tensor<32x16x1x1xf32>, %init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>\n  return %ret : tensor<16x32x128x128xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x16x256x256xf32>, %arg1: tensor<32x16x1x1xf32>, %arg2: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x16x256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x32x128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x32x128x128xf32>\n    memref.copy %2, %alloc : memref<16x32x128x128xf32> to memref<16x32x128x128xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x16x256x256xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x128x128xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x32x128x128xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x32x128x128xf32>\n    return %3 : tensor<16x32x128x128xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x32x128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x16x256x256xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x16x256x256xf32>) -> tensor<16x16x256x256xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x16x1x1xf32>) -> tensor<32x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x32x128x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x256x256xf32>, tensor<32x16x1x1xf32>) outs (%init: tensor<16x32x128x128xf32>) -> tensor<16x32x128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x32x128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x32x128x128xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 128, 1], ["%arg6", 0, 128, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 342787592}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x30x30xf32>) -> tensor<16x8x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x30x30xf32>) -> tensor<16x8x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<16x16x64x64xf32>, %filter: tensor<8x16x5x5xf32>, %init: tensor<16x8x30x30xf32>) -> tensor<16x8x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x30x30xf32>) -> tensor<16x8x30x30xf32>\n  return %ret : tensor<16x8x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<16x16x64x64xf32>, %arg1: tensor<8x16x5x5xf32>, %arg2: tensor<16x8x30x30xf32>) -> tensor<16x8x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<16x16x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<16x8x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<16x8x30x30xf32>\n    memref.copy %2, %alloc : memref<16x8x30x30xf32> to memref<16x8x30x30xf32>\n    affine.for %arg3 = 0 to 16 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<16x16x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<16x8x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<16x8x30x30xf32>\n    return %3 : tensor<16x8x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<16x8x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<16x16x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<16x16x64x64xf32>) -> tensor<16x16x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x5x5xf32>) -> tensor<8x16x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<16x8x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<16x8x30x30xf32>) -> tensor<16x8x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<16x16x64x64xf32>, tensor<8x16x5x5xf32>) outs (%init: tensor<16x8x30x30xf32>) -> tensor<16x8x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<16x8x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<16x8x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 16, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 173699919}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<128x128x1x1xf32>) outs (%init: tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<128x128x1x1xf32>) outs (%init: tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x128x64x64xf32>, %filter: tensor<128x128x1x1xf32>, %init: tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<128x128x1x1xf32>) outs (%init: tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32>\n  return %ret : tensor<8x128x32x32xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x128x64x64xf32>, %arg1: tensor<128x128x1x1xf32>, %arg2: tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x128x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x32x32xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x32x32xf32>\n    memref.copy %2, %alloc : memref<8x128x32x32xf32> to memref<8x128x32x32xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 32 {\n          affine.for %arg6 = 0 to 32 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x128x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x32x32xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x32x32xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x32x32xf32>\n    return %3 : tensor<8x128x32x32xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x32x32xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x128x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x128x1x1xf32>) -> tensor<128x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x32x32xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x64x64xf32>, tensor<128x128x1x1xf32>) outs (%init: tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x32x32xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x32x32xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 32, 1], ["%arg6", 0, 32, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 495788288}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<64x8x30x30xf32>) -> tensor<64x8x30x30xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<64x8x30x30xf32>) -> tensor<64x8x30x30xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x8x64x64xf32>, %filter: tensor<8x8x5x5xf32>, %init: tensor<64x8x30x30xf32>) -> tensor<64x8x30x30xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<64x8x30x30xf32>) -> tensor<64x8x30x30xf32>\n  return %ret : tensor<64x8x30x30xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x8x64x64xf32>, %arg1: tensor<8x8x5x5xf32>, %arg2: tensor<64x8x30x30xf32>) -> tensor<64x8x30x30xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x8x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x8x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x8x30x30xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x8x30x30xf32>\n    memref.copy %2, %alloc : memref<64x8x30x30xf32> to memref<64x8x30x30xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 30 {\n          affine.for %arg6 = 0 to 30 {\n            affine.for %arg7 = 0 to 8 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x8x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x8x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x30x30xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x8x30x30xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x8x30x30xf32>\n    return %3 : tensor<64x8x30x30xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x8x30x30xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x8x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x8x64x64xf32>) -> tensor<64x8x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x8x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x8x5x5xf32>) -> tensor<8x8x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x8x30x30xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x8x30x30xf32>) -> tensor<64x8x30x30xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x8x64x64xf32>, tensor<8x8x5x5xf32>) outs (%init: tensor<64x8x30x30xf32>) -> tensor<64x8x30x30xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x8x30x30xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x8x30x30xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 8, 1], ["%arg5", 0, 30, 1], ["%arg6", 0, 30, 1], ["%arg7", 0, 8, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 342954541}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<4x32x62x62xf32>) -> tensor<4x32x62x62xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<4x32x62x62xf32>) -> tensor<4x32x62x62xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x128x128xf32>, %filter: tensor<32x64x5x5xf32>, %init: tensor<4x32x62x62xf32>) -> tensor<4x32x62x62xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<4x32x62x62xf32>) -> tensor<4x32x62x62xf32>\n  return %ret : tensor<4x32x62x62xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x128x128xf32>, %arg1: tensor<32x64x5x5xf32>, %arg2: tensor<4x32x62x62xf32>) -> tensor<4x32x62x62xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x64x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x32x62x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x32x62x62xf32>\n    memref.copy %2, %alloc : memref<4x32x62x62xf32> to memref<4x32x62x62xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x64x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x62x62xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x32x62x62xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x32x62x62xf32>\n    return %3 : tensor<4x32x62x62xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x32x62x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x128x128xf32>) -> tensor<4x64x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x64x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x64x5x5xf32>) -> tensor<32x64x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x32x62x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x32x62x62xf32>) -> tensor<4x32x62x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x128x128xf32>, tensor<32x64x5x5xf32>) outs (%init: tensor<4x32x62x62xf32>) -> tensor<4x32x62x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x32x62x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x32x62x62xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 62, 1], ["%arg6", 0, 62, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 3011583301}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x16x32x32xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<64x32x15x15xf32>) -> tensor<64x32x15x15xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x16x32x32xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<64x32x15x15xf32>) -> tensor<64x32x15x15xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x16x32x32xf32>, %filter: tensor<32x16x3x3xf32>, %init: tensor<64x32x15x15xf32>) -> tensor<64x32x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x16x32x32xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<64x32x15x15xf32>) -> tensor<64x32x15x15xf32>\n  return %ret : tensor<64x32x15x15xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x16x32x32xf32>, %arg1: tensor<32x16x3x3xf32>, %arg2: tensor<64x32x15x15xf32>) -> tensor<64x32x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x16x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x32x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x32x15x15xf32>\n    memref.copy %2, %alloc : memref<64x32x15x15xf32> to memref<64x32x15x15xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x16x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x32x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x32x15x15xf32>\n    return %3 : tensor<64x32x15x15xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x32x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x16x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x16x32x32xf32>) -> tensor<64x16x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x16x3x3xf32>) -> tensor<32x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x32x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x32x15x15xf32>) -> tensor<64x32x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<64x16x32x32xf32>, tensor<32x16x3x3xf32>) outs (%init: tensor<64x32x15x15xf32>) -> tensor<64x32x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x32x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x32x15x15xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 32, 1], ["%arg5", 0, 15, 1], ["%arg6", 0, 15, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 245554870}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<64x64x7x7xf32>) outs (%init: tensor<4x64x13x13xf32>) -> tensor<4x64x13x13xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<64x64x7x7xf32>) outs (%init: tensor<4x64x13x13xf32>) -> tensor<4x64x13x13xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<4x64x32x32xf32>, %filter: tensor<64x64x7x7xf32>, %init: tensor<4x64x13x13xf32>) -> tensor<4x64x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<64x64x7x7xf32>) outs (%init: tensor<4x64x13x13xf32>) -> tensor<4x64x13x13xf32>\n  return %ret : tensor<4x64x13x13xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<4x64x32x32xf32>, %arg1: tensor<64x64x7x7xf32>, %arg2: tensor<4x64x13x13xf32>) -> tensor<4x64x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<4x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<4x64x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<4x64x13x13xf32>\n    memref.copy %2, %alloc : memref<4x64x13x13xf32> to memref<4x64x13x13xf32>\n    affine.for %arg3 = 0 to 4 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<4x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x64x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<4x64x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<4x64x13x13xf32>\n    return %3 : tensor<4x64x13x13xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<4x64x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<4x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<4x64x32x32xf32>) -> tensor<4x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x64x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x64x7x7xf32>) -> tensor<64x64x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<4x64x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<4x64x13x13xf32>) -> tensor<4x64x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<4x64x32x32xf32>, tensor<64x64x7x7xf32>) outs (%init: tensor<4x64x13x13xf32>) -> tensor<4x64x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<4x64x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<4x64x13x13xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 4, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 13, 1], ["%arg6", 0, 13, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 7, 1], ["%arg9", 0, 7, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 516621895}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x512xf32>, tensor<64x16x1x1xf32>) outs (%init: tensor<8x64x512x512xf32>) -> tensor<8x64x512x512xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x512xf32>, tensor<64x16x1x1xf32>) outs (%init: tensor<8x64x512x512xf32>) -> tensor<8x64x512x512xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x512x512xf32>, %filter: tensor<64x16x1x1xf32>, %init: tensor<8x64x512x512xf32>) -> tensor<8x64x512x512xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x512xf32>, tensor<64x16x1x1xf32>) outs (%init: tensor<8x64x512x512xf32>) -> tensor<8x64x512x512xf32>\n  return %ret : tensor<8x64x512x512xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x512x512xf32>, %arg1: tensor<64x16x1x1xf32>, %arg2: tensor<8x64x512x512xf32>) -> tensor<8x64x512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x64x512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x64x512x512xf32>\n    memref.copy %2, %alloc : memref<8x64x512x512xf32> to memref<8x64x512x512xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 512 {\n          affine.for %arg6 = 0 to 512 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x512x512xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x64x512x512xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x64x512x512xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x64x512x512xf32>\n    return %3 : tensor<8x64x512x512xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x64x512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x512x512xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x512x512xf32>) -> tensor<8x16x512x512xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x16x1x1xf32>) -> tensor<64x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x64x512x512xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x64x512x512xf32>) -> tensor<8x64x512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x512x512xf32>, tensor<64x16x1x1xf32>) outs (%init: tensor<8x64x512x512xf32>) -> tensor<8x64x512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x64x512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x64x512x512xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 64, 1], ["%arg5", 0, 512, 1], ["%arg6", 0, 512, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 6382808098}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x128x128xf32>, %filter: tensor<128x16x1x1xf32>, %init: tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32>\n  return %ret : tensor<8x128x64x64xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x128x128xf32>, %arg1: tensor<128x16x1x1xf32>, %arg2: tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x16x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x64x64xf32>\n    memref.copy %2, %alloc : memref<8x128x64x64xf32> to memref<8x128x64x64xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x16x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x64x64xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x64x64xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x64x64xf32>\n    return %3 : tensor<8x128x64x64xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x128x128xf32>) -> tensor<8x16x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x16x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x16x1x1xf32>) -> tensor<128x16x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<128x16x1x1xf32>) outs (%init: tensor<8x128x64x64xf32>) -> tensor<8x128x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x64x64xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 64, 1], ["%arg6", 0, 64, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 1, 1], ["%arg9", 0, 1, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 318821671}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x32x32xf32>, tensor<128x128x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x32x32xf32>, tensor<128x128x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x128x32x32xf32>, %filter: tensor<128x128x5x5xf32>, %init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x32x32xf32>, tensor<128x128x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>\n  return %ret : tensor<8x128x14x14xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x128x32x32xf32>, %arg1: tensor<128x128x5x5xf32>, %arg2: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x128x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x14x14xf32>\n    memref.copy %2, %alloc : memref<8x128x14x14xf32> to memref<8x128x14x14xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x128x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x128x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x14x14xf32>\n    return %3 : tensor<8x128x14x14xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x128x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x128x32x32xf32>) -> tensor<8x128x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x128x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x128x5x5xf32>) -> tensor<128x128x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x128x32x32xf32>, tensor<128x128x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x14x14xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 14, 1], ["%arg7", 0, 128, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 4944636554}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x64x64xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x60x60xf32>) -> tensor<64x16x60x60xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x64x64xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x60x60xf32>) -> tensor<64x16x60x60xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<64x32x64x64xf32>, %filter: tensor<16x32x5x5xf32>, %init: tensor<64x16x60x60xf32>) -> tensor<64x16x60x60xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x64x64xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x60x60xf32>) -> tensor<64x16x60x60xf32>\n  return %ret : tensor<64x16x60x60xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<64x32x64x64xf32>, %arg1: tensor<16x32x5x5xf32>, %arg2: tensor<64x16x60x60xf32>) -> tensor<64x16x60x60xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x32x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<64x32x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<64x16x60x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<64x16x60x60xf32>\n    memref.copy %2, %alloc : memref<64x16x60x60xf32> to memref<64x16x60x60xf32>\n    affine.for %arg3 = 0 to 64 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<64x32x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x32x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x60x60xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<64x16x60x60xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<64x16x60x60xf32>\n    return %3 : tensor<64x16x60x60xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<64x16x60x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<64x32x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<64x32x64x64xf32>) -> tensor<64x32x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x32x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x32x5x5xf32>) -> tensor<16x32x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<64x16x60x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<64x16x60x60xf32>) -> tensor<64x16x60x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<64x32x64x64xf32>, tensor<16x32x5x5xf32>) outs (%init: tensor<64x16x60x60xf32>) -> tensor<64x16x60x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<64x16x60x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<64x16x60x60xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 64, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 60, 1], ["%arg6", 0, 60, 1], ["%arg7", 0, 32, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 12199364053}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x126x126xf32>) -> tensor<8x16x126x126xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x126x126xf32>) -> tensor<8x16x126x126xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x16x128x128xf32>, %filter: tensor<16x16x3x3xf32>, %init: tensor<8x16x126x126xf32>) -> tensor<8x16x126x126xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x126x126xf32>) -> tensor<8x16x126x126xf32>\n  return %ret : tensor<8x16x126x126xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x16x128x128xf32>, %arg1: tensor<16x16x3x3xf32>, %arg2: tensor<8x16x126x126xf32>) -> tensor<8x16x126x126xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x16x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x16x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x16x126x126xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x16x126x126xf32>\n    memref.copy %2, %alloc : memref<8x16x126x126xf32> to memref<8x16x126x126xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 126 {\n          affine.for %arg6 = 0 to 126 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x16x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x16x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x126x126xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x16x126x126xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x16x126x126xf32>\n    return %3 : tensor<8x16x126x126xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x16x126x126xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x16x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x16x128x128xf32>) -> tensor<8x16x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x16x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x16x3x3xf32>) -> tensor<16x16x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x16x126x126xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x16x126x126xf32>) -> tensor<8x16x126x126xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<8x16x128x128xf32>, tensor<16x16x3x3xf32>) outs (%init: tensor<8x16x126x126xf32>) -> tensor<8x16x126x126xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x16x126x126xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x16x126x126xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 16, 1], ["%arg5", 0, 126, 1], ["%arg6", 0, 126, 1], ["%arg7", 0, 16, 1], ["%arg8", 0, 3, 1], ["%arg9", 0, 3, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 + %arg8", "%arg6 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1117623585}, "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<128x64x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>": {"operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<128x64x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>", "wrapped_operation": "func.func @func_call(%input: tensor<8x64x32x32xf32>, %filter: tensor<128x64x5x5xf32>, %init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<128x64x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>\n  return %ret : tensor<8x128x14x14xf32>\n}", "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<8x64x32x32xf32>, %arg1: tensor<128x64x5x5xf32>, %arg2: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x64x5x5xf32>\n    %1 = bufferization.to_memref %arg0 : memref<8x64x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<8x128x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8x128x14x14xf32>\n    memref.copy %2, %alloc : memref<8x128x14x14xf32> to memref<8x128x14x14xf32>\n    affine.for %arg3 = 0 to 8 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 5 {\n                affine.for %arg9 = 0 to 5 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<8x64x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x64x5x5xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<8x128x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<8x128x14x14xf32>\n    return %3 : tensor<8x128x14x14xf32>\n  }\n}\n\n", "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<8x128x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<8x64x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<8x64x32x32xf32>) -> tensor<8x64x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x64x5x5xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<8x128x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<8x64x32x32xf32>, tensor<128x64x5x5xf32>) outs (%init: tensor<8x128x14x14xf32>) -> tensor<8x128x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<8x128x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<8x128x14x14xf32>\n    }\n    return\n}\n}\n", "loops_data": {"nested_loops": [["%arg3", 0, 8, 1], ["%arg4", 0, 128, 1], ["%arg5", 0, 14, 1], ["%arg6", 0, 14, 1], ["%arg7", 0, 64, 1], ["%arg8", 0, 5, 1], ["%arg9", 0, 5, 1]], "op_count": {"+": 1, "-": 0, "*": 1, "/": 0, "exp": 0}, "load_data": [["%arg3", "%arg7", "%arg5 * 2 + %arg8", "%arg6 * 2 + %arg9"], ["%arg4", "%arg7", "%arg8", "%arg9"], ["%arg3", "%arg4", "%arg5", "%arg6"]], "store_data": []}, "execution_time": 1311524156}}