{"0": ["#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2240x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2240x1x1x224xf32>) -> tensor<2240x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2240xf32>) -> tensor<2240xf32>\n    %6 = tensor.empty() : tensor<666x1x1x2240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2240xf32>) outs(%6 : tensor<666x1x1x2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x2240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x224xf32>, tensor<2240x1x1x224xf32>) outs(%7 : tensor<666x1x1x2240xf32>) -> tensor<666x1x1x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x26xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x26xf32>) -> tensor<666x1x1x26xf32>\n    %2 = tensor.empty() : tensor<666x1x1x26xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x26xf32>) outs(%2 : tensor<666x1x1x26xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x26xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1728xf32>) -> tensor<666x7x7x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1728xf32>) -> tensor<1x1x1x1728xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1728xf32>, tensor<1x1x1x1728xf32>) outs(%4 : tensor<666x7x7x1728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = tensor.empty() : tensor<666x56x56x1xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x1xf32>) outs(%2 : tensor<666x56x56x1xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x512xf32>) -> tensor<512x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<512x1x1x512xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x42x42x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %4 = tensor.empty() : tensor<666x56x56x11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x11xf32>, tensor<666x56x56x11xf32>) outs(%4 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %4 = tensor.empty() : tensor<666x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1536xf32>, tensor<666x1536xf32>) outs(%4 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<12x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<12x1x1x48xf32>) -> tensor<12x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<12xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<12xf32>) -> tensor<12xf32>\n    %6 = tensor.empty() : tensor<666x1x1x12xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<12xf32>) outs(%6 : tensor<666x1x1x12xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x12xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x48xf32>, tensor<12x1x1x48xf32>) outs(%7 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x2048xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x120xf32>) -> tensor<666x56x56x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x120xf32>) -> tensor<1x1x1x120xf32>\n    %4 = tensor.empty() : tensor<666x56x56x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x120xf32>, tensor<1x1x1x120xf32>) outs(%4 : tensor<666x56x56x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x896xf32>) -> tensor<666x28x28x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x28x28x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x28x28x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x35x35x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x35x35x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x112xf32>) -> tensor<666x56x56x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x112xf32>) -> tensor<1x1x1x112xf32>\n    %4 = tensor.empty() : tensor<666x56x56x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x112xf32>, tensor<1x1x1x112xf32>) outs(%4 : tensor<666x56x56x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x2048xf32>) -> tensor<666x28x28x2048xf32>\n    %2 = tensor.empty() : tensor<666x28x28x2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x2048xf32>) outs(%2 : tensor<666x28x28x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<42x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<42x1x1x42xf32>) -> tensor<42x1x1x42xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %6 = tensor.empty() : tensor<666x83x83x42xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<42xf32>) outs(%6 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x83x83x42xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x83x83x42xf32>, tensor<42x1x1x42xf32>) outs(%7 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %4 = tensor.empty() : tensor<666x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1024xf32>, tensor<666x1024xf32>) outs(%4 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1728xf32>) -> tensor<666x7x7x1728xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1728xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1728xf32>) outs(%2 : tensor<666x7x7x1728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x176x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x176x1xf32>) -> tensor<5x5x176x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x7x7x176xf32> to tensor<666x11x11x176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %8 = tensor.empty() : tensor<666x7x7x176xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x11x11x176xf32>, tensor<5x5x176x1xf32>) outs(%7 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x7x7x176x1xf32> into tensor<666x7x7x176xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<176xf32>, tensor<666x7x7x176xf32>) outs(%8 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x113x113x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x113x113x96xf32>) -> tensor<666x113x113x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x96x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x96x1xf32>) -> tensor<3x3x96x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x56x56x96x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x56x56x96x1xf32>) -> tensor<666x56x56x96x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x96xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x113x113x96xf32>, tensor<3x3x96x1xf32>) outs(%7 : tensor<666x56x56x96x1xf32>) -> tensor<666x56x56x96x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x96x1xf32> into tensor<666x56x56x96xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<96xf32>, tensor<666x56x56x96xf32>) outs(%8 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x104xf32>) -> tensor<666x56x56x104xf32>\n    %2 = tensor.empty() : tensor<666x56x56x104xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x104xf32>) outs(%2 : tensor<666x56x56x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x480xf32>) -> tensor<666x14x14x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x480xf32>) -> tensor<128x1x1x480xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x480xf32>, tensor<128x1x1x480xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x336xf32>) -> tensor<672x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x56x56x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x56x56x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x336xf32>, tensor<672x1x1x336xf32>) outs(%7 : tensor<666x56x56x672xf32>) -> tensor<666x56x56x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x88xf32>) -> tensor<1x1x1x88xf32>\n    %4 = tensor.empty() : tensor<666x14x14x88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x88xf32>, tensor<1x1x1x88xf32>) outs(%4 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x2x2x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x2x2x192xf32>) -> tensor<384x2x2x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x28x28x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<384x2x2x192xf32>) outs(%7 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1536xf32>) -> tensor<666x8x8x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x8x8x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x8x8x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x56x56x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x336xf32>) -> tensor<666x42x42x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x42x42x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x42x42x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<696xf32>) -> tensor<696xf32>\n    %2 = tensor.empty() : tensor<696xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<696xf32>) outs(%2 : tensor<696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x672xf32>) -> tensor<666x21x21x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x21x21x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x21x21x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x21x21x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x21x21x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1312xf32>) -> tensor<666x14x14x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1312xf32>) -> tensor<128x1x1x1312xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1312xf32>, tensor<128x1x1x1312xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x368xf32>) -> tensor<666x1x1x368xf32>\n    %2 = tensor.empty() : tensor<666x1x1x368xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x368xf32>) outs(%2 : tensor<666x1x1x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x29x29x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x29x29x88xf32>) -> tensor<666x29x29x88xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x14x14x88xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x29x29x88xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %c1 = arith.constant 1 : index\n    %c14 = arith.constant 14 : index\n    %c2 = arith.constant 2 : index\n    %c14_1 = arith.constant 14 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c14, %c1_2 : index\n    %7 = arith.subi %c14_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x14x14x88xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x14x14x88xf32>) outs(%8 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x35x35x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %4 = tensor.empty() : tensor<666x28x28x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x168xf32>, tensor<666x28x28x168xf32>) outs(%4 : tensor<666x28x28x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x784xf32>) -> tensor<666x28x28x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x784xf32>) -> tensor<1x1x1x784xf32>\n    %4 = tensor.empty() : tensor<666x28x28x784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x784xf32>, tensor<1x1x1x784xf32>) outs(%4 : tensor<666x28x28x784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<666x14x14x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1536xf32>) -> tensor<1536xf32>\n    %2 = tensor.empty() : tensor<1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1536xf32>) outs(%2 : tensor<1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x888xf32>) -> tensor<666x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x888xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2016xf32>) -> tensor<666x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x2016xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x216xf32>) -> tensor<666x56x56x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x216xf32>) -> tensor<1x1x1x216xf32>\n    %4 = tensor.empty() : tensor<666x56x56x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x216xf32>, tensor<1x1x1x216xf32>) outs(%4 : tensor<666x56x56x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    %2 = tensor.empty() : tensor<666x17x17x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x256xf32>) outs(%2 : tensor<666x17x17x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = tensor.empty() : tensor<666x56x56x80xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x80xf32>) outs(%2 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %4 = tensor.empty() : tensor<666x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x768xf32>, tensor<666x768xf32>) outs(%4 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1760xf32>) -> tensor<666x7x7x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1760xf32>) -> tensor<1x1x1x1760xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1760xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1760xf32>, tensor<1x1x1x1760xf32>) outs(%4 : tensor<666x7x7x1760xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = tensor.empty() : tensor<666x1x1x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x128xf32>) outs(%2 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %4 = tensor.empty() : tensor<666x28x28x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x112xf32>, tensor<666x28x28x112xf32>) outs(%4 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = tensor.empty() : tensor<666x56x56x144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x144xf32>) outs(%2 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1632xf32>) -> tensor<666x7x7x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1632xf32>) -> tensor<1x1x1x1632xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1632xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1632xf32>, tensor<1x1x1x1632xf32>) outs(%4 : tensor<666x7x7x1632xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x324xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x324xf32>) -> tensor<666x1x1x324xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1296x1x1x324xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1296x1x1x324xf32>) -> tensor<1296x1x1x324xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1296xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1296xf32>) -> tensor<1296xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1296xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1296xf32>) outs(%6 : tensor<666x1x1x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1296xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x324xf32>, tensor<1296x1x1x324xf32>) outs(%7 : tensor<666x1x1x1296xf32>) -> tensor<666x1x1x1296xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %2 = tensor.empty() : tensor<666xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666xf32>) -> tensor<666xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1536xf32>) outs(%3 : tensor<666xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0, 1]] : tensor<666xf32> into tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x288xf32>) -> tensor<672x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x14x14x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x14x14x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<672x1x1x288xf32>) outs(%7 : tensor<666x14x14x672xf32>) -> tensor<666x14x14x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = tensor.empty() : tensor<666x7x7x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x7x7x768xf32>, tensor<666x7x7x768xf32>) outs(%2 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1392x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1392x1x1x1392xf32>) -> tensor<1392x1x1x1392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1392xf32>) -> tensor<1392xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1392xf32>) outs(%6 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1392xf32>, tensor<1392x1x1x1392xf32>) outs(%7 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1696xf32>) -> tensor<666x7x7x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1696xf32>) -> tensor<1x1x1x1696xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1696xf32>, tensor<1x1x1x1696xf32>) outs(%4 : tensor<666x7x7x1696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<104x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<104x1x1x48xf32>) -> tensor<104x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<104xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<104xf32>) -> tensor<104xf32>\n    %6 = tensor.empty() : tensor<666x28x28x104xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<104xf32>) outs(%6 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x104xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<104x1x1x48xf32>) outs(%7 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1296xf32>) -> tensor<1x1x1x1296xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1296xf32>, tensor<1x1x1x1296xf32>) outs(%4 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x80xf32>) -> tensor<666x112x112x80xf32>\n    %2 = tensor.empty() : tensor<666x112x112x80xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x80xf32>) outs(%2 : tensor<666x112x112x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x1024xf32>, tensor<666x7x7x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<720xf32>) -> tensor<720xf32>\n    %2 = tensor.empty() : tensor<720xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<720xf32>) outs(%2 : tensor<720xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1008xf32>) -> tensor<666x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1008xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1008xf32>) -> tensor<1x1x1x1008xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1008xf32>, tensor<1x1x1x1008xf32>) outs(%4 : tensor<666x7x7x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<440xf32>) -> tensor<440xf32>\n    %2 = tensor.empty() : tensor<440xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<440xf32>) outs(%2 : tensor<440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x22x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x22x1xf32>) -> tensor<7x7x22x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x22xf32> to tensor<666x34x34x22xf32>\n    %6 = tensor.empty() : tensor<666x28x28x22x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x22xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x34x34x22xf32>, tensor<7x7x22x1xf32>) outs(%7 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x22x1xf32> into tensor<666x28x28x22xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<22xf32>, tensor<666x28x28x22xf32>) outs(%8 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1664xf32>) -> tensor<1664xf32>\n    %2 = tensor.empty() : tensor<1664xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1664xf32>) outs(%2 : tensor<1664xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1624x1x1x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1624x1x1x1624xf32>) -> tensor<1624x1x1x1624xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1624xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1624xf32>) -> tensor<1624xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1624xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1624xf32>) outs(%6 : tensor<666x7x7x1624xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1624xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1624xf32>, tensor<1624x1x1x1624xf32>) outs(%7 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = tensor.empty() : tensor<666x28x28x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x128xf32>) outs(%2 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x440xf32>, tensor<666x7x7x440xf32>) outs(%4 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x14x14x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1216xf32>) -> tensor<666x7x7x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1216xf32>) -> tensor<128x1x1x1216xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1216xf32>, tensor<128x1x1x1216xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1600xf32>) -> tensor<1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1600xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1600xf32>, tensor<1xf32>) outs(%4 : tensor<1600xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x576xf32>) -> tensor<666x7x7x576xf32>\n    %2 = tensor.empty() : tensor<666x7x7x576xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x576xf32>) outs(%2 : tensor<666x7x7x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x560xf32>) -> tensor<666x28x28x560xf32>\n    %2 = tensor.empty() : tensor<666x28x28x560xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x560xf32>) outs(%2 : tensor<666x28x28x560xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<42x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<42x1x1x448xf32>) -> tensor<42x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %6 = tensor.empty() : tensor<666x1x1x42xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<42xf32>) outs(%6 : tensor<666x1x1x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x42xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x448xf32>, tensor<42x1x1x448xf32>) outs(%7 : tensor<666x1x1x42xf32>) -> tensor<666x1x1x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x128xf32>) -> tensor<128x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x147x147x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x147x147x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x147x147x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x147x147x128xf32>, tensor<128x1x1x128xf32>) outs(%7 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1472xf32>) -> tensor<1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1472xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1472xf32>, tensor<1xf32>) outs(%4 : tensor<1472xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1472xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x696xf32>) -> tensor<666x1x28x696xf32>\n    %2 = tensor.empty() : tensor<666x1x696xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x696xf32>) -> tensor<666x1x696xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x696xf32>) outs(%3 : tensor<666x1x696xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x696xf32> into tensor<666x1x1x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1824xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1824xf32>) -> tensor<666x7x7x1824xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1824xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1824xf32>) -> tensor<128x1x1x1824xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1824xf32>, tensor<128x1x1x1824xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1760xf32>) -> tensor<666x14x14x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1760xf32>) -> tensor<128x1x1x1760xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1760xf32>, tensor<128x1x1x1760xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x32xf32>) -> tensor<256x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x112x112x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x112x112x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<256x1x1x32xf32>) outs(%7 : tensor<666x112x112x256xf32>) -> tensor<666x112x112x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x416xf32>) -> tensor<666x14x14x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x416xf32>) -> tensor<1x1x1x416xf32>\n    %4 = tensor.empty() : tensor<666x14x14x416xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x416xf32>, tensor<1x1x1x416xf32>) outs(%4 : tensor<666x14x14x416xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = tensor.empty() : tensor<666x7x7x672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x672xf32>) outs(%2 : tensor<666x7x7x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<22xf32>) -> tensor<22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<22xf32>, tensor<1xf32>) outs(%4 : tensor<22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x576xf32>) -> tensor<666x28x28x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x28x28x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x28x28x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %4 = tensor.empty() : tensor<666x28x28x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x112xf32>, tensor<666x28x28x112xf32>) outs(%4 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<56xf32>) -> tensor<56xf32>\n    %2 = tensor.empty() : tensor<56xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<56xf32>) outs(%2 : tensor<56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x32xf32>) -> tensor<666x1x1x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x32xf32>) -> tensor<128x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x1x1x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x32xf32>, tensor<128x1x1x32xf32>) outs(%7 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<666x28x28x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3024x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3024x1x1x1232xf32>) -> tensor<3024x1x1x1232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3024xf32>) -> tensor<3024xf32>\n    %6 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3024xf32>) outs(%6 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x3024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1232xf32>, tensor<3024x1x1x1232xf32>) outs(%7 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x35x35x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1512xf32>, tensor<666x7x7x1512xf32>) outs(%4 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x2016xf32>) -> tensor<666x1x7x2016xf32>\n    %2 = tensor.empty() : tensor<666x1x2016xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x2016xf32>) -> tensor<666x1x2016xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x2016xf32>) outs(%3 : tensor<666x1x2016xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x2016xf32> into tensor<666x1x1x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x992xf32>) -> tensor<666x7x7x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x992xf32>) -> tensor<1x1x1x992xf32>\n    %4 = tensor.empty() : tensor<666x7x7x992xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x992xf32>, tensor<1x1x1x992xf32>) outs(%4 : tensor<666x7x7x992xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<208xf32>) -> tensor<208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<208xf32>, tensor<1xf32>) outs(%4 : tensor<208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = tensor.empty() : tensor<666x1x1x144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x144xf32>) outs(%2 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x3072xf32>) -> tensor<1x130536x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x3072x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x3072x768xf32>) -> tensor<1x3072x768xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x768xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x768xf32>) -> tensor<1x130536x768xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x3072xf32>, tensor<1x3072x768xf32>) outs(%5 : tensor<1x130536x768xf32>) -> tensor<1x130536x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x2048xf32>) outs(%2 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x336xf32>) -> tensor<666x1x1x336xf32>\n    %2 = tensor.empty() : tensor<666x1x1x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x336xf32>) outs(%2 : tensor<666x1x1x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x864xf32>) -> tensor<666x7x7x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x864xf32>) -> tensor<128x1x1x864xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x864xf32>, tensor<128x1x1x864xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x608xf32>) -> tensor<1x1x1x608xf32>\n    %4 = tensor.empty() : tensor<666x7x7x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x608xf32>, tensor<1x1x1x608xf32>) outs(%4 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<666x7x7x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x960xf32>) -> tensor<666x14x14x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x960xf32>) -> tensor<1x1x1x960xf32>\n    %4 = tensor.empty() : tensor<666x14x14x960xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x960xf32>, tensor<1x1x1x960xf32>) outs(%4 : tensor<666x14x14x960xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x28x28x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %4 = tensor.empty() : tensor<666x7x7x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x608xf32>, tensor<666x7x7x608xf32>) outs(%4 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x224xf32>) -> tensor<666x112x112x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x112x112x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x112x112x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x224xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x8x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x8x2048xf32>) -> tensor<666x1x8x2048xf32>\n    %2 = tensor.empty() : tensor<666x1x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x2048xf32>) -> tensor<666x1x2048xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x8x2048xf32>) outs(%3 : tensor<666x1x2048xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x2048xf32> into tensor<666x1x1x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<42xf32>) -> tensor<42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<42xf32>, tensor<1xf32>) outs(%4 : tensor<42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<666x28x28x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = tensor.empty() : tensor<666x14x14x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x768xf32>) outs(%2 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x16xf32>) -> tensor<666x1x1x16xf32>\n    %2 = tensor.empty() : tensor<666x1x1x16xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x16xf32>) outs(%2 : tensor<666x1x1x16xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<56x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<56x1x1x224xf32>) -> tensor<56x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<56xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<56xf32>) -> tensor<56xf32>\n    %6 = tensor.empty() : tensor<666x1x1x56xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<56xf32>) outs(%6 : tensor<666x1x1x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x56xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x224xf32>, tensor<56x1x1x224xf32>) outs(%7 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x432xf32>) -> tensor<666x28x28x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x432xf32>) -> tensor<1x1x1x432xf32>\n    %4 = tensor.empty() : tensor<666x28x28x432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x432xf32>, tensor<1x1x1x432xf32>) outs(%4 : tensor<666x28x28x432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x432xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = tensor.empty() : tensor<666x28x104xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x104xf32>) -> tensor<666x28x104xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x104xf32>) outs(%3 : tensor<666x28x104xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x104xf32> into tensor<666x1x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x480xf32>) -> tensor<666x28x28x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x480xf32>) -> tensor<1x1x1x480xf32>\n    %4 = tensor.empty() : tensor<666x28x28x480xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x480xf32>, tensor<1x1x1x480xf32>) outs(%4 : tensor<666x28x28x480xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = tensor.empty() : tensor<666x28x28x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x96xf32>) outs(%2 : tensor<666x28x28x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1600xf32>) -> tensor<666x14x14x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1600xf32>) -> tensor<1x1x1x1600xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1600xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1600xf32>, tensor<1x1x1x1600xf32>) outs(%4 : tensor<666x14x14x1600xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x224xf32>) -> tensor<666x112x112x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x112x112x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x112x112x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1280xf32>, tensor<1x1x1x1280xf32>) outs(%4 : tensor<666x7x7x1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x28x28x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x28x28x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<128xf32>) -> tensor<128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<128xf32>, tensor<1xf32>) outs(%4 : tensor<128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %4 = tensor.empty() : tensor<666x14x14x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x208xf32>, tensor<666x14x14x208xf32>) outs(%4 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %4 = tensor.empty() : tensor<666x14x14x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<666x14x14x896xf32>) outs(%4 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x167x167x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x167x167x42xf32>) -> tensor<666x167x167x42xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x83x83x42xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x167x167x42xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %c1 = arith.constant 1 : index\n    %c83 = arith.constant 83 : index\n    %c2 = arith.constant 2 : index\n    %c83_1 = arith.constant 83 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c83, %c1_2 : index\n    %7 = arith.subi %c83_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x83x83x42xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x83x83x42xf32>) outs(%8 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x720xf32>) -> tensor<1x1x1x720xf32>\n    %4 = tensor.empty() : tensor<666x14x14x720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x720xf32>, tensor<1x1x1x720xf32>) outs(%4 : tensor<666x14x14x720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x720xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x128xf32>) -> tensor<666x1x28x128xf32>\n    %2 = tensor.empty() : tensor<666x1x128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x128xf32>) -> tensor<666x1x128xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x128xf32>) outs(%3 : tensor<666x1x128xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x128xf32> into tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x120xf32>) -> tensor<336x1x1x120xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x28x28x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x28x28x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x120xf32>, tensor<336x1x1x120xf32>) outs(%7 : tensor<666x28x28x336xf32>) -> tensor<666x28x28x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1024xf32>) -> tensor<666x28x28x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x1024xf32>) -> tensor<666x28x28x1024xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1024xf32>, tensor<666x28x28x1024xf32>) outs(%4 : tensor<666x28x28x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1344xf32>) -> tensor<1344xf32>\n    %2 = tensor.empty() : tensor<1344xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1344xf32>) outs(%2 : tensor<1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = tensor.empty() : tensor<666x112x112x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x32xf32>) outs(%2 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x208xf32>) -> tensor<666x28x28x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x208xf32>) -> tensor<1x1x1x208xf32>\n    %4 = tensor.empty() : tensor<666x28x28x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x208xf32>, tensor<1x1x1x208xf32>) outs(%4 : tensor<666x28x28x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x152xf32>) -> tensor<1x1x1x152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x152xf32>, tensor<1x1x1x152xf32>) outs(%4 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x3072xf32>) -> tensor<1x32634x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x3072x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x3072x768xf32>) -> tensor<1x3072x768xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x768xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x768xf32>) -> tensor<1x32634x768xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x3072xf32>, tensor<1x3072x768xf32>) outs(%5 : tensor<1x32634x768xf32>) -> tensor<1x32634x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1312xf32>) -> tensor<666x14x14x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1312xf32>) -> tensor<1x1x1x1312xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1312xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1312xf32>, tensor<1x1x1x1312xf32>) outs(%4 : tensor<666x14x14x1312xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x2048xf32>) outs(%2 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x56x56x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x64xf32>) -> tensor<666x224x224x64xf32>\n    %2 = tensor.empty() : tensor<666x224x224x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x224x224x64xf32>) outs(%2 : tensor<666x224x224x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x224x224x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = tensor.empty() : tensor<666x56x56x144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x144xf32>) outs(%2 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<64xf32>) -> tensor<64xf32>\n    %2 = tensor.empty() : tensor<64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<64xf32>) outs(%2 : tensor<64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<216x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<216x1x1x72xf32>) -> tensor<216x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<216xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<216xf32>) -> tensor<216xf32>\n    %6 = tensor.empty() : tensor<666x28x28x216xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<216xf32>) outs(%6 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x216xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<216x1x1x72xf32>) outs(%7 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %2 = tensor.empty() : tensor<666xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666xf32>) -> tensor<666xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1024xf32>) outs(%3 : tensor<666xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0, 1]] : tensor<666xf32> into tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1056xf32>) -> tensor<666x14x14x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1056xf32>) -> tensor<1x1x1x1056xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1056xf32>, tensor<1x1x1x1056xf32>) outs(%4 : tensor<666x14x14x1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x32xf32>) -> tensor<666x147x147x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x147x147x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x147x147x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x576xf32>) -> tensor<666x7x7x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x1x576xf32>) -> tensor<160x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %6 = tensor.empty() : tensor<666x7x7x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x7x7x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x576xf32>, tensor<160x1x1x576xf32>) outs(%7 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x1x1x728xf32>) -> tensor<1024x1x1x728xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x19x19x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x19x19x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x19x19x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x19x19x728xf32>, tensor<1024x1x1x728xf32>) outs(%7 : tensor<666x19x19x1024xf32>) -> tensor<666x19x19x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %4 = tensor.empty() : tensor<666x28x28x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x448xf32>, tensor<666x28x28x448xf32>) outs(%4 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1000xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1000xf32>) -> tensor<666x1000xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %4 = tensor.empty() : tensor<666x1000xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1000xf32>, tensor<666x1xf32>) outs(%4 : tensor<666x1000xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1000xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = tensor.empty() : tensor<666x56x56xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56xf32>) -> tensor<666x56x56xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x256xf32>) outs(%3 : tensor<666x56x56xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x56x56xf32> into tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x48xf32>) -> tensor<96x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x28x28x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x28x28x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<96x1x1x48xf32>) outs(%7 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x32xf32>) -> tensor<224x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x112x112x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x112x112x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<224x1x1x32xf32>) outs(%7 : tensor<666x112x112x224xf32>) -> tensor<666x112x112x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x3x3x256xf32>) -> tensor<288x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x8x8x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x8x8x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x256xf32>, tensor<288x3x3x256xf32>) outs(%7 : tensor<666x8x8x288xf32>) -> tensor<666x8x8x288xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x896xf32>) -> tensor<666x1x14x896xf32>\n    %2 = tensor.empty() : tensor<666x1x896xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x896xf32>) -> tensor<666x1x896xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x896xf32>) outs(%3 : tensor<666x1x896xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x896xf32> into tensor<666x1x1x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x32xf32>) -> tensor<336x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x56x56x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x56x56x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<336x1x1x32xf32>) outs(%7 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x14x14x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1632xf32>) -> tensor<666x14x14x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1632xf32>) -> tensor<128x1x1x1632xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1632xf32>, tensor<128x1x1x1632xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<666x28x28x1xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<3712xf32>) -> tensor<3712xf32>\n    %2 = tensor.empty() : tensor<3712xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<3712xf32>) outs(%2 : tensor<3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x368xf32>) -> tensor<666x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x368xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1024xf32>) -> tensor<1024xf32>\n    %2 = tensor.empty() : tensor<1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1024xf32>) outs(%2 : tensor<1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = tensor.empty() : tensor<666x1x1x224xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x224xf32>) outs(%2 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x408xf32>) -> tensor<1x1x1x408xf32>\n    %4 = tensor.empty() : tensor<666x14x14x408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x408xf32>, tensor<1x1x1x408xf32>) outs(%4 : tensor<666x14x14x408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1856xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1856xf32>) -> tensor<666x7x7x1856xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1856xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1856xf32>) -> tensor<1x1x1x1856xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1856xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1856xf32>, tensor<1x1x1x1856xf32>) outs(%4 : tensor<666x7x7x1856xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1856xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x832xf32>) -> tensor<666x14x14x832xf32>\n    %2 = tensor.empty() : tensor<666x14x14x832xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x832xf32>) outs(%2 : tensor<666x14x14x832xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x14x14x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x14x14x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x128xf32>) -> tensor<512x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<512x1x1x128xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = tensor.empty() : tensor<666x7x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x2048xf32>) -> tensor<666x7x2048xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x2048xf32>) outs(%3 : tensor<666x7x2048xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x2048xf32> into tensor<666x1x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x26xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x26xf32>) -> tensor<666x1x1x26xf32>\n    %2 = bufferization.alloc_tensor() : tensor<104x1x1x26xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<104x1x1x26xf32>) -> tensor<104x1x1x26xf32>\n    %4 = bufferization.alloc_tensor() : tensor<104xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<104xf32>) -> tensor<104xf32>\n    %6 = tensor.empty() : tensor<666x1x1x104xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<104xf32>) outs(%6 : tensor<666x1x1x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x104xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x26xf32>, tensor<104x1x1x26xf32>) outs(%7 : tensor<666x1x1x104xf32>) -> tensor<666x1x1x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x352xf32>) -> tensor<666x28x28x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x352xf32>) -> tensor<1x1x1x352xf32>\n    %4 = tensor.empty() : tensor<666x28x28x352xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x352xf32>, tensor<1x1x1x352xf32>) outs(%4 : tensor<666x28x28x352xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x1x1x896xf32>) -> tensor<2048x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<2048x1x1x896xf32>) outs(%7 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\n#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x171x171x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x171x171x96xf32>) -> tensor<666x171x171x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x96x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x96x1xf32>) -> tensor<7x7x96x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x83x83x96x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x83x83x96x1xf32>) -> tensor<666x83x83x96x1xf32>\n    %8 = tensor.empty() : tensor<666x83x83x96xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x171x171x96xf32>, tensor<7x7x96x1xf32>) outs(%7 : tensor<666x83x83x96x1xf32>) -> tensor<666x83x83x96x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x83x83x96x1xf32> into tensor<666x83x83x96xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<96xf32>, tensor<666x83x83x96xf32>) outs(%8 : tensor<666x83x83x96xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x83x83x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x1x1x32xf32>) -> tensor<80x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %6 = tensor.empty() : tensor<666x56x56x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<80x1x1x32xf32>) outs(%7 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x768xf32>) -> tensor<666x1x7x768xf32>\n    %2 = tensor.empty() : tensor<666x1x768xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x768xf32>) -> tensor<666x1x768xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x768xf32>) outs(%3 : tensor<666x1x768xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x768xf32> into tensor<666x1x1x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<448xf32>) -> tensor<448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<448xf32>, tensor<1xf32>) outs(%4 : tensor<448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1088xf32>) -> tensor<666x1x1x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1088xf32>) -> tensor<128x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x1x1x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1088xf32>, tensor<128x1x1x1088xf32>) outs(%7 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1664xf32>) -> tensor<666x14x14x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1664xf32>) -> tensor<1x1x1x1664xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1664xf32>, tensor<1x1x1x1664xf32>) outs(%4 : tensor<666x14x14x1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<666x7x7x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x17x17x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x17x17x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x912xf32>) -> tensor<1x1x1x912xf32>\n    %4 = tensor.empty() : tensor<666x7x7x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x912xf32>, tensor<1x1x1x912xf32>) outs(%4 : tensor<666x7x7x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x800xf32>) -> tensor<666x7x7x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x800xf32>) -> tensor<128x1x1x800xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x800xf32>, tensor<128x1x1x800xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1216xf32>) -> tensor<666x14x14x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1216xf32>) -> tensor<1x1x1x1216xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1216xf32>, tensor<1x1x1x1216xf32>) outs(%4 : tensor<666x14x14x1216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<152x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<152x1x1x152xf32>) -> tensor<152x1x1x152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<152xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<152xf32>) -> tensor<152xf32>\n    %6 = tensor.empty() : tensor<666x14x14x152xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<152xf32>) outs(%6 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x152xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x152xf32>, tensor<152x1x1x152xf32>) outs(%7 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x87x87x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x87x87x84xf32>) -> tensor<666x87x87x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x84x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x84x1xf32>) -> tensor<5x5x84x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %6 = tensor.empty() : tensor<666x42x42x84x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %8 = tensor.empty() : tensor<666x42x42x84xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x87x87x84xf32>, tensor<5x5x84x1xf32>) outs(%7 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x42x42x84x1xf32> into tensor<666x42x42x84xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<84xf32>, tensor<666x42x42x84xf32>) outs(%8 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x288xf32>) -> tensor<666x56x56x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x56x56x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x56x56x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1248xf32>) -> tensor<666x7x7x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1248xf32>) -> tensor<1x1x1x1248xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1248xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1248xf32>, tensor<1x1x1x1248xf32>) outs(%4 : tensor<666x7x7x1248xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x32x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x32x1xf32>) -> tensor<3x3x32x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x112x112x32xf32> to tensor<666x114x114x32xf32>\n    %6 = tensor.empty() : tensor<666x112x112x32x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x112x112x32x1xf32>) -> tensor<666x112x112x32x1xf32>\n    %8 = tensor.empty() : tensor<666x112x112x32xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x114x114x32xf32>, tensor<3x3x32x1xf32>) outs(%7 : tensor<666x112x112x32x1xf32>) -> tensor<666x112x112x32x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x112x112x32x1xf32> into tensor<666x112x112x32xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<32xf32>, tensor<666x112x112x32xf32>) outs(%8 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x768xf32>) -> tensor<666x56x56x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x768xf32>) -> tensor<666x56x56x768xf32>\n    %4 = tensor.empty() : tensor<666x56x56x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x768xf32>, tensor<666x56x56x768xf32>) outs(%4 : tensor<666x56x56x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1360x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1360x1x1x560xf32>) -> tensor<1360x1x1x560xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1360xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1360xf32>) -> tensor<1360xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1360xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1360xf32>) outs(%6 : tensor<666x7x7x1360xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1360xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x560xf32>, tensor<1360x1x1x560xf32>) outs(%7 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1024xf32>) -> tensor<666x56x56x1024xf32>\n    %2 = tensor.empty() : tensor<666x56x56x1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x1024xf32>) outs(%2 : tensor<666x56x56x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x120xf32>) -> tensor<1x1x1x120xf32>\n    %4 = tensor.empty() : tensor<666x28x28x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x120xf32>, tensor<1x1x1x120xf32>) outs(%4 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = tensor.empty() : tensor<666x28x28x696xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x696xf32>) outs(%2 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1392xf32>) -> tensor<1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1392xf32>, tensor<1xf32>) outs(%4 : tensor<1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x32xf32>) -> tensor<64x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x56x56x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<64x1x1x32xf32>) outs(%7 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x216xf32>) -> tensor<666x1x1x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<18x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<18x1x1x216xf32>) -> tensor<18x1x1x216xf32>\n    %4 = bufferization.alloc_tensor() : tensor<18xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<18xf32>) -> tensor<18xf32>\n    %6 = tensor.empty() : tensor<666x1x1x18xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<18xf32>) outs(%6 : tensor<666x1x1x18xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x18xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x216xf32>, tensor<18x1x1x216xf32>) outs(%7 : tensor<666x1x1x18xf32>) -> tensor<666x1x1x18xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x256xf32>) -> tensor<666x8x8x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x8x8x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x8x8x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1312xf32>) -> tensor<666x14x14x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1312xf32>) -> tensor<1x1x1x1312xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1312xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1312xf32>, tensor<1x1x1x1312xf32>) outs(%4 : tensor<666x14x14x1312xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x149x149x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x149x149x32xf32>) -> tensor<666x149x149x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x32xf32>) -> tensor<64x3x3x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x147x147x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x147x147x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x147x147x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x149x149x32xf32>, tensor<64x3x3x32xf32>) outs(%7 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x152xf32>) -> tensor<666x28x28x152xf32>\n    %2 = tensor.empty() : tensor<666x28x28x152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x152xf32>) outs(%2 : tensor<666x28x28x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %4 = tensor.empty() : tensor<666x7x7x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x384xf32>, tensor<666x7x7x384xf32>) outs(%4 : tensor<666x7x7x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x112xf32>) -> tensor<1x1x1x112xf32>\n    %4 = tensor.empty() : tensor<666x28x28x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x112xf32>, tensor<1x1x1x112xf32>) outs(%4 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1280xf32>) -> tensor<128x1x1x1280xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1280xf32>, tensor<128x1x1x1280xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x640xf32>) -> tensor<666x14x14x640xf32>\n    %2 = tensor.empty() : tensor<666x14x14x640xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x640xf32>) outs(%2 : tensor<666x14x14x640xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x640xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x384xf32>) -> tensor<1x2088576x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x384x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x384x96xf32>) -> tensor<1x384x96xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x96xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x96xf32>) -> tensor<1x2088576x96xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x384xf32>, tensor<1x384x96xf32>) outs(%5 : tensor<1x2088576x96xf32>) -> tensor<1x2088576x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x14x14x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x14x14x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x176xf32>) -> tensor<1x1x1x176xf32>\n    %4 = tensor.empty() : tensor<666x7x7x176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x176xf32>, tensor<1x1x1x176xf32>) outs(%4 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x4096xf32>) -> tensor<666x7x7x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x4096xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = tensor.empty() : tensor<666x7x7x528xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x528xf32>) outs(%2 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x14x14x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<416xf32>) -> tensor<416xf32>\n    %2 = tensor.empty() : tensor<416xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<416xf32>) outs(%2 : tensor<416xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1376xf32>) -> tensor<666x7x7x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1376xf32>) -> tensor<128x1x1x1376xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1376xf32>, tensor<128x1x1x1376xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1728xf32>) -> tensor<666x7x7x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1728xf32>) -> tensor<1x1x1x1728xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1728xf32>, tensor<1x1x1x1728xf32>) outs(%4 : tensor<666x7x7x1728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<352xf32>) -> tensor<352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<352xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<352xf32>, tensor<1xf32>) outs(%4 : tensor<352xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x64xf32>) -> tensor<128x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x74x74x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x74x74x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x74x74x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x147x147x64xf32>, tensor<128x1x1x64xf32>) outs(%7 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x384xf32>) -> tensor<666x56x56x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x384xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1392xf32>) -> tensor<1392xf32>\n    %2 = tensor.empty() : tensor<1392xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1392xf32>) outs(%2 : tensor<1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1392xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x3712xf32>) -> tensor<666x1x7x3712xf32>\n    %2 = tensor.empty() : tensor<666x1x3712xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x3712xf32>) -> tensor<666x1x3712xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x3712xf32>) outs(%3 : tensor<666x1x3712xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x3712xf32> into tensor<666x1x1x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1280xf32>) -> tensor<1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1280xf32>, tensor<1xf32>) outs(%4 : tensor<1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x64xf32>) -> tensor<8x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x64xf32>, tensor<8x1x1x64xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x288xf32>) -> tensor<666x8x8x288xf32>\n    %2 = tensor.empty() : tensor<666x8x8x288xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x288xf32>) outs(%2 : tensor<666x8x8x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<176x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<176x1x1x528xf32>) -> tensor<176x1x1x528xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %6 = tensor.empty() : tensor<666x14x14x176xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<176xf32>) outs(%6 : tensor<666x14x14x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x176xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x528xf32>, tensor<176x1x1x528xf32>) outs(%7 : tensor<666x14x14x176xf32>) -> tensor<666x14x14x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x1x64xf32>) -> tensor<160x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %6 = tensor.empty() : tensor<666x14x14x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x14x14x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<160x1x1x64xf32>) outs(%7 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x224x224x3xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x224x224x3xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x224x224x3xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x864xf32>) -> tensor<666x14x14x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x864xf32>) -> tensor<128x1x1x864xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x864xf32>, tensor<128x1x1x864xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x576xf32>) -> tensor<666x28x28x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x28x28x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x28x28x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1184xf32>) -> tensor<666x14x14x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1184xf32>) -> tensor<128x1x1x1184xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1184xf32>, tensor<128x1x1x1184xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x368xf32>) -> tensor<666x14x14x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x368xf32>) -> tensor<1x1x1x368xf32>\n    %4 = tensor.empty() : tensor<666x14x14x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x368xf32>, tensor<1x1x1x368xf32>) outs(%4 : tensor<666x14x14x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x128xf32>) -> tensor<192x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x56x56x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<192x1x1x128xf32>) outs(%7 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1664xf32>) -> tensor<1x666x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1664x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1664x1000xf32>) -> tensor<1x1664x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1664xf32>, tensor<1x1664x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<88x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<88x1x1x528xf32>) -> tensor<88x1x1x528xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<88xf32>) outs(%6 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x88xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x528xf32>, tensor<88x1x1x528xf32>) outs(%7 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2016x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2016x1x1x896xf32>) -> tensor<2016x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2016xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2016xf32>) -> tensor<2016xf32>\n    %6 = tensor.empty() : tensor<666x14x14x2016xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2016xf32>) outs(%6 : tensor<666x14x14x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x2016xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<2016x1x1x896xf32>) outs(%7 : tensor<666x14x14x2016xf32>) -> tensor<666x14x14x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1408xf32>) -> tensor<1408xf32>\n    %2 = tensor.empty() : tensor<1408xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1408xf32>) outs(%2 : tensor<1408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<392x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<392x1x1x168xf32>) -> tensor<392x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<392xf32>) -> tensor<392xf32>\n    %6 = tensor.empty() : tensor<666x56x56x392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<392xf32>) outs(%6 : tensor<666x56x56x392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<392x1x1x168xf32>) outs(%7 : tensor<666x56x56x392xf32>) -> tensor<666x56x56x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x4096xf32>) -> tensor<666x4096xf32>\n    %2 = tensor.empty() : tensor<666x4096xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1 : tensor<666x4096xf32>) outs(%2 : tensor<666x4096xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x4096xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x1024xf32>) -> tensor<666x19x19x1024xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x19x19x1024xf32> to tensor<666x21x21x1024xf32>\n    %cst_1 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x10x10x1024xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%padded, %4 : tensor<666x21x21x1024xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = tensor.empty() : tensor<666x7x7x960xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x960xf32>) outs(%2 : tensor<666x7x7x960xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x256xf32>) -> tensor<64x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x56x56x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<64x1x1x256xf32>) outs(%7 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1536xf32>) -> tensor<1x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %4 = tensor.empty() : tensor<666x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1536xf32>, tensor<666x1536xf32>) outs(%4 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1856xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1856xf32>) -> tensor<666x7x7x1856xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1856xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1856xf32>) -> tensor<128x1x1x1856xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1856xf32>, tensor<128x1x1x1856xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1440xf32>) -> tensor<666x14x14x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1440xf32>) -> tensor<1x1x1x1440xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1440xf32>, tensor<1x1x1x1440xf32>) outs(%4 : tensor<666x14x14x1440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1440xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x384xf32>) -> tensor<1x666x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x384x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x384x1000xf32>) -> tensor<1x384x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x384xf32>, tensor<1x384x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x8x8x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x8x8x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x3x3x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x3x3x32xf32>) -> tensor<48x3x3x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x32xf32> to tensor<666x37x37x32xf32>\n    %6 = tensor.empty() : tensor<666x35x35x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x37x37x32xf32>, tensor<48x3x3x32xf32>) outs(%7 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x56x56x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x30xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x30xf32>) -> tensor<666x1x1x30xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x30xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x30xf32>) -> tensor<336x1x1x30xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x1x1x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x1x1x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x30xf32>, tensor<336x1x1x30xf32>) outs(%7 : tensor<666x1x1x336xf32>) -> tensor<666x1x1x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<352xf32>) -> tensor<352xf32>\n    %2 = tensor.empty() : tensor<352xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<352xf32>) outs(%2 : tensor<352xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = tensor.empty() : tensor<666x28x28x104xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x104xf32>) outs(%2 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x336xf32>) -> tensor<666x1x14x336xf32>\n    %2 = tensor.empty() : tensor<666x1x336xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x336xf32>) -> tensor<666x1x336xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x336xf32>) outs(%3 : tensor<666x1x336xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x336xf32> into tensor<666x1x1x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1632xf32>) -> tensor<666x14x14x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1632xf32>) -> tensor<1x1x1x1632xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1632xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1632xf32>, tensor<1x1x1x1632xf32>) outs(%4 : tensor<666x14x14x1632xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<288xf32>) -> tensor<288xf32>\n    %2 = tensor.empty() : tensor<288xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<288xf32>) outs(%2 : tensor<288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x640xf32>) -> tensor<666x14x14x640xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x7x7x640xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x640xf32>) -> tensor<666x7x7x640xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x14x14x640xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x7x7x640xf32>) -> tensor<666x7x7x640xf32>\n    %c1 = arith.constant 1 : index\n    %c7 = arith.constant 7 : index\n    %c2 = arith.constant 2 : index\n    %c7_1 = arith.constant 7 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c7, %c1_2 : index\n    %7 = arith.subi %c7_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x7x7x640xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x7x7x640xf32>) outs(%8 : tensor<666x7x7x640xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c2_4 = arith.constant 2 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c2_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c2_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c2_6 = arith.constant 2 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c2_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c2_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x7x7x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x888xf32>) -> tensor<1x1x1x888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x888xf32>, tensor<1x1x1x888xf32>) outs(%4 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %2 = tensor.empty() : tensor<666x7x384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x384xf32>) -> tensor<666x7x384xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x384xf32>) outs(%3 : tensor<666x7x384xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x384xf32> into tensor<666x1x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x42x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x42x1xf32>) -> tensor<5x5x42x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x83x83x42xf32> to tensor<666x87x87x42xf32>\n    %6 = tensor.empty() : tensor<666x83x83x42x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %8 = tensor.empty() : tensor<666x83x83x42xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x87x87x42xf32>, tensor<5x5x42x1xf32>) outs(%7 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x83x83x42x1xf32> into tensor<666x83x83x42xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<42xf32>, tensor<666x83x83x42xf32>) outs(%8 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<56x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<56x1x1x56xf32>) -> tensor<56x1x1x56xf32>\n    %4 = bufferization.alloc_tensor() : tensor<56xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<56xf32>) -> tensor<56xf32>\n    %6 = tensor.empty() : tensor<666x28x28x56xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<56xf32>) outs(%6 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x56xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x56xf32>, tensor<56x1x1x56xf32>) outs(%7 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x288xf32>) -> tensor<666x56x56x288xf32>\n    %2 = tensor.empty() : tensor<666x56x56x288xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x288xf32>) outs(%2 : tensor<666x56x56x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<440x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<440x1x1x208xf32>) -> tensor<440x1x1x208xf32>\n    %4 = bufferization.alloc_tensor() : tensor<440xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<440xf32>) -> tensor<440xf32>\n    %6 = tensor.empty() : tensor<666x14x14x440xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<440xf32>) outs(%6 : tensor<666x14x14x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x440xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x208xf32>, tensor<440x1x1x208xf32>) outs(%7 : tensor<666x14x14x440xf32>) -> tensor<666x14x14x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x4x4x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x4x4x3xf32>) -> tensor<128x4x4x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<4> : tensor<2xi64>} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<128x4x4x3xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1512xf32>) -> tensor<666x14x14x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1512xf32>) -> tensor<1x1x1x1512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1512xf32>, tensor<1x1x1x1512xf32>) outs(%4 : tensor<666x14x14x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    %2 = tensor.empty() : tensor<666x7x1280xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1280xf32>) -> tensor<666x7x1280xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1280xf32>) outs(%3 : tensor<666x7x1280xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1280xf32> into tensor<666x1x7x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x3x3x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x3x3x448xf32>) -> tensor<384x3x3x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x8x8x448xf32> to tensor<666x10x10x448xf32>\n    %6 = tensor.empty() : tensor<666x8x8x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x10x10x448xf32>, tensor<384x3x3x448xf32>) outs(%7 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x2048xf32>) -> tensor<192x1x1x2048xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x8x8x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x2048xf32>, tensor<192x1x1x2048xf32>) outs(%7 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = tensor.empty() : tensor<666x14x14x408xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x408xf32>) outs(%2 : tensor<666x14x14x408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1280xf32>, tensor<1x1x1x1280xf32>) outs(%4 : tensor<666x7x7x1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1280xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x4096xf32>) -> tensor<1x32634x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x4096x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x4096x1024xf32>) -> tensor<1x4096x1024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x1024xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x1024xf32>) -> tensor<1x32634x1024xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x4096xf32>, tensor<1x4096x1024xf32>) outs(%5 : tensor<1x32634x1024xf32>) -> tensor<1x32634x1024xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x888xf32>) -> tensor<1x666x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x888x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x888x1000xf32>) -> tensor<1x888x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x888xf32>, tensor<1x888x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x208xf32>) -> tensor<666x1x1x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<26x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<26x1x1x208xf32>) -> tensor<26x1x1x208xf32>\n    %4 = bufferization.alloc_tensor() : tensor<26xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<26xf32>) -> tensor<26xf32>\n    %6 = tensor.empty() : tensor<666x1x1x26xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<26xf32>) outs(%6 : tensor<666x1x1x26xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x26xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x208xf32>, tensor<26x1x1x208xf32>) outs(%7 : tensor<666x1x1x26xf32>) -> tensor<666x1x1x26xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<84x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<84x1x1x84xf32>) -> tensor<84x1x1x84xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %6 = tensor.empty() : tensor<666x42x42x84xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<84xf32>) outs(%6 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x42x42x84xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x42x42x84xf32>, tensor<84x1x1x84xf32>) outs(%7 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x8x8x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x8x8x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x5x5x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x5x5x48xf32>) -> tensor<64x5x5x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x48xf32> to tensor<666x39x39x48xf32>\n    %6 = tensor.empty() : tensor<666x35x35x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x39x39x48xf32>, tensor<64x5x5x48xf32>) outs(%7 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x147x147x128xf32> to tensor<666x149x149x128xf32>\n    %cst_1 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x74x74x128xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%padded, %4 : tensor<666x149x149x128xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x256xf32>) -> tensor<1x522144x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x256x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x256x1024xf32>) -> tensor<1x256x1024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x1024xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x1024xf32>) -> tensor<1x522144x1024xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x256xf32>, tensor<1x256x1024xf32>) outs(%5 : tensor<1x522144x1024xf32>) -> tensor<1x522144x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x3x3x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x3x3x192xf32>) -> tensor<192x3x3x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x8x8x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x192xf32>, tensor<192x3x3x192xf32>) outs(%7 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    %2 = tensor.empty() : tensor<666x35x35x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x35x35x96xf32>) outs(%2 : tensor<666x35x35x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x35x35x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1312xf32>) -> tensor<666x7x7x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1312xf32>) -> tensor<1x1x1x1312xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1312xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1312xf32>, tensor<1x1x1x1312xf32>) outs(%4 : tensor<666x7x7x1312xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x608xf32>) -> tensor<666x14x14x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x608xf32>) -> tensor<1x1x1x608xf32>\n    %4 = tensor.empty() : tensor<666x14x14x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x608xf32>, tensor<1x1x1x608xf32>) outs(%4 : tensor<666x14x14x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2016xf32>) -> tensor<666x14x14x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2016xf32>) -> tensor<1x1x1x2016xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2016xf32>, tensor<1x1x1x2016xf32>) outs(%4 : tensor<666x14x14x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x224xf32>) -> tensor<896x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x1x1x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x1x1x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x224xf32>, tensor<896x1x1x224xf32>) outs(%7 : tensor<666x1x1x896xf32>) -> tensor<666x1x1x896xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x37x37x728xf32> to tensor<666x39x39x728xf32>\n    %cst_1 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x19x19x728xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%padded, %4 : tensor<666x39x39x728xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x28x28x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x28x28x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x768xf32>) -> tensor<666x56x56x768xf32>\n    %2 = tensor.empty() : tensor<666x56x56x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x768xf32>) outs(%2 : tensor<666x56x56x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1088xf32>) -> tensor<666x14x14x1088xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1088xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1088xf32>) outs(%2 : tensor<666x14x14x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %2 = tensor.empty() : tensor<666x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x1536xf32>, tensor<666x1536xf32>) outs(%2 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x64xf32>) -> tensor<128x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<128x1x1x64xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<560x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<560x1x1x240xf32>) -> tensor<560x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<560xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<560xf32>) -> tensor<560xf32>\n    %6 = tensor.empty() : tensor<666x28x28x560xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<560xf32>) outs(%6 : tensor<666x28x28x560xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x560xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<560x1x1x240xf32>) outs(%7 : tensor<666x28x28x560xf32>) -> tensor<666x28x28x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x1008xf32>) -> tensor<666x21x21x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x1008xf32>) -> tensor<168x1x1x1008xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x21x21x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x21x21x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x21x21x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x21x21x1008xf32>, tensor<168x1x1x1008xf32>) outs(%7 : tensor<666x21x21x168xf32>) -> tensor<666x21x21x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x32xf32>) -> tensor<666x111x111x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x111x111x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x111x111x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x111x111x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x111x111x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2520xf32>) -> tensor<2520xf32>\n    %2 = tensor.empty() : tensor<2520xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<2520xf32>) outs(%2 : tensor<2520xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x24xf32>) -> tensor<1x1x1x24xf32>\n    %4 = tensor.empty() : tensor<666x56x56x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<1x1x1x24xf32>) outs(%4 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1536xf32>) -> tensor<666x28x28x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x1536xf32>) -> tensor<666x28x28x1536xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1536xf32>, tensor<666x28x28x1536xf32>) outs(%4 : tensor<666x28x28x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<912xf32>) -> tensor<912xf32>\n    %2 = tensor.empty() : tensor<912xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<912xf32>) outs(%2 : tensor<912xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2240xf32>, tensor<666x7x7x2240xf32>) outs(%4 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<440x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<440x1x1x440xf32>) -> tensor<440x1x1x440xf32>\n    %4 = bufferization.alloc_tensor() : tensor<440xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<440xf32>) -> tensor<440xf32>\n    %6 = tensor.empty() : tensor<666x7x7x440xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<440xf32>) outs(%6 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x440xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x440xf32>, tensor<440x1x1x440xf32>) outs(%7 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2080xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2080xf32>) -> tensor<666x8x8x2080xf32>\n    %2 = tensor.empty() : tensor<666x8x8x2080xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x2080xf32>) outs(%2 : tensor<666x8x8x2080xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x2080xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x528xf32>) -> tensor<1x666x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x528x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x528x1000xf32>) -> tensor<1x528x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x528xf32>, tensor<1x528x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x232xf32>) -> tensor<666x112x112x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x232xf32>) -> tensor<1x1x1x232xf32>\n    %4 = tensor.empty() : tensor<666x112x112x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x232xf32>, tensor<1x1x1x232xf32>) outs(%4 : tensor<666x112x112x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1472xf32>) -> tensor<666x14x14x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1472xf32>) -> tensor<128x1x1x1472xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1472xf32>, tensor<128x1x1x1472xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<704xf32>) -> tensor<704xf32>\n    %2 = tensor.empty() : tensor<704xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<704xf32>) outs(%2 : tensor<704xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x72xf32>) -> tensor<1x1x1x72xf32>\n    %4 = tensor.empty() : tensor<666x56x56x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<1x1x1x72xf32>) outs(%4 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1536xf32>) outs(%2 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x57x57x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x57x57x144xf32>) -> tensor<666x57x57x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x144x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x144x1xf32>) -> tensor<3x3x144x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x28x28x144x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x28x28x144x1xf32>) -> tensor<666x28x28x144x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x144xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x57x57x144xf32>, tensor<3x3x144x1xf32>) outs(%7 : tensor<666x28x28x144x1xf32>) -> tensor<666x28x28x144x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x144x1xf32> into tensor<666x28x28x144xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<144xf32>, tensor<666x28x28x144xf32>) outs(%8 : tensor<666x28x28x144xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x56xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x7x7x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x216xf32>) -> tensor<1x1x1x216xf32>\n    %4 = tensor.empty() : tensor<666x28x28x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x216xf32>, tensor<1x1x1x216xf32>) outs(%4 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1280xf32>) -> tensor<666x8x8x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x1280xf32>) -> tensor<320x1x1x1280xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x8x8x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x1280xf32>, tensor<320x1x1x1280xf32>) outs(%7 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x17x17x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x17x17x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2048xf32>) -> tensor<1x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %4 = tensor.empty() : tensor<666x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x2048xf32>, tensor<666x2048xf32>) outs(%4 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1512xf32>) -> tensor<666x1x1x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1512xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<728x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<728x1x1x728xf32>) -> tensor<728x1x1x728xf32>\n    %4 = bufferization.alloc_tensor() : tensor<728xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<728xf32>) -> tensor<728xf32>\n    %6 = tensor.empty() : tensor<666x37x37x728xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<728xf32>) outs(%6 : tensor<666x37x37x728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x37x37x728xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x37x37x728xf32>, tensor<728x1x1x728xf32>) outs(%7 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1392xf32>) -> tensor<1x1x1x1392xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1392xf32>, tensor<1x1x1x1392xf32>) outs(%4 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = tensor.empty() : tensor<666x14x14x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x256xf32>) outs(%2 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x112xf32>) -> tensor<256x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x14x14x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x112xf32>, tensor<256x1x1x112xf32>) outs(%7 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1088x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1088x1x1x1088xf32>) -> tensor<1088x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1088xf32>) -> tensor<1088xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1088xf32>) outs(%6 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1088xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1088xf32>, tensor<1088x1x1x1088xf32>) outs(%7 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x672xf32>) -> tensor<666x21x21x672xf32>\n    %2 = tensor.empty() : tensor<666x21x21x672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x21x21x672xf32>) outs(%2 : tensor<666x21x21x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x21x21x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1440xf32>) -> tensor<1440xf32>\n    %2 = tensor.empty() : tensor<1440xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1440xf32>) outs(%2 : tensor<1440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<152xf32>) -> tensor<152xf32>\n    %2 = tensor.empty() : tensor<152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<152xf32>) outs(%2 : tensor<152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x42x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x42x1xf32>) -> tensor<3x3x42x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x83x83x42xf32> to tensor<666x85x85x42xf32>\n    %6 = tensor.empty() : tensor<666x83x83x42x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %8 = tensor.empty() : tensor<666x83x83x42xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x85x85x42xf32>, tensor<3x3x42x1xf32>) outs(%7 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x83x83x42x1xf32> into tensor<666x83x83x42xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<42xf32>, tensor<666x83x83x42xf32>) outs(%8 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1888xf32>) -> tensor<666x7x7x1888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1888xf32>) -> tensor<1x1x1x1888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1888xf32>, tensor<1x1x1x1888xf32>) outs(%4 : tensor<666x7x7x1888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x240xf32>) -> tensor<666x56x56x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x56x56x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x56x56x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x720xf32>) -> tensor<1x1x1x720xf32>\n    %4 = tensor.empty() : tensor<666x14x14x720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x720xf32>, tensor<1x1x1x720xf32>) outs(%4 : tensor<666x14x14x720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x3x3x256xf32>) -> tensor<256x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x256xf32> to tensor<666x58x58x256xf32>\n    %6 = tensor.empty() : tensor<666x56x56x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x256xf32>, tensor<256x3x3x256xf32>) outs(%7 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x8xf32>) -> tensor<64x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x1x1x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x1x1x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<64x1x1x8xf32>) outs(%7 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x1008xf32>) -> tensor<666x42x42x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x1008xf32>) -> tensor<168x1x1x1008xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x42x42x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x42x42x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x42x42x1008xf32>, tensor<168x1x1x1008xf32>) outs(%7 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x73x73x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x73x73x80xf32>) -> tensor<666x73x73x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x73x73x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x73x73x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x73x73x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x73x73x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x112xf32>) -> tensor<666x56x56x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x112xf32>) -> tensor<1x1x1x112xf32>\n    %4 = tensor.empty() : tensor<666x56x56x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x112xf32>, tensor<1x1x1x112xf32>) outs(%4 : tensor<666x56x56x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x56x56x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1152xf32>) -> tensor<666x14x14x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1152xf32>) -> tensor<1x1x1x1152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1152xf32>, tensor<1x1x1x1152xf32>) outs(%4 : tensor<666x14x14x1152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = tensor.empty() : tensor<666x56x56x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x512xf32>) outs(%2 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<666x28x28x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<240xf32>) -> tensor<240xf32>\n    %2 = tensor.empty() : tensor<240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<240xf32>) outs(%2 : tensor<240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3024xf32>) -> tensor<1x1x1x3024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3024xf32>, tensor<1x1x1x3024xf32>) outs(%4 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x512xf32>) -> tensor<1x2088576x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x512x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x512x128xf32>) -> tensor<1x512x128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x128xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x128xf32>) -> tensor<1x2088576x128xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x512xf32>, tensor<1x512x128xf32>) outs(%5 : tensor<1x2088576x128xf32>) -> tensor<1x2088576x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x696xf32>) -> tensor<666x56x56x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x696xf32>) -> tensor<1x1x1x696xf32>\n    %4 = tensor.empty() : tensor<666x56x56x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x696xf32>, tensor<1x1x1x696xf32>) outs(%4 : tensor<666x56x56x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x1x1x32xf32>) -> tensor<80x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %6 = tensor.empty() : tensor<666x112x112x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x112x112x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<80x1x1x32xf32>) outs(%7 : tensor<666x112x112x80xf32>) -> tensor<666x112x112x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x56x56x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x58xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x58xf32>) -> tensor<666x1x1x58xf32>\n    %2 = bufferization.alloc_tensor() : tensor<232x1x1x58xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<232x1x1x58xf32>) -> tensor<232x1x1x58xf32>\n    %4 = bufferization.alloc_tensor() : tensor<232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<232xf32>) -> tensor<232xf32>\n    %6 = tensor.empty() : tensor<666x1x1x232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<232xf32>) outs(%6 : tensor<666x1x1x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x58xf32>, tensor<232x1x1x58xf32>) outs(%7 : tensor<666x1x1x232xf32>) -> tensor<666x1x1x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    %2 = tensor.empty() : tensor<666x1x1x56xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x56xf32>) outs(%2 : tensor<666x1x1x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<784x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<784x1x1x784xf32>) -> tensor<784x1x1x784xf32>\n    %4 = bufferization.alloc_tensor() : tensor<784xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<784xf32>) -> tensor<784xf32>\n    %6 = tensor.empty() : tensor<666x14x14x784xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<784xf32>) outs(%6 : tensor<666x14x14x784xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x784xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x784xf32>, tensor<784x1x1x784xf32>) outs(%7 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<320xf32>) -> tensor<320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<320xf32>, tensor<1xf32>) outs(%4 : tensor<320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x80xf32>) -> tensor<666x1x1x80xf32>\n    %2 = tensor.empty() : tensor<666x1x1x80xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x80xf32>) outs(%2 : tensor<666x1x1x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x264xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x264xf32>) -> tensor<666x28x28x264xf32>\n    %2 = bufferization.alloc_tensor() : tensor<88x1x1x264xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<88x1x1x264xf32>) -> tensor<88x1x1x264xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %6 = tensor.empty() : tensor<666x28x28x88xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<88xf32>) outs(%6 : tensor<666x28x28x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x88xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x264xf32>, tensor<88x1x1x264xf32>) outs(%7 : tensor<666x28x28x88xf32>) -> tensor<666x28x28x88xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x168xf32>) -> tensor<666x1x56x168xf32>\n    %2 = tensor.empty() : tensor<666x1x168xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x168xf32>) -> tensor<666x1x168xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x168xf32>) outs(%3 : tensor<666x1x168xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x168xf32> into tensor<666x1x1x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1512xf32>) -> tensor<1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1512xf32>, tensor<1xf32>) outs(%4 : tensor<1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1512xf32>) -> tensor<666x1x1x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x1512xf32>) -> tensor<144x1x1x1512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x1x1x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1512xf32>, tensor<144x1x1x1512xf32>) outs(%7 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x26xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x26xf32>) -> tensor<666x1x1x26xf32>\n    %2 = bufferization.alloc_tensor() : tensor<208x1x1x26xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<208x1x1x26xf32>) -> tensor<208x1x1x26xf32>\n    %4 = bufferization.alloc_tensor() : tensor<208xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<208xf32>) -> tensor<208xf32>\n    %6 = tensor.empty() : tensor<666x1x1x208xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<208xf32>) outs(%6 : tensor<666x1x1x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x208xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x26xf32>, tensor<208x1x1x26xf32>) outs(%7 : tensor<666x1x1x208xf32>) -> tensor<666x1x1x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x96xf32>, tensor<666x56x56x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<120x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<120x1x1x48xf32>) -> tensor<120x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<120xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<120xf32>) -> tensor<120xf32>\n    %6 = tensor.empty() : tensor<666x28x28x120xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<120xf32>) outs(%6 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x120xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<120x1x1x48xf32>) outs(%7 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x42x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x42x1xf32>) -> tensor<7x7x42x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x83x83x42xf32> to tensor<666x89x89x42xf32>\n    %6 = tensor.empty() : tensor<666x83x83x42x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %8 = tensor.empty() : tensor<666x83x83x42xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x89x89x42xf32>, tensor<7x7x42x1xf32>) outs(%7 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x83x83x42x1xf32> into tensor<666x83x83x42xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<42xf32>, tensor<666x83x83x42xf32>) outs(%8 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = tensor.empty() : tensor<666x28x128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x128xf32>) -> tensor<666x28x128xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x128xf32>) outs(%3 : tensor<666x28x128xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x128xf32> into tensor<666x1x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1248xf32>) -> tensor<1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1248xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1248xf32>, tensor<1xf32>) outs(%4 : tensor<1248xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x17x17x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x17x17x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x35x35x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x35x35x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %4 = tensor.empty() : tensor<666x7x7x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x672xf32>, tensor<666x7x7x672xf32>) outs(%4 : tensor<666x7x7x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3072xf32>) -> tensor<666x14x14x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x3072xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x3072xf32>) -> tensor<666x14x14x3072xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3072xf32>, tensor<666x14x14x3072xf32>) outs(%4 : tensor<666x14x14x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x2016xf32>) -> tensor<666x21x21x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x2016xf32>) -> tensor<672x1x1x2016xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x21x21x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x21x21x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x21x21x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x21x21x2016xf32>, tensor<672x1x1x2016xf32>) outs(%7 : tensor<666x21x21x672xf32>) -> tensor<666x21x21x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<666x56x56x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x384xf32>, tensor<666x14x14x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1088xf32>) -> tensor<666x1x1x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1088xf32>, tensor<666x7x7x1088xf32>) outs(%4 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<448xf32>) -> tensor<448xf32>\n    %2 = tensor.empty() : tensor<448xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<448xf32>) outs(%2 : tensor<448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<448xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x232xf32>) -> tensor<666x1x56x232xf32>\n    %2 = tensor.empty() : tensor<666x1x232xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x232xf32>) -> tensor<666x1x232xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x232xf32>) outs(%3 : tensor<666x1x232xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x232xf32> into tensor<666x1x1x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x256xf32>) -> tensor<512x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<512x1x1x256xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<928xf32>) -> tensor<928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<928xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<928xf32>, tensor<1xf32>) outs(%4 : tensor<928xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x56x56x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1120xf32>) -> tensor<666x7x7x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1120xf32>) -> tensor<1x1x1x1120xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1120xf32>, tensor<1x1x1x1120xf32>) outs(%4 : tensor<666x7x7x1120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x64xf32>) -> tensor<256x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x1x1x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x1x1x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x64xf32>, tensor<256x1x1x64xf32>) outs(%7 : tensor<666x1x1x256xf32>) -> tensor<666x1x1x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x384xf32>) -> tensor<666x56x56x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x384xf32>) -> tensor<666x56x56x384xf32>\n    %4 = tensor.empty() : tensor<666x56x56x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x384xf32>, tensor<666x56x56x384xf32>) outs(%4 : tensor<666x56x56x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x3x3x256xf32>) -> tensor<384x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x17x17x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x17x17x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x256xf32>, tensor<384x3x3x256xf32>) outs(%7 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<104xf32>) -> tensor<104xf32>\n    %2 = tensor.empty() : tensor<104xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<104xf32>) outs(%2 : tensor<104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1280xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1280xf32>) outs(%2 : tensor<666x7x7x1280xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2240xf32>) -> tensor<2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<2240xf32>, tensor<1xf32>) outs(%4 : tensor<2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1296xf32>, tensor<666x7x7x1296xf32>) outs(%4 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x2048xf32>) -> tensor<666x28x28x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x28x28x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x28x28x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x168xf32>) -> tensor<666x83x83x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<84x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<84x1x1x168xf32>) -> tensor<84x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %6 = tensor.empty() : tensor<666x83x83x84xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<84xf32>) outs(%6 : tensor<666x83x83x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x83x83x84xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x83x83x168xf32>, tensor<84x1x1x168xf32>) outs(%7 : tensor<666x83x83x84xf32>) -> tensor<666x83x83x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1376xf32>) -> tensor<666x7x7x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1376xf32>) -> tensor<1x1x1x1376xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1376xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1376xf32>, tensor<1x1x1x1376xf32>) outs(%4 : tensor<666x7x7x1376xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x480xf32>) -> tensor<666x14x14x480xf32>\n    %2 = tensor.empty() : tensor<666x14x14x480xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x480xf32>) outs(%2 : tensor<666x14x14x480xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x2x2x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x2x2x96xf32>) -> tensor<192x2x2x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x28x28x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<192x2x2x96xf32>) outs(%7 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x2048xf32>) -> tensor<320x1x1x2048xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x8x8x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x2048xf32>, tensor<320x1x1x2048xf32>) outs(%7 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = tensor.empty() : tensor<666x56x56x24xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x24xf32>) outs(%2 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1360xf32>) -> tensor<1x1x1x1360xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1360xf32>, tensor<1x1x1x1360xf32>) outs(%4 : tensor<666x7x7x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x120xf32>) -> tensor<666x56x56x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x120xf32>) -> tensor<1x1x1x120xf32>\n    %4 = tensor.empty() : tensor<666x56x56x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x120xf32>, tensor<1x1x1x120xf32>) outs(%4 : tensor<666x56x56x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x104xf32>) -> tensor<666x1x1x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<26x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<26x1x1x104xf32>) -> tensor<26x1x1x104xf32>\n    %4 = bufferization.alloc_tensor() : tensor<26xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<26xf32>) -> tensor<26xf32>\n    %6 = tensor.empty() : tensor<666x1x1x26xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<26xf32>) outs(%6 : tensor<666x1x1x26xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x26xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x104xf32>, tensor<26x1x1x104xf32>) outs(%7 : tensor<666x1x1x26xf32>) -> tensor<666x1x1x26xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x18xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x18xf32>) -> tensor<666x1x1x18xf32>\n    %2 = bufferization.alloc_tensor() : tensor<216x1x1x18xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<216x1x1x18xf32>) -> tensor<216x1x1x18xf32>\n    %4 = bufferization.alloc_tensor() : tensor<216xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<216xf32>) -> tensor<216xf32>\n    %6 = tensor.empty() : tensor<666x1x1x216xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<216xf32>) outs(%6 : tensor<666x1x1x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x216xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x18xf32>, tensor<216x1x1x18xf32>) outs(%7 : tensor<666x1x1x216xf32>) -> tensor<666x1x1x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1024xf32>) outs(%2 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = tensor.empty() : tensor<666x14x14x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x14x14x384xf32>, tensor<666x14x14x384xf32>) outs(%2 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1184xf32>) -> tensor<666x7x7x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1184xf32>) -> tensor<128x1x1x1184xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1184xf32>, tensor<128x1x1x1184xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x128xf32>) -> tensor<128x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<128x1x1x128xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x2048xf32>) -> tensor<448x1x1x2048xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x8x8x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x8x8x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x2048xf32>, tensor<448x1x1x2048xf32>) outs(%7 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<666x28x28x1xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1696xf32>) -> tensor<1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1696xf32>, tensor<1xf32>) outs(%4 : tensor<1696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x896xf32>) -> tensor<666x7x7x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x896xf32>) -> tensor<128x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x896xf32>, tensor<128x1x1x896xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<24x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<24x1x1x32xf32>) -> tensor<24x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<24xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<24xf32>) -> tensor<24xf32>\n    %6 = tensor.empty() : tensor<666x112x112x24xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<24xf32>) outs(%6 : tensor<666x112x112x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x24xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<24x1x1x32xf32>) outs(%7 : tensor<666x112x112x24xf32>) -> tensor<666x112x112x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x61x61x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x61x61x22xf32>) -> tensor<666x61x61x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x22x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x22x1xf32>) -> tensor<7x7x22x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %6 = tensor.empty() : tensor<666x28x28x22x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x22xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x61x61x22xf32>, tensor<7x7x22x1xf32>) outs(%7 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x22x1xf32> into tensor<666x28x28x22xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<22xf32>, tensor<666x28x28x22xf32>) outs(%8 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x147x147x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x147x147x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<88x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<88x1x1x88xf32>) -> tensor<88x1x1x88xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<88xf32>) outs(%6 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x88xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x88xf32>, tensor<88x1x1x88xf32>) outs(%7 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x32xf32>) -> tensor<666x147x147x32xf32>\n    %2 = tensor.empty() : tensor<666x147x147x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x147x147x32xf32>) outs(%2 : tensor<666x147x147x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x147x147x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1216xf32>) -> tensor<666x7x7x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1216xf32>) -> tensor<1x1x1x1216xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1216xf32>, tensor<1x1x1x1216xf32>) outs(%4 : tensor<666x7x7x1216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x224xf32>) -> tensor<666x112x112x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x112x112x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x112x112x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x44xf32> to tensor<666x30x30x44xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x28x28x44xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x30x30x44xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %c1 = arith.constant 1 : index\n    %c28 = arith.constant 28 : index\n    %c2 = arith.constant 2 : index\n    %c28_2 = arith.constant 28 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c28, %c1_3 : index\n    %7 = arith.subi %c28_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x28x28x44xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x28x28x44xf32>) outs(%8 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x56x56x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x608xf32>) -> tensor<666x14x14x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x608xf32>) -> tensor<1x1x1x608xf32>\n    %4 = tensor.empty() : tensor<666x14x14x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x608xf32>, tensor<1x1x1x608xf32>) outs(%4 : tensor<666x14x14x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x2048xf32>) -> tensor<666x10x10x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x10x10x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x10x10x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x416xf32>) -> tensor<666x28x28x416xf32>\n    %2 = tensor.empty() : tensor<666x28x28x416xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x416xf32>) outs(%2 : tensor<666x28x28x416xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x416xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = tensor.empty() : tensor<666x56x56xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56xf32>) -> tensor<666x56x56xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x96xf32>) outs(%3 : tensor<666x56x56xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x56x56xf32> into tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<666x56x56x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x84xf32>) -> tensor<666x83x83x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x84xf32>) -> tensor<1x1x1x84xf32>\n    %4 = tensor.empty() : tensor<666x83x83x84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x83x83x84xf32>, tensor<1x1x1x84xf32>) outs(%4 : tensor<666x83x83x84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x83x83x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x176xf32>) -> tensor<666x14x14x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x176xf32>) -> tensor<1x1x1x176xf32>\n    %4 = tensor.empty() : tensor<666x14x14x176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x176xf32>, tensor<1x1x1x176xf32>) outs(%4 : tensor<666x14x14x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %4 = tensor.empty() : tensor<666x28x28x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x216xf32>, tensor<666x28x28x216xf32>) outs(%4 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1360xf32>) -> tensor<666x14x14x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1360xf32>) -> tensor<1x1x1x1360xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1360xf32>, tensor<1x1x1x1360xf32>) outs(%4 : tensor<666x14x14x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1360xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x29x29x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x29x29x88xf32>) -> tensor<666x29x29x88xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x14x14x88xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x29x29x88xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = tensor.empty() : tensor<666x14x14x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x14x14x512xf32>, tensor<666x14x14x512xf32>) outs(%2 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x736xf32>) -> tensor<666x14x14x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x736xf32>) -> tensor<1x1x1x736xf32>\n    %4 = tensor.empty() : tensor<666x14x14x736xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x736xf32>, tensor<1x1x1x736xf32>) outs(%4 : tensor<666x14x14x736xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x784xf32>) -> tensor<1x1x1x784xf32>\n    %4 = tensor.empty() : tensor<666x14x14x784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x784xf32>, tensor<1x1x1x784xf32>) outs(%4 : tensor<666x14x14x784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x672xf32>) -> tensor<672x1x1x672xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x28x28x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x28x28x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x672xf32>, tensor<672x1x1x672xf32>) outs(%7 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x256xf32>) -> tensor<256x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x14x14x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<256x1x1x256xf32>) outs(%7 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x4096xf32>) -> tensor<666x7x7x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x4096xf32>) -> tensor<1x1x1x4096xf32>\n    %4 = tensor.empty() : tensor<666x7x7x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x4096xf32>, tensor<1x1x1x4096xf32>) outs(%4 : tensor<666x7x7x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x576xf32>) -> tensor<666x28x28x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x28x28x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x28x28x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1632xf32>) -> tensor<666x7x7x1632xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1632xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1632xf32>) outs(%2 : tensor<666x7x7x1632xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<216xf32>) -> tensor<216xf32>\n    %2 = tensor.empty() : tensor<216xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<216xf32>) outs(%2 : tensor<216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<728x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<728x1x1x256xf32>) -> tensor<728x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<728xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<728xf32>) -> tensor<728xf32>\n    %6 = tensor.empty() : tensor<666x19x19x728xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<728xf32>) outs(%6 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x19x19x728xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x37x37x256xf32>, tensor<728x1x1x256xf32>) outs(%7 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x96xf32>) -> tensor<666x17x17x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x17x17x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x17x17x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x4096xf32>) -> tensor<666x14x14x4096xf32>\n    %2 = tensor.empty() : tensor<666x14x14x4096xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x4096xf32>) outs(%2 : tensor<666x14x14x4096xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1088xf32>) -> tensor<666x14x14x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1088xf32>) -> tensor<128x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1088xf32>, tensor<128x1x1x1088xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1392xf32>) -> tensor<666x1x1x1392xf32>\n    %2 = tensor.empty() : tensor<666x1x1x1392xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x1392xf32>) outs(%2 : tensor<666x1x1x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1624xf32>) -> tensor<1x1x1x1624xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1624xf32>, tensor<1x1x1x1624xf32>) outs(%4 : tensor<666x7x7x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x85x85x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x85x85x84xf32>) -> tensor<666x85x85x84xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x42x42x84xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x85x85x84xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %c1 = arith.constant 1 : index\n    %c42 = arith.constant 42 : index\n    %c2 = arith.constant 2 : index\n    %c42_1 = arith.constant 42 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c42, %c1_2 : index\n    %7 = arith.subi %c42_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x42x42x84xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x42x42x84xf32>) outs(%8 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<666x7x7x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x35x35x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x35x35x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1792xf32>) -> tensor<666x14x14x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1792xf32>) -> tensor<1x1x1x1792xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1792xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1792xf32>, tensor<1x1x1x1792xf32>) outs(%4 : tensor<666x14x14x1792xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1792xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1920xf32>) -> tensor<1x666x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1920x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1920x1000xf32>) -> tensor<1x1920x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1920xf32>, tensor<1x1920x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x42xf32>) -> tensor<666x165x165x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x42xf32>) -> tensor<1x1x1x42xf32>\n    %4 = tensor.empty() : tensor<666x165x165x42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x165x165x42xf32>, tensor<1x1x1x42xf32>) outs(%4 : tensor<666x165x165x42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x165x165x42xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = tensor.empty() : tensor<666x7x1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1536xf32>) -> tensor<666x7x1536xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1536xf32>) outs(%3 : tensor<666x7x1536xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1536xf32> into tensor<666x1x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x480xf32>) -> tensor<666x28x28x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x480xf32>) -> tensor<128x1x1x480xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x480xf32>, tensor<128x1x1x480xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x324xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x324xf32>) -> tensor<666x1x1x324xf32>\n    %2 = tensor.empty() : tensor<666x1x1x324xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x324xf32>) outs(%2 : tensor<666x1x1x324xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x324xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<72x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<72x1x1x72xf32>) -> tensor<72x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<72xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<72xf32>) -> tensor<72xf32>\n    %6 = tensor.empty() : tensor<666x56x56x72xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<72xf32>) outs(%6 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x72xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<72x1x1x72xf32>) outs(%7 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    %2 = tensor.empty() : tensor<666x1x1x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x64xf32>) outs(%2 : tensor<666x1x1x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %4 = tensor.empty() : tensor<666x56x56x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<666x56x56x24xf32>) outs(%4 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x3x3x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x3x3x512xf32>) -> tensor<512x3x3x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x7x7x512xf32> to tensor<666x9x9x512xf32>\n    %6 = tensor.empty() : tensor<666x7x7x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x9x9x512xf32>, tensor<512x3x3x512xf32>) outs(%7 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x224xf32>) -> tensor<666x28x28x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x28x28x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x28x28x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<696x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<696x1x1x232xf32>) -> tensor<696x1x1x232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<696xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<696xf32>) -> tensor<696xf32>\n    %6 = tensor.empty() : tensor<666x28x28x696xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<696xf32>) outs(%6 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x696xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x232xf32>, tensor<696x1x1x232xf32>) outs(%7 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x22x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x22x1xf32>) -> tensor<3x3x22x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x22xf32> to tensor<666x30x30x22xf32>\n    %6 = tensor.empty() : tensor<666x28x28x22x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x22xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x30x30x22xf32>, tensor<3x3x22x1xf32>) outs(%7 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x22x1xf32> into tensor<666x28x28x22xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<22xf32>, tensor<666x28x28x22xf32>) outs(%8 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1056xf32>) -> tensor<666x7x7x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<176x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<176x1x1x1056xf32>) -> tensor<176x1x1x1056xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<176xf32>) outs(%6 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x176xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1056xf32>, tensor<176x1x1x1056xf32>) outs(%7 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x74x74x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x74x74x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x74x74x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %2 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x2016xf32>) outs(%2 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x96xf32>) -> tensor<666x165x165x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x165x165x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x165x165x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x165x165x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x165x165x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1512xf32>) -> tensor<1x1x1x1512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1512xf32>, tensor<1x1x1x1512xf32>) outs(%4 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1536xf32>) outs(%2 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = tensor.empty() : tensor<666x7x7x960xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x960xf32>) outs(%2 : tensor<666x7x7x960xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = tensor.empty() : tensor<666x56x56x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x56x56x96xf32>, tensor<666x56x56x96xf32>) outs(%2 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    %2 = tensor.empty() : tensor<666x1x1x152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x152xf32>) outs(%2 : tensor<666x1x1x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<832xf32>) -> tensor<832xf32>\n    %2 = tensor.empty() : tensor<832xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<832xf32>) outs(%2 : tensor<832xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x720xf32>) -> tensor<1x1x1x720xf32>\n    %4 = tensor.empty() : tensor<666x14x14x720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x720xf32>, tensor<1x1x1x720xf32>) outs(%4 : tensor<666x14x14x720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x56xf32>) -> tensor<666x56x56x56xf32>\n    %2 = tensor.empty() : tensor<666x56x56x56xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x56xf32>) outs(%2 : tensor<666x56x56x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x56xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = tensor.empty() : tensor<666x56x56xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56xf32>) -> tensor<666x56x56xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x128xf32>) outs(%3 : tensor<666x56x56xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x56x56xf32> into tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1440xf32>) -> tensor<666x7x7x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1440xf32>) -> tensor<1x1x1x1440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1440xf32>, tensor<1x1x1x1440xf32>) outs(%4 : tensor<666x7x7x1440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1624xf32>) -> tensor<1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1624xf32>, tensor<1xf32>) outs(%4 : tensor<1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1696xf32>) -> tensor<666x14x14x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1696xf32>) -> tensor<128x1x1x1696xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1696xf32>, tensor<128x1x1x1696xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x112xf32>) -> tensor<666x56x56x112xf32>\n    %2 = tensor.empty() : tensor<666x56x56x112xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x112xf32>) outs(%2 : tensor<666x56x56x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3072xf32>) -> tensor<666x7x7x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3072xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1392xf32>) -> tensor<666x1x1x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<174x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<174x1x1x1392xf32>) -> tensor<174x1x1x1392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<174xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<174xf32>) -> tensor<174xf32>\n    %6 = tensor.empty() : tensor<666x1x1x174xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<174xf32>) outs(%6 : tensor<666x1x1x174xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x174xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1392xf32>, tensor<174x1x1x1392xf32>) outs(%7 : tensor<666x1x1x174xf32>) -> tensor<666x1x1x174xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %4 = tensor.empty() : tensor<666x56x56x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<666x56x56x224xf32>) outs(%4 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x84xf32>) -> tensor<1x1x1x84xf32>\n    %4 = tensor.empty() : tensor<666x42x42x84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x84xf32>, tensor<1x1x1x84xf32>) outs(%4 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x152xf32>) -> tensor<666x28x28x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x152xf32>) -> tensor<1x1x1x152xf32>\n    %4 = tensor.empty() : tensor<666x28x28x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x152xf32>, tensor<1x1x1x152xf32>) outs(%4 : tensor<666x28x28x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x168xf32>) -> tensor<666x1x1x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %4 = tensor.empty() : tensor<666x56x56x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x168xf32>, tensor<666x56x56x168xf32>) outs(%4 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<240x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<240x1x1x240xf32>) -> tensor<240x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<240xf32>) -> tensor<240xf32>\n    %6 = tensor.empty() : tensor<666x28x28x240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<240xf32>) outs(%6 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<240x1x1x240xf32>) outs(%7 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x768xf32>) -> tensor<666x17x17x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x1x768xf32>) -> tensor<160x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %6 = tensor.empty() : tensor<666x17x17x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x768xf32>, tensor<160x1x1x768xf32>) outs(%7 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x56x56x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x56x56x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1536xf32>) -> tensor<666x10x10x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x10x10x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x10x10x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x17x17x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x17x17x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<696x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<696x1x1x696xf32>) -> tensor<696x1x1x696xf32>\n    %4 = bufferization.alloc_tensor() : tensor<696xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<696xf32>) -> tensor<696xf32>\n    %6 = tensor.empty() : tensor<666x28x28x696xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<696xf32>) outs(%6 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x696xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x696xf32>, tensor<696x1x1x696xf32>) outs(%7 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x2048xf32>) -> tensor<1x32634x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2048x8192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2048x8192xf32>) -> tensor<1x2048x8192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x8192xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x8192xf32>) -> tensor<1x32634x8192xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x2048xf32>, tensor<1x2048x8192xf32>) outs(%5 : tensor<1x32634x8192xf32>) -> tensor<1x32634x8192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x608xf32>) -> tensor<666x1x7x608xf32>\n    %2 = tensor.empty() : tensor<666x1x608xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x608xf32>) -> tensor<666x1x608xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x608xf32>) outs(%3 : tensor<666x1x608xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x608xf32> into tensor<666x1x1x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x32xf32>) -> tensor<64x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x112x112x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x112x112x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<64x1x1x32xf32>) outs(%7 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1216xf32>) -> tensor<1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1216xf32>, tensor<1xf32>) outs(%4 : tensor<1216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1472xf32>) -> tensor<666x7x7x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1472xf32>) -> tensor<128x1x1x1472xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1472xf32>, tensor<128x1x1x1472xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x264xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x264xf32>) -> tensor<666x14x14x264xf32>\n    %2 = bufferization.alloc_tensor() : tensor<44x1x1x264xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<44x1x1x264xf32>) -> tensor<44x1x1x264xf32>\n    %4 = bufferization.alloc_tensor() : tensor<44xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<44xf32>) -> tensor<44xf32>\n    %6 = tensor.empty() : tensor<666x14x14x44xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<44xf32>) outs(%6 : tensor<666x14x14x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x44xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x264xf32>, tensor<44x1x1x264xf32>) outs(%7 : tensor<666x14x14x44xf32>) -> tensor<666x14x14x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x44xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x44xf32>) -> tensor<1x1x1x44xf32>\n    %4 = tensor.empty() : tensor<666x28x28x44xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x44xf32>, tensor<1x1x1x44xf32>) outs(%4 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1408xf32>) -> tensor<666x7x7x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1408xf32>) -> tensor<128x1x1x1408xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1408xf32>, tensor<128x1x1x1408xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1088xf32>) -> tensor<128x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x17x17x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x1088xf32>, tensor<128x1x1x1088xf32>) outs(%7 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<320xf32>) -> tensor<320xf32>\n    %2 = tensor.empty() : tensor<320xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<320xf32>) outs(%2 : tensor<320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x896xf32>) -> tensor<666x1x1x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x896xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x7x7x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x7x7x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<384xf32>) -> tensor<384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<384xf32>, tensor<1xf32>) outs(%4 : tensor<384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %4 = tensor.empty() : tensor<666x28x28x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x96xf32>, tensor<666x28x28x96xf32>) outs(%4 : tensor<666x28x28x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2520xf32>) -> tensor<2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<2520xf32>, tensor<1xf32>) outs(%4 : tensor<2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x888xf32>) -> tensor<1x1x1x888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x888xf32>, tensor<1x1x1x888xf32>) outs(%4 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x56xf32>) -> tensor<1x1x1x56xf32>\n    %4 = tensor.empty() : tensor<666x28x28x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x56xf32>, tensor<1x1x1x56xf32>) outs(%4 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1000xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1000xf32>) -> tensor<666x1000xf32>\n    %2 = tensor.empty() : tensor<666xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666xf32>) -> tensor<666xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1000xf32>) outs(%3 : tensor<666xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0, 1]] : tensor<666xf32> into tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1408xf32>) -> tensor<666x14x14x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1408xf32>) -> tensor<1x1x1x1408xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1408xf32>, tensor<1x1x1x1408xf32>) outs(%4 : tensor<666x14x14x1408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<336xf32>) -> tensor<336xf32>\n    %2 = tensor.empty() : tensor<336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<336xf32>) outs(%2 : tensor<336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = tensor.empty() : tensor<666x14x14x288xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x288xf32>) outs(%2 : tensor<666x14x14x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x216xf32>) -> tensor<666x1x1x216xf32>\n    %2 = tensor.empty() : tensor<666x1x1x216xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x216xf32>) outs(%2 : tensor<666x1x1x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x216xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %2 = tensor.empty() : tensor<666x7x888xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x888xf32>) -> tensor<666x7x888xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x888xf32>) outs(%3 : tensor<666x7x888xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x888xf32> into tensor<666x1x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1824xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1824xf32>) -> tensor<1824xf32>\n    %2 = tensor.empty() : tensor<1824xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1824xf32>) outs(%2 : tensor<1824xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1824xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x84x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x84x1xf32>) -> tensor<7x7x84x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x42x42x84xf32> to tensor<666x48x48x84xf32>\n    %6 = tensor.empty() : tensor<666x42x42x84x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %8 = tensor.empty() : tensor<666x42x42x84xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x48x48x84xf32>, tensor<7x7x84x1xf32>) outs(%7 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x42x42x84x1xf32> into tensor<666x42x42x84xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<84xf32>, tensor<666x42x42x84xf32>) outs(%8 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1120xf32>) -> tensor<666x14x14x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1120xf32>) -> tensor<1x1x1x1120xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1120xf32>, tensor<1x1x1x1120xf32>) outs(%4 : tensor<666x14x14x1120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1536xf32>) -> tensor<128x1x1x1536xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1536xf32>, tensor<128x1x1x1536xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    %4 = tensor.empty() : tensor<666x14x14x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x64xf32>, tensor<666x14x14x64xf32>) outs(%4 : tensor<666x14x14x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x208xf32>) -> tensor<666x28x28x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x208xf32>) -> tensor<1x1x1x208xf32>\n    %4 = tensor.empty() : tensor<666x28x28x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x208xf32>, tensor<1x1x1x208xf32>) outs(%4 : tensor<666x28x28x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<666x14x14x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = tensor.empty() : tensor<666x56x56x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x56x56x192xf32>, tensor<666x56x56x192xf32>) outs(%2 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x88xf32>) -> tensor<666x28x28x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x88xf32>) -> tensor<1x1x1x88xf32>\n    %4 = tensor.empty() : tensor<666x28x28x88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x88xf32>, tensor<1x1x1x88xf32>) outs(%4 : tensor<666x28x28x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x88xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x216xf32>) -> tensor<666x1x28x216xf32>\n    %2 = tensor.empty() : tensor<666x1x216xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x216xf32>) -> tensor<666x1x216xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x216xf32>) outs(%3 : tensor<666x1x216xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x216xf32> into tensor<666x1x1x216xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x288xf32>) -> tensor<666x1x28x288xf32>\n    %2 = tensor.empty() : tensor<666x1x288xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x288xf32>) -> tensor<666x1x288xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x288xf32>) outs(%3 : tensor<666x1x288xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x288xf32> into tensor<666x1x1x288xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x384xf32>) -> tensor<666x1x7x384xf32>\n    %2 = tensor.empty() : tensor<666x1x384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x384xf32>) -> tensor<666x1x384xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x384xf32>) outs(%3 : tensor<666x1x384xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x384xf32> into tensor<666x1x1x384xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x608xf32>) -> tensor<1x666x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x608x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x608x1000xf32>) -> tensor<1x608x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x608xf32>, tensor<1x608x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x88x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x88x1xf32>) -> tensor<3x3x88x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x88xf32> to tensor<666x16x16x88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x88xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x16x16x88xf32>, tensor<3x3x88x1xf32>) outs(%7 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x88x1xf32> into tensor<666x14x14x88xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<88xf32>, tensor<666x14x14x88xf32>) outs(%8 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1440xf32>) -> tensor<666x14x14x1440xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1440xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1440xf32>) outs(%2 : tensor<666x14x14x1440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x73x73x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x73x73x80xf32>) -> tensor<666x73x73x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x3x3x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x3x3x80xf32>) -> tensor<192x3x3x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x71x71x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x71x71x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x71x71x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x73x73x80xf32>, tensor<192x3x3x80xf32>) outs(%7 : tensor<666x71x71x192xf32>) -> tensor<666x71x71x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x216xf32>) -> tensor<666x56x56x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x216xf32>) -> tensor<1x1x1x216xf32>\n    %4 = tensor.empty() : tensor<666x56x56x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x216xf32>, tensor<1x1x1x216xf32>) outs(%4 : tensor<666x56x56x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x22xf32> to tensor<666x30x30x22xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x28x28x22xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x30x30x22xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %c1 = arith.constant 1 : index\n    %c28 = arith.constant 28 : index\n    %c2 = arith.constant 2 : index\n    %c28_2 = arith.constant 28 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c28, %c1_3 : index\n    %7 = arith.subi %c28_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x28x28x22xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x28x28x22xf32>) outs(%8 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x48xf32>) -> tensor<666x112x112x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x112x112x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x112x112x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x4096xf32>) -> tensor<666x7x7x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x4096xf32>) -> tensor<666x7x7x4096xf32>\n    %4 = tensor.empty() : tensor<666x7x7x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x4096xf32>, tensor<666x7x7x4096xf32>) outs(%4 : tensor<666x7x7x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x832xf32>) -> tensor<666x7x7x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x832xf32>) -> tensor<128x1x1x832xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x832xf32>, tensor<128x1x1x832xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = tensor.empty() : tensor<666x21x21x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x21x21x336xf32>) outs(%2 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x18xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x18xf32>) -> tensor<666x1x1x18xf32>\n    %2 = bufferization.alloc_tensor() : tensor<72x1x1x18xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<72x1x1x18xf32>) -> tensor<72x1x1x18xf32>\n    %4 = bufferization.alloc_tensor() : tensor<72xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<72xf32>) -> tensor<72xf32>\n    %6 = tensor.empty() : tensor<666x1x1x72xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<72xf32>) outs(%6 : tensor<666x1x1x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x72xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x18xf32>, tensor<72x1x1x18xf32>) outs(%7 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x3x3x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x3x3x288xf32>) -> tensor<320x3x3x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x8x8x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x288xf32>, tensor<320x3x3x288xf32>) outs(%7 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x232xf32>) -> tensor<1x1x1x232xf32>\n    %4 = tensor.empty() : tensor<666x56x56x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x232xf32>, tensor<1x1x1x232xf32>) outs(%4 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<6x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<6x1x1x56xf32>) -> tensor<6x1x1x56xf32>\n    %4 = bufferization.alloc_tensor() : tensor<6xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<6xf32>) -> tensor<6xf32>\n    %6 = tensor.empty() : tensor<666x1x1x6xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<6xf32>) outs(%6 : tensor<666x1x1x6xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x6xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x56xf32>, tensor<6x1x1x56xf32>) outs(%7 : tensor<666x1x1x6xf32>) -> tensor<666x1x1x6xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1664xf32>) -> tensor<666x7x7x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1664xf32>) -> tensor<128x1x1x1664xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1664xf32>, tensor<128x1x1x1664xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x104xf32>) -> tensor<666x1x28x104xf32>\n    %2 = tensor.empty() : tensor<666x1x104xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x104xf32>) -> tensor<666x1x104xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x104xf32>) outs(%3 : tensor<666x1x104xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x104xf32> into tensor<666x1x1x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x28x28x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x3x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x3x192xf32>) -> tensor<224x1x3x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 1, 0] high[0, 0, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x8x8x192xf32> to tensor<666x8x10x192xf32>\n    %6 = tensor.empty() : tensor<666x8x8x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x8x8x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x8x10x192xf32>, tensor<224x1x3x192xf32>) outs(%7 : tensor<666x8x8x224xf32>) -> tensor<666x8x8x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x672x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x672x1xf32>) -> tensor<5x5x672x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x11x11x672xf32> to tensor<666x15x15x672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %8 = tensor.empty() : tensor<666x11x11x672xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x15x15x672xf32>, tensor<5x5x672x1xf32>) outs(%7 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x11x11x672x1xf32> into tensor<666x11x11x672xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<672xf32>, tensor<666x11x11x672xf32>) outs(%8 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1536xf32>) -> tensor<666x28x28x1536xf32>\n    %2 = tensor.empty() : tensor<666x28x28x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x1536xf32>) outs(%2 : tensor<666x28x28x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<912x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<912x1x1x408xf32>) -> tensor<912x1x1x408xf32>\n    %4 = bufferization.alloc_tensor() : tensor<912xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<912xf32>) -> tensor<912xf32>\n    %6 = tensor.empty() : tensor<666x7x7x912xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<912xf32>) outs(%6 : tensor<666x7x7x912xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x912xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x408xf32>, tensor<912x1x1x408xf32>) outs(%7 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1792xf32>) -> tensor<666x14x14x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1792xf32>) -> tensor<1x1x1x1792xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1792xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1792xf32>, tensor<1x1x1x1792xf32>) outs(%4 : tensor<666x14x14x1792xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<112xf32>) -> tensor<112xf32>\n    %2 = tensor.empty() : tensor<112xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<112xf32>) outs(%2 : tensor<112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3024x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3024x1x1x1232xf32>) -> tensor<3024x1x1x1232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3024xf32>) -> tensor<3024xf32>\n    %6 = tensor.empty() : tensor<666x14x14x3024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3024xf32>) outs(%6 : tensor<666x14x14x3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x3024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1232xf32>, tensor<3024x1x1x1232xf32>) outs(%7 : tensor<666x14x14x3024xf32>) -> tensor<666x14x14x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<576xf32>) -> tensor<576xf32>\n    %2 = tensor.empty() : tensor<576xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<576xf32>) outs(%2 : tensor<576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x320xf32>) -> tensor<666x1x1x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x320xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2520xf32>) -> tensor<1x1x1x2520xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2520xf32>, tensor<1x1x1x2520xf32>) outs(%4 : tensor<666x7x7x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x72xf32>) -> tensor<1x1x1x72xf32>\n    %4 = tensor.empty() : tensor<666x56x56x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<1x1x1x72xf32>) outs(%4 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %4 = tensor.empty() : tensor<666x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x768xf32>, tensor<666x768xf32>) outs(%4 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x1x1x512xf32>) -> tensor<1024x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<1024x1x1x512xf32>) outs(%7 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2520x1x1x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2520x1x1x2520xf32>) -> tensor<2520x1x1x2520xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2520xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2520xf32>) -> tensor<2520xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2520xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2520xf32>) outs(%6 : tensor<666x7x7x2520xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2520xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x2520xf32>, tensor<2520x1x1x2520xf32>) outs(%7 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x14x14x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x192xf32>) -> tensor<48x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x1x1x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x1x1x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x192xf32>, tensor<48x1x1x192xf32>) outs(%7 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x96xf32>) -> tensor<666x112x112x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x112x112x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x112x112x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3xf32>) -> tensor<1x1x1x3xf32>\n    %4 = tensor.empty() : tensor<666x224x224x3xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<1x1x1x3xf32>) outs(%4 : tensor<666x224x224x3xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x224x224x3xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = tensor.empty() : tensor<666x56x56x232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x232xf32>) outs(%2 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x17x17x320xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x17x17x320xf32>) -> tensor<666x17x17x320xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x35x35x320xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x17x17x320xf32>) -> tensor<666x17x17x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1920x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1920x1x1x720xf32>) -> tensor<1920x1x1x720xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1920xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1920xf32>) -> tensor<1920xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1920xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1920xf32>) outs(%6 : tensor<666x14x14x1920xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1920xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x720xf32>, tensor<1920x1x1x720xf32>) outs(%7 : tensor<666x14x14x1920xf32>) -> tensor<666x14x14x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x368xf32>) -> tensor<666x1x1x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<92x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<92x1x1x368xf32>) -> tensor<92x1x1x368xf32>\n    %4 = bufferization.alloc_tensor() : tensor<92xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<92xf32>) -> tensor<92xf32>\n    %6 = tensor.empty() : tensor<666x1x1x92xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<92xf32>) outs(%6 : tensor<666x1x1x92xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x92xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x368xf32>, tensor<92x1x1x368xf32>) outs(%7 : tensor<666x1x1x92xf32>) -> tensor<666x1x1x92xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1536xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x36xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x36xf32>) -> tensor<666x1x1x36xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x36xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x36xf32>) -> tensor<144x1x1x36xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x1x1x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x36xf32>, tensor<144x1x1x36xf32>) outs(%7 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2016xf32>) -> tensor<666x1x1x2016xf32>\n    %2 = tensor.empty() : tensor<666x1x1x2016xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x2016xf32>) outs(%2 : tensor<666x1x1x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<240x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<240x1x1x96xf32>) -> tensor<240x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<240xf32>) -> tensor<240xf32>\n    %6 = tensor.empty() : tensor<666x14x14x240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<240xf32>) outs(%6 : tensor<666x14x14x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x96xf32>, tensor<240x1x1x96xf32>) outs(%7 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x896xf32>) -> tensor<128x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<128x1x1x896xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x512xf32>) -> tensor<1x130536x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x512x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x512x2048xf32>) -> tensor<1x512x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x2048xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x2048xf32>) -> tensor<1x130536x2048xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x512xf32>, tensor<1x512x2048xf32>) outs(%5 : tensor<1x130536x2048xf32>) -> tensor<1x130536x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1624xf32>) -> tensor<1x1x1x1624xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1624xf32>, tensor<1x1x1x1624xf32>) outs(%4 : tensor<666x7x7x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x352xf32>) -> tensor<666x14x14x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x352xf32>) -> tensor<128x1x1x352xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x352xf32>, tensor<128x1x1x352xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x128xf32>) -> tensor<32x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x1x1x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x1x1x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<32x1x1x128xf32>) outs(%7 : tensor<666x1x1x32xf32>) -> tensor<666x1x1x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x320xf32>) -> tensor<666x28x28x320xf32>\n    %2 = tensor.empty() : tensor<666x28x28x320xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x320xf32>) outs(%2 : tensor<666x28x28x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x256xf32>) -> tensor<666x112x112x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x112x112x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x112x112x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x120xf32>) -> tensor<336x1x1x120xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x14x14x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x120xf32>, tensor<336x1x1x120xf32>) outs(%7 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3024xf32>) -> tensor<666x1x1x3024xf32>\n    %2 = tensor.empty() : tensor<666x1x1x3024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x3024xf32>) outs(%2 : tensor<666x1x1x3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x1x1x80xf32>) -> tensor<80x1x1x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %6 = tensor.empty() : tensor<666x56x56x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x80xf32>, tensor<80x1x1x80xf32>) outs(%7 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<392x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<392x1x1x168xf32>) -> tensor<392x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<392xf32>) -> tensor<392xf32>\n    %6 = tensor.empty() : tensor<666x28x28x392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<392xf32>) outs(%6 : tensor<666x28x28x392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<392x1x1x168xf32>) outs(%7 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3024xf32>) -> tensor<666x14x14x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3024xf32>) -> tensor<1x1x1x3024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3024xf32>, tensor<1x1x1x3024xf32>) outs(%4 : tensor<666x14x14x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x440xf32>) -> tensor<666x14x14x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x440xf32>) -> tensor<1x1x1x440xf32>\n    %4 = tensor.empty() : tensor<666x14x14x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x440xf32>, tensor<1x1x1x440xf32>) outs(%4 : tensor<666x14x14x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x560xf32>) -> tensor<1x1x1x560xf32>\n    %4 = tensor.empty() : tensor<666x14x14x560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x560xf32>, tensor<1x1x1x560xf32>) outs(%4 : tensor<666x14x14x560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1248xf32>) -> tensor<666x14x14x1248xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1248xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1248xf32>) outs(%2 : tensor<666x14x14x1248xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1008x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1008x1x1x1008xf32>) -> tensor<1008x1x1x1008xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1008xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1008xf32>) -> tensor<1008xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1008xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1008xf32>) outs(%6 : tensor<666x7x7x1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1008xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1008xf32>, tensor<1008x1x1x1008xf32>) outs(%7 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2240xf32>) -> tensor<666x1x1x2240xf32>\n    %2 = tensor.empty() : tensor<666x1x1x2240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x2240xf32>) outs(%2 : tensor<666x1x1x2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x672xf32>) -> tensor<666x56x56x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x56x56x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x56x56x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x8x8x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1624xf32>) -> tensor<1624xf32>\n    %2 = tensor.empty() : tensor<1624xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1624xf32>) outs(%2 : tensor<1624xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x440xf32>) -> tensor<1x1x1x440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x440xf32>, tensor<1x1x1x440xf32>) outs(%4 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<608x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<608x1x1x256xf32>) -> tensor<608x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<608xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<608xf32>) -> tensor<608xf32>\n    %6 = tensor.empty() : tensor<666x14x14x608xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<608xf32>) outs(%6 : tensor<666x14x14x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x608xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<608x1x1x256xf32>) outs(%7 : tensor<666x14x14x608xf32>) -> tensor<666x14x14x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = tensor.empty() : tensor<666x56x56x48xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x48xf32>) outs(%2 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1088xf32>) -> tensor<1x1x1x1088xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1088xf32>, tensor<1x1x1x1088xf32>) outs(%4 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<368xf32>) -> tensor<368xf32>\n    %2 = tensor.empty() : tensor<368xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<368xf32>) outs(%2 : tensor<368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x17x17x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x608xf32>) -> tensor<1x1x1x608xf32>\n    %4 = tensor.empty() : tensor<666x7x7x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x608xf32>, tensor<1x1x1x608xf32>) outs(%4 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = tensor.empty() : tensor<666x7x7xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7xf32>) -> tensor<666x7x7xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x768xf32>) outs(%3 : tensor<666x7x7xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x7x7xf32> into tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1280xf32>, tensor<1x1x1x1280xf32>) outs(%4 : tensor<666x7x7x1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x640xf32>) -> tensor<666x7x7x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x640xf32>) -> tensor<1x1x1x640xf32>\n    %4 = tensor.empty() : tensor<666x7x7x640xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x640xf32>, tensor<1x1x1x640xf32>) outs(%4 : tensor<666x7x7x640xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x960x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x960x1xf32>) -> tensor<3x3x960x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<960xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<960xf32>) -> tensor<960xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x7x7x960xf32> to tensor<666x9x9x960xf32>\n    %6 = tensor.empty() : tensor<666x7x7x960x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x7x7x960x1xf32>) -> tensor<666x7x7x960x1xf32>\n    %8 = tensor.empty() : tensor<666x7x7x960xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x9x9x960xf32>, tensor<3x3x960x1xf32>) outs(%7 : tensor<666x7x7x960x1xf32>) -> tensor<666x7x7x960x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x7x7x960x1xf32> into tensor<666x7x7x960xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<960xf32>, tensor<666x7x7x960xf32>) outs(%8 : tensor<666x7x7x960xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x7x7x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<44xf32>) -> tensor<44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<44xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<44xf32>, tensor<1xf32>) outs(%4 : tensor<44xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x192xf32>) -> tensor<666x14x14x192xf32>\n    %2 = tensor.empty() : tensor<666x14x14x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x192xf32>) outs(%2 : tensor<666x14x14x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x192xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = tensor.empty() : tensor<666x14x896xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x896xf32>) -> tensor<666x14x896xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x896xf32>) outs(%3 : tensor<666x14x896xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x896xf32> into tensor<666x1x14x896xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x128xf32>) -> tensor<1x2088576x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x128x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x128x512xf32>) -> tensor<1x128x512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x512xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x512xf32>) -> tensor<1x2088576x512xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x128xf32>, tensor<1x128x512xf32>) outs(%5 : tensor<1x2088576x512xf32>) -> tensor<1x2088576x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<408x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<408x1x1x168xf32>) -> tensor<408x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<408xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<408xf32>) -> tensor<408xf32>\n    %6 = tensor.empty() : tensor<666x14x14x408xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<408xf32>) outs(%6 : tensor<666x14x14x408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x408xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x168xf32>, tensor<408x1x1x168xf32>) outs(%7 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1408xf32>) -> tensor<666x7x7x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1408xf32>) -> tensor<1x1x1x1408xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1408xf32>, tensor<1x1x1x1408xf32>) outs(%4 : tensor<666x7x7x1408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<666x7x7x1xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x168xf32>) -> tensor<666x112x112x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x112x112x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x112x112x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1392xf32>) -> tensor<666x28x28x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1392xf32>) -> tensor<1x1x1x1392xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1392xf32>, tensor<1x1x1x1392xf32>) outs(%4 : tensor<666x28x28x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x512xf32>) -> tensor<666x1x1x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x512xf32>, tensor<666x14x14x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x42xf32>) -> tensor<1x1x1x42xf32>\n    %4 = tensor.empty() : tensor<666x83x83x42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x83x83x42xf32>, tensor<1x1x1x42xf32>) outs(%4 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x64x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x64x1xf32>) -> tensor<3x3x64x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x147x147x64xf32> to tensor<666x149x149x64xf32>\n    %6 = tensor.empty() : tensor<666x147x147x64x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x147x147x64x1xf32>) -> tensor<666x147x147x64x1xf32>\n    %8 = tensor.empty() : tensor<666x147x147x64xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x149x149x64xf32>, tensor<3x3x64x1xf32>) outs(%7 : tensor<666x147x147x64x1xf32>) -> tensor<666x147x147x64x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x147x147x64x1xf32> into tensor<666x147x147x64xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<64xf32>, tensor<666x147x147x64xf32>) outs(%8 : tensor<666x147x147x64xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x147x147x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x576xf32>) -> tensor<666x28x28x576xf32>\n    %2 = tensor.empty() : tensor<666x28x28x576xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x576xf32>) outs(%2 : tensor<666x28x28x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = tensor.empty() : tensor<666x11x11x672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x11x11x672xf32>) outs(%2 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %4 = tensor.empty() : tensor<666x56x56x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<666x56x56x168xf32>) outs(%4 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    %2 = tensor.empty() : tensor<666x7x7x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x128xf32>) outs(%2 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x512xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<666x7x7x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1088x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1088x1x1x512xf32>) -> tensor<1088x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1088xf32>) -> tensor<1088xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1088xf32>) outs(%6 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1088xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<1088x1x1x512xf32>) outs(%7 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x800xf32>) -> tensor<666x14x14x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x800xf32>) -> tensor<1x1x1x800xf32>\n    %4 = tensor.empty() : tensor<666x14x14x800xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x800xf32>, tensor<1x1x1x800xf32>) outs(%4 : tensor<666x14x14x800xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x576xf32>) -> tensor<666x7x7x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x7x7x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x7x7x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2048xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = tensor.empty() : tensor<666x14x14x896xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x896xf32>) outs(%2 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x992xf32>) -> tensor<666x7x7x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x992xf32>) -> tensor<1x1x1x992xf32>\n    %4 = tensor.empty() : tensor<666x7x7x992xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x992xf32>, tensor<1x1x1x992xf32>) outs(%4 : tensor<666x7x7x992xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1296x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1296x1x1x144xf32>) -> tensor<1296x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1296xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1296xf32>) -> tensor<1296xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1296xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1296xf32>) outs(%6 : tensor<666x1x1x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1296xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x144xf32>, tensor<1296x1x1x144xf32>) outs(%7 : tensor<666x1x1x1296xf32>) -> tensor<666x1x1x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x1024xf32>) -> tensor<666x19x19x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x19x19x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x19x19x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x19x19x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x19x19x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3072xf32>) -> tensor<666x7x7x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3072xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3072xf32>) -> tensor<1x1x1x3072xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3072xf32>, tensor<1x1x1x3072xf32>) outs(%4 : tensor<666x7x7x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3712x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3712x1x1x1392xf32>) -> tensor<3712x1x1x1392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3712xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3712xf32>) -> tensor<3712xf32>\n    %6 = tensor.empty() : tensor<666x14x14x3712xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3712xf32>) outs(%6 : tensor<666x14x14x3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x3712xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1392xf32>, tensor<3712x1x1x1392xf32>) outs(%7 : tensor<666x14x14x3712xf32>) -> tensor<666x14x14x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x128xf32>) -> tensor<288x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x28x28x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<288x1x1x128xf32>) outs(%7 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x32xf32>) -> tensor<666x111x111x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x111x111x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x111x111x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x111x111x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x111x111x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x336xf32>) -> tensor<666x112x112x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x112x112x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x112x112x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<42xf32>) -> tensor<42xf32>\n    %2 = tensor.empty() : tensor<42xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<42xf32>) outs(%2 : tensor<42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x672xf32>) -> tensor<666x56x56x672xf32>\n    %2 = tensor.empty() : tensor<666x56x56x672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x672xf32>) outs(%2 : tensor<666x56x56x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1504xf32>) -> tensor<666x14x14x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1504xf32>) -> tensor<1x1x1x1504xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1504xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1504xf32>, tensor<1x1x1x1504xf32>) outs(%4 : tensor<666x14x14x1504xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1088x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1088x1x1x128xf32>) -> tensor<1088x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1088xf32>) -> tensor<1088xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1088xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1088xf32>) outs(%6 : tensor<666x1x1x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1088xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<1088x1x1x128xf32>) outs(%7 : tensor<666x1x1x1088xf32>) -> tensor<666x1x1x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1120xf32>) -> tensor<666x7x7x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1120xf32>) -> tensor<128x1x1x1120xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1120xf32>, tensor<128x1x1x1120xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1792xf32>) -> tensor<666x7x7x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1792xf32>) -> tensor<1x1x1x1792xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1792xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1792xf32>, tensor<1x1x1x1792xf32>) outs(%4 : tensor<666x7x7x1792xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1504xf32>) -> tensor<666x14x14x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1504xf32>) -> tensor<128x1x1x1504xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1504xf32>, tensor<128x1x1x1504xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2016xf32>) -> tensor<666x1x1x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x2016xf32>, tensor<666x7x7x2016xf32>) outs(%4 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1120xf32>) -> tensor<1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1120xf32>, tensor<1xf32>) outs(%4 : tensor<1120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<408xf32>) -> tensor<408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<408xf32>, tensor<1xf32>) outs(%4 : tensor<408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x7x7x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x7x7x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1512xf32>) outs(%2 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x768xf32>) -> tensor<666x17x17x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x768xf32>) -> tensor<192x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x768xf32>, tensor<192x1x1x768xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1664xf32>) -> tensor<666x7x7x1664xf32>\n    %2 = tensor.empty() : tensor<666x7x1664xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1664xf32>) -> tensor<666x7x1664xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1664xf32>) outs(%3 : tensor<666x7x1664xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1664xf32> into tensor<666x1x7x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x264xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x264xf32>) -> tensor<666x28x28x264xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x14x14x264xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14x264xf32>) -> tensor<666x14x14x264xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x28x28x264xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x14x14x264xf32>) -> tensor<666x14x14x264xf32>\n    %c1 = arith.constant 1 : index\n    %c14 = arith.constant 14 : index\n    %c2 = arith.constant 2 : index\n    %c14_1 = arith.constant 14 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c14, %c1_2 : index\n    %7 = arith.subi %c14_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x14x14x264xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x14x14x264xf32>) outs(%8 : tensor<666x14x14x264xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x14x14x264xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<232xf32>) -> tensor<232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<232xf32>, tensor<1xf32>) outs(%4 : tensor<232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<728xf32>) -> tensor<728xf32>\n    %2 = tensor.empty() : tensor<728xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<728xf32>) outs(%2 : tensor<728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1504xf32>) -> tensor<1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1504xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1504xf32>, tensor<1xf32>) outs(%4 : tensor<1504xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x288xf32>) -> tensor<666x35x35x288xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x288xf32> to tensor<666x37x37x288xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x35x35x288xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x35x35x288xf32>) -> tensor<666x35x35x288xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x37x37x288xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x35x35x288xf32>) -> tensor<666x35x35x288xf32>\n    %c1 = arith.constant 1 : index\n    %c35 = arith.constant 35 : index\n    %c2 = arith.constant 2 : index\n    %c35_2 = arith.constant 35 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c35, %c1_3 : index\n    %7 = arith.subi %c35_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x35x35x288xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x35x35x288xf32>) outs(%8 : tensor<666x35x35x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x35x35x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x320xf32>) -> tensor<666x1x1x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x1x1x320xf32>) -> tensor<80x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %6 = tensor.empty() : tensor<666x1x1x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x1x1x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x320xf32>, tensor<80x1x1x320xf32>) outs(%7 : tensor<666x1x1x80xf32>) -> tensor<666x1x1x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1920xf32>) -> tensor<1x1x1x1920xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1920xf32>, tensor<1x1x1x1920xf32>) outs(%4 : tensor<666x7x7x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2016xf32>, tensor<666x7x7x2016xf32>) outs(%4 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x58xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x58xf32>) -> tensor<666x1x1x58xf32>\n    %2 = bufferization.alloc_tensor() : tensor<696x1x1x58xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<696x1x1x58xf32>) -> tensor<696x1x1x58xf32>\n    %4 = bufferization.alloc_tensor() : tensor<696xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<696xf32>) -> tensor<696xf32>\n    %6 = tensor.empty() : tensor<666x1x1x696xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<696xf32>) outs(%6 : tensor<666x1x1x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x696xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x58xf32>, tensor<696x1x1x58xf32>) outs(%7 : tensor<666x1x1x696xf32>) -> tensor<666x1x1x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x768xf32>) -> tensor<666x28x28x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x28x28x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x28x28x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1512xf32>) -> tensor<666x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1512xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %4 = tensor.empty() : tensor<666x56x56x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x72xf32>, tensor<666x56x56x72xf32>) outs(%4 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x928xf32>) -> tensor<666x7x7x928xf32>\n    %2 = tensor.empty() : tensor<666x7x7x928xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x928xf32>) outs(%2 : tensor<666x7x7x928xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<192xf32>) -> tensor<192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<192xf32>, tensor<1xf32>) outs(%4 : tensor<192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x8xf32>) -> tensor<144x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x1x1x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<144x1x1x8xf32>) outs(%7 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x256xf32>) -> tensor<512x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x56x56x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<512x1x1x256xf32>) outs(%7 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<888x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<888x1x1x888xf32>) -> tensor<888x1x1x888xf32>\n    %4 = bufferization.alloc_tensor() : tensor<888xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<888xf32>) -> tensor<888xf32>\n    %6 = tensor.empty() : tensor<666x7x7x888xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<888xf32>) outs(%6 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x888xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x888xf32>, tensor<888x1x1x888xf32>) outs(%7 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x120xf32>) -> tensor<1x1x1x120xf32>\n    %4 = tensor.empty() : tensor<666x28x28x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x120xf32>, tensor<1x1x1x120xf32>) outs(%4 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<666x14x14x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1632xf32>) -> tensor<666x14x14x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1632xf32>) -> tensor<1x1x1x1632xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1632xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1632xf32>, tensor<1x1x1x1632xf32>) outs(%4 : tensor<666x14x14x1632xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x368xf32>) -> tensor<1x1x1x368xf32>\n    %4 = tensor.empty() : tensor<666x7x7x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x368xf32>, tensor<1x1x1x368xf32>) outs(%4 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x4096xf32>) -> tensor<666x14x14x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x4096xf32>) -> tensor<666x14x14x4096xf32>\n    %4 = tensor.empty() : tensor<666x14x14x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x4096xf32>, tensor<666x14x14x4096xf32>) outs(%4 : tensor<666x14x14x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x3x3x256xf32>) -> tensor<384x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x8x8x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x256xf32>, tensor<384x3x3x256xf32>) outs(%7 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x88xf32>) -> tensor<666x28x28x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x88xf32>) -> tensor<1x1x1x88xf32>\n    %4 = tensor.empty() : tensor<666x28x28x88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x88xf32>, tensor<1x1x1x88xf32>) outs(%4 : tensor<666x28x28x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1xf32>) outs(%2 : tensor<666x14x14x1xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x896xf32>) -> tensor<666x1x1x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %4 = tensor.empty() : tensor<666x14x14x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x896xf32>, tensor<666x14x14x896xf32>) outs(%4 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x352xf32>) -> tensor<666x28x28x352xf32>\n    %2 = tensor.empty() : tensor<666x28x28x352xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x352xf32>) outs(%2 : tensor<666x28x28x352xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x768xf32>, tensor<666x7x7x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1248xf32>) -> tensor<666x14x14x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1248xf32>) -> tensor<1x1x1x1248xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1248xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1248xf32>, tensor<1x1x1x1248xf32>) outs(%4 : tensor<666x14x14x1248xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1248xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %2 = tensor.empty() : tensor<666x7x368xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x368xf32>) -> tensor<666x7x368xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x368xf32>) outs(%3 : tensor<666x7x368xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x368xf32> into tensor<666x1x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1696xf32>) -> tensor<666x14x14x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1696xf32>) -> tensor<1x1x1x1696xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1696xf32>, tensor<1x1x1x1696xf32>) outs(%4 : tensor<666x14x14x1696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x800xf32>) -> tensor<666x14x14x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x800xf32>) -> tensor<1x1x1x800xf32>\n    %4 = tensor.empty() : tensor<666x14x14x800xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x800xf32>, tensor<1x1x1x800xf32>) outs(%4 : tensor<666x14x14x800xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x14x14x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x720xf32>) -> tensor<666x28x28x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x720xf32>) -> tensor<1x1x1x720xf32>\n    %4 = tensor.empty() : tensor<666x28x28x720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x720xf32>, tensor<1x1x1x720xf32>) outs(%4 : tensor<666x28x28x720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1280xf32>) -> tensor<666x8x8x1280xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x8x8x1280xf32> to tensor<666x10x10x1280xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x8x8x1280xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x8x8x1280xf32>) -> tensor<666x8x8x1280xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x10x10x1280xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x8x8x1280xf32>) -> tensor<666x8x8x1280xf32>\n    %c1 = arith.constant 1 : index\n    %c8 = arith.constant 8 : index\n    %c2 = arith.constant 2 : index\n    %c8_2 = arith.constant 8 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c8, %c1_3 : index\n    %7 = arith.subi %c8_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x8x8x1280xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x8x8x1280xf32>) outs(%8 : tensor<666x8x8x1280xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x8x8x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x48xf32>) -> tensor<192x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x1x1x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x1x1x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x48xf32>, tensor<192x1x1x48xf32>) outs(%7 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %4 = tensor.empty() : tensor<666x28x28x44xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x44xf32>, tensor<666x28x28x44xf32>) outs(%4 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x84xf32>) -> tensor<1x1x1x84xf32>\n    %4 = tensor.empty() : tensor<666x42x42x84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x84xf32>, tensor<1x1x1x84xf32>) outs(%4 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x96xf32>) -> tensor<666x165x165x96xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x83x83x96xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x83x83x96xf32>) -> tensor<666x83x83x96xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x165x165x96xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x83x83x96xf32>) -> tensor<666x83x83x96xf32>\n    %c1 = arith.constant 1 : index\n    %c83 = arith.constant 83 : index\n    %c2 = arith.constant 2 : index\n    %c83_1 = arith.constant 83 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c83, %c1_2 : index\n    %7 = arith.subi %c83_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x83x83x96xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x83x83x96xf32>) outs(%8 : tensor<666x83x83x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x83x83x96xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1280xf32>) -> tensor<1x666x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1280x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1280x1000xf32>) -> tensor<1x1280x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1280xf32>, tensor<1x1280x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x88xf32>) -> tensor<666x28x28x88xf32>\n    %2 = tensor.empty() : tensor<666x28x28x88xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x88xf32>) outs(%2 : tensor<666x28x28x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<666x56x56x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x14x14x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x14x14x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x44xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x44xf32>) -> tensor<1x1x1x44xf32>\n    %4 = tensor.empty() : tensor<666x28x28x44xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x44xf32>, tensor<1x1x1x44xf32>) outs(%4 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<28x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<28x1x1x112xf32>) -> tensor<28x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<28xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<28xf32>) -> tensor<28xf32>\n    %6 = tensor.empty() : tensor<666x1x1x28xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<28xf32>) outs(%6 : tensor<666x1x1x28xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x28xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x112xf32>, tensor<28x1x1x112xf32>) outs(%7 : tensor<666x1x1x28xf32>) -> tensor<666x1x1x28xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1088xf32>) -> tensor<1088xf32>\n    %2 = tensor.empty() : tensor<1088xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1088xf32>) outs(%2 : tensor<1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x7x7x1536xf32>, tensor<666x7x7x1536xf32>) outs(%2 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1664xf32>) -> tensor<666x7x7x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1664xf32>) -> tensor<1x1x1x1664xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1664xf32>, tensor<1x1x1x1664xf32>) outs(%4 : tensor<666x7x7x1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1296xf32>) -> tensor<666x14x14x1296xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1296xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1296xf32>) outs(%2 : tensor<666x14x14x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x672x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x672x1xf32>) -> tensor<3x3x672x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x11x11x672xf32> to tensor<666x13x13x672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %8 = tensor.empty() : tensor<666x11x11x672xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x13x13x672xf32>, tensor<3x3x672x1xf32>) outs(%7 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x11x11x672x1xf32> into tensor<666x11x11x672xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<672xf32>, tensor<666x11x11x672xf32>) outs(%8 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<666x7x7x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x56x56x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<832xf32>) -> tensor<832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<832xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<832xf32>, tensor<1xf32>) outs(%4 : tensor<832xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x480xf32>) -> tensor<666x28x28x480xf32>\n    %2 = tensor.empty() : tensor<666x28x28x480xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x480xf32>) outs(%2 : tensor<666x28x28x480xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x72xf32>) -> tensor<1x1x1x72xf32>\n    %4 = tensor.empty() : tensor<666x56x56x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<1x1x1x72xf32>) outs(%4 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x544xf32>) -> tensor<666x14x14x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x544xf32>) -> tensor<1x1x1x544xf32>\n    %4 = tensor.empty() : tensor<666x14x14x544xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x544xf32>, tensor<1x1x1x544xf32>) outs(%4 : tensor<666x14x14x544xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x120xf32>) -> tensor<1x1x1x120xf32>\n    %4 = tensor.empty() : tensor<666x28x28x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x120xf32>, tensor<1x1x1x120xf32>) outs(%4 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x384xf32>) -> tensor<666x56x56x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x56x56x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x56x56x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x35x35x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x320xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x35x35x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<160xf32>) -> tensor<160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<160xf32>, tensor<1xf32>) outs(%4 : tensor<160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1504xf32>) -> tensor<666x7x7x1504xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1504xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1504xf32>) outs(%2 : tensor<666x7x7x1504xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x896xf32>) -> tensor<666x7x7x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x7x7x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x7x7x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x14x14x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x14x14x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x272xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x272xf32>) -> tensor<666x1x1x272xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1088x1x1x272xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1088x1x1x272xf32>) -> tensor<1088x1x1x272xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1088xf32>) -> tensor<1088xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1088xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1088xf32>) outs(%6 : tensor<666x1x1x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1088xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x272xf32>, tensor<1088x1x1x272xf32>) outs(%7 : tensor<666x1x1x1088xf32>) -> tensor<666x1x1x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x160xf32>) -> tensor<666x56x56x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x56x56x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x56x56x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1056xf32>) -> tensor<1056xf32>\n    %2 = tensor.empty() : tensor<1056xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1056xf32>) outs(%2 : tensor<1056xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %4 = tensor.empty() : tensor<666x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<666x768xf32>) outs(%4 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x512xf32>) -> tensor<128x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<128x1x1x512xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<528x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<528x1x1x240xf32>) -> tensor<528x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<528xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<528xf32>) -> tensor<528xf32>\n    %6 = tensor.empty() : tensor<666x7x7x528xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<528xf32>) outs(%6 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x528xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x240xf32>, tensor<528x1x1x240xf32>) outs(%7 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1760xf32>) -> tensor<666x14x14x1760xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1760xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1760xf32>) outs(%2 : tensor<666x14x14x1760xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x11xf32>) -> tensor<666x111x111x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x11xf32>) -> tensor<1x1x1x11xf32>\n    %4 = tensor.empty() : tensor<666x111x111x11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x111x111x11xf32>, tensor<1x1x1x11xf32>) outs(%4 : tensor<666x111x111x11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x111x111x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = tensor.empty() : tensor<666x28x28x1xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x1xf32>) outs(%2 : tensor<666x28x28x1xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1232xf32>) -> tensor<1x1x1x1232xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1232xf32>, tensor<1x1x1x1232xf32>) outs(%4 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = tensor.empty() : tensor<666x56x56x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x56x56x128xf32>, tensor<666x56x56x128xf32>) outs(%2 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x256x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x256x1xf32>) -> tensor<3x3x256x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x37x37x256xf32> to tensor<666x39x39x256xf32>\n    %6 = tensor.empty() : tensor<666x37x37x256x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x37x37x256x1xf32>) -> tensor<666x37x37x256x1xf32>\n    %8 = tensor.empty() : tensor<666x37x37x256xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x39x39x256xf32>, tensor<3x3x256x1xf32>) outs(%7 : tensor<666x37x37x256x1xf32>) -> tensor<666x37x37x256x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x37x37x256x1xf32> into tensor<666x37x37x256xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<256xf32>, tensor<666x37x37x256xf32>) outs(%8 : tensor<666x37x37x256xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1008xf32>) -> tensor<666x14x14x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1008xf32>) -> tensor<1x1x1x1008xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1008xf32>, tensor<1x1x1x1008xf32>) outs(%4 : tensor<666x14x14x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2240xf32>) -> tensor<666x1x1x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x2240xf32>, tensor<666x7x7x2240xf32>) outs(%4 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x256xf32>) -> tensor<666x112x112x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x112x112x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x112x112x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x336xf32>) -> tensor<666x42x42x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x336xf32>) -> tensor<168x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x42x42x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x42x42x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x42x42x336xf32>, tensor<168x1x1x336xf32>) outs(%7 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x38xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x38xf32>) -> tensor<666x1x1x38xf32>\n    %2 = bufferization.alloc_tensor() : tensor<368x1x1x38xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<368x1x1x38xf32>) -> tensor<368x1x1x38xf32>\n    %4 = bufferization.alloc_tensor() : tensor<368xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<368xf32>) -> tensor<368xf32>\n    %6 = tensor.empty() : tensor<666x1x1x368xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<368xf32>) outs(%6 : tensor<666x1x1x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x368xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x38xf32>, tensor<368x1x1x38xf32>) outs(%7 : tensor<666x1x1x368xf32>) -> tensor<666x1x1x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1472xf32>) -> tensor<1472xf32>\n    %2 = tensor.empty() : tensor<1472xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1472xf32>) outs(%2 : tensor<1472xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<232xf32>) -> tensor<232xf32>\n    %2 = tensor.empty() : tensor<232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<232xf32>) outs(%2 : tensor<232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1792xf32>) -> tensor<1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1792xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1792xf32>, tensor<1xf32>) outs(%4 : tensor<1792xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = tensor.empty() : tensor<666x56x56x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x336xf32>) outs(%2 : tensor<666x56x56x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2520xf32>) -> tensor<1x1x1x2520xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2520xf32>, tensor<1x1x1x2520xf32>) outs(%4 : tensor<666x7x7x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1624xf32>, tensor<666x7x7x1624xf32>) outs(%4 : tensor<666x7x7x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x864xf32>) -> tensor<666x14x14x864xf32>\n    %2 = tensor.empty() : tensor<666x14x14x864xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x864xf32>) outs(%2 : tensor<666x14x14x864xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x864xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1624xf32>) -> tensor<1x666x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1624x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1624x1000xf32>) -> tensor<1x1624x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1624xf32>, tensor<1x1624x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x144xf32>) -> tensor<666x1x56x144xf32>\n    %2 = tensor.empty() : tensor<666x1x144xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x144xf32>) -> tensor<666x1x144xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x144xf32>) outs(%3 : tensor<666x1x144xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x144xf32> into tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<768xf32>) -> tensor<768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<768xf32>, tensor<1xf32>) outs(%4 : tensor<768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x512xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x256xf32>, tensor<666x28x28x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1760xf32>) -> tensor<666x7x7x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1760xf32>) -> tensor<128x1x1x1760xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1760xf32>, tensor<128x1x1x1760xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1536xf32>) -> tensor<666x1x7x1536xf32>\n    %2 = tensor.empty() : tensor<666x1x1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1536xf32>) -> tensor<666x1x1536xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1536xf32>) outs(%3 : tensor<666x1x1536xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1536xf32> into tensor<666x1x1x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x35x35x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x728xf32>) -> tensor<1x1x1x728xf32>\n    %4 = tensor.empty() : tensor<666x37x37x728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x37x37x728xf32>, tensor<1x1x1x728xf32>) outs(%4 : tensor<666x37x37x728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x37x37x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x216xf32>) -> tensor<666x1x1x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x216xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    %2 = tensor.empty() : tensor<666x8x8x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x384xf32>) outs(%2 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1296xf32>) -> tensor<1x666x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1296x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1296x1000xf32>) -> tensor<1x1296x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1296xf32>, tensor<1x1296x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x32xf32>) -> tensor<128x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<128x1x1x32xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = tensor.empty() : tensor<666x37x37x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x37x37x256xf32>) outs(%2 : tensor<666x37x37x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x256xf32>) -> tensor<666x112x112x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x112x112x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x112x112x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1512x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1512x1x1x144xf32>) -> tensor<1512x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1512xf32>) -> tensor<1512xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1512xf32>) outs(%6 : tensor<666x1x1x1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x144xf32>, tensor<1512x1x1x144xf32>) outs(%7 : tensor<666x1x1x1512xf32>) -> tensor<666x1x1x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1344xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1344xf32>) outs(%2 : tensor<666x14x14x1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x74x74x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x74x74x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x74x74x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x74x74x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x56x56x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = tensor.empty() : tensor<666x17x17x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x192xf32>) outs(%2 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1184xf32>) -> tensor<666x14x14x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1184xf32>) -> tensor<1x1x1x1184xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1184xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1184xf32>, tensor<1x1x1x1184xf32>) outs(%4 : tensor<666x14x14x1184xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x736xf32>) -> tensor<666x7x7x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x736xf32>) -> tensor<1x1x1x736xf32>\n    %4 = tensor.empty() : tensor<666x7x7x736xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x736xf32>, tensor<1x1x1x736xf32>) outs(%4 : tensor<666x7x7x736xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = tensor.empty() : tensor<666x7x7x176xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x176xf32>) outs(%2 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x992xf32>) -> tensor<666x14x14x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x992xf32>) -> tensor<128x1x1x992xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x992xf32>, tensor<128x1x1x992xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x864xf32>) -> tensor<666x14x14x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x864xf32>) -> tensor<1x1x1x864xf32>\n    %4 = tensor.empty() : tensor<666x14x14x864xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x864xf32>, tensor<1x1x1x864xf32>) outs(%4 : tensor<666x14x14x864xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x704xf32>) -> tensor<666x14x14x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x704xf32>) -> tensor<1x1x1x704xf32>\n    %4 = tensor.empty() : tensor<666x14x14x704xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x704xf32>, tensor<1x1x1x704xf32>) outs(%4 : tensor<666x14x14x704xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x864xf32>) -> tensor<666x7x7x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x864xf32>) -> tensor<1x1x1x864xf32>\n    %4 = tensor.empty() : tensor<666x7x7x864xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x864xf32>, tensor<1x1x1x864xf32>) outs(%4 : tensor<666x7x7x864xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x336xf32>) -> tensor<666x42x42x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x42x42x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x42x42x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<992xf32>) -> tensor<992xf32>\n    %2 = tensor.empty() : tensor<992xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<992xf32>) outs(%2 : tensor<992xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x1x160xf32>) -> tensor<160x1x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %6 = tensor.empty() : tensor<666x14x14x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x14x14x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x160xf32>, tensor<160x1x1x160xf32>) outs(%7 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x336xf32>) -> tensor<666x42x42x336xf32>\n    %2 = tensor.empty() : tensor<666x42x42x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x42x42x336xf32>) outs(%2 : tensor<666x42x42x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x42x42x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %4 = tensor.empty() : tensor<666x56x56x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x64xf32>, tensor<666x56x56x64xf32>) outs(%4 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x576xf32>) -> tensor<144x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x1x1x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x576xf32>, tensor<144x1x1x576xf32>) outs(%7 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1088xf32>) -> tensor<1x666x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1088x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1088x1000xf32>) -> tensor<1x1088x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1088xf32>, tensor<1x1088x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x149x149x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x149x149x32xf32>) -> tensor<666x149x149x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x32xf32>) -> tensor<32x3x3x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x147x147x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x147x147x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x147x147x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x149x149x32xf32>, tensor<32x3x3x32xf32>) outs(%7 : tensor<666x147x147x32xf32>) -> tensor<666x147x147x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x784xf32>) -> tensor<1x1x1x784xf32>\n    %4 = tensor.empty() : tensor<666x14x14x784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x784xf32>, tensor<1x1x1x784xf32>) outs(%4 : tensor<666x14x14x784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<666x56x56x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x3024xf32>) -> tensor<666x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x3024xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2016xf32>) -> tensor<666x14x14x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2016xf32>) -> tensor<1x1x1x2016xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2016xf32>, tensor<1x1x1x2016xf32>) outs(%4 : tensor<666x14x14x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x736xf32>) -> tensor<666x7x7x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x736xf32>) -> tensor<1x1x1x736xf32>\n    %4 = tensor.empty() : tensor<666x7x7x736xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x736xf32>, tensor<1x1x1x736xf32>) outs(%4 : tensor<666x7x7x736xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x960xf32>) -> tensor<1x1x1x960xf32>\n    %4 = tensor.empty() : tensor<666x7x7x960xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x960xf32>, tensor<1x1x1x960xf32>) outs(%4 : tensor<666x7x7x960xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %2 = tensor.empty() : tensor<666x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x768xf32>, tensor<666x768xf32>) outs(%2 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<11x1x1x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<11x1x1x11xf32>) -> tensor<11x1x1x11xf32>\n    %4 = bufferization.alloc_tensor() : tensor<11xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<11xf32>) -> tensor<11xf32>\n    %6 = tensor.empty() : tensor<666x56x56x11xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<11xf32>) outs(%6 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x11xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x11xf32>, tensor<11x1x1x11xf32>) outs(%7 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x25x25x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x25x25x672xf32>) -> tensor<666x25x25x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x672x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x672x1xf32>) -> tensor<5x5x672x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %8 = tensor.empty() : tensor<666x11x11x672xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x25x25x672xf32>, tensor<5x5x672x1xf32>) outs(%7 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x11x11x672x1xf32> into tensor<666x11x11x672xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<672xf32>, tensor<666x11x11x672xf32>) outs(%8 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x384x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x384x1xf32>) -> tensor<3x3x384x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x384xf32> to tensor<666x16x16x384xf32>\n    %6 = tensor.empty() : tensor<666x14x14x384x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x14x14x384x1xf32>) -> tensor<666x14x14x384x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x384xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x16x16x384xf32>, tensor<3x3x384x1xf32>) outs(%7 : tensor<666x14x14x384x1xf32>) -> tensor<666x14x14x384x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x384x1xf32> into tensor<666x14x14x384xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<384xf32>, tensor<666x14x14x384xf32>) outs(%8 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x256xf32> to tensor<666x37x37x256xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x35x35x256xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x37x37x256xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %c1 = arith.constant 1 : index\n    %c35 = arith.constant 35 : index\n    %c2 = arith.constant 2 : index\n    %c35_2 = arith.constant 35 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c35, %c1_3 : index\n    %7 = arith.subi %c35_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x35x35x256xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x35x35x256xf32>) outs(%8 : tensor<666x35x35x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x35x35x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x29x29x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x29x29x192xf32>) -> tensor<666x29x29x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x192x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x192x1xf32>) -> tensor<3x3x192x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x14x14x192x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x14x14x192x1xf32>) -> tensor<666x14x14x192x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x192xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x29x29x192xf32>, tensor<3x3x192x1xf32>) outs(%7 : tensor<666x14x14x192x1xf32>) -> tensor<666x14x14x192x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x192x1xf32> into tensor<666x14x14x192xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<192xf32>, tensor<666x14x14x192xf32>) outs(%8 : tensor<666x14x14x192xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x928xf32>) -> tensor<666x14x14x928xf32>\n    %2 = tensor.empty() : tensor<666x14x14x928xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x928xf32>) outs(%2 : tensor<666x14x14x928xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x336x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x336x1xf32>) -> tensor<5x5x336x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x21x21x336xf32> to tensor<666x25x25x336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %8 = tensor.empty() : tensor<666x21x21x336xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x25x25x336xf32>, tensor<5x5x336x1xf32>) outs(%7 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x21x21x336x1xf32> into tensor<666x21x21x336xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<336xf32>, tensor<666x21x21x336xf32>) outs(%8 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x192xf32>) -> tensor<666x14x14x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x14x14x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x14x14x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x192xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = tensor.empty() : tensor<666x28x28xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28xf32>) -> tensor<666x28x28xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x256xf32>) outs(%3 : tensor<666x28x28xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x28x28xf32> into tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2520xf32>) -> tensor<666x14x14x2520xf32>\n    %2 = tensor.empty() : tensor<666x14x14x2520xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x2520xf32>) outs(%2 : tensor<666x14x14x2520xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x28x28x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x28x28x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x448xf32>) -> tensor<896x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x28x28x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x28x28x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<896x1x1x448xf32>) outs(%7 : tensor<666x28x28x896xf32>) -> tensor<666x28x28x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x392xf32>) -> tensor<666x56x56x392xf32>\n    %2 = tensor.empty() : tensor<666x56x56x392xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x392xf32>) outs(%2 : tensor<666x56x56x392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = tensor.empty() : tensor<666x1x1x8xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x8xf32>) outs(%2 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = tensor.empty() : tensor<666x7x768xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x768xf32>) -> tensor<666x7x768xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x768xf32>) outs(%3 : tensor<666x7x768xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x768xf32> into tensor<666x1x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1664xf32>) -> tensor<666x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1664xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2240xf32>) -> tensor<666x14x14x2240xf32>\n    %2 = tensor.empty() : tensor<666x14x14x2240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x2240xf32>) outs(%2 : tensor<666x14x14x2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x392xf32>) -> tensor<666x56x56x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x392xf32>) -> tensor<1x1x1x392xf32>\n    %4 = tensor.empty() : tensor<666x56x56x392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x392xf32>, tensor<1x1x1x392xf32>) outs(%4 : tensor<666x56x56x392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x832xf32>) -> tensor<666x14x14x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x832xf32>) -> tensor<1x1x1x832xf32>\n    %4 = tensor.empty() : tensor<666x14x14x832xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x832xf32>, tensor<1x1x1x832xf32>) outs(%4 : tensor<666x14x14x832xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x512xf32>) -> tensor<256x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x14x14x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<256x1x1x512xf32>) outs(%7 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x2048xf32>) -> tensor<666x1x7x2048xf32>\n    %2 = tensor.empty() : tensor<666x1x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x2048xf32>) -> tensor<666x1x2048xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x2048xf32>) outs(%3 : tensor<666x1x2048xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x2048xf32> into tensor<666x1x1x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x14x14x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x14x14x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x2048xf32>) -> tensor<666x28x28x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x2048xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x2048xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = tensor.empty() : tensor<666x14x208xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x208xf32>) -> tensor<666x14x208xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x208xf32>) outs(%3 : tensor<666x14x208xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x208xf32> into tensor<666x1x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x912xf32>) -> tensor<666x14x14x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x912xf32>) -> tensor<1x1x1x912xf32>\n    %4 = tensor.empty() : tensor<666x14x14x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x912xf32>, tensor<1x1x1x912xf32>) outs(%4 : tensor<666x14x14x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    %2 = tensor.empty() : tensor<666x8x8x448xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x448xf32>) outs(%2 : tensor<666x8x8x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x11xf32>) -> tensor<666x111x111x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x11xf32>) -> tensor<1x1x1x11xf32>\n    %4 = tensor.empty() : tensor<666x111x111x11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x111x111x11xf32>, tensor<1x1x1x11xf32>) outs(%4 : tensor<666x111x111x11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x111x111x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %4 = tensor.empty() : tensor<666x56x56x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x80xf32>, tensor<666x56x56x80xf32>) outs(%4 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x192xf32>) -> tensor<666x14x14x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x14x14x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x14x14x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x14xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x14xf32>) -> tensor<666x1x1x14xf32>\n    %2 = bufferization.alloc_tensor() : tensor<152x1x1x14xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<152x1x1x14xf32>) -> tensor<152x1x1x14xf32>\n    %4 = bufferization.alloc_tensor() : tensor<152xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<152xf32>) -> tensor<152xf32>\n    %6 = tensor.empty() : tensor<666x1x1x152xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<152xf32>) outs(%6 : tensor<666x1x1x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x152xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x14xf32>, tensor<152x1x1x14xf32>) outs(%7 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<912x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<912x1x1x408xf32>) -> tensor<912x1x1x408xf32>\n    %4 = bufferization.alloc_tensor() : tensor<912xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<912xf32>) -> tensor<912xf32>\n    %6 = tensor.empty() : tensor<666x14x14x912xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<912xf32>) outs(%6 : tensor<666x14x14x912xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x912xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x408xf32>, tensor<912x1x1x408xf32>) outs(%7 : tensor<666x14x14x912xf32>) -> tensor<666x14x14x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1376xf32>) -> tensor<666x14x14x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1376xf32>) -> tensor<1x1x1x1376xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1376xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1376xf32>, tensor<1x1x1x1376xf32>) outs(%4 : tensor<666x14x14x1376xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x7x7x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x7x7x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x528xf32>) -> tensor<1x1x1x528xf32>\n    %4 = tensor.empty() : tensor<666x14x14x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x528xf32>, tensor<1x1x1x528xf32>) outs(%4 : tensor<666x14x14x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x832xf32>) -> tensor<666x7x7x832xf32>\n    %2 = tensor.empty() : tensor<666x7x7x832xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x832xf32>) outs(%2 : tensor<666x7x7x832xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1512xf32>) -> tensor<666x14x14x1512xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1512xf32>) outs(%2 : tensor<666x14x14x1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<666x7x7x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1296x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1296x1x1x1296xf32>) -> tensor<1296x1x1x1296xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1296xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1296xf32>) -> tensor<1296xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1296xf32>) outs(%6 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1296xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1296xf32>, tensor<1296x1x1x1296xf32>) outs(%7 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1856xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1856xf32>) -> tensor<666x7x7x1856xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1856xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1856xf32>) -> tensor<1x1x1x1856xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1856xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1856xf32>, tensor<1x1x1x1856xf32>) outs(%4 : tensor<666x7x7x1856xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1856xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x96xf32>) -> tensor<1x2088576x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x96x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x96x384xf32>) -> tensor<1x96x384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x384xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x384xf32>) -> tensor<1x2088576x384xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x96xf32>, tensor<1x96x384xf32>) outs(%5 : tensor<1x2088576x384xf32>) -> tensor<1x2088576x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x10x10x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x10x10x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1232xf32>) -> tensor<1x1x1x1232xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1232xf32>, tensor<1x1x1x1232xf32>) outs(%4 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1632xf32>) -> tensor<666x14x14x1632xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1632xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1632xf32>) outs(%2 : tensor<666x14x14x1632xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = tensor.empty() : tensor<666x1x1x112xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x112xf32>) outs(%2 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x4x4x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x4x4x3xf32>) -> tensor<256x4x4x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x56x56x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<4> : tensor<2xi64>} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<256x4x4x3xf32>) outs(%7 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x544xf32>) -> tensor<666x14x14x544xf32>\n    %2 = tensor.empty() : tensor<666x14x14x544xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x544xf32>) outs(%2 : tensor<666x14x14x544xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x8192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x8192xf32>) -> tensor<666x7x7x8192xf32>\n    %2 = tensor.empty() : tensor<666x7x7x8192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x8192xf32>) outs(%2 : tensor<666x7x7x8192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x8192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<784x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<784x1x1x392xf32>) -> tensor<784x1x1x392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<784xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<784xf32>) -> tensor<784xf32>\n    %6 = tensor.empty() : tensor<666x28x28x784xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<784xf32>) outs(%6 : tensor<666x28x28x784xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x784xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x392xf32>, tensor<784x1x1x392xf32>) outs(%7 : tensor<666x28x28x784xf32>) -> tensor<666x28x28x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x96xf32>) -> tensor<96x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x56x56x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<96x1x1x96xf32>) outs(%7 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x1024xf32>) -> tensor<1x522144x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1024x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1024x256xf32>) -> tensor<1x1024x256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x256xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x256xf32>) -> tensor<1x522144x256xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x1024xf32>, tensor<1x1024x256xf32>) outs(%5 : tensor<1x522144x256xf32>) -> tensor<1x522144x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1600xf32>) -> tensor<666x7x7x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1600xf32>) -> tensor<1x1x1x1600xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1600xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1600xf32>, tensor<1x1x1x1600xf32>) outs(%4 : tensor<666x7x7x1600xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x72xf32>) -> tensor<8x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x72xf32>, tensor<8x1x1x72xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %4 = tensor.empty() : tensor<666x14x14x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x160xf32>, tensor<666x14x14x160xf32>) outs(%4 : tensor<666x14x14x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x128x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x128x1xf32>) -> tensor<3x3x128x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x147x147x128xf32> to tensor<666x149x149x128xf32>\n    %6 = tensor.empty() : tensor<666x147x147x128x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x147x147x128x1xf32>) -> tensor<666x147x147x128x1xf32>\n    %8 = tensor.empty() : tensor<666x147x147x128xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x149x149x128xf32>, tensor<3x3x128x1xf32>) outs(%7 : tensor<666x147x147x128x1xf32>) -> tensor<666x147x147x128x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x147x147x128x1xf32> into tensor<666x147x147x128xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<128xf32>, tensor<666x147x147x128xf32>) outs(%8 : tensor<666x147x147x128xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x147x147x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x56x56x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x56x56x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x28x28x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x168xf32>) -> tensor<666x112x112x168xf32>\n    %2 = tensor.empty() : tensor<666x112x112x168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x168xf32>) outs(%2 : tensor<666x112x112x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x299x299x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x299x299x3xf32>) -> tensor<666x299x299x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x3xf32>) -> tensor<32x3x3x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x149x149x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x149x149x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x149x149x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x299x299x3xf32>, tensor<32x3x3x3xf32>) outs(%7 : tensor<666x149x149x32xf32>) -> tensor<666x149x149x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x8x8x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<48xf32>) -> tensor<48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<48xf32>, tensor<1xf32>) outs(%4 : tensor<48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x288xf32>) -> tensor<666x1x1x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x288xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x288xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = tensor.empty() : tensor<666x14x320xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x320xf32>) -> tensor<666x14x320xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x320xf32>) outs(%3 : tensor<666x14x320xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x320xf32> into tensor<666x1x14x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x1536xf32>, tensor<666x7x7x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1536x2x2x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1536x2x2x768xf32>) -> tensor<1536x2x2x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1536xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1536xf32>) -> tensor<1536xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1536xf32>) outs(%6 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1536xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<1536x2x2x768xf32>) outs(%7 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x4x4x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x4x4x3xf32>) -> tensor<96x4x4x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x56x56x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<4> : tensor<2xi64>} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<96x4x4x3xf32>) outs(%7 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1088xf32>) -> tensor<666x1x1x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1088xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x832xf32>) -> tensor<666x14x14x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x832xf32>) -> tensor<1x1x1x832xf32>\n    %4 = tensor.empty() : tensor<666x14x14x832xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x832xf32>, tensor<1x1x1x832xf32>) outs(%4 : tensor<666x14x14x832xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x560xf32>) -> tensor<666x28x28x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x560xf32>) -> tensor<1x1x1x560xf32>\n    %4 = tensor.empty() : tensor<666x28x28x560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x560xf32>, tensor<1x1x1x560xf32>) outs(%4 : tensor<666x28x28x560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1056xf32>) -> tensor<1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1056xf32>, tensor<1xf32>) outs(%4 : tensor<1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x240xf32>) -> tensor<666x56x56x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x56x56x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x56x56x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x512xf32>) -> tensor<256x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x28x28x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<256x1x1x512xf32>) outs(%7 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x15x15x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x15x15x576xf32>) -> tensor<666x15x15x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x576x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x576x1xf32>) -> tensor<3x3x576x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x7x7x576x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x7x7x576x1xf32>) -> tensor<666x7x7x576x1xf32>\n    %8 = tensor.empty() : tensor<666x7x7x576xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x15x15x576xf32>, tensor<3x3x576x1xf32>) outs(%7 : tensor<666x7x7x576x1xf32>) -> tensor<666x7x7x576x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x7x7x576x1xf32> into tensor<666x7x7x576xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<576xf32>, tensor<666x7x7x576xf32>) outs(%8 : tensor<666x7x7x576xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x7x7x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x112xf32>) -> tensor<1x1x1x112xf32>\n    %4 = tensor.empty() : tensor<666x28x28x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x112xf32>, tensor<1x1x1x112xf32>) outs(%4 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %4 = tensor.empty() : tensor<666x56x56x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<666x56x56x32xf32>) outs(%4 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x256xf32>) -> tensor<1x2088576x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x256x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x256x1024xf32>) -> tensor<1x256x1024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x1024xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x1024xf32>) -> tensor<1x2088576x1024xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x256xf32>, tensor<1x256x1024xf32>) outs(%5 : tensor<1x2088576x1024xf32>) -> tensor<1x2088576x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1344xf32>) -> tensor<666x7x7x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x7x7x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = tensor.empty() : tensor<666x14x14x88xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x14x14x88xf32>, tensor<666x14x14x88xf32>) outs(%2 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.addf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1696xf32>) -> tensor<666x7x7x1696xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1696xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1696xf32>) outs(%2 : tensor<666x7x7x1696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<560x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<560x1x1x560xf32>) -> tensor<560x1x1x560xf32>\n    %4 = bufferization.alloc_tensor() : tensor<560xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<560xf32>) -> tensor<560xf32>\n    %6 = tensor.empty() : tensor<666x14x14x560xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<560xf32>) outs(%6 : tensor<666x14x14x560xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x560xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x560xf32>, tensor<560x1x1x560xf32>) outs(%7 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x288xf32>) -> tensor<666x8x8x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x8x8x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x8x8x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %4 = tensor.empty() : tensor<666x56x56x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x224xf32>, tensor<666x56x56x224xf32>) outs(%4 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x1232xf32>) -> tensor<666x1x14x1232xf32>\n    %2 = tensor.empty() : tensor<666x1x1232xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1232xf32>) -> tensor<666x1x1232xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x1232xf32>) outs(%3 : tensor<666x1x1232xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1232xf32> into tensor<666x1x1x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x736xf32>) -> tensor<666x14x14x736xf32>\n    %2 = tensor.empty() : tensor<666x14x14x736xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x736xf32>) outs(%2 : tensor<666x14x14x736xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x11xf32>) -> tensor<666x111x111x11xf32>\n    %2 = tensor.empty() : tensor<666x111x111x11xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x111x111x11xf32>) outs(%2 : tensor<666x111x111x11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x111x111x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x336xf32>) -> tensor<666x112x112x336xf32>\n    %2 = tensor.empty() : tensor<666x112x112x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x336xf32>) outs(%2 : tensor<666x112x112x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x71x71x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x71x71x192xf32>) -> tensor<666x71x71x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x71x71x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x71x71x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x71x71x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x71x71x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3024xf32>) -> tensor<666x14x14x3024xf32>\n    %2 = tensor.empty() : tensor<666x14x14x3024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x3024xf32>) outs(%2 : tensor<666x14x14x3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1568xf32>) -> tensor<666x14x14x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1568xf32>) -> tensor<1x1x1x1568xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1568xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1568xf32>, tensor<1x1x1x1568xf32>) outs(%4 : tensor<666x14x14x1568xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1760xf32>) -> tensor<666x7x7x1760xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1760xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1760xf32>) outs(%2 : tensor<666x7x7x1760xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<44xf32>) -> tensor<44xf32>\n    %2 = tensor.empty() : tensor<44xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<44xf32>) outs(%2 : tensor<44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<88xf32>) -> tensor<88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<88xf32>, tensor<1xf32>) outs(%4 : tensor<88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<88xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = tensor.empty() : tensor<666x7x672xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x672xf32>) -> tensor<666x7x672xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x672xf32>) outs(%3 : tensor<666x7x672xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x672xf32> into tensor<666x1x7x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x14x14x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1536xf32>) -> tensor<666x8x8x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x8x8x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x8x8x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x1536xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %2 = tensor.empty() : tensor<666x7x1008xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1008xf32>) -> tensor<666x7x1008xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1008xf32>) outs(%3 : tensor<666x7x1008xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1008xf32> into tensor<666x1x7x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1504xf32>) -> tensor<666x14x14x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1504xf32>) -> tensor<1x1x1x1504xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1504xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1504xf32>, tensor<1x1x1x1504xf32>) outs(%4 : tensor<666x14x14x1504xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = tensor.empty() : tensor<666x14x14x784xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x784xf32>) outs(%2 : tensor<666x14x14x784xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x704xf32>) -> tensor<666x7x7x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x704xf32>) -> tensor<128x1x1x704xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x704xf32>, tensor<128x1x1x704xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x8x8x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x8x8x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x448xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x512xf32>) -> tensor<666x1x14x512xf32>\n    %2 = tensor.empty() : tensor<666x1x512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x512xf32>) -> tensor<666x1x512xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x512xf32>) outs(%3 : tensor<666x1x512xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x512xf32> into tensor<666x1x1x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x16xf32>) -> tensor<666x1x1x16xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x16xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x16xf32>) -> tensor<128x1x1x16xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x1x1x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x16xf32>, tensor<128x1x1x16xf32>) outs(%7 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<728x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<728x1x1x728xf32>) -> tensor<728x1x1x728xf32>\n    %4 = bufferization.alloc_tensor() : tensor<728xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<728xf32>) -> tensor<728xf32>\n    %6 = tensor.empty() : tensor<666x19x19x728xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<728xf32>) outs(%6 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x19x19x728xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x19x19x728xf32>, tensor<728x1x1x728xf32>) outs(%7 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %4 = tensor.empty() : tensor<666x7x7x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x368xf32>, tensor<666x7x7x368xf32>) outs(%4 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1664xf32>) -> tensor<1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1664xf32>, tensor<1xf32>) outs(%4 : tensor<1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x912xf32>) -> tensor<1x1x1x912xf32>\n    %4 = tensor.empty() : tensor<666x7x7x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x912xf32>, tensor<1x1x1x912xf32>) outs(%4 : tensor<666x7x7x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2240xf32>) -> tensor<1x1x1x2240xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2240xf32>, tensor<1x1x1x2240xf32>) outs(%4 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1360xf32>) -> tensor<1x666x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1360x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1360x1000xf32>) -> tensor<1x1360x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1360xf32>, tensor<1x1360x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3072xf32>) -> tensor<666x14x14x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3072xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x308xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x308xf32>) -> tensor<666x1x1x308xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1232x1x1x308xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1232x1x1x308xf32>) -> tensor<1232x1x1x308xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1232xf32>) -> tensor<1232xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1232xf32>) outs(%6 : tensor<666x1x1x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x308xf32>, tensor<1232x1x1x308xf32>) outs(%7 : tensor<666x1x1x1232xf32>) -> tensor<666x1x1x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x72xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x416xf32>) -> tensor<666x28x28x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x416xf32>) -> tensor<1x1x1x416xf32>\n    %4 = tensor.empty() : tensor<666x28x28x416xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x416xf32>, tensor<1x1x1x416xf32>) outs(%4 : tensor<666x28x28x416xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1624xf32>) -> tensor<666x14x14x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1624xf32>) -> tensor<1x1x1x1624xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1624xf32>, tensor<1x1x1x1624xf32>) outs(%4 : tensor<666x14x14x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %4 = tensor.empty() : tensor<666x14x14x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x576xf32>, tensor<666x14x14x576xf32>) outs(%4 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2048xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x74x74x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x74x74x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x74x74x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x74x74x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1440xf32>) -> tensor<666x7x7x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1440xf32>) -> tensor<128x1x1x1440xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1440xf32>, tensor<128x1x1x1440xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x8x8x2048xf32> to tensor<666x10x10x2048xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x8x8x2048xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x10x10x2048xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %c1 = arith.constant 1 : index\n    %c8 = arith.constant 8 : index\n    %c2 = arith.constant 2 : index\n    %c8_2 = arith.constant 8 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c8, %c1_3 : index\n    %7 = arith.subi %c8_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x8x8x2048xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x8x8x2048xf32>) outs(%8 : tensor<666x8x8x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x8x8x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x1024xf32>) -> tensor<512x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x7x7x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<512x1x1x1024xf32>) outs(%7 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x10x10x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %4 = tensor.empty() : tensor<666x10x10x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x1024xf32>, tensor<666x10x10x1024xf32>) outs(%4 : tensor<666x10x10x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2016xf32>) -> tensor<666x1x1x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x2016xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1056xf32>) -> tensor<666x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1056xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x672xf32>) -> tensor<666x14x14x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x672xf32>) -> tensor<128x1x1x672xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x672xf32>, tensor<128x1x1x672xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x320xf32>) -> tensor<666x7x7x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x7x7x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x7x7x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x112x112x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x112x112x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x2016xf32>) -> tensor<666x21x21x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x2016xf32>) -> tensor<336x1x1x2016xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x21x21x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x21x21x2016xf32>, tensor<336x1x1x2016xf32>) outs(%7 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x192xf32>) -> tensor<1x522144x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x192x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x192x768xf32>) -> tensor<1x192x768xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x768xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x768xf32>) -> tensor<1x522144x768xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x192xf32>, tensor<1x192x768xf32>) outs(%5 : tensor<1x522144x768xf32>) -> tensor<1x522144x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1232x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1232x1x1x448xf32>) -> tensor<1232x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1232xf32>) -> tensor<1232xf32>\n    %6 = tensor.empty() : tensor<666x28x28x1232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1232xf32>) outs(%6 : tensor<666x28x28x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x1232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<1232x1x1x448xf32>) outs(%7 : tensor<666x28x28x1232xf32>) -> tensor<666x28x28x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1344xf32>) -> tensor<666x28x28x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x28x28x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x144xf32>) -> tensor<666x28x28x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x28x28x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x28x28x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x144xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x4096xf32>) -> tensor<1x666x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x4096x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x4096x4096xf32>) -> tensor<1x4096x4096xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x4096xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x4096xf32>) -> tensor<1x666x4096xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x4096xf32>, tensor<1x4096x4096xf32>) outs(%5 : tensor<1x666x4096xf32>) -> tensor<1x666x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %4 = tensor.empty() : tensor<666x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1024xf32>, tensor<666x1024xf32>) outs(%4 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1408xf32>) -> tensor<666x14x14x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1408xf32>) -> tensor<1x1x1x1408xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1408xf32>, tensor<1x1x1x1408xf32>) outs(%4 : tensor<666x14x14x1408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x832xf32>) -> tensor<666x14x14x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x832xf32>) -> tensor<128x1x1x832xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x832xf32>, tensor<128x1x1x832xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x2016xf32>) -> tensor<1x666x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2016x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2016x1000xf32>) -> tensor<1x2016x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x2016xf32>, tensor<1x2016x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1344xf32>) -> tensor<666x7x7x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x7x7x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\n#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x230x230x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x230x230x3xf32>) -> tensor<666x230x230x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x7x7x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x7x7x3xf32>) -> tensor<64x7x7x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x112x112x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x112x112x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x230x230x3xf32>, tensor<64x7x7x3xf32>) outs(%7 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1024xf32>) outs(%2 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = tensor.empty() : tensor<666x1x1x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x128xf32>) outs(%2 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x992xf32>) -> tensor<666x14x14x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x992xf32>) -> tensor<1x1x1x992xf32>\n    %4 = tensor.empty() : tensor<666x14x14x992xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x992xf32>, tensor<1x1x1x992xf32>) outs(%4 : tensor<666x14x14x992xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1664xf32>) -> tensor<666x7x7x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1664xf32>) -> tensor<1x1x1x1664xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1664xf32>, tensor<1x1x1x1664xf32>) outs(%4 : tensor<666x7x7x1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3024xf32>) -> tensor<1x1x1x3024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3024xf32>, tensor<1x1x1x3024xf32>) outs(%4 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1920xf32>) -> tensor<1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1920xf32>, tensor<1xf32>) outs(%4 : tensor<1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x224xf32>) -> tensor<666x8x8x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x8x8x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x8x8x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x14x14x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1408xf32>) -> tensor<666x7x7x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1408xf32>) -> tensor<1x1x1x1408xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1408xf32>, tensor<1x1x1x1408xf32>) outs(%4 : tensor<666x7x7x1408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1408xf32>) -> tensor<666x14x14x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1408xf32>) -> tensor<1x1x1x1408xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1408xf32>, tensor<1x1x1x1408xf32>) outs(%4 : tensor<666x14x14x1408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<56x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<56x1x1x24xf32>) -> tensor<56x1x1x24xf32>\n    %4 = bufferization.alloc_tensor() : tensor<56xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<56xf32>) -> tensor<56xf32>\n    %6 = tensor.empty() : tensor<666x56x56x56xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<56xf32>) outs(%6 : tensor<666x56x56x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x56xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<56x1x1x24xf32>) outs(%7 : tensor<666x56x56x56xf32>) -> tensor<666x56x56x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x32xf32>) -> tensor<168x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x56x56x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<168x1x1x32xf32>) outs(%7 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x672xf32>) -> tensor<666x14x14x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x14x14x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x14x14x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1632xf32>) -> tensor<666x7x7x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1632xf32>) -> tensor<1x1x1x1632xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1632xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1632xf32>, tensor<1x1x1x1632xf32>) outs(%4 : tensor<666x7x7x1632xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x96xf32>) -> tensor<666x112x112x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x112x112x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x112x112x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x96xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = tensor.empty() : tensor<666x14x512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x512xf32>) -> tensor<666x14x512xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x512xf32>) outs(%3 : tensor<666x14x512xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x512xf32> into tensor<666x1x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x2x2x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x2x2x192xf32>) -> tensor<384x2x2x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x14x14x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<384x2x2x192xf32>) outs(%7 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x22xf32>) -> tensor<1x1x1x22xf32>\n    %4 = tensor.empty() : tensor<666x28x28x22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x22xf32>, tensor<1x1x1x22xf32>) outs(%4 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = tensor.empty() : tensor<666x14x14x208xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x208xf32>) outs(%2 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x14x14x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x728x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x728x1xf32>) -> tensor<3x3x728x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<728xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<728xf32>) -> tensor<728xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x37x37x728xf32> to tensor<666x39x39x728xf32>\n    %6 = tensor.empty() : tensor<666x37x37x728x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x37x37x728x1xf32>) -> tensor<666x37x37x728x1xf32>\n    %8 = tensor.empty() : tensor<666x37x37x728xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x39x39x728xf32>, tensor<3x3x728x1xf32>) outs(%7 : tensor<666x37x37x728x1xf32>) -> tensor<666x37x37x728x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x37x37x728x1xf32> into tensor<666x37x37x728xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<728xf32>, tensor<666x37x37x728xf32>) outs(%8 : tensor<666x37x37x728xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x37x37x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x768xf32>, tensor<666x14x14x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x704xf32>) -> tensor<666x14x14x704xf32>\n    %2 = tensor.empty() : tensor<666x14x14x704xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x704xf32>) outs(%2 : tensor<666x14x14x704xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x704xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x384xf32>) -> tensor<1x522144x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x384x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x384x1536xf32>) -> tensor<1x384x1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x1536xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x1536xf32>) -> tensor<1x522144x1536xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x384xf32>, tensor<1x384x1536xf32>) outs(%5 : tensor<1x522144x1536xf32>) -> tensor<1x522144x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x672xf32>) -> tensor<666x14x14x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x14x14x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x14x14x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<32xf32>) -> tensor<32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<32xf32>, tensor<1xf32>) outs(%4 : tensor<32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3712x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3712x1x1x1392xf32>) -> tensor<3712x1x1x1392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3712xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3712xf32>) -> tensor<3712xf32>\n    %6 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3712xf32>) outs(%6 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x3712xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1392xf32>, tensor<3712x1x1x1392xf32>) outs(%7 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1232x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1232x1x1x448xf32>) -> tensor<1232x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1232xf32>) -> tensor<1232xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1232xf32>) outs(%6 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<1232x1x1x448xf32>) outs(%7 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x149x149x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x149x149x32xf32>) -> tensor<666x149x149x32xf32>\n    %2 = tensor.empty() : tensor<666x149x149x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x149x149x32xf32>) outs(%2 : tensor<666x149x149x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x149x149x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x8x8x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1232xf32>) -> tensor<666x28x28x1232xf32>\n    %2 = tensor.empty() : tensor<666x28x28x1232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x1232xf32>) outs(%2 : tensor<666x28x28x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x3x3x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x3x3x80xf32>) -> tensor<80x3x3x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x80xf32> to tensor<666x58x58x80xf32>\n    %6 = tensor.empty() : tensor<666x56x56x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x80xf32>, tensor<80x3x3x80xf32>) outs(%7 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x1x1x2048xf32>) -> tensor<384x1x1x2048xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x8x8x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x2048xf32>, tensor<384x1x1x2048xf32>) outs(%7 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = tensor.empty() : tensor<666x19x19x728xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x19x19x728xf32>) outs(%2 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1232xf32>) -> tensor<666x1x1x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x1232xf32>) -> tensor<112x1x1x1232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x1x1x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1232xf32>, tensor<112x1x1x1232xf32>) outs(%7 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x560xf32>) -> tensor<1x1x1x560xf32>\n    %4 = tensor.empty() : tensor<666x14x14x560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x560xf32>, tensor<1x1x1x560xf32>) outs(%4 : tensor<666x14x14x560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = tensor.empty() : tensor<666x28x28x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x512xf32>) outs(%2 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x2048xf32>) -> tensor<666x28x28x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x2048xf32>) -> tensor<666x28x28x2048xf32>\n    %4 = tensor.empty() : tensor<666x28x28x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x2048xf32>, tensor<666x28x28x2048xf32>) outs(%4 : tensor<666x28x28x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x4096xf32>) -> tensor<666x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x4096xf32>) -> tensor<1x4096xf32>\n    %4 = tensor.empty() : tensor<666x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x4096xf32>, tensor<1x4096xf32>) outs(%4 : tensor<666x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x768xf32>) -> tensor<128x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<128x1x1x768xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3712xf32>) -> tensor<666x1x1x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x3712xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1504xf32>) -> tensor<666x7x7x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1504xf32>) -> tensor<128x1x1x1504xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1504xf32>, tensor<128x1x1x1504xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x672xf32>) -> tensor<1x666x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x672x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x672x1000xf32>) -> tensor<1x672x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x672xf32>, tensor<1x672x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x222xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x222xf32>) -> tensor<666x1x1x222xf32>\n    %2 = tensor.empty() : tensor<666x1x1x222xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x222xf32>) outs(%2 : tensor<666x1x1x222xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x222xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x7x7x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x7x7x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x640xf32>) -> tensor<666x14x14x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x640xf32>) -> tensor<1x1x1x640xf32>\n    %4 = tensor.empty() : tensor<666x14x14x640xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x640xf32>, tensor<1x1x1x640xf32>) outs(%4 : tensor<666x14x14x640xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x89x89x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x89x89x84xf32>) -> tensor<666x89x89x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x84x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x84x1xf32>) -> tensor<7x7x84x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %6 = tensor.empty() : tensor<666x42x42x84x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %8 = tensor.empty() : tensor<666x42x42x84xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x89x89x84xf32>, tensor<7x7x84x1xf32>) outs(%7 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x42x42x84x1xf32> into tensor<666x42x42x84xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<84xf32>, tensor<666x42x42x84xf32>) outs(%8 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x448xf32>) -> tensor<896x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x14x14x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<896x1x1x448xf32>) outs(%7 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x864xf32>) -> tensor<666x14x14x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x864xf32>) -> tensor<1x1x1x864xf32>\n    %4 = tensor.empty() : tensor<666x14x14x864xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x864xf32>, tensor<1x1x1x864xf32>) outs(%4 : tensor<666x14x14x864xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x14x14x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x14x14x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x42xf32>) -> tensor<1x1x1x42xf32>\n    %4 = tensor.empty() : tensor<666x83x83x42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x83x83x42xf32>, tensor<1x1x1x42xf32>) outs(%4 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x88xf32>) -> tensor<1x1x1x88xf32>\n    %4 = tensor.empty() : tensor<666x14x14x88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x88xf32>, tensor<1x1x1x88xf32>) outs(%4 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1184xf32>) -> tensor<666x7x7x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1184xf32>) -> tensor<1x1x1x1184xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1184xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1184xf32>, tensor<1x1x1x1184xf32>) outs(%4 : tensor<666x7x7x1184xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x144xf32>) -> tensor<576x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x1x1x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x1x1x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x144xf32>, tensor<576x1x1x144xf32>) outs(%7 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1296xf32>) -> tensor<1x1x1x1296xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1296xf32>, tensor<1x1x1x1296xf32>) outs(%4 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<56x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<56x1x1x24xf32>) -> tensor<56x1x1x24xf32>\n    %4 = bufferization.alloc_tensor() : tensor<56xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<56xf32>) -> tensor<56xf32>\n    %6 = tensor.empty() : tensor<666x28x28x56xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<56xf32>) outs(%6 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x56xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<56x1x1x24xf32>) outs(%7 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1392x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1392x1x1x696xf32>) -> tensor<1392x1x1x696xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1392xf32>) -> tensor<1392xf32>\n    %6 = tensor.empty() : tensor<666x28x28x1392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1392xf32>) outs(%6 : tensor<666x28x28x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x1392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x696xf32>, tensor<1392x1x1x696xf32>) outs(%7 : tensor<666x28x28x1392xf32>) -> tensor<666x28x28x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x512xf32>) -> tensor<666x1x1x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x512xf32>) -> tensor<128x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x1x1x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x512xf32>, tensor<128x1x1x512xf32>) outs(%7 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    %2 = tensor.empty() : tensor<666x14x14x528xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x528xf32>) outs(%2 : tensor<666x14x14x528xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1216xf32>) -> tensor<1216xf32>\n    %2 = tensor.empty() : tensor<1216xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1216xf32>) outs(%2 : tensor<1216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1512x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1512x1x1x576xf32>) -> tensor<1512x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1512xf32>) -> tensor<1512xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1512xf32>) outs(%6 : tensor<666x14x14x1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<1512x1x1x576xf32>) outs(%7 : tensor<666x14x14x1512xf32>) -> tensor<666x14x14x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1408xf32>) -> tensor<666x14x14x1408xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1408xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1408xf32>) outs(%2 : tensor<666x14x14x1408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1792xf32>) -> tensor<666x7x7x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1792xf32>) -> tensor<128x1x1x1792xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1792xf32>, tensor<128x1x1x1792xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x672xf32>) -> tensor<666x21x21x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x21x21x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x21x21x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x21x21x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x21x21x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x168xf32>) -> tensor<666x1x1x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x168xf32>) -> tensor<8x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x168xf32>, tensor<8x1x1x168xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1024xf32>) -> tensor<128x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<128x1x1x1024xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x84xf32>) -> tensor<1x1x1x84xf32>\n    %4 = tensor.empty() : tensor<666x42x42x84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x84xf32>, tensor<1x1x1x84xf32>) outs(%4 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = tensor.empty() : tensor<666x28x28x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x192xf32>) outs(%2 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x14x14x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<256xf32>) -> tensor<256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<256xf32>, tensor<1xf32>) outs(%4 : tensor<256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x167x167x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x167x167x42xf32>) -> tensor<666x167x167x42xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x83x83x42xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x167x167x42xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3712xf32>) -> tensor<666x14x14x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3712xf32>) -> tensor<1x1x1x3712xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3712xf32>, tensor<1x1x1x3712xf32>) outs(%4 : tensor<666x14x14x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x14x14x1024xf32>, tensor<666x14x14x1024xf32>) outs(%2 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x864xf32>) -> tensor<666x7x7x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x864xf32>) -> tensor<1x1x1x864xf32>\n    %4 = tensor.empty() : tensor<666x7x7x864xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x864xf32>, tensor<1x1x1x864xf32>) outs(%4 : tensor<666x7x7x864xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x113x113x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x113x113x11xf32>) -> tensor<666x113x113x11xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x56x56x11xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x113x113x11xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %c1 = arith.constant 1 : index\n    %c56 = arith.constant 56 : index\n    %c2 = arith.constant 2 : index\n    %c56_1 = arith.constant 56 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c56, %c1_2 : index\n    %7 = arith.subi %c56_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x56x56x11xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x56x56x11xf32>) outs(%8 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x208xf32>) -> tensor<666x1x14x208xf32>\n    %2 = tensor.empty() : tensor<666x1x208xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x208xf32>) -> tensor<666x1x208xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x208xf32>) outs(%3 : tensor<666x1x208xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x208xf32> into tensor<666x1x1x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x576xf32>) -> tensor<576x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x14x14x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<576x1x1x576xf32>) outs(%7 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1120xf32>) -> tensor<666x14x14x1120xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1120xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1120xf32>) outs(%2 : tensor<666x14x14x1120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x512xf32>, tensor<666x28x28x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x768xf32>) -> tensor<666x1x1x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x1x1x768xf32>) -> tensor<80x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %6 = tensor.empty() : tensor<666x1x1x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x1x1x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x768xf32>, tensor<80x1x1x768xf32>) outs(%7 : tensor<666x1x1x80xf32>) -> tensor<666x1x1x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x544xf32>) -> tensor<666x7x7x544xf32>\n    %2 = tensor.empty() : tensor<666x7x7x544xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x544xf32>) outs(%2 : tensor<666x7x7x544xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<104x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<104x1x1x48xf32>) -> tensor<104x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<104xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<104xf32>) -> tensor<104xf32>\n    %6 = tensor.empty() : tensor<666x56x56x104xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<104xf32>) outs(%6 : tensor<666x56x56x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x104xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<104x1x1x48xf32>) outs(%7 : tensor<666x56x56x104xf32>) -> tensor<666x56x56x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1920xf32>, tensor<666x7x7x1920xf32>) outs(%4 : tensor<666x7x7x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1008xf32>) -> tensor<666x14x14x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1008xf32>) -> tensor<1x1x1x1008xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1008xf32>, tensor<1x1x1x1008xf32>) outs(%4 : tensor<666x14x14x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x28x28x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1088xf32>) -> tensor<666x14x14x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1088xf32>) -> tensor<1x1x1x1088xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1088xf32>, tensor<1x1x1x1088xf32>) outs(%4 : tensor<666x14x14x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x672xf32>) -> tensor<128x1x1x672xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x672xf32>, tensor<128x1x1x672xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<666x28x28x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<560xf32>) -> tensor<560xf32>\n    %2 = tensor.empty() : tensor<560xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<560xf32>) outs(%2 : tensor<560xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<768x2x2x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<768x2x2x384xf32>) -> tensor<768x2x2x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<768xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<768xf32>) -> tensor<768xf32>\n    %6 = tensor.empty() : tensor<666x7x7x768xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<768xf32>) outs(%6 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x768xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<768x2x2x384xf32>) outs(%7 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<666x7x7x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<80xf32>) -> tensor<80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<80xf32>, tensor<1xf32>) outs(%4 : tensor<80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x224xf32>) -> tensor<666x28x28x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x224xf32>) -> tensor<128x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x224xf32>, tensor<128x1x1x224xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x440xf32>) -> tensor<666x1x1x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<52x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<52x1x1x440xf32>) -> tensor<52x1x1x440xf32>\n    %4 = bufferization.alloc_tensor() : tensor<52xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<52xf32>) -> tensor<52xf32>\n    %6 = tensor.empty() : tensor<666x1x1x52xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<52xf32>) outs(%6 : tensor<666x1x1x52xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x52xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x440xf32>, tensor<52x1x1x440xf32>) outs(%7 : tensor<666x1x1x52xf32>) -> tensor<666x1x1x52xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x368xf32>) -> tensor<666x1x1x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<38x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<38x1x1x368xf32>) -> tensor<38x1x1x368xf32>\n    %4 = bufferization.alloc_tensor() : tensor<38xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<38xf32>) -> tensor<38xf32>\n    %6 = tensor.empty() : tensor<666x1x1x38xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<38xf32>) outs(%6 : tensor<666x1x1x38xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x38xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x368xf32>, tensor<38x1x1x368xf32>) outs(%7 : tensor<666x1x1x38xf32>) -> tensor<666x1x1x38xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1008xf32>, tensor<666x7x7x1008xf32>) outs(%4 : tensor<666x7x7x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x24xf32>) -> tensor<666x1x1x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x24xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x608xf32>) -> tensor<666x1x1x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x608xf32>) -> tensor<64x1x1x608xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x1x1x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x1x1x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x608xf32>, tensor<64x1x1x608xf32>) outs(%7 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x104xf32>) -> tensor<666x56x56x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x104xf32>) -> tensor<1x1x1x104xf32>\n    %4 = tensor.empty() : tensor<666x56x56x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x104xf32>, tensor<1x1x1x104xf32>) outs(%4 : tensor<666x56x56x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %4 = tensor.empty() : tensor<666x56x56x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x232xf32>, tensor<666x56x56x232xf32>) outs(%4 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x408xf32>) -> tensor<666x28x28x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x408xf32>) -> tensor<1x1x1x408xf32>\n    %4 = tensor.empty() : tensor<666x28x28x408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x408xf32>, tensor<1x1x1x408xf32>) outs(%4 : tensor<666x28x28x408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1360xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1360xf32>) outs(%2 : tensor<666x7x7x1360xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1344x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1344x1x1x1344xf32>) -> tensor<1344x1x1x1344xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1344xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1344xf32>) -> tensor<1344xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1344xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1344xf32>) outs(%6 : tensor<666x14x14x1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1344xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<1344x1x1x1344xf32>) outs(%7 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x640xf32>) -> tensor<666x14x14x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x640xf32>) -> tensor<1x1x1x640xf32>\n    %4 = tensor.empty() : tensor<666x14x14x640xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x640xf32>, tensor<1x1x1x640xf32>) outs(%4 : tensor<666x14x14x640xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1728xf32>) -> tensor<666x14x14x1728xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1728xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1728xf32>) outs(%2 : tensor<666x14x14x1728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1920x1x1x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1920x1x1x1920xf32>) -> tensor<1920x1x1x1920xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1920xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1920xf32>) -> tensor<1920xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1920xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1920xf32>) outs(%6 : tensor<666x7x7x1920xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1920xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1920xf32>, tensor<1920x1x1x1920xf32>) outs(%7 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %4 = tensor.empty() : tensor<666x56x56x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x336xf32>, tensor<666x56x56x336xf32>) outs(%4 : tensor<666x56x56x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1664xf32>) -> tensor<666x14x14x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1664xf32>) -> tensor<1x1x1x1664xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1664xf32>, tensor<1x1x1x1664xf32>) outs(%4 : tensor<666x14x14x1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x368xf32>) -> tensor<666x14x14x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x368xf32>) -> tensor<1x1x1x368xf32>\n    %4 = tensor.empty() : tensor<666x14x14x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x368xf32>, tensor<1x1x1x368xf32>) outs(%4 : tensor<666x14x14x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1296xf32>) -> tensor<666x1x1x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1296xf32>, tensor<666x7x7x1296xf32>) outs(%4 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x21x21x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x21x21x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x728x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x728x1xf32>) -> tensor<3x3x728x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<728xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<728xf32>) -> tensor<728xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x19x19x728xf32> to tensor<666x21x21x728xf32>\n    %6 = tensor.empty() : tensor<666x19x19x728x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x19x19x728x1xf32>) -> tensor<666x19x19x728x1xf32>\n    %8 = tensor.empty() : tensor<666x19x19x728xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x21x21x728xf32>, tensor<3x3x728x1xf32>) outs(%7 : tensor<666x19x19x728x1xf32>) -> tensor<666x19x19x728x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x19x19x728x1xf32> into tensor<666x19x19x728xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<728xf32>, tensor<666x19x19x728xf32>) outs(%8 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x440xf32>) -> tensor<666x1x1x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<110x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<110x1x1x440xf32>) -> tensor<110x1x1x440xf32>\n    %4 = bufferization.alloc_tensor() : tensor<110xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<110xf32>) -> tensor<110xf32>\n    %6 = tensor.empty() : tensor<666x1x1x110xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<110xf32>) outs(%6 : tensor<666x1x1x110xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x110xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x440xf32>, tensor<110x1x1x440xf32>) outs(%7 : tensor<666x1x1x110xf32>) -> tensor<666x1x1x110xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x24xf32>) -> tensor<666x1x1x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %4 = tensor.empty() : tensor<666x56x56x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x24xf32>, tensor<666x56x56x24xf32>) outs(%4 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1792xf32>) -> tensor<666x14x14x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1792xf32>) -> tensor<1x1x1x1792xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1792xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1792xf32>, tensor<1x1x1x1792xf32>) outs(%4 : tensor<666x14x14x1792xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1024xf32>) -> tensor<666x28x28x1024xf32>\n    %2 = tensor.empty() : tensor<666x28x28x1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x1024xf32>) outs(%2 : tensor<666x28x28x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x73x73x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x73x73x80xf32>) -> tensor<666x73x73x80xf32>\n    %2 = tensor.empty() : tensor<666x73x73x80xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x73x73x80xf32>) outs(%2 : tensor<666x73x73x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x73x73x80xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x768xf32>) -> tensor<1x522144x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x768x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x768x192xf32>) -> tensor<1x768x192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x192xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x192xf32>) -> tensor<1x522144x192xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x768xf32>, tensor<1x768x192xf32>) outs(%5 : tensor<1x522144x192xf32>) -> tensor<1x522144x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x512xf32>) -> tensor<896x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x14x14x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<896x1x1x512xf32>) outs(%7 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x96xf32>) -> tensor<666x112x112x96xf32>\n    %2 = tensor.empty() : tensor<666x112x112x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x96xf32>) outs(%2 : tensor<666x112x112x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x336xf32>) -> tensor<666x28x28x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x28x28x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x28x28x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x128xf32>) -> tensor<192x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x28x28x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<192x1x1x128xf32>) outs(%7 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x48xf32>) -> tensor<666x112x112x48xf32>\n    %2 = tensor.empty() : tensor<666x112x112x48xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x48xf32>) outs(%2 : tensor<666x112x112x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (0, d1)>\n#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1024xf32>) -> tensor<1x1024xf32>\n    %4 = tensor.empty() : tensor<666x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<1x1024xf32>) outs(%4 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<432x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<432x1x1x432xf32>) -> tensor<432x1x1x432xf32>\n    %4 = bufferization.alloc_tensor() : tensor<432xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<432xf32>) -> tensor<432xf32>\n    %6 = tensor.empty() : tensor<666x14x14x432xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<432xf32>) outs(%6 : tensor<666x14x14x432xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x432xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x432xf32>, tensor<432x1x1x432xf32>) outs(%7 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x28x28x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x28x28x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1184xf32>) -> tensor<1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1184xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1184xf32>, tensor<1xf32>) outs(%4 : tensor<1184xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x174xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x174xf32>) -> tensor<666x1x1x174xf32>\n    %2 = tensor.empty() : tensor<666x1x1x174xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x174xf32>) outs(%2 : tensor<666x1x1x174xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x174xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x42x42x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    %2 = tensor.empty() : tensor<666x1x1x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x64xf32>) outs(%2 : tensor<666x1x1x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x149x149x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x149x149x32xf32>) -> tensor<666x149x149x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x149x149x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x149x149x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x149x149x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x149x149x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x1024xf32>) -> tensor<666x19x19x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x19x19x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x19x19x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x19x19x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x19x19x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x192xf32>) -> tensor<64x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x35x35x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x192xf32>, tensor<64x1x1x192xf32>) outs(%7 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = tensor.empty() : tensor<666x14x14x576xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x576xf32>) outs(%2 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x80xf32>) -> tensor<666x112x112x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x3x3x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x3x3x80xf32>) -> tensor<80x3x3x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 0, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x112x112x80xf32> to tensor<666x113x113x80xf32>\n    %6 = tensor.empty() : tensor<666x56x56x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded, %3 : tensor<666x113x113x80xf32>, tensor<80x3x3x80xf32>) outs(%7 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x448xf32>) -> tensor<666x14x14x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x14x14x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x14x14x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x160xf32>) -> tensor<666x56x56x160xf32>\n    %2 = tensor.empty() : tensor<666x56x56x160xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x160xf32>) outs(%2 : tensor<666x56x56x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x24xf32>) -> tensor<1x1x1x24xf32>\n    %4 = tensor.empty() : tensor<666x56x56x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<1x1x1x24xf32>) outs(%4 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1296xf32>) -> tensor<666x1x1x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1296xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x288xf32>) -> tensor<666x1x1x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %4 = tensor.empty() : tensor<666x28x28x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x288xf32>, tensor<666x28x28x288xf32>) outs(%4 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1504xf32>) -> tensor<666x14x14x1504xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1504xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1504xf32>) outs(%2 : tensor<666x14x14x1504xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = tensor.empty() : tensor<666x14x14x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x512xf32>) outs(%2 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = tensor.empty() : tensor<666x14x152xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x152xf32>) -> tensor<666x14x152xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x152xf32>) outs(%3 : tensor<666x14x152xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x152xf32> into tensor<666x1x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<96xf32>) -> tensor<96xf32>\n    %2 = tensor.empty() : tensor<96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<96xf32>) outs(%2 : tensor<96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<96xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = tensor.empty() : tensor<666x28x120xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x120xf32>) -> tensor<666x28x120xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x120xf32>) outs(%3 : tensor<666x28x120xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x120xf32> into tensor<666x1x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x6xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x6xf32>) -> tensor<666x1x1x6xf32>\n    %2 = bufferization.alloc_tensor() : tensor<56x1x1x6xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<56x1x1x6xf32>) -> tensor<56x1x1x6xf32>\n    %4 = bufferization.alloc_tensor() : tensor<56xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<56xf32>) -> tensor<56xf32>\n    %6 = tensor.empty() : tensor<666x1x1x56xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<56xf32>) outs(%6 : tensor<666x1x1x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x56xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x6xf32>, tensor<56x1x1x6xf32>) outs(%7 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x336xf32>) -> tensor<666x112x112x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x112x112x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x112x112x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1664xf32>) -> tensor<666x14x14x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1664xf32>) -> tensor<128x1x1x1664xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1664xf32>, tensor<128x1x1x1664xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %2 = tensor.empty() : tensor<666xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666xf32>) -> tensor<666xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x2048xf32>) outs(%3 : tensor<666xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0, 1]] : tensor<666xf32> into tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x28x28x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x28x28x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1600xf32>) -> tensor<666x14x14x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1600xf32>) -> tensor<128x1x1x1600xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1600xf32>, tensor<128x1x1x1600xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<666x14x14x1344xf32>) outs(%4 : tensor<666x14x14x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x128xf32>, tensor<666x56x56x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<44x1x1x44xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<44x1x1x44xf32>) -> tensor<44x1x1x44xf32>\n    %4 = bufferization.alloc_tensor() : tensor<44xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<44xf32>) -> tensor<44xf32>\n    %6 = tensor.empty() : tensor<666x28x28x44xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<44xf32>) outs(%6 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x44xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x44xf32>, tensor<44x1x1x44xf32>) outs(%7 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x3x3x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x3x3x64xf32>) -> tensor<128x3x3x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x112x112x64xf32> to tensor<666x114x114x64xf32>\n    %6 = tensor.empty() : tensor<666x112x112x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x112x112x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x114x114x64xf32>, tensor<128x3x3x64xf32>) outs(%7 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x168xf32>) -> tensor<666x1x1x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x168xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %4 = tensor.empty() : tensor<666x28x28x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<666x28x28x288xf32>) outs(%4 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x42x42x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %4 = tensor.empty() : tensor<666x28x28x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x120xf32>, tensor<666x28x28x120xf32>) outs(%4 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x128x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x128x1xf32>) -> tensor<3x3x128x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x74x74x128xf32> to tensor<666x76x76x128xf32>\n    %6 = tensor.empty() : tensor<666x74x74x128x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x74x74x128x1xf32>) -> tensor<666x74x74x128x1xf32>\n    %8 = tensor.empty() : tensor<666x74x74x128xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x76x76x128xf32>, tensor<3x3x128x1xf32>) outs(%7 : tensor<666x74x74x128x1xf32>) -> tensor<666x74x74x128x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x74x74x128x1xf32> into tensor<666x74x74x128xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<128xf32>, tensor<666x74x74x128xf32>) outs(%8 : tensor<666x74x74x128xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<768x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<768x1x1x320xf32>) -> tensor<768x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<768xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<768xf32>) -> tensor<768xf32>\n    %6 = tensor.empty() : tensor<666x14x14x768xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<768xf32>) outs(%6 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x768xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<768x1x1x320xf32>) outs(%7 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = tensor.empty() : tensor<666x28x28x22xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x22xf32>) outs(%2 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x336xf32>) -> tensor<666x1x1x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<84x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<84x1x1x336xf32>) -> tensor<84x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %6 = tensor.empty() : tensor<666x1x1x84xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<84xf32>) outs(%6 : tensor<666x1x1x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x84xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x336xf32>, tensor<84x1x1x336xf32>) outs(%7 : tensor<666x1x1x84xf32>) -> tensor<666x1x1x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x96xf32>) -> tensor<666x112x112x96xf32>\n    %2 = tensor.empty() : tensor<666x112x112x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x96xf32>) outs(%2 : tensor<666x112x112x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2080xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2080xf32>) -> tensor<666x8x8x2080xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x8x8x2080xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x8x8x2080xf32>) -> tensor<666x8x8x2080xf32>\n    %4 = tensor.empty() : tensor<666x8x8x2080xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x2080xf32>, tensor<666x8x8x2080xf32>) outs(%4 : tensor<666x8x8x2080xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x2080xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x42x42x84xf32> to tensor<666x44x44x84xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x42x42x84xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x44x44x84xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %c1 = arith.constant 1 : index\n    %c42 = arith.constant 42 : index\n    %c2 = arith.constant 2 : index\n    %c42_2 = arith.constant 42 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c42, %c1_3 : index\n    %7 = arith.subi %c42_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x42x42x84xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x42x42x84xf32>) outs(%8 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<666x14x14x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x176x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x176x1xf32>) -> tensor<3x3x176x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x7x7x176xf32> to tensor<666x9x9x176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %8 = tensor.empty() : tensor<666x7x7x176xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x9x9x176xf32>, tensor<3x3x176x1xf32>) outs(%7 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x7x7x176x1xf32> into tensor<666x7x7x176xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<176xf32>, tensor<666x7x7x176xf32>) outs(%8 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1696xf32>) -> tensor<666x7x7x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1696xf32>) -> tensor<128x1x1x1696xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1696xf32>, tensor<128x1x1x1696xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = tensor.empty() : tensor<666x28x28x120xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x120xf32>) outs(%2 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x73x73x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x73x73x80xf32>) -> tensor<666x73x73x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x73x73x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x73x73x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x73x73x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x73x73x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x16x16x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x16x16x256xf32>) -> tensor<666x16x16x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x3x3x256xf32>) -> tensor<256x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x14x14x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x16x16x256xf32>, tensor<256x3x3x256xf32>) outs(%7 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1056xf32>) -> tensor<1x666x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1056x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1056x1000xf32>) -> tensor<1x1056x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1056xf32>, tensor<1x1056x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1344xf32>) -> tensor<1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1344xf32>, tensor<1xf32>) outs(%4 : tensor<1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<864xf32>) -> tensor<864xf32>\n    %2 = tensor.empty() : tensor<864xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<864xf32>) outs(%2 : tensor<864xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x8xf32>) -> tensor<48x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x1x1x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x1x1x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<48x1x1x8xf32>) outs(%7 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<666x14x14x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x222xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x222xf32>) -> tensor<666x1x1x222xf32>\n    %2 = bufferization.alloc_tensor() : tensor<888x1x1x222xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<888x1x1x222xf32>) -> tensor<888x1x1x222xf32>\n    %4 = bufferization.alloc_tensor() : tensor<888xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<888xf32>) -> tensor<888xf32>\n    %6 = tensor.empty() : tensor<666x1x1x888xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<888xf32>) outs(%6 : tensor<666x1x1x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x888xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x222xf32>, tensor<888x1x1x222xf32>) outs(%7 : tensor<666x1x1x888xf32>) -> tensor<666x1x1x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x256xf32>) -> tensor<666x7x7x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x7x7x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x7x7x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1312xf32>) -> tensor<666x7x7x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1312xf32>) -> tensor<1x1x1x1312xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1312xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1312xf32>, tensor<1x1x1x1312xf32>) outs(%4 : tensor<666x7x7x1312xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x42xf32>) -> tensor<666x1x1x42xf32>\n    %2 = tensor.empty() : tensor<666x1x1x42xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x42xf32>) outs(%2 : tensor<666x1x1x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x1x1x512xf32>) -> tensor<2048x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x512xf32>, tensor<2048x1x1x512xf32>) outs(%7 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x232xf32>) -> tensor<666x1x1x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x232xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x320xf32>) -> tensor<666x28x28x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x320xf32>) -> tensor<128x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x320xf32>, tensor<128x1x1x320xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x168x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x168x1xf32>) -> tensor<5x5x168x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x42x42x168xf32> to tensor<666x46x46x168xf32>\n    %6 = tensor.empty() : tensor<666x42x42x168x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x42x42x168x1xf32>) -> tensor<666x42x42x168x1xf32>\n    %8 = tensor.empty() : tensor<666x42x42x168xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x46x46x168xf32>, tensor<5x5x168x1xf32>) outs(%7 : tensor<666x42x42x168x1xf32>) -> tensor<666x42x42x168x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x42x42x168x1xf32> into tensor<666x42x42x168xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<168xf32>, tensor<666x42x42x168xf32>) outs(%8 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3024xf32>) -> tensor<1x1x1x3024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3024xf32>, tensor<1x1x1x3024xf32>) outs(%4 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x4032xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x4032xf32>) -> tensor<666x11x11x4032xf32>\n    %2 = tensor.empty() : tensor<666x11x4032xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x11x4032xf32>) -> tensor<666x11x4032xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x11x11x4032xf32>) outs(%3 : tensor<666x11x4032xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x11x4032xf32> into tensor<666x1x11x4032xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x28xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x28xf32>) -> tensor<666x1x1x28xf32>\n    %2 = tensor.empty() : tensor<666x1x1x28xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x28xf32>) outs(%2 : tensor<666x1x1x28xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x28xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %4 = tensor.empty() : tensor<666x28x28x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<666x28x28x240xf32>) outs(%4 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x35x35x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x35x35x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x2688xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x2688xf32>) -> tensor<666x11x11x2688xf32>\n    %2 = tensor.empty() : tensor<666x11x11x2688xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x11x11x2688xf32>) outs(%2 : tensor<666x11x11x2688xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x11x11x2688xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x528xf32>) -> tensor<1x1x1x528xf32>\n    %4 = tensor.empty() : tensor<666x7x7x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x528xf32>, tensor<1x1x1x528xf32>) outs(%4 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x256xf32>) -> tensor<666x112x112x256xf32>\n    %2 = tensor.empty() : tensor<666x112x112x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x256xf32>) outs(%2 : tensor<666x112x112x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = tensor.empty() : tensor<666x7x7x176xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x7x7x176xf32>, tensor<666x7x7x176xf32>) outs(%2 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.addf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1232x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1232x1x1x112xf32>) -> tensor<1232x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1232xf32>) -> tensor<1232xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1232xf32>) outs(%6 : tensor<666x1x1x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x112xf32>, tensor<1232x1x1x112xf32>) outs(%7 : tensor<666x1x1x1232xf32>) -> tensor<666x1x1x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x216xf32>) -> tensor<1x1x1x216xf32>\n    %4 = tensor.empty() : tensor<666x28x28x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x216xf32>, tensor<1x1x1x216xf32>) outs(%4 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1008xf32>) -> tensor<666x14x14x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1008xf32>) -> tensor<1x1x1x1008xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1008xf32>, tensor<1x1x1x1008xf32>) outs(%4 : tensor<666x14x14x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x960xf32>) -> tensor<666x14x14x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x960xf32>) -> tensor<1x1x1x960xf32>\n    %4 = tensor.empty() : tensor<666x14x14x960xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x960xf32>, tensor<1x1x1x960xf32>) outs(%4 : tensor<666x14x14x960xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x144xf32>) -> tensor<666x112x112x144xf32>\n    %2 = tensor.empty() : tensor<666x112x112x144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x144xf32>) outs(%2 : tensor<666x112x112x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x22xf32>) -> tensor<666x56x56x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x22xf32>) -> tensor<1x1x1x22xf32>\n    %4 = tensor.empty() : tensor<666x56x56x22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x22xf32>, tensor<1x1x1x22xf32>) outs(%4 : tensor<666x56x56x22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x35x35x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x28x28x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x128xf32>) -> tensor<128x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<128x1x1x128xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x28x28x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x28x28x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x704xf32>) -> tensor<666x14x14x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x704xf32>) -> tensor<1x1x1x704xf32>\n    %4 = tensor.empty() : tensor<666x14x14x704xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x704xf32>, tensor<1x1x1x704xf32>) outs(%4 : tensor<666x14x14x704xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x512xf32>) -> tensor<128x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<128x1x1x512xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1664xf32>) -> tensor<666x1x7x1664xf32>\n    %2 = tensor.empty() : tensor<666x1x1664xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1664xf32>) -> tensor<666x1x1664xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1664xf32>) outs(%3 : tensor<666x1x1664xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1664xf32> into tensor<666x1x1x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x232xf32>) -> tensor<666x112x112x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<232x3x3x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<232x3x3x232xf32>) -> tensor<232x3x3x232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<232xf32>) -> tensor<232xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 0, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x112x112x232xf32> to tensor<666x113x113x232xf32>\n    %6 = tensor.empty() : tensor<666x56x56x232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<232xf32>) outs(%6 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded, %3 : tensor<666x113x113x232xf32>, tensor<232x3x3x232xf32>) outs(%7 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x1024xf32>) -> tensor<666x19x19x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x19x19x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x19x19x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x19x19x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x19x19x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x960xf32>) -> tensor<666x14x14x960xf32>\n    %2 = tensor.empty() : tensor<666x14x14x960xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x960xf32>) outs(%2 : tensor<666x14x14x960xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1088xf32>) -> tensor<1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1088xf32>, tensor<1xf32>) outs(%4 : tensor<1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x28x28x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x544xf32>) -> tensor<666x14x14x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x544xf32>) -> tensor<128x1x1x544xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x544xf32>, tensor<128x1x1x544xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x608xf32>) -> tensor<666x14x14x608xf32>\n    %2 = tensor.empty() : tensor<666x14x14x608xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x608xf32>) outs(%2 : tensor<666x14x14x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x768xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x368xf32>) -> tensor<1x1x1x368xf32>\n    %4 = tensor.empty() : tensor<666x7x7x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x368xf32>, tensor<1x1x1x368xf32>) outs(%4 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = tensor.empty() : tensor<666x14x14x560xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x560xf32>) outs(%2 : tensor<666x14x14x560xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x288xf32>) -> tensor<666x1x1x288xf32>\n    %2 = tensor.empty() : tensor<666x1x1x288xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x288xf32>) outs(%2 : tensor<666x1x1x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1920xf32>) -> tensor<666x14x14x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1920xf32>) -> tensor<1x1x1x1920xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1920xf32>, tensor<1x1x1x1920xf32>) outs(%4 : tensor<666x14x14x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x768xf32>) -> tensor<666x56x56x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x768xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x3x3x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x3x3x192xf32>) -> tensor<320x3x3x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x8x8x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x192xf32>, tensor<320x3x3x192xf32>) outs(%7 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = tensor.empty() : tensor<666x56x144xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x144xf32>) -> tensor<666x56x144xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x144xf32>) outs(%3 : tensor<666x56x144xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x144xf32> into tensor<666x1x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x28x28x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x224xf32>) -> tensor<666x8x8x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x3x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x3x1x224xf32>) -> tensor<256x3x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 0, 0] high[0, 1, 0, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x8x8x224xf32> to tensor<666x10x8x224xf32>\n    %6 = tensor.empty() : tensor<666x8x8x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x8x8x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x10x8x224xf32>, tensor<256x3x1x224xf32>) outs(%7 : tensor<666x8x8x256xf32>) -> tensor<666x8x8x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2240x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2240x1x1x2240xf32>) -> tensor<2240x1x1x2240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2240xf32>) -> tensor<2240xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2240xf32>) outs(%6 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x2240xf32>, tensor<2240x1x1x2240xf32>) outs(%7 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1392xf32>) outs(%2 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<408x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<408x1x1x168xf32>) -> tensor<408x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<408xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<408xf32>) -> tensor<408xf32>\n    %6 = tensor.empty() : tensor<666x28x28x408xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<408xf32>) outs(%6 : tensor<666x28x28x408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x408xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x168xf32>, tensor<408x1x1x168xf32>) outs(%7 : tensor<666x28x28x408xf32>) -> tensor<666x28x28x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x160xf32>) -> tensor<666x56x56x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x56x56x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x56x56x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1632xf32>) -> tensor<666x7x7x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1632xf32>) -> tensor<128x1x1x1632xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1632xf32>, tensor<128x1x1x1632xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<576xf32>) -> tensor<576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<576xf32>, tensor<1xf32>) outs(%4 : tensor<576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x896xf32>) -> tensor<666x28x28x896xf32>\n    %2 = tensor.empty() : tensor<666x28x28x896xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x896xf32>) outs(%2 : tensor<666x28x28x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x58x58x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x58x58x64xf32>) -> tensor<666x58x58x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x64xf32>) -> tensor<64x3x3x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x56x56x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x58x58x64xf32>, tensor<64x3x3x64xf32>) outs(%7 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1792xf32>) -> tensor<666x7x7x1792xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1792xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1792xf32>) outs(%2 : tensor<666x7x7x1792xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x728xf32>) -> tensor<1x1x1x728xf32>\n    %4 = tensor.empty() : tensor<666x19x19x728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x19x19x728xf32>, tensor<1x1x1x728xf32>) outs(%4 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x288xf32>) -> tensor<666x56x56x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x56x56x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x56x56x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x2x2x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x2x2x256xf32>) -> tensor<512x2x2x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<512x2x2x256xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x4032xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x4032xf32>) -> tensor<1x666x4032xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x4032x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x4032x1000xf32>) -> tensor<1x4032x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x4032xf32>, tensor<1x4032x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1000xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1000xf32>) -> tensor<666x1000xf32>\n    %2 = tensor.empty() : tensor<666x1000xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1 : tensor<666x1000xf32>) outs(%2 : tensor<666x1000xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.exp %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x336xf32>) -> tensor<666x28x28x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x28x28x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x28x28x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x83x83x42xf32> to tensor<666x85x85x42xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x83x83x42xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x85x85x42xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %c1 = arith.constant 1 : index\n    %c83 = arith.constant 83 : index\n    %c2 = arith.constant 2 : index\n    %c83_2 = arith.constant 83 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c83, %c1_3 : index\n    %7 = arith.subi %c83_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x83x83x42xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x83x83x42xf32>) outs(%8 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<768x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<768x1x1x768xf32>) -> tensor<768x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<768xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<768xf32>) -> tensor<768xf32>\n    %6 = tensor.empty() : tensor<666x7x7x768xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<768xf32>) outs(%6 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x768xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<768x1x1x768xf32>) outs(%7 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x224xf32>) -> tensor<666x8x8x224xf32>\n    %2 = tensor.empty() : tensor<666x8x8x224xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x224xf32>) outs(%2 : tensor<666x8x8x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1360xf32>) -> tensor<666x14x14x1360xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1360xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1360xf32>) outs(%2 : tensor<666x14x14x1360xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1360xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1280xf32>) -> tensor<666x1x7x1280xf32>\n    %2 = tensor.empty() : tensor<666x1x1280xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1280xf32>) -> tensor<666x1x1280xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1280xf32>) outs(%3 : tensor<666x1x1280xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1280xf32> into tensor<666x1x1x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x144xf32>) -> tensor<288x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x56x56x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x56x56x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<288x1x1x144xf32>) outs(%7 : tensor<666x56x56x288xf32>) -> tensor<666x56x56x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x176xf32>) -> tensor<1x1x1x176xf32>\n    %4 = tensor.empty() : tensor<666x7x7x176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x176xf32>, tensor<1x1x1x176xf32>) outs(%4 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = tensor.empty() : tensor<666x56x56x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x192xf32>) outs(%2 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x224xf32>) -> tensor<448x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x56x56x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x56x56x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<448x1x1x224xf32>) outs(%7 : tensor<666x56x56x448xf32>) -> tensor<666x56x56x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1440xf32>) -> tensor<666x7x7x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1440xf32>) -> tensor<1x1x1x1440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1440xf32>, tensor<1x1x1x1440xf32>) outs(%4 : tensor<666x7x7x1440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x392xf32>) -> tensor<666x56x56x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x392xf32>) -> tensor<1x1x1x392xf32>\n    %4 = tensor.empty() : tensor<666x56x56x392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x392xf32>, tensor<1x1x1x392xf32>) outs(%4 : tensor<666x56x56x392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = tensor.empty() : tensor<666x56x56x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x96xf32>) outs(%2 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<440x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<440x1x1x208xf32>) -> tensor<440x1x1x208xf32>\n    %4 = bufferization.alloc_tensor() : tensor<440xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<440xf32>) -> tensor<440xf32>\n    %6 = tensor.empty() : tensor<666x7x7x440xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<440xf32>) outs(%6 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x440xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x208xf32>, tensor<440x1x1x208xf32>) outs(%7 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1024xf32>) -> tensor<666x1x7x1024xf32>\n    %2 = tensor.empty() : tensor<666x1x1024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1024xf32>) -> tensor<666x1x1024xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1024xf32>) outs(%3 : tensor<666x1x1024xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1024xf32> into tensor<666x1x1x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x512xf32>) -> tensor<896x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x28x28x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x28x28x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<896x1x1x512xf32>) outs(%7 : tensor<666x28x28x896xf32>) -> tensor<666x28x28x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1440xf32>) -> tensor<666x14x14x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1440xf32>) -> tensor<1x1x1x1440xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1440xf32>, tensor<1x1x1x1440xf32>) outs(%4 : tensor<666x14x14x1440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<666x28x28x1xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1024xf32>) -> tensor<666x56x56x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x56x56x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x56x56x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x736xf32>) -> tensor<666x14x14x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x736xf32>) -> tensor<1x1x1x736xf32>\n    %4 = tensor.empty() : tensor<666x14x14x736xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x736xf32>, tensor<1x1x1x736xf32>) outs(%4 : tensor<666x14x14x736xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1360xf32>) -> tensor<1x1x1x1360xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1360xf32>, tensor<1x1x1x1360xf32>) outs(%4 : tensor<666x7x7x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x208xf32>) -> tensor<666x28x28x208xf32>\n    %2 = tensor.empty() : tensor<666x28x28x208xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x208xf32>) outs(%2 : tensor<666x28x28x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1696xf32>) -> tensor<1696xf32>\n    %2 = tensor.empty() : tensor<1696xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1696xf32>) outs(%2 : tensor<1696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x1x3x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x1x3x384xf32>) -> tensor<384x1x3x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 1, 0] high[0, 0, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x8x8x384xf32> to tensor<666x8x10x384xf32>\n    %6 = tensor.empty() : tensor<666x8x8x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x8x10x384xf32>, tensor<384x1x3x384xf32>) outs(%7 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<512xf32>) -> tensor<512xf32>\n    %2 = tensor.empty() : tensor<512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<512xf32>) outs(%2 : tensor<512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x56x56x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2240xf32>) -> tensor<666x1x1x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x2240xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x71x71x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x71x71x192xf32>) -> tensor<666x71x71x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x71x71x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x71x71x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x71x71x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x71x71x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x8xf32>) -> tensor<168x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x1x1x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x1x1x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<168x1x1x8xf32>) outs(%7 : tensor<666x1x1x168xf32>) -> tensor<666x1x1x168xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x528xf32>) -> tensor<666x1x7x528xf32>\n    %2 = tensor.empty() : tensor<666x1x528xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x528xf32>) -> tensor<666x1x528xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x528xf32>) outs(%3 : tensor<666x1x528xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x528xf32> into tensor<666x1x1x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1296xf32>) -> tensor<1296xf32>\n    %2 = tensor.empty() : tensor<1296xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1296xf32>) outs(%2 : tensor<1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1568xf32>) -> tensor<666x7x7x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1568xf32>) -> tensor<128x1x1x1568xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1568xf32>, tensor<128x1x1x1568xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1632xf32>) -> tensor<666x14x14x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1632xf32>) -> tensor<1x1x1x1632xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1632xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1632xf32>, tensor<1x1x1x1632xf32>) outs(%4 : tensor<666x14x14x1632xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1280xf32>) -> tensor<666x8x8x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x1x1x1280xf32>) -> tensor<384x1x1x1280xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x8x8x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x1280xf32>, tensor<384x1x1x1280xf32>) outs(%7 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1296xf32>) outs(%2 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1248xf32>) -> tensor<666x14x14x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1248xf32>) -> tensor<1x1x1x1248xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1248xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1248xf32>, tensor<1x1x1x1248xf32>) outs(%4 : tensor<666x14x14x1248xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1088xf32>) -> tensor<1x1x1x1088xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1088xf32>, tensor<1x1x1x1088xf32>) outs(%4 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x888xf32>) -> tensor<666x1x1x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x888xf32>, tensor<666x7x7x888xf32>) outs(%4 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x528xf32>) -> tensor<666x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x528xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1152xf32>) -> tensor<666x14x14x1152xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1152xf32>) outs(%2 : tensor<666x14x14x1152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x8x8x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x48xf32>) -> tensor<112x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x56x56x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x56x56x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<112x1x1x48xf32>) outs(%7 : tensor<666x56x56x112xf32>) -> tensor<666x56x56x112xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x1536xf32>) -> tensor<1x32634x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1536x6144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1536x6144xf32>) -> tensor<1x1536x6144xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x6144xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x6144xf32>) -> tensor<1x32634x6144xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x1536xf32>, tensor<1x1536x6144xf32>) outs(%5 : tensor<1x32634x6144xf32>) -> tensor<1x32634x6144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = tensor.empty() : tensor<666x28x28x392xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x392xf32>) outs(%2 : tensor<666x28x28x392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x168xf32>) -> tensor<666x1x1x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<42x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<42x1x1x168xf32>) -> tensor<42x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %6 = tensor.empty() : tensor<666x1x1x42xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<42xf32>) outs(%6 : tensor<666x1x1x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x42xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x168xf32>, tensor<42x1x1x168xf32>) outs(%7 : tensor<666x1x1x42xf32>) -> tensor<666x1x1x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x104xf32>) -> tensor<1x1x1x104xf32>\n    %4 = tensor.empty() : tensor<666x28x28x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x104xf32>, tensor<1x1x1x104xf32>) outs(%4 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = tensor.empty() : tensor<666x28x28x44xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x28x28x44xf32>, tensor<666x28x28x44xf32>) outs(%2 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.addf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1120xf32>) -> tensor<1120xf32>\n    %2 = tensor.empty() : tensor<1120xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1120xf32>) outs(%2 : tensor<1120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1184xf32>) -> tensor<666x7x7x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1184xf32>) -> tensor<1x1x1x1184xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1184xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1184xf32>, tensor<1x1x1x1184xf32>) outs(%4 : tensor<666x7x7x1184xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = tensor.empty() : tensor<666x28x28x112xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x112xf32>) outs(%2 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x888xf32>) -> tensor<666x14x14x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x888xf32>) -> tensor<1x1x1x888xf32>\n    %4 = tensor.empty() : tensor<666x14x14x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x888xf32>, tensor<1x1x1x888xf32>) outs(%4 : tensor<666x14x14x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x14x14x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x14x14x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %4 = tensor.empty() : tensor<666x28x28x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<666x28x28x128xf32>) outs(%4 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1760xf32>) -> tensor<1760xf32>\n    %2 = tensor.empty() : tensor<1760xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1760xf32>) outs(%2 : tensor<1760xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x800xf32>) -> tensor<666x7x7x800xf32>\n    %2 = tensor.empty() : tensor<666x7x7x800xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x800xf32>) outs(%2 : tensor<666x7x7x800xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1360xf32>) -> tensor<1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1360xf32>, tensor<1xf32>) outs(%4 : tensor<1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1360xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1000xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1000xf32>) -> tensor<666x1000xf32>\n    %2 = tensor.empty() : tensor<666xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666xf32>) -> tensor<666xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1000xf32>) outs(%3 : tensor<666xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.maximumf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0, 1]] : tensor<666xf32> into tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x64xf32>) -> tensor<64x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x56x56x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<64x1x1x64xf32>) outs(%7 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x928xf32>) -> tensor<666x7x7x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x928xf32>) -> tensor<1x1x1x928xf32>\n    %4 = tensor.empty() : tensor<666x7x7x928xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x928xf32>, tensor<1x1x1x928xf32>) outs(%4 : tensor<666x7x7x928xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x48xf32>) -> tensor<8x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x48xf32>, tensor<8x1x1x48xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x416xf32>) -> tensor<666x14x14x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x416xf32>) -> tensor<1x1x1x416xf32>\n    %4 = tensor.empty() : tensor<666x14x14x416xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x416xf32>, tensor<1x1x1x416xf32>) outs(%4 : tensor<666x14x14x416xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x3xf32>) -> tensor<32x3x3x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x111x111x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x111x111x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x111x111x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<32x3x3x3xf32>) outs(%7 : tensor<666x111x111x32xf32>) -> tensor<666x111x111x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x192x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x192x1xf32>) -> tensor<3x3x192x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x192xf32> to tensor<666x30x30x192xf32>\n    %6 = tensor.empty() : tensor<666x28x28x192x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x28x28x192x1xf32>) -> tensor<666x28x28x192x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x192xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x30x30x192xf32>, tensor<3x3x192x1xf32>) outs(%7 : tensor<666x28x28x192x1xf32>) -> tensor<666x28x28x192x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x192x1xf32> into tensor<666x28x28x192xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<192xf32>, tensor<666x28x28x192xf32>) outs(%8 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x912xf32>) -> tensor<666x1x7x912xf32>\n    %2 = tensor.empty() : tensor<666x1x912xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x912xf32>) -> tensor<666x1x912xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x912xf32>) outs(%3 : tensor<666x1x912xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x912xf32> into tensor<666x1x1x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x448xf32>) -> tensor<666x14x14x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x448xf32>) -> tensor<128x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x448xf32>, tensor<128x1x1x448xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1312xf32>) -> tensor<666x14x14x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1312xf32>) -> tensor<1x1x1x1312xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1312xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1312xf32>, tensor<1x1x1x1312xf32>) outs(%4 : tensor<666x14x14x1312xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x64xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<608xf32>) -> tensor<608xf32>\n    %2 = tensor.empty() : tensor<608xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<608xf32>) outs(%2 : tensor<608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x1x1x160xf32>) -> tensor<384x1x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x14x14x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x160xf32>, tensor<384x1x1x160xf32>) outs(%7 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x16xf32>) -> tensor<666x112x112x16xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x16xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x16xf32>) -> tensor<1x1x1x16xf32>\n    %4 = tensor.empty() : tensor<666x112x112x16xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x16xf32>, tensor<1x1x1x16xf32>) outs(%4 : tensor<666x112x112x16xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<16x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<16x1x1x128xf32>) -> tensor<16x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<16xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<16xf32>) -> tensor<16xf32>\n    %6 = tensor.empty() : tensor<666x1x1x16xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<16xf32>) outs(%6 : tensor<666x1x1x16xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x16xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<16x1x1x128xf32>) outs(%7 : tensor<666x1x1x16xf32>) -> tensor<666x1x1x16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %4 = tensor.empty() : tensor<666x56x56x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x48xf32>, tensor<666x56x56x48xf32>) outs(%4 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x31x31x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x31x31x88xf32>) -> tensor<666x31x31x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x88x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x88x1xf32>) -> tensor<5x5x88x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x88xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x31x31x88xf32>, tensor<5x5x88x1xf32>) outs(%7 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x88x1xf32> into tensor<666x14x14x88xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<88xf32>, tensor<666x14x14x88xf32>) outs(%8 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x720xf32>) -> tensor<666x28x28x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x720xf32>) -> tensor<1x1x1x720xf32>\n    %4 = tensor.empty() : tensor<666x28x28x720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x720xf32>, tensor<1x1x1x720xf32>) outs(%4 : tensor<666x28x28x720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x720xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = tensor.empty() : tensor<666x56x24xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x24xf32>) -> tensor<666x56x24xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x24xf32>) outs(%3 : tensor<666x56x24xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x24xf32> into tensor<666x1x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<528x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<528x1x1x528xf32>) -> tensor<528x1x1x528xf32>\n    %4 = bufferization.alloc_tensor() : tensor<528xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<528xf32>) -> tensor<528xf32>\n    %6 = tensor.empty() : tensor<666x7x7x528xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<528xf32>) outs(%6 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x528xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x528xf32>, tensor<528x1x1x528xf32>) outs(%7 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x696xf32>) -> tensor<666x1x1x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<58x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<58x1x1x696xf32>) -> tensor<58x1x1x696xf32>\n    %4 = bufferization.alloc_tensor() : tensor<58xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<58xf32>) -> tensor<58xf32>\n    %6 = tensor.empty() : tensor<666x1x1x58xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<58xf32>) outs(%6 : tensor<666x1x1x58xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x58xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x696xf32>, tensor<58x1x1x696xf32>) outs(%7 : tensor<666x1x1x58xf32>) -> tensor<666x1x1x58xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x64xf32>) -> tensor<256x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x56x56x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<256x1x1x64xf32>) outs(%7 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x768xf32>) -> tensor<666x28x28x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x768xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x17x17x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<912x1x1x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<912x1x1x912xf32>) -> tensor<912x1x1x912xf32>\n    %4 = bufferization.alloc_tensor() : tensor<912xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<912xf32>) -> tensor<912xf32>\n    %6 = tensor.empty() : tensor<666x7x7x912xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<912xf32>) outs(%6 : tensor<666x7x7x912xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x912xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x912xf32>, tensor<912x1x1x912xf32>) outs(%7 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x57x57x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x57x57x22xf32>) -> tensor<666x57x57x22xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x28x28x22xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x57x57x22xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1152xf32>) -> tensor<666x7x7x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1152xf32>) -> tensor<1x1x1x1152xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1152xf32>, tensor<1x1x1x1152xf32>) outs(%4 : tensor<666x7x7x1152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x392xf32>) -> tensor<1x1x1x392xf32>\n    %4 = tensor.empty() : tensor<666x28x28x392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x392xf32>, tensor<1x1x1x392xf32>) outs(%4 : tensor<666x28x28x392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1280xf32>) -> tensor<666x14x14x1280xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1280xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1280xf32>) outs(%2 : tensor<666x14x14x1280xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<368xf32>) -> tensor<368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<368xf32>, tensor<1xf32>) outs(%4 : tensor<368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x800xf32>) -> tensor<666x7x7x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x800xf32>) -> tensor<1x1x1x800xf32>\n    %4 = tensor.empty() : tensor<666x7x7x800xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x800xf32>, tensor<1x1x1x800xf32>) outs(%4 : tensor<666x7x7x800xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x28x28x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x28x28x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<432x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<432x1x1x192xf32>) -> tensor<432x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<432xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<432xf32>) -> tensor<432xf32>\n    %6 = tensor.empty() : tensor<666x14x14x432xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<432xf32>) outs(%6 : tensor<666x14x14x432xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x432xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<432x1x1x192xf32>) outs(%7 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x2048xf32>) -> tensor<1x666x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2048x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2048x1000xf32>) -> tensor<1x2048x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x2048xf32>, tensor<1x2048x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<120xf32>) -> tensor<120xf32>\n    %2 = tensor.empty() : tensor<120xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<120xf32>) outs(%2 : tensor<120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<120xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1920xf32>) -> tensor<666x1x7x1920xf32>\n    %2 = tensor.empty() : tensor<666x1x1920xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1920xf32>) -> tensor<666x1x1920xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1920xf32>) outs(%3 : tensor<666x1x1920xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1920xf32> into tensor<666x1x1x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<992xf32>) -> tensor<992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<992xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<992xf32>, tensor<1xf32>) outs(%4 : tensor<992xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x7x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x7x128xf32>) -> tensor<128x1x7x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 3, 0] high[0, 0, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x128xf32> to tensor<666x17x23x128xf32>\n    %6 = tensor.empty() : tensor<666x17x17x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x17x23x128xf32>, tensor<128x1x7x128xf32>) outs(%7 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1216xf32>) -> tensor<666x14x14x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1216xf32>) -> tensor<1x1x1x1216xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1216xf32>, tensor<1x1x1x1216xf32>) outs(%4 : tensor<666x14x14x1216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2016xf32>) -> tensor<1x1x1x2016xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2016xf32>, tensor<1x1x1x2016xf32>) outs(%4 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = tensor.empty() : tensor<666x14x1232xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x1232xf32>) -> tensor<666x14x1232xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x1232xf32>) outs(%3 : tensor<666x14x1232xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x1232xf32> into tensor<666x1x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x11xf32>) -> tensor<1x1x1x11xf32>\n    %4 = tensor.empty() : tensor<666x56x56x11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x11xf32>, tensor<1x1x1x11xf32>) outs(%4 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1472xf32>) -> tensor<666x7x7x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1472xf32>) -> tensor<1x1x1x1472xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1472xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1472xf32>, tensor<1x1x1x1472xf32>) outs(%4 : tensor<666x7x7x1472xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<666x28x28x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x232xf32>) -> tensor<1x1x1x232xf32>\n    %4 = tensor.empty() : tensor<666x56x56x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x232xf32>, tensor<1x1x1x232xf32>) outs(%4 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<528xf32>) -> tensor<528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<528xf32>, tensor<1xf32>) outs(%4 : tensor<528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2016x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2016x1x1x224xf32>) -> tensor<2016x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2016xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2016xf32>) -> tensor<2016xf32>\n    %6 = tensor.empty() : tensor<666x1x1x2016xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2016xf32>) outs(%6 : tensor<666x1x1x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x2016xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x224xf32>, tensor<2016x1x1x224xf32>) outs(%7 : tensor<666x1x1x2016xf32>) -> tensor<666x1x1x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x160xf32>) -> tensor<666x56x56x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x160xf32>) -> tensor<128x1x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x160xf32>, tensor<128x1x1x160xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2016xf32>) -> tensor<2016xf32>\n    %2 = tensor.empty() : tensor<2016xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<2016xf32>) outs(%2 : tensor<2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1312xf32>) -> tensor<666x7x7x1312xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1312xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1312xf32>) outs(%2 : tensor<666x7x7x1312xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x44xf32>) -> tensor<666x56x56x44xf32>\n    %2 = tensor.empty() : tensor<666x56x56x44xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x44xf32>) outs(%2 : tensor<666x56x56x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1824xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1824xf32>) -> tensor<666x7x7x1824xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1824xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1824xf32>) -> tensor<1x1x1x1824xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1824xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1824xf32>, tensor<1x1x1x1824xf32>) outs(%4 : tensor<666x7x7x1824xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1824xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x696xf32>) -> tensor<666x56x56x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x696xf32>) -> tensor<1x1x1x696xf32>\n    %4 = tensor.empty() : tensor<666x56x56x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x696xf32>, tensor<1x1x1x696xf32>) outs(%4 : tensor<666x56x56x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x800xf32>) -> tensor<666x14x14x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x800xf32>) -> tensor<1x1x1x800xf32>\n    %4 = tensor.empty() : tensor<666x14x14x800xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x800xf32>, tensor<1x1x1x800xf32>) outs(%4 : tensor<666x14x14x800xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<120x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<120x1x1x48xf32>) -> tensor<120x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<120xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<120xf32>) -> tensor<120xf32>\n    %6 = tensor.empty() : tensor<666x56x56x120xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<120xf32>) outs(%6 : tensor<666x56x56x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x120xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<120x1x1x48xf32>) outs(%7 : tensor<666x56x56x120xf32>) -> tensor<666x56x56x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x28x28x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x110xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x110xf32>) -> tensor<666x1x1x110xf32>\n    %2 = bufferization.alloc_tensor() : tensor<440x1x1x110xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<440x1x1x110xf32>) -> tensor<440x1x1x110xf32>\n    %4 = bufferization.alloc_tensor() : tensor<440xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<440xf32>) -> tensor<440xf32>\n    %6 = tensor.empty() : tensor<666x1x1x440xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<440xf32>) outs(%6 : tensor<666x1x1x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x440xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x110xf32>, tensor<440x1x1x110xf32>) outs(%7 : tensor<666x1x1x440xf32>) -> tensor<666x1x1x440xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = tensor.empty() : tensor<666x14x14xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14xf32>) -> tensor<666x14x14xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x512xf32>) outs(%3 : tensor<666x14x14xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x14x14xf32> into tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<72xf32>) -> tensor<72xf32>\n    %2 = tensor.empty() : tensor<72xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<72xf32>) outs(%2 : tensor<72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<152xf32>) -> tensor<152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<152xf32>, tensor<1xf32>) outs(%4 : tensor<152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<666x28x28x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x2048xf32>) -> tensor<666x10x10x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x10x10x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x10x10x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x308xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x308xf32>) -> tensor<666x1x1x308xf32>\n    %2 = tensor.empty() : tensor<666x1x1x308xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x308xf32>) outs(%2 : tensor<666x1x1x308xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x308xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x92xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x92xf32>) -> tensor<666x1x1x92xf32>\n    %2 = tensor.empty() : tensor<666x1x1x92xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x92xf32>) outs(%2 : tensor<666x1x1x92xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x92xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x22x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x22x1xf32>) -> tensor<5x5x22x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x22xf32> to tensor<666x32x32x22xf32>\n    %6 = tensor.empty() : tensor<666x28x28x22x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x22xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x32x32x22xf32>, tensor<5x5x22x1xf32>) outs(%7 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x22x1xf32> into tensor<666x28x28x22xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<22xf32>, tensor<666x28x28x22xf32>) outs(%8 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x144xf32>) -> tensor<666x28x28x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x28x28x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x28x28x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x84xf32>) -> tensor<666x1x1x84xf32>\n    %2 = tensor.empty() : tensor<666x1x1x84xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x84xf32>) outs(%2 : tensor<666x1x1x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %4 = tensor.empty() : tensor<666x21x21x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x21x21x336xf32>, tensor<666x21x21x336xf32>) outs(%4 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x56x56x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x56x56x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %4 = tensor.empty() : tensor<666x7x7x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x528xf32>, tensor<666x7x7x528xf32>) outs(%4 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x3x3x256xf32>) -> tensor<256x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x256xf32> to tensor<666x37x37x256xf32>\n    %6 = tensor.empty() : tensor<666x35x35x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x35x35x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x37x37x256xf32>, tensor<256x3x3x256xf32>) outs(%7 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2016x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2016x1x1x2016xf32>) -> tensor<2016x1x1x2016xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2016xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2016xf32>) -> tensor<2016xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2016xf32>) outs(%6 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2016xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x2016xf32>, tensor<2016x1x1x2016xf32>) outs(%7 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x52xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x52xf32>) -> tensor<666x1x1x52xf32>\n    %2 = tensor.empty() : tensor<666x1x1x52xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x52xf32>) outs(%2 : tensor<666x1x1x52xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x52xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1152xf32>) -> tensor<1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1152xf32>, tensor<1xf32>) outs(%4 : tensor<1152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1152xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x23x23x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x23x23x672xf32>) -> tensor<666x23x23x672xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x11x11x672xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x23x23x672xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x74x74x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x74x74x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x74x74x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1248xf32>) -> tensor<666x7x7x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1248xf32>) -> tensor<128x1x1x1248xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1248xf32>, tensor<128x1x1x1248xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x320xf32>) -> tensor<666x7x7x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x7x7x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x7x7x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %4 = tensor.empty() : tensor<666x28x28x392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x392xf32>, tensor<666x28x28x392xf32>) outs(%4 : tensor<666x28x28x392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1728xf32>) -> tensor<666x14x14x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1728xf32>) -> tensor<1x1x1x1728xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1728xf32>, tensor<1x1x1x1728xf32>) outs(%4 : tensor<666x14x14x1728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<208x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<208x1x1x104xf32>) -> tensor<208x1x1x104xf32>\n    %4 = bufferization.alloc_tensor() : tensor<208xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<208xf32>) -> tensor<208xf32>\n    %6 = tensor.empty() : tensor<666x28x28x208xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<208xf32>) outs(%6 : tensor<666x28x28x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x208xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x104xf32>, tensor<208x1x1x104xf32>) outs(%7 : tensor<666x28x28x208xf32>) -> tensor<666x28x28x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x88xf32> to tensor<666x16x16x88xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x14x14x88xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x16x16x88xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %c1 = arith.constant 1 : index\n    %c14 = arith.constant 14 : index\n    %c2 = arith.constant 2 : index\n    %c14_2 = arith.constant 14 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c14, %c1_3 : index\n    %7 = arith.subi %c14_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x14x14x88xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x14x14x88xf32>) outs(%8 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1360xf32>) -> tensor<1360xf32>\n    %2 = tensor.empty() : tensor<1360xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1360xf32>) outs(%2 : tensor<1360xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x320xf32>) -> tensor<256x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x35x35x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x35x35x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x320xf32>, tensor<256x1x1x320xf32>) outs(%7 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x216xf32>) -> tensor<666x1x1x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<54x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<54x1x1x216xf32>) -> tensor<54x1x1x216xf32>\n    %4 = bufferization.alloc_tensor() : tensor<54xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<54xf32>) -> tensor<54xf32>\n    %6 = tensor.empty() : tensor<666x1x1x54xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<54xf32>) outs(%6 : tensor<666x1x1x54xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x54xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x216xf32>, tensor<54x1x1x216xf32>) outs(%7 : tensor<666x1x1x54xf32>) -> tensor<666x1x1x54xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<3712xf32>) -> tensor<3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<3712xf32>, tensor<1xf32>) outs(%4 : tensor<3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<208xf32>) -> tensor<208xf32>\n    %2 = tensor.empty() : tensor<208xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<208xf32>) outs(%2 : tensor<208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<152x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<152x1x1x56xf32>) -> tensor<152x1x1x56xf32>\n    %4 = bufferization.alloc_tensor() : tensor<152xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<152xf32>) -> tensor<152xf32>\n    %6 = tensor.empty() : tensor<666x14x14x152xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<152xf32>) outs(%6 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x152xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x56xf32>, tensor<152x1x1x56xf32>) outs(%7 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<14x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<14x1x1x152xf32>) -> tensor<14x1x1x152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<14xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<14xf32>) -> tensor<14xf32>\n    %6 = tensor.empty() : tensor<666x1x1x14xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<14xf32>) outs(%6 : tensor<666x1x1x14xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x14xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x152xf32>, tensor<14x1x1x152xf32>) outs(%7 : tensor<666x1x1x14xf32>) -> tensor<666x1x1x14xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %4 = tensor.empty() : tensor<666x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1536xf32>, tensor<666x1xf32>) outs(%4 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x384xf32>) -> tensor<1x130536x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x384x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x384x1536xf32>) -> tensor<1x384x1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x1536xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x1536xf32>) -> tensor<1x130536x1536xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x384xf32>, tensor<1x384x1536xf32>) outs(%5 : tensor<1x130536x1536xf32>) -> tensor<1x130536x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<666x14x14x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1728xf32>) -> tensor<666x14x14x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1728xf32>) -> tensor<1x1x1x1728xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1728xf32>, tensor<1x1x1x1728xf32>) outs(%4 : tensor<666x14x14x1728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<56xf32>) -> tensor<56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<56xf32>, tensor<1xf32>) outs(%4 : tensor<56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x112xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1664xf32>) -> tensor<666x7x7x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1664xf32>) -> tensor<1x1x1x1664xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1664xf32>, tensor<1x1x1x1664xf32>) outs(%4 : tensor<666x7x7x1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<666x56x56x1xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x72xf32>) -> tensor<288x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x1x1x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x1x1x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x72xf32>, tensor<288x1x1x72xf32>) outs(%7 : tensor<666x1x1x288xf32>) -> tensor<666x1x1x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x1x1x256xf32>) -> tensor<1024x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<1024x1x1x256xf32>) outs(%7 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1152xf32>) -> tensor<666x7x7x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1152xf32>) -> tensor<128x1x1x1152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1152xf32>, tensor<128x1x1x1152xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1536xf32>) -> tensor<666x28x28x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x28x28x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x96xf32>) -> tensor<666x165x165x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x165x165x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x165x165x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x165x165x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x165x165x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1392xf32>) -> tensor<666x28x28x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1392xf32>) -> tensor<1x1x1x1392xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1392xf32>, tensor<1x1x1x1392xf32>) outs(%4 : tensor<666x28x28x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x432xf32>) -> tensor<666x28x28x432xf32>\n    %2 = tensor.empty() : tensor<666x28x28x432xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x432xf32>) outs(%2 : tensor<666x28x28x432xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = tensor.empty() : tensor<666x1x1x72xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x72xf32>) outs(%2 : tensor<666x1x1x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x6144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x6144xf32>) -> tensor<1x32634x6144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x6144x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x6144x1536xf32>) -> tensor<1x6144x1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x1536xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x1536xf32>) -> tensor<1x32634x1536xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x6144xf32>, tensor<1x6144x1536xf32>) outs(%5 : tensor<1x32634x1536xf32>) -> tensor<1x32634x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x3x3x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x3x3x96xf32>) -> tensor<96x3x3x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x96xf32> to tensor<666x37x37x96xf32>\n    %6 = tensor.empty() : tensor<666x35x35x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x35x35x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x37x37x96xf32>, tensor<96x3x3x96xf32>) outs(%7 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x11x11x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x11x11x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<666x14x14x768xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x992xf32>) -> tensor<666x7x7x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x992xf32>) -> tensor<128x1x1x992xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x992xf32>, tensor<128x1x1x992xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x32xf32>) -> tensor<666x111x111x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<11x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<11x1x1x32xf32>) -> tensor<11x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<11xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<11xf32>) -> tensor<11xf32>\n    %6 = tensor.empty() : tensor<666x111x111x11xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<11xf32>) outs(%6 : tensor<666x111x111x11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x111x111x11xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x111x111x32xf32>, tensor<11x1x1x32xf32>) outs(%7 : tensor<666x111x111x11xf32>) -> tensor<666x111x111x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    %4 = tensor.empty() : tensor<666x28x28x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x32xf32>, tensor<666x28x28x32xf32>) outs(%4 : tensor<666x28x28x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1536xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x24xf32>) -> tensor<666x112x112x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x24xf32>) -> tensor<1x1x1x24xf32>\n    %4 = tensor.empty() : tensor<666x112x112x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x24xf32>, tensor<1x1x1x24xf32>) outs(%4 : tensor<666x112x112x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x10x10x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x10x10x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x14x14x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x14x14x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1600xf32>) -> tensor<1600xf32>\n    %2 = tensor.empty() : tensor<1600xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1600xf32>) outs(%2 : tensor<1600xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %4 = tensor.empty() : tensor<666x35x35x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x320xf32>, tensor<666x35x35x320xf32>) outs(%4 : tensor<666x35x35x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x73x73x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x73x73x80xf32>) -> tensor<666x73x73x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x73x73x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x73x73x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x73x73x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x73x73x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x336xf32>) -> tensor<666x112x112x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x112x112x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x112x112x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x152xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x28xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x28xf32>) -> tensor<666x1x1x28xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x28xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x28xf32>) -> tensor<112x1x1x28xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x1x1x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x28xf32>, tensor<112x1x1x28xf32>) outs(%7 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x11x11x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x11x11x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    %2 = tensor.empty() : tensor<666x37x37x728xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x37x37x728xf32>) outs(%2 : tensor<666x37x37x728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x37x37x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x168xf32>) -> tensor<666x112x112x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x112x112x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x112x112x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x48xf32>) -> tensor<112x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x28x28x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<112x1x1x48xf32>) outs(%7 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = tensor.empty() : tensor<666x56x168xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x168xf32>) -> tensor<666x56x168xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x168xf32>) outs(%3 : tensor<666x56x168xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x168xf32> into tensor<666x1x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %4 = tensor.empty() : tensor<666x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1024xf32>, tensor<666x1xf32>) outs(%4 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %4 = tensor.empty() : tensor<666x14x14x408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x408xf32>, tensor<666x14x14x408xf32>) outs(%4 : tensor<666x14x14x408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x216xf32>) -> tensor<666x56x56x216xf32>\n    %2 = tensor.empty() : tensor<666x56x56x216xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x216xf32>) outs(%2 : tensor<666x56x56x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1760xf32>) -> tensor<666x14x14x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1760xf32>) -> tensor<1x1x1x1760xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1760xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1760xf32>, tensor<1x1x1x1760xf32>) outs(%4 : tensor<666x14x14x1760xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1760xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %2 = tensor.empty() : tensor<666x7x1624xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1624xf32>) -> tensor<666x7x1624xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1624xf32>) outs(%3 : tensor<666x7x1624xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1624xf32> into tensor<666x1x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = tensor.empty() : tensor<666x56x56x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x32xf32>) outs(%2 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x1x64xf32>) -> tensor<160x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %6 = tensor.empty() : tensor<666x28x28x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x28x28x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<160x1x1x64xf32>) outs(%7 : tensor<666x28x28x160xf32>) -> tensor<666x28x28x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x896xf32>) -> tensor<666x1x1x896xf32>\n    %2 = tensor.empty() : tensor<666x1x1x896xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x896xf32>) outs(%2 : tensor<666x1x1x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x896xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x768xf32>) -> tensor<1x2088576x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x768x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x768x192xf32>) -> tensor<1x768x192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x192xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x192xf32>) -> tensor<1x2088576x192xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x768xf32>, tensor<1x768x192xf32>) outs(%5 : tensor<1x2088576x192xf32>) -> tensor<1x2088576x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x42x42x168xf32> to tensor<666x44x44x168xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x42x42x168xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x44x44x168xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %c1 = arith.constant 1 : index\n    %c42 = arith.constant 42 : index\n    %c2 = arith.constant 2 : index\n    %c42_2 = arith.constant 42 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c42, %c1_3 : index\n    %7 = arith.subi %c42_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x42x42x168xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x42x42x168xf32>) outs(%8 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = tensor.empty() : tensor<666x28x448xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x448xf32>) -> tensor<666x28x448xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x448xf32>) outs(%3 : tensor<666x28x448xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x448xf32> into tensor<666x1x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3712xf32>) -> tensor<666x14x14x3712xf32>\n    %2 = tensor.empty() : tensor<666x14x14x3712xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x3712xf32>) outs(%2 : tensor<666x14x14x3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1568xf32>) -> tensor<1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1568xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1568xf32>, tensor<1xf32>) outs(%4 : tensor<1568xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1376xf32>) -> tensor<666x14x14x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1376xf32>) -> tensor<1x1x1x1376xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1376xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1376xf32>, tensor<1x1x1x1376xf32>) outs(%4 : tensor<666x14x14x1376xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x30xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x30xf32>) -> tensor<666x1x1x30xf32>\n    %2 = bufferization.alloc_tensor() : tensor<120x1x1x30xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<120x1x1x30xf32>) -> tensor<120x1x1x30xf32>\n    %4 = bufferization.alloc_tensor() : tensor<120xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<120xf32>) -> tensor<120xf32>\n    %6 = tensor.empty() : tensor<666x1x1x120xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<120xf32>) outs(%6 : tensor<666x1x1x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x120xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x30xf32>, tensor<120x1x1x30xf32>) outs(%7 : tensor<666x1x1x120xf32>) -> tensor<666x1x1x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x928xf32>) -> tensor<666x7x7x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x928xf32>) -> tensor<1x1x1x928xf32>\n    %4 = tensor.empty() : tensor<666x7x7x928xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x928xf32>, tensor<1x1x1x928xf32>) outs(%4 : tensor<666x7x7x928xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x208xf32>) -> tensor<1x1x1x208xf32>\n    %4 = tensor.empty() : tensor<666x14x14x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x208xf32>, tensor<1x1x1x208xf32>) outs(%4 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x224xf32>) -> tensor<448x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x28x28x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<448x1x1x224xf32>) outs(%7 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x112x112x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<800xf32>) -> tensor<800xf32>\n    %2 = tensor.empty() : tensor<800xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<800xf32>) outs(%2 : tensor<800xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x72xf32>) -> tensor<168x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x28x28x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x28x28x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<168x1x1x72xf32>) outs(%7 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1344xf32>) -> tensor<666x28x28x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x28x28x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x800xf32>) -> tensor<666x14x14x800xf32>\n    %2 = tensor.empty() : tensor<666x14x14x800xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x800xf32>) outs(%2 : tensor<666x14x14x800xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1536xf32>, tensor<666x14x14x1536xf32>) outs(%4 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x864xf32>) -> tensor<666x7x7x864xf32>\n    %2 = tensor.empty() : tensor<666x7x7x864xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x864xf32>) outs(%2 : tensor<666x7x7x864xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2520xf32>) -> tensor<666x14x14x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2520xf32>) -> tensor<1x1x1x2520xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2520xf32>, tensor<1x1x1x2520xf32>) outs(%4 : tensor<666x14x14x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = tensor.empty() : tensor<666x7x7x608xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x608xf32>) outs(%2 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x256xf32>) -> tensor<128x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<128x1x1x256xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1152xf32>) -> tensor<1152xf32>\n    %2 = tensor.empty() : tensor<1152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1152xf32>) outs(%2 : tensor<1152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    %2 = tensor.empty() : tensor<666x1x1x56xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x56xf32>) outs(%2 : tensor<666x1x1x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x320xf32>) -> tensor<320x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x14x14x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<320x1x1x320xf32>) outs(%7 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x896xf32>) -> tensor<666x1x1x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x896xf32>) -> tensor<224x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x1x1x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x896xf32>, tensor<224x1x1x896xf32>) outs(%7 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x336xf32>) -> tensor<666x42x42x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x42x42x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x42x42x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x24xf32>) -> tensor<1x1x1x24xf32>\n    %4 = tensor.empty() : tensor<666x56x56x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<1x1x1x24xf32>) outs(%4 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x384xf32>) -> tensor<96x1x1x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x14x14x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x14x14x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<96x1x1x384xf32>) outs(%7 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x16xf32>) -> tensor<666x112x112x16xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x16xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x16xf32>) -> tensor<1x1x1x16xf32>\n    %4 = tensor.empty() : tensor<666x112x112x16xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x16xf32>, tensor<1x1x1x16xf32>) outs(%4 : tensor<666x112x112x16xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x264xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x264xf32>) -> tensor<666x28x28x264xf32>\n    %2 = tensor.empty() : tensor<666x28x28x264xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x264xf32>) outs(%2 : tensor<666x28x28x264xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x264xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<232x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<232x1x1x8xf32>) -> tensor<232x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<232xf32>) -> tensor<232xf32>\n    %6 = tensor.empty() : tensor<666x1x1x232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<232xf32>) outs(%6 : tensor<666x1x1x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<232x1x1x8xf32>) outs(%7 : tensor<666x1x1x232xf32>) -> tensor<666x1x1x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x48xf32>) -> tensor<666x112x112x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x112x112x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x112x112x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x28x28x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x28x28x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1512xf32>) -> tensor<1x1x1x1512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1512xf32>, tensor<1x1x1x1512xf32>) outs(%4 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1024xf32>) -> tensor<666x28x28x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x28x28x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x1x1x1024xf32>) -> tensor<2048x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<2048x1x1x1024xf32>) outs(%7 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x96xf32>) -> tensor<192x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x28x28x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<192x1x1x96xf32>) outs(%7 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<240x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<240x1x1x80xf32>) -> tensor<240x1x1x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<240xf32>) -> tensor<240xf32>\n    %6 = tensor.empty() : tensor<666x56x56x240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<240xf32>) outs(%6 : tensor<666x56x56x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x80xf32>, tensor<240x1x1x80xf32>) outs(%7 : tensor<666x56x56x240xf32>) -> tensor<666x56x56x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<608x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<608x1x1x64xf32>) -> tensor<608x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<608xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<608xf32>) -> tensor<608xf32>\n    %6 = tensor.empty() : tensor<666x1x1x608xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<608xf32>) outs(%6 : tensor<666x1x1x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x608xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x64xf32>, tensor<608x1x1x64xf32>) outs(%7 : tensor<666x1x1x608xf32>) -> tensor<666x1x1x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x960xf32>) -> tensor<128x1x1x960xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x960xf32>, tensor<128x1x1x960xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x128xf32>) -> tensor<666x1x56x128xf32>\n    %2 = tensor.empty() : tensor<666x1x128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x128xf32>) -> tensor<666x1x128xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x128xf32>) outs(%3 : tensor<666x1x128xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x128xf32> into tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = tensor.empty() : tensor<666x56x56x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x96xf32>) outs(%2 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<368x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<368x1x1x152xf32>) -> tensor<368x1x1x152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<368xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<368xf32>) -> tensor<368xf32>\n    %6 = tensor.empty() : tensor<666x7x7x368xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<368xf32>) outs(%6 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x368xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x152xf32>, tensor<368x1x1x152xf32>) outs(%7 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1280xf32>) -> tensor<666x14x14x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1280xf32>, tensor<1x1x1x1280xf32>) outs(%4 : tensor<666x14x14x1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x17x17x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x17x17x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<480xf32>) -> tensor<480xf32>\n    %2 = tensor.empty() : tensor<480xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<480xf32>) outs(%2 : tensor<480xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = tensor.empty() : tensor<666x28x28x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x28x28x192xf32>, tensor<666x28x28x192xf32>) outs(%2 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3712xf32>) -> tensor<1x1x1x3712xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3712xf32>, tensor<1x1x1x3712xf32>) outs(%4 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1512xf32>) -> tensor<666x14x14x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1512xf32>) -> tensor<1x1x1x1512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1512xf32>, tensor<1x1x1x1512xf32>) outs(%4 : tensor<666x14x14x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = tensor.empty() : tensor<666x17x17x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x128xf32>) outs(%2 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x704xf32>) -> tensor<666x7x7x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x704xf32>) -> tensor<1x1x1x704xf32>\n    %4 = tensor.empty() : tensor<666x7x7x704xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x704xf32>, tensor<1x1x1x704xf32>) outs(%4 : tensor<666x7x7x704xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x80xf32>) -> tensor<666x112x112x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x112x112x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x112x112x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1600xf32>) -> tensor<666x14x14x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1600xf32>) -> tensor<1x1x1x1600xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1600xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1600xf32>, tensor<1x1x1x1600xf32>) outs(%4 : tensor<666x14x14x1600xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x736xf32>) -> tensor<666x7x7x736xf32>\n    %2 = tensor.empty() : tensor<666x7x7x736xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x736xf32>) outs(%2 : tensor<666x7x7x736xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %4 = tensor.empty() : tensor<666x42x42x84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x84xf32>, tensor<666x42x42x84xf32>) outs(%4 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1504xf32>) -> tensor<1504xf32>\n    %2 = tensor.empty() : tensor<1504xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1504xf32>) outs(%2 : tensor<1504xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x1x1x64xf32>) -> tensor<384x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x14x14x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x64xf32>, tensor<384x1x1x64xf32>) outs(%7 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<666x14x14x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1504xf32>) -> tensor<666x7x7x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1504xf32>) -> tensor<1x1x1x1504xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1504xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1504xf32>, tensor<1x1x1x1504xf32>) outs(%4 : tensor<666x7x7x1504xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1360xf32>) -> tensor<1x1x1x1360xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1360xf32>, tensor<1x1x1x1360xf32>) outs(%4 : tensor<666x7x7x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x1x1x1024xf32>) -> tensor<2048x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<2048x1x1x1024xf32>) outs(%7 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x85x85x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x85x85x84xf32>) -> tensor<666x85x85x84xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x42x42x84xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x85x85x84xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<368x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<368x1x1x368xf32>) -> tensor<368x1x1x368xf32>\n    %4 = bufferization.alloc_tensor() : tensor<368xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<368xf32>) -> tensor<368xf32>\n    %6 = tensor.empty() : tensor<666x7x7x368xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<368xf32>) outs(%6 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x368xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x368xf32>, tensor<368x1x1x368xf32>) outs(%7 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x32xf32>) -> tensor<666x111x111x32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x56x56x32xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x111x111x32xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %c1 = arith.constant 1 : index\n    %c56 = arith.constant 56 : index\n    %c2 = arith.constant 2 : index\n    %c56_1 = arith.constant 56 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c56, %c1_2 : index\n    %7 = arith.subi %c56_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x56x56x32xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x56x56x32xf32>) outs(%8 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x408xf32>) -> tensor<666x28x28x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x408xf32>) -> tensor<1x1x1x408xf32>\n    %4 = tensor.empty() : tensor<666x28x28x408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x408xf32>, tensor<1x1x1x408xf32>) outs(%4 : tensor<666x28x28x408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x32xf32>) -> tensor<96x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x112x112x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x112x112x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<96x1x1x32xf32>) outs(%7 : tensor<666x112x112x96xf32>) -> tensor<666x112x112x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<440xf32>) -> tensor<440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<440xf32>, tensor<1xf32>) outs(%4 : tensor<440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %4 = tensor.empty() : tensor<666x28x28x22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x22xf32>, tensor<666x28x28x22xf32>) outs(%4 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x147x147x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x147x147x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x28x28x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1920xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1920xf32>) outs(%2 : tensor<666x7x7x1920xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x17x17x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x112xf32>) -> tensor<256x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x28x28x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x112xf32>, tensor<256x1x1x112xf32>) outs(%7 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x6144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x6144xf32>) -> tensor<666x7x7x6144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x6144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x6144xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x6144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x6144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x176xf32>) -> tensor<1x1x1x176xf32>\n    %4 = tensor.empty() : tensor<666x7x7x176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x176xf32>, tensor<1x1x1x176xf32>) outs(%4 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x696xf32>) -> tensor<666x56x56x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x696xf32>) -> tensor<1x1x1x696xf32>\n    %4 = tensor.empty() : tensor<666x56x56x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x696xf32>, tensor<1x1x1x696xf32>) outs(%4 : tensor<666x56x56x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = tensor.empty() : tensor<666x1x1x224xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x224xf32>) outs(%2 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = tensor.empty() : tensor<666x1x1x72xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x72xf32>) outs(%2 : tensor<666x1x1x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1728xf32>) -> tensor<666x7x7x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1728xf32>) -> tensor<128x1x1x1728xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1728xf32>, tensor<128x1x1x1728xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1512xf32>) -> tensor<666x14x14x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1512xf32>) -> tensor<1x1x1x1512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1512xf32>, tensor<1x1x1x1512xf32>) outs(%4 : tensor<666x14x14x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1536xf32>) -> tensor<666x8x8x1536xf32>\n    %2 = tensor.empty() : tensor<666x8x1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x8x1536xf32>) -> tensor<666x8x1536xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x8x8x1536xf32>) outs(%3 : tensor<666x8x1536xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x8x1536xf32> into tensor<666x1x8x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x192xf32>) -> tensor<32x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x1x1x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x1x1x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x192xf32>, tensor<32x1x1x192xf32>) outs(%7 : tensor<666x1x1x32xf32>) -> tensor<666x1x1x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<232x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<232x1x1x32xf32>) -> tensor<232x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<232xf32>) -> tensor<232xf32>\n    %6 = tensor.empty() : tensor<666x112x112x232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<232xf32>) outs(%6 : tensor<666x112x112x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<232x1x1x32xf32>) outs(%7 : tensor<666x112x112x232xf32>) -> tensor<666x112x112x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x7x7x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x28x28x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<11xf32>) -> tensor<11xf32>\n    %2 = tensor.empty() : tensor<11xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<11xf32>) outs(%2 : tensor<11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x32xf32>) -> tensor<128x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x112x112x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x112x112x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<128x1x1x32xf32>) outs(%7 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<72xf32>) -> tensor<72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<72xf32>, tensor<1xf32>) outs(%4 : tensor<72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x352xf32>) -> tensor<666x28x28x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x352xf32>) -> tensor<128x1x1x352xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x352xf32>, tensor<128x1x1x352xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1632xf32>) -> tensor<666x7x7x1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1632xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1632xf32>) -> tensor<1x1x1x1632xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1632xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1632xf32>, tensor<1x1x1x1632xf32>) outs(%4 : tensor<666x7x7x1632xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = tensor.empty() : tensor<666x28x28x448xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x448xf32>) outs(%2 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x608xf32>) -> tensor<666x14x14x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x608xf32>) -> tensor<1x1x1x608xf32>\n    %4 = tensor.empty() : tensor<666x14x14x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x608xf32>, tensor<1x1x1x608xf32>) outs(%4 : tensor<666x14x14x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x8x8x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x80xf32>) -> tensor<666x1x1x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x80xf32>) -> tensor<320x1x1x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x1x1x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x1x1x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x80xf32>, tensor<320x1x1x80xf32>) outs(%7 : tensor<666x1x1x320xf32>) -> tensor<666x1x1x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<80xf32>) -> tensor<80xf32>\n    %2 = tensor.empty() : tensor<80xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<80xf32>) outs(%2 : tensor<80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x696xf32>) -> tensor<666x1x1x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<174x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<174x1x1x696xf32>) -> tensor<174x1x1x696xf32>\n    %4 = bufferization.alloc_tensor() : tensor<174xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<174xf32>) -> tensor<174xf32>\n    %6 = tensor.empty() : tensor<666x1x1x174xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<174xf32>) outs(%6 : tensor<666x1x1x174xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x174xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x696xf32>, tensor<174x1x1x696xf32>) outs(%7 : tensor<666x1x1x174xf32>) -> tensor<666x1x1x174xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x768xf32>) -> tensor<666x1x1x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x768xf32>) -> tensor<192x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x1x1x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x1x1x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x768xf32>, tensor<192x1x1x768xf32>) outs(%7 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1008xf32>) -> tensor<1008xf32>\n    %2 = tensor.empty() : tensor<1008xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1008xf32>) outs(%2 : tensor<1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x288xf32>) -> tensor<666x35x35x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x288xf32>) -> tensor<48x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x35x35x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x288xf32>, tensor<48x1x1x288xf32>) outs(%7 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x3xf32>) -> tensor<1x1x1x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<1x1x1x3xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x3xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<1x1x1x3xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.maximumf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1x1x1x3xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x960xf32>) -> tensor<320x1x1x960xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x7x7x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x7x7x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x960xf32>, tensor<320x1x1x960xf32>) outs(%7 : tensor<666x7x7x320xf32>) -> tensor<666x7x7x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x28x28x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x28x28x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x208xf32>) -> tensor<666x28x28x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x208xf32>) -> tensor<1x1x1x208xf32>\n    %4 = tensor.empty() : tensor<666x28x28x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x208xf32>, tensor<1x1x1x208xf32>) outs(%4 : tensor<666x28x28x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = tensor.empty() : tensor<666x74x74x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x74x74x128xf32>) outs(%2 : tensor<666x74x74x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x4096xf32>) -> tensor<666x7x7x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x4096xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x54xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x54xf32>) -> tensor<666x1x1x54xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x54xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x54xf32>) -> tensor<576x1x1x54xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x1x1x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x1x1x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x54xf32>, tensor<576x1x1x54xf32>) outs(%7 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x320xf32>) -> tensor<666x28x28x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x28x28x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x28x28x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<666x28x28x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %2 = tensor.empty() : tensor<666x7x7x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x384xf32>) outs(%2 : tensor<666x7x7x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x192xf32>, tensor<666x28x28x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x17x17x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<560x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<560x1x1x240xf32>) -> tensor<560x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<560xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<560xf32>) -> tensor<560xf32>\n    %6 = tensor.empty() : tensor<666x14x14x560xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<560xf32>) outs(%6 : tensor<666x14x14x560xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x560xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<560x1x1x240xf32>) outs(%7 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x440xf32>) -> tensor<1x1x1x440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x440xf32>, tensor<1x1x1x440xf32>) outs(%4 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x4x4x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x4x4x3xf32>) -> tensor<192x4x4x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x56x56x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<4> : tensor<2xi64>} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<192x4x4x3xf32>) outs(%7 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x4032xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x4032xf32>) -> tensor<666x11x11x4032xf32>\n    %2 = tensor.empty() : tensor<666x11x11x4032xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x11x11x4032xf32>) outs(%2 : tensor<666x11x11x4032xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x11x11x4032xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1920xf32>) -> tensor<666x14x14x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1920xf32>) -> tensor<1x1x1x1920xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1920xf32>, tensor<1x1x1x1920xf32>) outs(%4 : tensor<666x14x14x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1920xf32>) -> tensor<1x1x1x1920xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1920xf32>, tensor<1x1x1x1920xf32>) outs(%4 : tensor<666x7x7x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x4032xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x4032xf32>) -> tensor<666x4032xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x4032xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x4032xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x4032xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x4032xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x14x14x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = tensor.empty() : tensor<666x1x1x112xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x112xf32>) outs(%2 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1056xf32>) -> tensor<666x7x7x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1056xf32>) -> tensor<128x1x1x1056xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1056xf32>, tensor<128x1x1x1056xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1536xf32>) -> tensor<666x28x28x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1536xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = tensor.empty() : tensor<666x7x7x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x768xf32>) outs(%2 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x784xf32>) -> tensor<666x28x28x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x784xf32>) -> tensor<1x1x1x784xf32>\n    %4 = tensor.empty() : tensor<666x28x28x784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x784xf32>, tensor<1x1x1x784xf32>) outs(%4 : tensor<666x28x28x784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1344x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1344x1x1x672xf32>) -> tensor<1344x1x1x672xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1344xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1344xf32>) -> tensor<1344xf32>\n    %6 = tensor.empty() : tensor<666x28x28x1344xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1344xf32>) outs(%6 : tensor<666x28x28x1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x1344xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x672xf32>, tensor<1344x1x1x672xf32>) outs(%7 : tensor<666x28x28x1344xf32>) -> tensor<666x28x28x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1760xf32>) -> tensor<1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1760xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1760xf32>, tensor<1xf32>) outs(%4 : tensor<1760xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1632xf32>) -> tensor<1632xf32>\n    %2 = tensor.empty() : tensor<1632xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1632xf32>) outs(%2 : tensor<1632xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1024xf32>) -> tensor<1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1024xf32>, tensor<1xf32>) outs(%4 : tensor<1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = tensor.empty() : tensor<666x28x28x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x256xf32>) outs(%2 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x3x3x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x3x3x512xf32>) -> tensor<512x3x3x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x512xf32> to tensor<666x16x16x512xf32>\n    %6 = tensor.empty() : tensor<666x14x14x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x16x16x512xf32>, tensor<512x3x3x512xf32>) outs(%7 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x832xf32>) -> tensor<666x7x7x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x832xf32>) -> tensor<1x1x1x832xf32>\n    %4 = tensor.empty() : tensor<666x7x7x832xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x832xf32>, tensor<1x1x1x832xf32>) outs(%4 : tensor<666x7x7x832xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x7x7x528xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x14x14x528xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %c1 = arith.constant 1 : index\n    %c7 = arith.constant 7 : index\n    %c2 = arith.constant 2 : index\n    %c7_1 = arith.constant 7 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c7, %c1_2 : index\n    %7 = arith.subi %c7_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x7x7x528xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x7x7x528xf32>) outs(%8 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<168xf32>) -> tensor<168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<168xf32>, tensor<1xf32>) outs(%4 : tensor<168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x35x35x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x256xf32>) -> tensor<256x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x74x74x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x74x74x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x74x74x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x74x74x256xf32>, tensor<256x1x1x256xf32>) outs(%7 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<666x56x56x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1536xf32>) -> tensor<666x10x10x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x10x10x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x10x10x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x232xf32>) -> tensor<666x112x112x232xf32>\n    %2 = tensor.empty() : tensor<666x112x112x232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x232xf32>) outs(%2 : tensor<666x112x112x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x232xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %padded = tensor.pad %1 low[0, 0, 0, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x74x74x256xf32> to tensor<666x75x75x256xf32>\n    %cst_1 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x37x37x256xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%padded, %4 : tensor<666x75x75x256xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = tensor.empty() : tensor<666x21x21x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x21x21x336xf32>, tensor<666x21x21x336xf32>) outs(%2 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.addf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x192xf32>) -> tensor<48x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x35x35x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x192xf32>, tensor<48x1x1x192xf32>) outs(%7 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1360xf32>) -> tensor<666x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1360xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x8x8x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<608x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<608x1x1x256xf32>) -> tensor<608x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<608xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<608xf32>) -> tensor<608xf32>\n    %6 = tensor.empty() : tensor<666x7x7x608xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<608xf32>) outs(%6 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x608xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<608x1x1x256xf32>) outs(%7 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1536xf32>) -> tensor<666x10x10x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x1536x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x1536x1xf32>) -> tensor<3x3x1536x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1536xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1536xf32>) -> tensor<1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x10x10x1536xf32> to tensor<666x12x12x1536xf32>\n    %6 = tensor.empty() : tensor<666x10x10x1536x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x10x10x1536x1xf32>) -> tensor<666x10x10x1536x1xf32>\n    %8 = tensor.empty() : tensor<666x10x10x1536xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x12x12x1536xf32>, tensor<3x3x1536x1xf32>) outs(%7 : tensor<666x10x10x1536x1xf32>) -> tensor<666x10x10x1536x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x10x10x1536x1xf32> into tensor<666x10x10x1536xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<1536xf32>, tensor<666x10x10x1536xf32>) outs(%8 : tensor<666x10x10x1536xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x10x10x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x256xf32>) -> tensor<666x7x7x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x7x7x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x7x7x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x368xf32>) -> tensor<666x1x7x368xf32>\n    %2 = tensor.empty() : tensor<666x1x368xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x368xf32>) -> tensor<666x1x368xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x368xf32>) outs(%3 : tensor<666x1x368xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x368xf32> into tensor<666x1x1x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x336xf32>) -> tensor<672x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x28x28x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x28x28x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x336xf32>, tensor<672x1x1x336xf32>) outs(%7 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<208x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<208x1x1x208xf32>) -> tensor<208x1x1x208xf32>\n    %4 = bufferization.alloc_tensor() : tensor<208xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<208xf32>) -> tensor<208xf32>\n    %6 = tensor.empty() : tensor<666x14x14x208xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<208xf32>) outs(%6 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x208xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x208xf32>, tensor<208x1x1x208xf32>) outs(%7 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x288xf32>) -> tensor<666x35x35x288xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x17x17x288xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x35x35x288xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<144xf32>) -> tensor<144xf32>\n    %2 = tensor.empty() : tensor<144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<144xf32>) outs(%2 : tensor<144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x704xf32>) -> tensor<666x7x7x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x704xf32>) -> tensor<1x1x1x704xf32>\n    %4 = tensor.empty() : tensor<666x7x7x704xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x704xf32>, tensor<1x1x1x704xf32>) outs(%4 : tensor<666x7x7x704xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1536xf32>) -> tensor<666x10x10x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x1x1x1536xf32>) -> tensor<2048x1x1x1536xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x10x10x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x10x10x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x10x10x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x10x10x1536xf32>, tensor<2048x1x1x1536xf32>) outs(%7 : tensor<666x10x10x2048xf32>) -> tensor<666x10x10x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x1x1x896xf32>) -> tensor<2048x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<2048x1x1x896xf32>) outs(%7 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<666x56x56x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x864xf32>) -> tensor<666x14x14x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x864xf32>) -> tensor<1x1x1x864xf32>\n    %4 = tensor.empty() : tensor<666x14x14x864xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x864xf32>, tensor<1x1x1x864xf32>) outs(%4 : tensor<666x14x14x864xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x32xf32>) -> tensor<48x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x56x56x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<48x1x1x32xf32>) outs(%7 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1504xf32>) -> tensor<666x14x14x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1504xf32>) -> tensor<1x1x1x1504xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1504xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1504xf32>, tensor<1x1x1x1504xf32>) outs(%4 : tensor<666x14x14x1504xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1920xf32>) -> tensor<666x14x14x1920xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1920xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1920xf32>) outs(%2 : tensor<666x14x14x1920xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x112x112x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x4096xf32>) -> tensor<666x14x14x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x4096xf32>) -> tensor<1x1x1x4096xf32>\n    %4 = tensor.empty() : tensor<666x14x14x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x4096xf32>, tensor<1x1x1x4096xf32>) outs(%4 : tensor<666x14x14x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x576xf32>) -> tensor<666x7x7x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x7x7x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x7x7x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2520xf32>) -> tensor<666x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x2520xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = tensor.empty() : tensor<666x42x42x84xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x42x42x84xf32>) outs(%2 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = tensor.empty() : tensor<666x56x56xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56xf32>) -> tensor<666x56x56xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x192xf32>) outs(%3 : tensor<666x56x56xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x56x56xf32> into tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x104xf32>) -> tensor<1x1x1x104xf32>\n    %4 = tensor.empty() : tensor<666x28x28x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x104xf32>, tensor<1x1x1x104xf32>) outs(%4 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x336xf32>) -> tensor<336x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x14x14x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x336xf32>, tensor<336x1x1x336xf32>) outs(%7 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %2 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x2240xf32>) outs(%2 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x912xf32>) -> tensor<666x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x912xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x84xf32>) -> tensor<666x83x83x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x84xf32>) -> tensor<1x1x1x84xf32>\n    %4 = tensor.empty() : tensor<666x83x83x84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x83x83x84xf32>, tensor<1x1x1x84xf32>) outs(%4 : tensor<666x83x83x84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x83x83x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x264xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x264xf32>) -> tensor<666x28x28x264xf32>\n    %2 = bufferization.alloc_tensor() : tensor<44x1x1x264xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<44x1x1x264xf32>) -> tensor<44x1x1x264xf32>\n    %4 = bufferization.alloc_tensor() : tensor<44xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<44xf32>) -> tensor<44xf32>\n    %6 = tensor.empty() : tensor<666x28x28x44xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<44xf32>) outs(%6 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x44xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x264xf32>, tensor<44x1x1x264xf32>) outs(%7 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = tensor.empty() : tensor<666x14x14x576xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x576xf32>) outs(%2 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1184xf32>) -> tensor<666x14x14x1184xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1184xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1184xf32>) outs(%2 : tensor<666x14x14x1184xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2240xf32>) -> tensor<666x1x1x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x2240xf32>) -> tensor<224x1x1x2240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x1x1x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x2240xf32>, tensor<224x1x1x2240xf32>) outs(%7 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x384xf32>, tensor<666x28x28x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x768xf32>) -> tensor<128x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<128x1x1x768xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x232xf32>) -> tensor<1x1x1x232xf32>\n    %4 = tensor.empty() : tensor<666x56x56x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x232xf32>, tensor<1x1x1x232xf32>) outs(%4 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1568xf32>) -> tensor<666x7x7x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1568xf32>) -> tensor<1x1x1x1568xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1568xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1568xf32>, tensor<1x1x1x1568xf32>) outs(%4 : tensor<666x7x7x1568xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1472xf32>) -> tensor<666x14x14x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1472xf32>) -> tensor<1x1x1x1472xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1472xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1472xf32>, tensor<1x1x1x1472xf32>) outs(%4 : tensor<666x14x14x1472xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x608xf32>) -> tensor<666x1x1x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x608xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x352xf32>) -> tensor<666x14x14x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x352xf32>) -> tensor<1x1x1x352xf32>\n    %4 = tensor.empty() : tensor<666x14x14x352xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x352xf32>, tensor<1x1x1x352xf32>) outs(%4 : tensor<666x14x14x352xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x28x28x128xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x56x56x128xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %c1 = arith.constant 1 : index\n    %c28 = arith.constant 28 : index\n    %c2 = arith.constant 2 : index\n    %c28_1 = arith.constant 28 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c28, %c1_2 : index\n    %7 = arith.subi %c28_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x28x28x128xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x28x28x128xf32>) outs(%8 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c2_4 = arith.constant 2 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c2_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c2_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c2_6 = arith.constant 2 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c2_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c2_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x73x73x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x73x73x64xf32>) -> tensor<666x73x73x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<80x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<80x1x1x64xf32>) -> tensor<80x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<80xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<80xf32>) -> tensor<80xf32>\n    %6 = tensor.empty() : tensor<666x73x73x80xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<80xf32>) outs(%6 : tensor<666x73x73x80xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x73x73x80xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x73x73x64xf32>, tensor<80x1x1x64xf32>) outs(%7 : tensor<666x73x73x80xf32>) -> tensor<666x73x73x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1392xf32>) -> tensor<666x28x28x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1392xf32>) -> tensor<1x1x1x1392xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1392xf32>, tensor<1x1x1x1392xf32>) outs(%4 : tensor<666x28x28x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<928xf32>) -> tensor<928xf32>\n    %2 = tensor.empty() : tensor<928xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<928xf32>) outs(%2 : tensor<928xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x288xf32>) -> tensor<666x1x1x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<36x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<36x1x1x288xf32>) -> tensor<36x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<36xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<36xf32>) -> tensor<36xf32>\n    %6 = tensor.empty() : tensor<666x1x1x36xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<36xf32>) outs(%6 : tensor<666x1x1x36xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x36xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x288xf32>, tensor<36x1x1x288xf32>) outs(%7 : tensor<666x1x1x36xf32>) -> tensor<666x1x1x36xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x728xf32>) -> tensor<1x1x1x728xf32>\n    %4 = tensor.empty() : tensor<666x19x19x728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x19x19x728xf32>, tensor<1x1x1x728xf32>) outs(%4 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x169x169x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x169x169x96xf32>) -> tensor<666x169x169x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x96x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x96x1xf32>) -> tensor<5x5x96x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x83x83x96x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x83x83x96x1xf32>) -> tensor<666x83x83x96x1xf32>\n    %8 = tensor.empty() : tensor<666x83x83x96xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x169x169x96xf32>, tensor<5x5x96x1xf32>) outs(%7 : tensor<666x83x83x96x1xf32>) -> tensor<666x83x83x96x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x83x83x96x1xf32> into tensor<666x83x83x96xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<96xf32>, tensor<666x83x83x96xf32>) outs(%8 : tensor<666x83x83x96xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x83x83x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x84x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x84x1xf32>) -> tensor<3x3x84x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x42x42x84xf32> to tensor<666x44x44x84xf32>\n    %6 = tensor.empty() : tensor<666x42x42x84x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %8 = tensor.empty() : tensor<666x42x42x84xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x44x44x84xf32>, tensor<3x3x84x1xf32>) outs(%7 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x42x42x84x1xf32> into tensor<666x42x42x84xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<84xf32>, tensor<666x42x42x84xf32>) outs(%8 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x160xf32>) -> tensor<666x56x56x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x56x56x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x56x56x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<608x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<608x1x1x152xf32>) -> tensor<608x1x1x152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<608xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<608xf32>) -> tensor<608xf32>\n    %6 = tensor.empty() : tensor<666x1x1x608xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<608xf32>) outs(%6 : tensor<666x1x1x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x608xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x152xf32>, tensor<608x1x1x152xf32>) outs(%7 : tensor<666x1x1x608xf32>) -> tensor<666x1x1x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1856xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1856xf32>) -> tensor<1856xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1856xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1856xf32>, tensor<1xf32>) outs(%4 : tensor<1856xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1856xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x768xf32>) -> tensor<666x17x17x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x768xf32>) -> tensor<128x1x1x768xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x17x17x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x768xf32>, tensor<128x1x1x768xf32>) outs(%7 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x192xf32>) -> tensor<666x1x28x192xf32>\n    %2 = tensor.empty() : tensor<666x1x192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x192xf32>) -> tensor<666x1x192xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x192xf32>) outs(%3 : tensor<666x1x192xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x192xf32> into tensor<666x1x1x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x416xf32>) -> tensor<666x14x14x416xf32>\n    %2 = tensor.empty() : tensor<666x14x14x416xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x416xf32>) outs(%2 : tensor<666x14x14x416xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x18xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x18xf32>) -> tensor<666x1x1x18xf32>\n    %2 = tensor.empty() : tensor<666x1x1x18xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x18xf32>) outs(%2 : tensor<666x1x1x18xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x18xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1568xf32>) -> tensor<666x7x7x1568xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1568xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1568xf32>) outs(%2 : tensor<666x7x7x1568xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1568xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = tensor.empty() : tensor<666x7x528xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x528xf32>) -> tensor<666x7x528xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x528xf32>) outs(%3 : tensor<666x7x528xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x528xf32> into tensor<666x1x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1360xf32>, tensor<666x7x7x1360xf32>) outs(%4 : tensor<666x7x7x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<256xf32>) -> tensor<256xf32>\n    %2 = tensor.empty() : tensor<256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<256xf32>) outs(%2 : tensor<256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x888xf32>) -> tensor<666x1x1x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<84x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<84x1x1x888xf32>) -> tensor<84x1x1x888xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %6 = tensor.empty() : tensor<666x1x1x84xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<84xf32>) outs(%6 : tensor<666x1x1x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x84xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x888xf32>, tensor<84x1x1x888xf32>) outs(%7 : tensor<666x1x1x84xf32>) -> tensor<666x1x1x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x1008xf32>) -> tensor<666x42x42x1008xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x21x21x1008xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x21x21x1008xf32>) -> tensor<666x21x21x1008xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x42x42x1008xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x21x21x1008xf32>) -> tensor<666x21x21x1008xf32>\n    %c1 = arith.constant 1 : index\n    %c21 = arith.constant 21 : index\n    %c2 = arith.constant 2 : index\n    %c21_1 = arith.constant 21 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c21, %c1_2 : index\n    %7 = arith.subi %c21_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x21x21x1008xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x21x21x1008xf32>) outs(%8 : tensor<666x21x21x1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x21x21x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<84x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<84x1x1x168xf32>) -> tensor<84x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %6 = tensor.empty() : tensor<666x42x42x84xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<84xf32>) outs(%6 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x42x42x84xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x42x42x168xf32>, tensor<84x1x1x168xf32>) outs(%7 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x208xf32>) -> tensor<666x1x1x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x208xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x96xf32>) -> tensor<576x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x14x14x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x96xf32>, tensor<576x1x1x96xf32>) outs(%7 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x27x27x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x27x27x672xf32>) -> tensor<666x27x27x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x672x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x672x1xf32>) -> tensor<7x7x672x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %8 = tensor.empty() : tensor<666x11x11x672xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x27x27x672xf32>, tensor<7x7x672x1xf32>) outs(%7 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x11x11x672x1xf32> into tensor<666x11x11x672xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<672xf32>, tensor<666x11x11x672xf32>) outs(%8 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1056xf32>) -> tensor<666x7x7x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1056xf32>) -> tensor<1x1x1x1056xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1056xf32>, tensor<1x1x1x1056xf32>) outs(%4 : tensor<666x7x7x1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x2048xf32>) -> tensor<666x28x28x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x2048xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x24xf32>) -> tensor<666x1x1x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x24xf32>) -> tensor<8x1x1x24xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x24xf32>, tensor<8x1x1x24xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2016x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2016x1x1x896xf32>) -> tensor<2016x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2016xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2016xf32>) -> tensor<2016xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2016xf32>) outs(%6 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2016xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<2016x1x1x896xf32>) outs(%7 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1536xf32>) -> tensor<128x1x1x1536xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1536xf32>, tensor<128x1x1x1536xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x112x112x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x112x112x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x168xf32>) -> tensor<666x112x112x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x112x112x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x112x112x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x640xf32>) -> tensor<666x7x7x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x640xf32>) -> tensor<128x1x1x640xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x640xf32>, tensor<128x1x1x640xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %4 = tensor.empty() : tensor<666x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x2048xf32>, tensor<666x2048xf32>) outs(%4 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<800xf32>) -> tensor<800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<800xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<800xf32>, tensor<1xf32>) outs(%4 : tensor<800xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<800xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x3024xf32>) -> tensor<666x1x7x3024xf32>\n    %2 = tensor.empty() : tensor<666x1x3024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x3024xf32>) -> tensor<666x1x3024xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x3024xf32>) outs(%3 : tensor<666x1x3024xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x3024xf32> into tensor<666x1x1x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<160xf32>) -> tensor<160xf32>\n    %2 = tensor.empty() : tensor<160xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<160xf32>) outs(%2 : tensor<160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x8x8x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x7x7x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x7x7x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x768xf32>) -> tensor<1x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %4 = tensor.empty() : tensor<666x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x768xf32>, tensor<666x768xf32>) outs(%4 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3072xf32>) -> tensor<666x7x7x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x3072xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x3072xf32>) -> tensor<666x7x7x3072xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3072xf32>, tensor<666x7x7x3072xf32>) outs(%4 : tensor<666x7x7x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1008xf32>) -> tensor<666x14x14x1008xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1008xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1008xf32>) outs(%2 : tensor<666x14x14x1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x6144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x6144xf32>) -> tensor<666x7x7x6144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x6144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x6144xf32>) -> tensor<666x7x7x6144xf32>\n    %4 = tensor.empty() : tensor<666x7x7x6144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x6144xf32>, tensor<666x7x7x6144xf32>) outs(%4 : tensor<666x7x7x6144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x6144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<432xf32>) -> tensor<432xf32>\n    %2 = tensor.empty() : tensor<432xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<432xf32>) outs(%2 : tensor<432xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x528xf32>) -> tensor<1x1x1x528xf32>\n    %4 = tensor.empty() : tensor<666x7x7x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x528xf32>, tensor<1x1x1x528xf32>) outs(%4 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x72xf32>) -> tensor<576x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x1x1x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x1x1x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x72xf32>, tensor<576x1x1x72xf32>) outs(%7 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = tensor.empty() : tensor<666x28x28x168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x168xf32>) outs(%2 : tensor<666x28x28x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x960xf32>) -> tensor<666x14x14x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x960xf32>) -> tensor<1x1x1x960xf32>\n    %4 = tensor.empty() : tensor<666x14x14x960xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x960xf32>, tensor<1x1x1x960xf32>) outs(%4 : tensor<666x14x14x960xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x912xf32>) -> tensor<666x14x14x912xf32>\n    %2 = tensor.empty() : tensor<666x14x14x912xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x912xf32>) outs(%2 : tensor<666x14x14x912xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x912xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %2 = tensor.empty() : tensor<666x7x440xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x440xf32>) -> tensor<666x7x440xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x440xf32>) outs(%3 : tensor<666x7x440xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x440xf32> into tensor<666x1x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x696xf32>) -> tensor<666x1x1x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %4 = tensor.empty() : tensor<666x28x28x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x696xf32>, tensor<666x28x28x696xf32>) outs(%4 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x88xf32>) -> tensor<666x28x28x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x88xf32>) -> tensor<1x1x1x88xf32>\n    %4 = tensor.empty() : tensor<666x28x28x88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x88xf32>, tensor<1x1x1x88xf32>) outs(%4 : tensor<666x28x28x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x224xf32>) -> tensor<666x28x28x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x28x28x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x28x28x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x11x11x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x11x11x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    %2 = tensor.empty() : tensor<666x14x14x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x128xf32>) outs(%2 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %4 = tensor.empty() : tensor<666x56x56x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<666x56x56x48xf32>) outs(%4 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1280xf32>) -> tensor<666x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1280xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2240xf32>) -> tensor<666x14x14x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2240xf32>) -> tensor<1x1x1x2240xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2240xf32>, tensor<1x1x1x2240xf32>) outs(%4 : tensor<666x14x14x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x160xf32>) -> tensor<666x28x28x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x28x28x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x28x28x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x96xf32>) -> tensor<666x165x165x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x165x165x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x165x165x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x165x165x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x165x165x96xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x2240xf32>) -> tensor<1x666x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2240x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2240x1000xf32>) -> tensor<1x2240x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x2240xf32>, tensor<1x2240x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<88xf32>) -> tensor<88xf32>\n    %2 = tensor.empty() : tensor<88xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<88xf32>) outs(%2 : tensor<88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2016xf32>) -> tensor<1x1x1x2016xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2016xf32>, tensor<1x1x1x2016xf32>) outs(%4 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<112xf32>) -> tensor<112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<112xf32>, tensor<1xf32>) outs(%4 : tensor<112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1392x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1392x1x1x696xf32>) -> tensor<1392x1x1x696xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1392xf32>) -> tensor<1392xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1392xf32>) outs(%6 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x696xf32>, tensor<1392x1x1x696xf32>) outs(%7 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<432x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<432x1x1x192xf32>) -> tensor<432x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<432xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<432xf32>) -> tensor<432xf32>\n    %6 = tensor.empty() : tensor<666x28x28x432xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<432xf32>) outs(%6 : tensor<666x28x28x432xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x432xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<432x1x1x192xf32>) outs(%7 : tensor<666x28x28x432xf32>) -> tensor<666x28x28x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1152xf32>) -> tensor<666x7x7x1152xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1152xf32>) outs(%2 : tensor<666x7x7x1152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x216xf32>) -> tensor<576x1x1x216xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x14x14x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x216xf32>, tensor<576x1x1x216xf32>) outs(%7 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x4096xf32>) -> tensor<666x14x14x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x4096xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x416xf32>) -> tensor<666x14x14x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x416xf32>) -> tensor<1x1x1x416xf32>\n    %4 = tensor.empty() : tensor<666x14x14x416xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x416xf32>, tensor<1x1x1x416xf32>) outs(%4 : tensor<666x14x14x416xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2520xf32>, tensor<666x7x7x2520xf32>) outs(%4 : tensor<666x7x7x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x120xf32>) -> tensor<666x1x1x120xf32>\n    %2 = tensor.empty() : tensor<666x1x1x120xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x120xf32>) outs(%2 : tensor<666x1x1x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1280xf32>) -> tensor<1280xf32>\n    %2 = tensor.empty() : tensor<1280xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1280xf32>) outs(%2 : tensor<1280xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = tensor.empty() : tensor<666x56x56x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x128xf32>) outs(%2 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x232xf32>) -> tensor<666x1x1x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x232xf32>) -> tensor<8x1x1x232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x232xf32>, tensor<8x1x1x232xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x128xf32>) -> tensor<288x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x14x14x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x14x14x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<288x1x1x128xf32>) outs(%7 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x240xf32>) -> tensor<666x56x56x240xf32>\n    %2 = tensor.empty() : tensor<666x56x56x240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x240xf32>) outs(%2 : tensor<666x56x56x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1408xf32>) -> tensor<666x7x7x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1408xf32>) -> tensor<1x1x1x1408xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1408xf32>, tensor<1x1x1x1408xf32>) outs(%4 : tensor<666x7x7x1408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x512xf32>) -> tensor<666x1x1x512xf32>\n    %2 = tensor.empty() : tensor<666x1x1x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x512xf32>) outs(%2 : tensor<666x1x1x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x256xf32>) -> tensor<64x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x35x35x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x256xf32>, tensor<64x1x1x256xf32>) outs(%7 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x672xf32>) -> tensor<666x14x14x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x14x14x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x14x14x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1512x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1512x1x1x576xf32>) -> tensor<1512x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1512xf32>) -> tensor<1512xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1512xf32>) outs(%6 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<1512x1x1x576xf32>) outs(%7 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x88xf32>) -> tensor<666x28x28x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<44x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<44x1x1x88xf32>) -> tensor<44x1x1x88xf32>\n    %4 = bufferization.alloc_tensor() : tensor<44xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<44xf32>) -> tensor<44xf32>\n    %6 = tensor.empty() : tensor<666x28x28x44xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<44xf32>) outs(%6 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x44xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x88xf32>, tensor<44x1x1x88xf32>) outs(%7 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x208xf32>) -> tensor<666x1x1x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<52x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<52x1x1x208xf32>) -> tensor<52x1x1x208xf32>\n    %4 = bufferization.alloc_tensor() : tensor<52xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<52xf32>) -> tensor<52xf32>\n    %6 = tensor.empty() : tensor<666x1x1x52xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<52xf32>) outs(%6 : tensor<666x1x1x52xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x52xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x208xf32>, tensor<52x1x1x208xf32>) outs(%7 : tensor<666x1x1x52xf32>) -> tensor<666x1x1x52xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1536xf32>) outs(%2 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x192xf32>) -> tensor<666x14x14x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x14x14x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x14x14x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x336xf32>) -> tensor<336x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x56x56x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x56x56x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x336xf32>, tensor<336x1x1x336xf32>) outs(%7 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x128xf32>) -> tensor<32x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x128xf32> to tensor<666x58x58x128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x128xf32>, tensor<32x3x3x128xf32>) outs(%7 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x704xf32>) -> tensor<666x14x14x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x704xf32>) -> tensor<128x1x1x704xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x704xf32>, tensor<128x1x1x704xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1728xf32>) -> tensor<1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1728xf32>, tensor<1xf32>) outs(%4 : tensor<1728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %4 = tensor.empty() : tensor<666x11x11x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x11x11x672xf32>, tensor<666x11x11x672xf32>) outs(%4 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x17x17x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x448xf32>) -> tensor<112x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x1x1x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x448xf32>, tensor<112x1x1x448xf32>) outs(%7 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3712xf32>, tensor<666x7x7x3712xf32>) outs(%4 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3024x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3024x1x1x3024xf32>) -> tensor<3024x1x1x3024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3024xf32>) -> tensor<3024xf32>\n    %6 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3024xf32>) outs(%6 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x3024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x3024xf32>, tensor<3024x1x1x3024xf32>) outs(%7 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x152xf32>) -> tensor<666x28x28x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x152xf32>) -> tensor<1x1x1x152xf32>\n    %4 = tensor.empty() : tensor<666x28x28x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x152xf32>, tensor<1x1x1x152xf32>) outs(%4 : tensor<666x28x28x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x528xf32>) -> tensor<1x1x1x528xf32>\n    %4 = tensor.empty() : tensor<666x7x7x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x528xf32>, tensor<1x1x1x528xf32>) outs(%4 : tensor<666x7x7x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x392xf32>) -> tensor<666x56x56x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x392xf32>) -> tensor<1x1x1x392xf32>\n    %4 = tensor.empty() : tensor<666x56x56x392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x392xf32>, tensor<1x1x1x392xf32>) outs(%4 : tensor<666x56x56x392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x12xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x12xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x12xf32>) -> tensor<48x1x1x12xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x1x1x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x1x1x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x12xf32>, tensor<48x1x1x12xf32>) outs(%7 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<666x56x56x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x2048xf32>) -> tensor<1x522144x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2048x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2048x512xf32>) -> tensor<1x2048x512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x512xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x512xf32>) -> tensor<1x522144x512xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x2048xf32>, tensor<1x2048x512xf32>) outs(%5 : tensor<1x522144x512xf32>) -> tensor<1x522144x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %2 = tensor.empty() : tensor<666x7x3024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x3024xf32>) -> tensor<666x7x3024xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x3024xf32>) outs(%3 : tensor<666x7x3024xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x3024xf32> into tensor<666x1x7x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x232xf32>) -> tensor<666x1x1x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<58x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<58x1x1x232xf32>) -> tensor<58x1x1x232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<58xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<58xf32>) -> tensor<58xf32>\n    %6 = tensor.empty() : tensor<666x1x1x58xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<58xf32>) outs(%6 : tensor<666x1x1x58xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x58xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x232xf32>, tensor<58x1x1x232xf32>) outs(%7 : tensor<666x1x1x58xf32>) -> tensor<666x1x1x58xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x28x28x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x28x28x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x168xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = tensor.empty() : tensor<666x7x1088xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1088xf32>) -> tensor<666x7x1088xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1088xf32>) outs(%3 : tensor<666x7x1088xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1088xf32> into tensor<666x1x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x896xf32>) -> tensor<896x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x14x14x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<896x1x1x896xf32>) outs(%7 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x2520xf32>) -> tensor<666x1x7x2520xf32>\n    %2 = tensor.empty() : tensor<666x1x2520xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x2520xf32>) -> tensor<666x1x2520xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x2520xf32>) outs(%3 : tensor<666x1x2520xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x2520xf32> into tensor<666x1x1x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    %2 = tensor.empty() : tensor<666x35x35x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x35x35x64xf32>) outs(%2 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = tensor.empty() : tensor<666x28x288xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x288xf32>) -> tensor<666x28x288xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x288xf32>) outs(%3 : tensor<666x28x288xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x288xf32> into tensor<666x1x28x288xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x1392xf32>) -> tensor<666x1x14x1392xf32>\n    %2 = tensor.empty() : tensor<666x1x1392xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1392xf32>) -> tensor<666x1x1392xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x1392xf32>) outs(%3 : tensor<666x1x1392xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1392xf32> into tensor<666x1x1x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %4 = tensor.empty() : tensor<666x14x14x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<666x14x14x320xf32>) outs(%4 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x144xf32>) -> tensor<8x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x144xf32>, tensor<8x1x1x144xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x512xf32>) -> tensor<256x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x14x14x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<256x1x1x512xf32>) outs(%7 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x64xf32>) -> tensor<666x1x56x64xf32>\n    %2 = tensor.empty() : tensor<666x1x64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x64xf32>) -> tensor<666x1x64xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x64xf32>) outs(%3 : tensor<666x1x64xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x64xf32> into tensor<666x1x1x64xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %2 = tensor.empty() : tensor<666x7x2520xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x2520xf32>) -> tensor<666x7x2520xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x2520xf32>) outs(%3 : tensor<666x7x2520xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x2520xf32> into tensor<666x1x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %2 = tensor.empty() : tensor<666x35x35x320xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x35x35x320xf32>) outs(%2 : tensor<666x35x35x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x35x35x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1568xf32>) -> tensor<666x14x14x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1568xf32>) -> tensor<1x1x1x1568xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1568xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1568xf32>, tensor<1x1x1x1568xf32>) outs(%4 : tensor<666x14x14x1568xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x32xf32>) -> tensor<256x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x56x56x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<256x1x1x32xf32>) outs(%7 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x608xf32>) -> tensor<1x1x1x608xf32>\n    %4 = tensor.empty() : tensor<666x7x7x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x608xf32>, tensor<1x1x1x608xf32>) outs(%4 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x56x56x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1512x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1512x1x1x1512xf32>) -> tensor<1512x1x1x1512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1512xf32>) -> tensor<1512xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1512xf32>) outs(%6 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1512xf32>, tensor<1512x1x1x1512xf32>) outs(%7 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1000xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1000xf32>) -> tensor<666x1000xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1000xf32>) -> tensor<1x1000xf32>\n    %4 = tensor.empty() : tensor<666x1000xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1000xf32>, tensor<1x1000xf32>) outs(%4 : tensor<666x1000xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x112x112x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x112x112x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<240x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<240x1x1x240xf32>) -> tensor<240x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<240xf32>) -> tensor<240xf32>\n    %6 = tensor.empty() : tensor<666x14x14x240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<240xf32>) outs(%6 : tensor<666x14x14x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x240xf32>, tensor<240x1x1x240xf32>) outs(%7 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %2 = tensor.empty() : tensor<666x7x912xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x912xf32>) -> tensor<666x7x912xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x912xf32>) outs(%3 : tensor<666x7x912xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x912xf32> into tensor<666x1x7x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x720xf32>) -> tensor<666x28x28x720xf32>\n    %2 = tensor.empty() : tensor<666x28x28x720xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x720xf32>) outs(%2 : tensor<666x28x28x720xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x36xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x36xf32>) -> tensor<666x1x1x36xf32>\n    %2 = tensor.empty() : tensor<666x1x1x36xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x36xf32>) outs(%2 : tensor<666x1x1x36xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x36xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x608xf32>) -> tensor<128x1x1x608xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x608xf32>, tensor<128x1x1x608xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (0, d1)>\n#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x768xf32>) -> tensor<1x768xf32>\n    %4 = tensor.empty() : tensor<666x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<1x768xf32>) outs(%4 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    %2 = tensor.empty() : tensor<666x35x35x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x35x35x32xf32>) outs(%2 : tensor<666x35x35x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x35x35x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x320xf32>) -> tensor<128x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<128x1x1x320xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<666x14x14x1xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1600xf32>) -> tensor<666x14x14x1600xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1600xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1600xf32>) outs(%2 : tensor<666x14x14x1600xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1920xf32>) -> tensor<666x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1920xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x84xf32>) -> tensor<666x1x1x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x84xf32>) -> tensor<336x1x1x84xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x1x1x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x1x1x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x84xf32>, tensor<336x1x1x84xf32>) outs(%7 : tensor<666x1x1x336xf32>) -> tensor<666x1x1x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<864xf32>) -> tensor<864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<864xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<864xf32>, tensor<1xf32>) outs(%4 : tensor<864xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x7x7x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x7x7x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2240xf32>) -> tensor<1x1x1x2240xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2240xf32>, tensor<1x1x1x2240xf32>) outs(%4 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x912xf32>) -> tensor<1x666x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x912x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x912x1000xf32>) -> tensor<1x912x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x912xf32>, tensor<1x912x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x440xf32>) -> tensor<1x666x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x440x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x440x1000xf32>) -> tensor<1x440x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x440xf32>, tensor<1x440x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x17x17x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x896xf32>) -> tensor<666x28x28x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x28x28x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x28x28x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x1024xf32>, tensor<666x14x14x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x144xf32>) -> tensor<666x112x112x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x112x112x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x112x112x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1512xf32>) -> tensor<666x1x1x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1512xf32>, tensor<666x7x7x1512xf32>) outs(%4 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x32xf32>) -> tensor<666x1x1x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x32xf32>) -> tensor<320x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x1x1x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x1x1x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x32xf32>, tensor<320x1x1x32xf32>) outs(%7 : tensor<666x1x1x320xf32>) -> tensor<666x1x1x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x32xf32>) -> tensor<144x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x56x56x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<144x1x1x32xf32>) outs(%7 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1536xf32>) -> tensor<666x10x10x1536xf32>\n    %2 = tensor.empty() : tensor<666x10x10x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x10x10x1536xf32>) outs(%2 : tensor<666x10x10x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x10x10x1536xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = tensor.empty() : tensor<666x28x216xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x216xf32>) -> tensor<666x28x216xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x216xf32>) outs(%3 : tensor<666x28x216xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x216xf32> into tensor<666x1x28x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x3x3x128xf32>) -> tensor<128x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x128xf32> to tensor<666x30x30x128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x30x30x128xf32>, tensor<128x3x3x128xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x1x1x384xf32>) -> tensor<384x1x1x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x7x7x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x7x7x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x384xf32>, tensor<384x1x1x384xf32>) outs(%7 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x2048xf32>, tensor<666x7x7x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x208xf32>) -> tensor<666x1x1x208xf32>\n    %2 = tensor.empty() : tensor<666x1x1x208xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x208xf32>) outs(%2 : tensor<666x1x1x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x736xf32>) -> tensor<666x7x7x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x736xf32>) -> tensor<1x1x1x736xf32>\n    %4 = tensor.empty() : tensor<666x7x7x736xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x736xf32>, tensor<1x1x1x736xf32>) outs(%4 : tensor<666x7x7x736xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x14x14x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x14x14x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x240xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2048xf32>) -> tensor<666x8x8x2048xf32>\n    %2 = tensor.empty() : tensor<666x8x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x8x2048xf32>) -> tensor<666x8x2048xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x8x8x2048xf32>) outs(%3 : tensor<666x8x2048xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x8x2048xf32> into tensor<666x1x8x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %4 = tensor.empty() : tensor<666x14x14x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x336xf32>, tensor<666x14x14x336xf32>) outs(%4 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x1x1x512xf32>) -> tensor<1024x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<1024x1x1x512xf32>) outs(%7 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %2 = tensor.empty() : tensor<666x7x7x368xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x368xf32>) outs(%2 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x12xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    %2 = tensor.empty() : tensor<666x1x1x12xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x12xf32>) outs(%2 : tensor<666x1x1x12xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x12xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = tensor.empty() : tensor<666x56x128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x128xf32>) -> tensor<666x56x128xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x128xf32>) outs(%3 : tensor<666x56x128xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x128xf32> into tensor<666x1x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x448xf32>) -> tensor<666x14x14x448xf32>\n    %2 = tensor.empty() : tensor<666x14x14x448xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x448xf32>) outs(%2 : tensor<666x14x14x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x32xf32>) -> tensor<168x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x112x112x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x112x112x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<168x1x1x32xf32>) outs(%7 : tensor<666x112x112x168xf32>) -> tensor<666x112x112x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x96xf32>) -> tensor<96x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x28x28x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x28x28x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x96xf32>, tensor<96x1x1x96xf32>) outs(%7 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x14x14x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x224xf32>) -> tensor<666x112x112x224xf32>\n    %2 = tensor.empty() : tensor<666x112x112x224xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x224xf32>) outs(%2 : tensor<666x112x112x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<728xf32>) -> tensor<728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<728xf32>, tensor<1xf32>) outs(%4 : tensor<728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x256xf32>) -> tensor<256x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x56x56x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<256x1x1x256xf32>) outs(%7 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<176xf32>) -> tensor<176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<176xf32>, tensor<1xf32>) outs(%4 : tensor<176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3072xf32>) -> tensor<666x7x7x3072xf32>\n    %2 = tensor.empty() : tensor<666x7x7x3072xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x3072xf32>) outs(%2 : tensor<666x7x7x3072xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x147x147x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x147x147x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %4 = tensor.empty() : tensor<666x14x14x88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x88xf32>, tensor<666x14x14x88xf32>) outs(%4 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x24xf32>) -> tensor<666x112x112x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x24xf32>) -> tensor<1x1x1x24xf32>\n    %4 = tensor.empty() : tensor<666x112x112x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x24xf32>, tensor<1x1x1x24xf32>) outs(%4 : tensor<666x112x112x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<768x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<768x1x1x192xf32>) -> tensor<768x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<768xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<768xf32>) -> tensor<768xf32>\n    %6 = tensor.empty() : tensor<666x1x1x768xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<768xf32>) outs(%6 : tensor<666x1x1x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x768xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x192xf32>, tensor<768x1x1x192xf32>) outs(%7 : tensor<666x1x1x768xf32>) -> tensor<666x1x1x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<96xf32>) -> tensor<96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<96xf32>, tensor<1xf32>) outs(%4 : tensor<96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<666x28x28x1xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = tensor.empty() : tensor<666x28x28xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28xf32>) -> tensor<666x28x28xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x192xf32>) outs(%3 : tensor<666x28x28xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x28x28xf32> into tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x8192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x8192xf32>) -> tensor<1x32634x8192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x8192x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x8192x2048xf32>) -> tensor<1x8192x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x2048xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x2048xf32>) -> tensor<1x32634x2048xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x8192xf32>, tensor<1x8192x2048xf32>) outs(%5 : tensor<1x32634x2048xf32>) -> tensor<1x32634x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x64xf32>) -> tensor<128x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x147x147x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x147x147x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x147x147x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x147x147x64xf32>, tensor<128x1x1x64xf32>) outs(%7 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1624xf32>) -> tensor<1x1x1x1624xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1624xf32>, tensor<1x1x1x1624xf32>) outs(%4 : tensor<666x7x7x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2240xf32>) -> tensor<2240xf32>\n    %2 = tensor.empty() : tensor<2240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<2240xf32>) outs(%2 : tensor<2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x7x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x7x160xf32>) -> tensor<192x1x7x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 3, 0] high[0, 0, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x160xf32> to tensor<666x17x23x160xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x17x23x160xf32>, tensor<192x1x7x160xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<666x56x56x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x28x28x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = tensor.empty() : tensor<666x14x576xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x576xf32>) -> tensor<666x14x576xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x576xf32>) outs(%3 : tensor<666x14x576xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x576xf32> into tensor<666x1x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x84xf32>) -> tensor<666x1x1x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<888x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<888x1x1x84xf32>) -> tensor<888x1x1x84xf32>\n    %4 = bufferization.alloc_tensor() : tensor<888xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<888xf32>) -> tensor<888xf32>\n    %6 = tensor.empty() : tensor<666x1x1x888xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<888xf32>) outs(%6 : tensor<666x1x1x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x888xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x84xf32>, tensor<888x1x1x84xf32>) outs(%7 : tensor<666x1x1x888xf32>) -> tensor<666x1x1x888xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x768xf32>) -> tensor<1x130536x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x768x3072xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x768x3072xf32>) -> tensor<1x768x3072xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x3072xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x3072xf32>) -> tensor<1x130536x3072xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x768xf32>, tensor<1x768x3072xf32>) outs(%5 : tensor<1x130536x3072xf32>) -> tensor<1x130536x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x14x14x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x14x14x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x14x14x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x24xf32>) -> tensor<666x1x1x24xf32>\n    %2 = tensor.empty() : tensor<666x1x1x24xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x24xf32>) outs(%2 : tensor<666x1x1x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x14x14x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1344xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x56xf32>) -> tensor<666x1x28x56xf32>\n    %2 = tensor.empty() : tensor<666x1x56xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x56xf32>) -> tensor<666x1x56xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x56xf32>) outs(%3 : tensor<666x1x56xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x56xf32> into tensor<666x1x1x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1248xf32>) -> tensor<666x7x7x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1248xf32>) -> tensor<1x1x1x1248xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1248xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1248xf32>, tensor<1x1x1x1248xf32>) outs(%4 : tensor<666x7x7x1248xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x14x14x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x44xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x44xf32>) -> tensor<1x1x1x44xf32>\n    %4 = tensor.empty() : tensor<666x28x28x44xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x44xf32>, tensor<1x1x1x44xf32>) outs(%4 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x992xf32>) -> tensor<666x14x14x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x992xf32>) -> tensor<1x1x1x992xf32>\n    %4 = tensor.empty() : tensor<666x14x14x992xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x992xf32>, tensor<1x1x1x992xf32>) outs(%4 : tensor<666x14x14x992xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x32xf32>) -> tensor<336x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x112x112x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x112x112x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<336x1x1x32xf32>) outs(%7 : tensor<666x112x112x336xf32>) -> tensor<666x112x112x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %4 = tensor.empty() : tensor<666x28x28x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x696xf32>, tensor<666x28x28x696xf32>) outs(%4 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x7x7x176xf32> to tensor<666x9x9x176xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x7x7x176xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x9x9x176xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %c1 = arith.constant 1 : index\n    %c7 = arith.constant 7 : index\n    %c2 = arith.constant 2 : index\n    %c7_2 = arith.constant 7 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c7, %c1_3 : index\n    %7 = arith.subi %c7_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x7x7x176xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x7x7x176xf32>) outs(%8 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<696xf32>) -> tensor<696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<696xf32>, tensor<1xf32>) outs(%4 : tensor<696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x16xf32>) -> tensor<666x112x112x16xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x16xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x16xf32>) -> tensor<96x1x1x16xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x112x112x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x112x112x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x16xf32>, tensor<96x1x1x16xf32>) outs(%7 : tensor<666x112x112x96xf32>) -> tensor<666x112x112x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<672xf32>) -> tensor<672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<672xf32>, tensor<1xf32>) outs(%4 : tensor<672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1392xf32>, tensor<666x14x14x1392xf32>) outs(%4 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x64xf32>) -> tensor<666x224x224x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x64xf32>) -> tensor<64x3x3x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x224x224x64xf32> to tensor<666x226x226x64xf32>\n    %6 = tensor.empty() : tensor<666x224x224x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x224x224x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x224x224x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x226x226x64xf32>, tensor<64x3x3x64xf32>) outs(%7 : tensor<666x224x224x64xf32>) -> tensor<666x224x224x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1152xf32>) -> tensor<666x7x7x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1152xf32>) -> tensor<1x1x1x1152xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1152xf32>, tensor<1x1x1x1152xf32>) outs(%4 : tensor<666x7x7x1152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x544xf32>) -> tensor<666x7x7x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x544xf32>) -> tensor<128x1x1x544xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x544xf32>, tensor<128x1x1x544xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x115x115x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x115x115x32xf32>) -> tensor<666x115x115x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x32x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x32x1xf32>) -> tensor<5x5x32x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x56x56x32x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x56x56x32x1xf32>) -> tensor<666x56x56x32x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x32xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x115x115x32xf32>, tensor<5x5x32x1xf32>) outs(%7 : tensor<666x56x56x32x1xf32>) -> tensor<666x56x56x32x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x32x1xf32> into tensor<666x56x56x32xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<32xf32>, tensor<666x56x56x32xf32>) outs(%8 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1392xf32>) -> tensor<1x1x1x1392xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1392xf32>, tensor<1x1x1x1392xf32>) outs(%4 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x17x17x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x1088xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x17x17x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x1x1x160xf32>) -> tensor<384x1x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x7x7x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x7x7x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x160xf32>, tensor<384x1x1x160xf32>) outs(%7 : tensor<666x7x7x384xf32>) -> tensor<666x7x7x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x4096xf32>) -> tensor<666x7x7x4096xf32>\n    %2 = tensor.empty() : tensor<666x7x7x4096xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x4096xf32>) outs(%2 : tensor<666x7x7x4096xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3024xf32>, tensor<666x7x7x3024xf32>) outs(%4 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x308xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x308xf32>) -> tensor<666x1x1x308xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3024x1x1x308xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3024x1x1x308xf32>) -> tensor<3024x1x1x308xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3024xf32>) -> tensor<3024xf32>\n    %6 = tensor.empty() : tensor<666x1x1x3024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3024xf32>) outs(%6 : tensor<666x1x1x3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x3024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x308xf32>, tensor<3024x1x1x308xf32>) outs(%7 : tensor<666x1x1x3024xf32>) -> tensor<666x1x1x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x448xf32>) -> tensor<448x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x28x28x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<448x1x1x448xf32>) outs(%7 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<104x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<104x1x1x104xf32>) -> tensor<104x1x1x104xf32>\n    %4 = bufferization.alloc_tensor() : tensor<104xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<104xf32>) -> tensor<104xf32>\n    %6 = tensor.empty() : tensor<666x28x28x104xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<104xf32>) outs(%6 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x104xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x104xf32>, tensor<104x1x1x104xf32>) outs(%7 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x1344xf32>) -> tensor<666x21x21x1344xf32>\n    %2 = tensor.empty() : tensor<666x21x21x1344xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x21x21x1344xf32>) outs(%2 : tensor<666x21x21x1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x21x21x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1088xf32>) outs(%2 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x696xf32>) -> tensor<1x1x1x696xf32>\n    %4 = tensor.empty() : tensor<666x28x28x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x696xf32>, tensor<1x1x1x696xf32>) outs(%4 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %2 = tensor.empty() : tensor<666x7x2016xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x2016xf32>) -> tensor<666x7x2016xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x2016xf32>) outs(%3 : tensor<666x7x2016xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x2016xf32> into tensor<666x1x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x768xf32>) -> tensor<666x28x28x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x768xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<666x56x56x1xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x192xf32>) -> tensor<512x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x14x14x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<512x1x1x192xf32>) outs(%7 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2048xf32>, tensor<666x14x14x2048xf32>) outs(%4 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x32xf32>) -> tensor<666x147x147x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x32xf32>) -> tensor<64x3x3x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x147x147x32xf32> to tensor<666x149x149x32xf32>\n    %6 = tensor.empty() : tensor<666x147x147x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x147x147x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x147x147x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x149x149x32xf32>, tensor<64x3x3x32xf32>) outs(%7 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1184xf32>) -> tensor<666x7x7x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1184xf32>) -> tensor<1x1x1x1184xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1184xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1184xf32>, tensor<1x1x1x1184xf32>) outs(%4 : tensor<666x7x7x1184xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1472xf32>) -> tensor<666x14x14x1472xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1472xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1472xf32>) outs(%2 : tensor<666x14x14x1472xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x144xf32>) -> tensor<666x112x112x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x112x112x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x112x112x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<16xf32>) -> tensor<16xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<16xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<16xf32>, tensor<1xf32>) outs(%4 : tensor<16xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x128xf32>) -> tensor<8x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<8x1x1x128xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x160xf32>) -> tensor<666x28x28x160xf32>\n    %2 = tensor.empty() : tensor<666x28x28x160xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x160xf32>) outs(%2 : tensor<666x28x28x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1216xf32>) -> tensor<666x14x14x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1216xf32>) -> tensor<1x1x1x1216xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1216xf32>, tensor<1x1x1x1216xf32>) outs(%4 : tensor<666x14x14x1216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<960xf32>) -> tensor<960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<960xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<960xf32>, tensor<1xf32>) outs(%4 : tensor<960xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %4 = tensor.empty() : tensor<666x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x768xf32>, tensor<666x1xf32>) outs(%4 : tensor<666x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1120xf32>) -> tensor<666x14x14x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1120xf32>) -> tensor<128x1x1x1120xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1120xf32>, tensor<128x1x1x1120xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x7x7x2048xf32>, tensor<666x7x7x2048xf32>) outs(%2 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x480xf32>) -> tensor<666x14x14x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x480xf32>) -> tensor<1x1x1x480xf32>\n    %4 = tensor.empty() : tensor<666x14x14x480xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x480xf32>, tensor<1x1x1x480xf32>) outs(%4 : tensor<666x14x14x480xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x480xf32>) -> tensor<666x14x14x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x480xf32>) -> tensor<1x1x1x480xf32>\n    %4 = tensor.empty() : tensor<666x14x14x480xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x480xf32>, tensor<1x1x1x480xf32>) outs(%4 : tensor<666x14x14x480xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<384xf32>) -> tensor<384xf32>\n    %2 = tensor.empty() : tensor<384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<384xf32>) outs(%2 : tensor<384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x6xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x6xf32>) -> tensor<666x1x1x6xf32>\n    %2 = tensor.empty() : tensor<666x1x1x6xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x6xf32>) outs(%2 : tensor<666x1x1x6xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x6xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<888x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<888x1x1x336xf32>) -> tensor<888x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<888xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<888xf32>) -> tensor<888xf32>\n    %6 = tensor.empty() : tensor<666x14x14x888xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<888xf32>) outs(%6 : tensor<666x14x14x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x888xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x336xf32>, tensor<888x1x1x336xf32>) outs(%7 : tensor<666x14x14x888xf32>) -> tensor<666x14x14x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x288xf32>) -> tensor<288x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x28x28x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<288x1x1x288xf32>) outs(%7 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x232xf32>) -> tensor<666x112x112x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x232xf32>) -> tensor<1x1x1x232xf32>\n    %4 = tensor.empty() : tensor<666x112x112x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x232xf32>, tensor<1x1x1x232xf32>) outs(%4 : tensor<666x112x112x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3xf32>) -> tensor<1x1x1x3xf32>\n    %4 = tensor.empty() : tensor<666x224x224x3xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x224x224x3xf32>, tensor<1x1x1x3xf32>) outs(%4 : tensor<666x224x224x3xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x224x224x3xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = tensor.empty() : tensor<666x42x42x168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x42x42x168xf32>, tensor<666x42x42x168xf32>) outs(%2 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.addf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3712xf32>) -> tensor<1x1x1x3712xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3712xf32>, tensor<1x1x1x3712xf32>) outs(%4 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<84xf32>) -> tensor<84xf32>\n    %2 = tensor.empty() : tensor<84xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<84xf32>) outs(%2 : tensor<84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1344xf32>) -> tensor<666x7x7x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x7x7x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<896xf32>) -> tensor<896xf32>\n    %2 = tensor.empty() : tensor<896xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<896xf32>) outs(%2 : tensor<896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<896xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x114x114x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x114x114x64xf32>) -> tensor<666x114x114x64xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x56x56x64xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x114x114x64xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x1024x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x1024x1xf32>) -> tensor<3x3x1024x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x10x10x1024xf32> to tensor<666x12x12x1024xf32>\n    %6 = tensor.empty() : tensor<666x10x10x1024x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x10x10x1024x1xf32>) -> tensor<666x10x10x1024x1xf32>\n    %8 = tensor.empty() : tensor<666x10x10x1024xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x12x12x1024xf32>, tensor<3x3x1024x1xf32>) outs(%7 : tensor<666x10x10x1024x1xf32>) -> tensor<666x10x10x1024x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x10x10x1024x1xf32> into tensor<666x10x10x1024xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<1024xf32>, tensor<666x10x10x1024xf32>) outs(%8 : tensor<666x10x10x1024xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x10x10x1024xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x1024xf32>) -> tensor<1x2088576x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1024x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1024x256xf32>) -> tensor<1x1024x256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x256xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x256xf32>) -> tensor<1x2088576x256xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x1024xf32>, tensor<1x1024x256xf32>) outs(%5 : tensor<1x2088576x256xf32>) -> tensor<1x2088576x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1888xf32>) -> tensor<666x7x7x1888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1888xf32>) -> tensor<1x1x1x1888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1888xf32>, tensor<1x1x1x1888xf32>) outs(%4 : tensor<666x7x7x1888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1888xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x2088576x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x2088576x192xf32>) -> tensor<1x2088576x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x192x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x192x768xf32>) -> tensor<1x192x768xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x2088576x768xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x2088576x768xf32>) -> tensor<1x2088576x768xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x2088576x192xf32>, tensor<1x192x768xf32>) outs(%5 : tensor<1x2088576x768xf32>) -> tensor<1x2088576x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<432xf32>) -> tensor<432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<432xf32>, tensor<1xf32>) outs(%4 : tensor<432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x608xf32>) -> tensor<666x1x1x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<152x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<152x1x1x608xf32>) -> tensor<152x1x1x608xf32>\n    %4 = bufferization.alloc_tensor() : tensor<152xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<152xf32>) -> tensor<152xf32>\n    %6 = tensor.empty() : tensor<666x1x1x152xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<152xf32>) outs(%6 : tensor<666x1x1x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x152xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x608xf32>, tensor<152x1x1x608xf32>) outs(%7 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    %2 = tensor.empty() : tensor<666x1x1x152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x152xf32>) outs(%2 : tensor<666x1x1x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<24x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<24x1x1x32xf32>) -> tensor<24x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<24xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<24xf32>) -> tensor<24xf32>\n    %6 = tensor.empty() : tensor<666x56x56x24xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<24xf32>) outs(%6 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x24xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<24x1x1x32xf32>) outs(%7 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x384xf32>) -> tensor<666x56x56x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x384xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x14x14x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x128xf32>) -> tensor<256x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x37x37x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x37x37x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x37x37x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x74x74x128xf32>, tensor<256x1x1x128xf32>) outs(%7 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<392x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<392x1x1x392xf32>) -> tensor<392x1x1x392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<392xf32>) -> tensor<392xf32>\n    %6 = tensor.empty() : tensor<666x28x28x392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<392xf32>) outs(%6 : tensor<666x28x28x392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x392xf32>, tensor<392x1x1x392xf32>) outs(%7 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x64xf32>) -> tensor<128x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<128x1x1x64xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = tensor.empty() : tensor<666x7x1024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1024xf32>) -> tensor<666x7x1024xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1024xf32>) outs(%3 : tensor<666x7x1024xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1024xf32> into tensor<666x1x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x352xf32>) -> tensor<666x14x14x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<88x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<88x1x1x352xf32>) -> tensor<88x1x1x352xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<88xf32>) outs(%6 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x88xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x352xf32>, tensor<88x1x1x352xf32>) outs(%7 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1360xf32>) -> tensor<666x14x14x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1360xf32>) -> tensor<1x1x1x1360xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1360xf32>, tensor<1x1x1x1360xf32>) outs(%4 : tensor<666x14x14x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x56x56x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x28x28x256xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x56x56x256xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x168xf32>) -> tensor<666x83x83x168xf32>\n    %2 = tensor.empty() : tensor<666x83x83x168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x83x83x168xf32>) outs(%2 : tensor<666x83x83x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x83x83x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<240x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<240x1x1x96xf32>) -> tensor<240x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<240xf32>) -> tensor<240xf32>\n    %6 = tensor.empty() : tensor<666x28x28x240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<240xf32>) outs(%6 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x96xf32>, tensor<240x1x1x96xf32>) outs(%7 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x54xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x54xf32>) -> tensor<666x1x1x54xf32>\n    %2 = bufferization.alloc_tensor() : tensor<216x1x1x54xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<216x1x1x54xf32>) -> tensor<216x1x1x54xf32>\n    %4 = bufferization.alloc_tensor() : tensor<216xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<216xf32>) -> tensor<216xf32>\n    %6 = tensor.empty() : tensor<666x1x1x216xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<216xf32>) outs(%6 : tensor<666x1x1x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x216xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x54xf32>, tensor<216x1x1x54xf32>) outs(%7 : tensor<666x1x1x216xf32>) -> tensor<666x1x1x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x74x74x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x74x74x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x74x74x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x74x74x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x115x115x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x115x115x11xf32>) -> tensor<666x115x115x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x11x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x11x1xf32>) -> tensor<5x5x11x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<11xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<11xf32>) -> tensor<11xf32>\n    %6 = tensor.empty() : tensor<666x56x56x11x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x11xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x115x115x11xf32>, tensor<5x5x11x1xf32>) outs(%7 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x11x1xf32> into tensor<666x56x56x11xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<11xf32>, tensor<666x56x56x11xf32>) outs(%8 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x528xf32>) -> tensor<1x1x1x528xf32>\n    %4 = tensor.empty() : tensor<666x14x14x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x528xf32>, tensor<1x1x1x528xf32>) outs(%4 : tensor<666x14x14x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1088xf32>) -> tensor<666x1x1x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<272x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<272x1x1x1088xf32>) -> tensor<272x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<272xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<272xf32>) -> tensor<272xf32>\n    %6 = tensor.empty() : tensor<666x1x1x272xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<272xf32>) outs(%6 : tensor<666x1x1x272xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x272xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1088xf32>, tensor<272x1x1x1088xf32>) outs(%7 : tensor<666x1x1x272xf32>) -> tensor<666x1x1x272xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<666x56x56x1xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x30x30x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x30x30x128xf32>) -> tensor<666x30x30x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x3x3x128xf32>) -> tensor<128x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x30x30x128xf32>, tensor<128x3x3x128xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x672xf32>) -> tensor<666x21x21x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x21x21x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x21x21x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x21x21x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x21x21x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<736xf32>) -> tensor<736xf32>\n    %2 = tensor.empty() : tensor<736xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<736xf32>) outs(%2 : tensor<736xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x896xf32>) -> tensor<666x7x7x896xf32>\n    %2 = tensor.empty() : tensor<666x7x7x896xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x896xf32>) outs(%2 : tensor<666x7x7x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1696xf32>) -> tensor<666x14x14x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1696xf32>) -> tensor<1x1x1x1696xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1696xf32>, tensor<1x1x1x1696xf32>) outs(%4 : tensor<666x14x14x1696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1232xf32>) -> tensor<666x1x1x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<308x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<308x1x1x1232xf32>) -> tensor<308x1x1x1232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<308xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<308xf32>) -> tensor<308xf32>\n    %6 = tensor.empty() : tensor<666x1x1x308xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<308xf32>) outs(%6 : tensor<666x1x1x308xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x308xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1232xf32>, tensor<308x1x1x1232xf32>) outs(%7 : tensor<666x1x1x308xf32>) -> tensor<666x1x1x308xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x88xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x88xf32>) -> tensor<1x1x1x88xf32>\n    %4 = tensor.empty() : tensor<666x14x14x88xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x88xf32>, tensor<1x1x1x88xf32>) outs(%4 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1536xf32>) -> tensor<666x8x8x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x8x8x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x8x8x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x1536xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x888xf32>) -> tensor<666x1x7x888xf32>\n    %2 = tensor.empty() : tensor<666x1x888xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x888xf32>) -> tensor<666x1x888xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x888xf32>) outs(%3 : tensor<666x1x888xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x888xf32> into tensor<666x1x1x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1056xf32>) -> tensor<666x7x7x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1056xf32>) -> tensor<1x1x1x1056xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1056xf32>, tensor<1x1x1x1056xf32>) outs(%4 : tensor<666x7x7x1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x6144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x6144xf32>) -> tensor<666x7x7x6144xf32>\n    %2 = tensor.empty() : tensor<666x7x7x6144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x6144xf32>) outs(%2 : tensor<666x7x7x6144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x6144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x7x7x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x7x7x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x160xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x112xf32>) -> tensor<666x1x28x112xf32>\n    %2 = tensor.empty() : tensor<666x1x112xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x112xf32>) -> tensor<666x1x112xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x112xf32>) outs(%3 : tensor<666x1x112xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x112xf32> into tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x32xf32>) -> tensor<666x111x111x32xf32>\n    %2 = tensor.empty() : tensor<666x111x111x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x111x111x32xf32>) outs(%2 : tensor<666x111x111x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x111x111x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %4 = tensor.empty() : tensor<666x14x14x784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x784xf32>, tensor<666x14x14x784xf32>) outs(%4 : tensor<666x14x14x784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2520x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2520x1x1x1344xf32>) -> tensor<2520x1x1x1344xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2520xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2520xf32>) -> tensor<2520xf32>\n    %6 = tensor.empty() : tensor<666x14x14x2520xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2520xf32>) outs(%6 : tensor<666x14x14x2520xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x2520xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<2520x1x1x1344xf32>) outs(%7 : tensor<666x14x14x2520xf32>) -> tensor<666x14x14x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x512xf32>) -> tensor<666x1x1x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x512xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x120xf32>) -> tensor<666x56x56x120xf32>\n    %2 = tensor.empty() : tensor<666x56x56x120xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x120xf32>) outs(%2 : tensor<666x56x56x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x7x7x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x7x7x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<666x14x14x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x528xf32>) -> tensor<666x7x7x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<88x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<88x1x1x528xf32>) -> tensor<88x1x1x528xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %6 = tensor.empty() : tensor<666x7x7x88xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<88xf32>) outs(%6 : tensor<666x7x7x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x88xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x528xf32>, tensor<88x1x1x528xf32>) outs(%7 : tensor<666x7x7x88xf32>) -> tensor<666x7x7x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<216x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<216x1x1x216xf32>) -> tensor<216x1x1x216xf32>\n    %4 = bufferization.alloc_tensor() : tensor<216xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<216xf32>) -> tensor<216xf32>\n    %6 = tensor.empty() : tensor<666x28x28x216xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<216xf32>) outs(%6 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x216xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x216xf32>, tensor<216x1x1x216xf32>) outs(%7 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x15x15x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x15x15x176xf32>) -> tensor<666x15x15x176xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x7x7x176xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x15x15x176xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x192xf32> to tensor<666x37x37x192xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x35x35x192xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x37x37x192xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %c1 = arith.constant 1 : index\n    %c35 = arith.constant 35 : index\n    %c2 = arith.constant 2 : index\n    %c35_2 = arith.constant 35 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c35, %c1_3 : index\n    %7 = arith.subi %c35_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x35x35x192xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x35x35x192xf32>) outs(%8 : tensor<666x35x35x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x35x35x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<736xf32>) -> tensor<736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<736xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<736xf32>, tensor<1xf32>) outs(%4 : tensor<736xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<736xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x2x2x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x2x2x256xf32>) -> tensor<512x2x2x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x14x14x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<512x2x2x256xf32>) outs(%7 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x192xf32>) -> tensor<96x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x35x35x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x35x35x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x192xf32>, tensor<96x1x1x192xf32>) outs(%7 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<666x56x56x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x48xf32>) -> tensor<48x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x56x56x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<48x1x1x48xf32>) outs(%7 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1696xf32>) -> tensor<666x14x14x1696xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1696xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1696xf32>) outs(%2 : tensor<666x14x14x1696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x3x3x128xf32>) -> tensor<128x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x112x112x128xf32> to tensor<666x114x114x128xf32>\n    %6 = tensor.empty() : tensor<666x112x112x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x112x112x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x114x114x128xf32>, tensor<128x3x3x128xf32>) outs(%7 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<18x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<18x1x1x72xf32>) -> tensor<18x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<18xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<18xf32>) -> tensor<18xf32>\n    %6 = tensor.empty() : tensor<666x1x1x18xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<18xf32>) outs(%6 : tensor<666x1x1x18xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x18xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x72xf32>, tensor<18x1x1x72xf32>) outs(%7 : tensor<666x1x1x18xf32>) -> tensor<666x1x1x18xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1792xf32>) -> tensor<666x14x14x1792xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1792xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1792xf32>) outs(%2 : tensor<666x14x14x1792xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x888xf32>) -> tensor<1x1x1x888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x888xf32>, tensor<1x1x1x888xf32>) outs(%4 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2240xf32>) -> tensor<666x14x14x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2240xf32>) -> tensor<1x1x1x2240xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2240xf32>, tensor<1x1x1x2240xf32>) outs(%4 : tensor<666x14x14x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x704xf32>) -> tensor<666x7x7x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<176x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<176x1x1x704xf32>) -> tensor<176x1x1x704xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<176xf32>) outs(%6 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x176xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x704xf32>, tensor<176x1x1x704xf32>) outs(%7 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x128xf32>) -> tensor<512x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x1x1x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x1x1x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<512x1x1x128xf32>) outs(%7 : tensor<666x1x1x512xf32>) -> tensor<666x1x1x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x37x37x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x37x37x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x37x37x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x8xf32>) -> tensor<128x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x1x1x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x1x1x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<128x1x1x8xf32>) outs(%7 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x2x2x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x2x2x512xf32>) -> tensor<1024x2x2x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<1024x2x2x512xf32>) outs(%7 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x168xf32>) -> tensor<168x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x56x56x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<168x1x1x168xf32>) outs(%7 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<528x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<528x1x1x240xf32>) -> tensor<528x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<528xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<528xf32>) -> tensor<528xf32>\n    %6 = tensor.empty() : tensor<666x14x14x528xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<528xf32>) outs(%6 : tensor<666x14x14x528xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x528xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x240xf32>, tensor<528x1x1x240xf32>) outs(%7 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x3024xf32>) -> tensor<1x666x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x3024x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x3024x1000xf32>) -> tensor<1x3024x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x3024xf32>, tensor<1x3024x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x33x33x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x33x33x88xf32>) -> tensor<666x33x33x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x88x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x88x1xf32>) -> tensor<7x7x88x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x88xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x33x33x88xf32>, tensor<7x7x88x1xf32>) outs(%7 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x88x1xf32> into tensor<666x14x14x88xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<88xf32>, tensor<666x14x14x88xf32>) outs(%8 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<208x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<208x1x1x104xf32>) -> tensor<208x1x1x104xf32>\n    %4 = bufferization.alloc_tensor() : tensor<208xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<208xf32>) -> tensor<208xf32>\n    %6 = tensor.empty() : tensor<666x14x14x208xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<208xf32>) outs(%6 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x208xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x104xf32>, tensor<208x1x1x104xf32>) outs(%7 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1088x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1088x1x1x512xf32>) -> tensor<1088x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1088xf32>) -> tensor<1088xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1088xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1088xf32>) outs(%6 : tensor<666x14x14x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1088xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<1088x1x1x512xf32>) outs(%7 : tensor<666x14x14x1088xf32>) -> tensor<666x14x14x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %2 = tensor.empty() : tensor<666x147x147x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x147x147x64xf32>) outs(%2 : tensor<666x147x147x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x147x147x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<336xf32>) -> tensor<336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<336xf32>, tensor<1xf32>) outs(%4 : tensor<336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2240x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2240x1x1x896xf32>) -> tensor<2240x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2240xf32>) -> tensor<2240xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2240xf32>) outs(%6 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<2240x1x1x896xf32>) outs(%7 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x112x112x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x112x112x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1008x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1008x1x1x432xf32>) -> tensor<1008x1x1x432xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1008xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1008xf32>) -> tensor<1008xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1008xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1008xf32>) outs(%6 : tensor<666x14x14x1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1008xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x432xf32>, tensor<1008x1x1x432xf32>) outs(%7 : tensor<666x14x14x1008xf32>) -> tensor<666x14x14x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<666x7x7x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x32xf32>) -> tensor<666x147x147x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x147x147x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x147x147x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x368xf32>) -> tensor<666x14x14x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x368xf32>) -> tensor<1x1x1x368xf32>\n    %4 = tensor.empty() : tensor<666x14x14x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x368xf32>, tensor<1x1x1x368xf32>) outs(%4 : tensor<666x14x14x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x192xf32>, tensor<666x56x56x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1728xf32>) -> tensor<666x7x7x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1728xf32>) -> tensor<1x1x1x1728xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1728xf32>, tensor<1x1x1x1728xf32>) outs(%4 : tensor<666x7x7x1728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x56xf32>) -> tensor<666x56x56x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x56xf32>) -> tensor<1x1x1x56xf32>\n    %4 = tensor.empty() : tensor<666x56x56x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x56xf32>, tensor<1x1x1x56xf32>) outs(%4 : tensor<666x56x56x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1392xf32>) -> tensor<666x1x1x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1392xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x14x14x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1296xf32>) -> tensor<666x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1296xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x896xf32>) -> tensor<666x7x7x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x7x7x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x7x7x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = tensor.empty() : tensor<666x28x28x240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x240xf32>) outs(%2 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x30x30x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x30x30x128xf32>) -> tensor<666x30x30x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x3x3x128xf32>) -> tensor<128x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x30x30x128xf32>, tensor<128x3x3x128xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x928xf32>) -> tensor<666x7x7x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x928xf32>) -> tensor<128x1x1x928xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x928xf32>, tensor<128x1x1x928xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x832xf32>) -> tensor<666x14x14x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x832xf32>) -> tensor<1x1x1x832xf32>\n    %4 = tensor.empty() : tensor<666x14x14x832xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x832xf32>, tensor<1x1x1x832xf32>) outs(%4 : tensor<666x14x14x832xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3072xf32>) -> tensor<666x14x14x3072xf32>\n    %2 = tensor.empty() : tensor<666x14x14x3072xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x3072xf32>) outs(%2 : tensor<666x14x14x3072xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1312xf32>) -> tensor<1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1312xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1312xf32>, tensor<1xf32>) outs(%4 : tensor<1312xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<728x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<728x1x1x256xf32>) -> tensor<728x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<728xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<728xf32>) -> tensor<728xf32>\n    %6 = tensor.empty() : tensor<666x37x37x728xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<728xf32>) outs(%6 : tensor<666x37x37x728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x37x37x728xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x37x37x256xf32>, tensor<728x1x1x256xf32>) outs(%7 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x640xf32>) -> tensor<666x14x14x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x640xf32>) -> tensor<1x1x1x640xf32>\n    %4 = tensor.empty() : tensor<666x14x14x640xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x640xf32>, tensor<1x1x1x640xf32>) outs(%4 : tensor<666x14x14x640xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x14x14x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    %2 = tensor.empty() : tensor<666x112x112x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x64xf32>) outs(%2 : tensor<666x112x112x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1696xf32>) -> tensor<666x7x7x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1696xf32>) -> tensor<1x1x1x1696xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1696xf32>, tensor<1x1x1x1696xf32>) outs(%4 : tensor<666x7x7x1696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x14x14x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %4 = tensor.empty() : tensor<666x14x14x432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x432xf32>, tensor<666x14x14x432xf32>) outs(%4 : tensor<666x14x14x432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1184xf32>) -> tensor<666x7x7x1184xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1184xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1184xf32>) outs(%2 : tensor<666x7x7x1184xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x288xf32>) -> tensor<666x8x8x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x8x8x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x8x8x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x35x35x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    %2 = tensor.empty() : tensor<666x112x112x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x128xf32>) outs(%2 : tensor<666x112x112x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = tensor.empty() : tensor<666x7x7xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7xf32>) -> tensor<666x7x7xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1536xf32>) outs(%3 : tensor<666x7x7xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x7x7xf32> into tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<960xf32>) -> tensor<960xf32>\n    %2 = tensor.empty() : tensor<960xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<960xf32>) outs(%2 : tensor<960xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x37x37x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x37x37x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x37x37x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1232xf32>, tensor<666x14x14x1232xf32>) outs(%4 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x576xf32>) -> tensor<96x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x14x14x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x14x14x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<96x1x1x576xf32>) outs(%7 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1024xf32>) -> tensor<1x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %4 = tensor.empty() : tensor<666x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1024xf32>, tensor<666x1024xf32>) outs(%4 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x80xf32>) -> tensor<666x1x1x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<768x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<768x1x1x80xf32>) -> tensor<768x1x1x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<768xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<768xf32>) -> tensor<768xf32>\n    %6 = tensor.empty() : tensor<666x1x1x768xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<768xf32>) outs(%6 : tensor<666x1x1x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x768xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x80xf32>, tensor<768x1x1x80xf32>) outs(%7 : tensor<666x1x1x768xf32>) -> tensor<666x1x1x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x32xf32>) -> tensor<48x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x112x112x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x112x112x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<48x1x1x32xf32>) outs(%7 : tensor<666x112x112x48xf32>) -> tensor<666x112x112x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x15x15x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x15x15x176xf32>) -> tensor<666x15x15x176xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x7x7x176xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x15x15x176xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %c1 = arith.constant 1 : index\n    %c7 = arith.constant 7 : index\n    %c2 = arith.constant 2 : index\n    %c7_1 = arith.constant 7 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c7, %c1_2 : index\n    %7 = arith.subi %c7_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x7x7x176xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x7x7x176xf32>) outs(%8 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = tensor.empty() : tensor<666x28x28x56xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x56xf32>) outs(%2 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x54xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x54xf32>) -> tensor<666x1x1x54xf32>\n    %2 = tensor.empty() : tensor<666x1x1x54xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x54xf32>) outs(%2 : tensor<666x1x1x54xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x54xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    %2 = tensor.empty() : tensor<666x1x1x576xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x576xf32>) outs(%2 : tensor<666x1x1x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2240xf32>) -> tensor<666x14x14x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2240xf32>) -> tensor<1x1x1x2240xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2240xf32>, tensor<1x1x1x2240xf32>) outs(%4 : tensor<666x14x14x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1824xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1824xf32>) -> tensor<666x7x7x1824xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1824xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1824xf32>) -> tensor<1x1x1x1824xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1824xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1824xf32>, tensor<1x1x1x1824xf32>) outs(%4 : tensor<666x7x7x1824xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1824xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x448xf32>) -> tensor<666x56x56x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x56x56x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x56x56x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2016xf32>) -> tensor<666x7x7x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2016xf32>) -> tensor<1x1x1x2016xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2016xf32>, tensor<1x1x1x2016xf32>) outs(%4 : tensor<666x7x7x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = tensor.empty() : tensor<666x56x56x11xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x11xf32>) outs(%2 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x544xf32>) -> tensor<666x7x7x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x544xf32>) -> tensor<1x1x1x544xf32>\n    %4 = tensor.empty() : tensor<666x7x7x544xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x544xf32>, tensor<1x1x1x544xf32>) outs(%4 : tensor<666x7x7x544xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1360xf32>) -> tensor<666x14x14x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1360xf32>) -> tensor<1x1x1x1360xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1360xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1360xf32>, tensor<1x1x1x1360xf32>) outs(%4 : tensor<666x14x14x1360xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1088xf32>) -> tensor<666x14x14x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1088xf32>) -> tensor<1x1x1x1088xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1088xf32>, tensor<1x1x1x1088xf32>) outs(%4 : tensor<666x14x14x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x672xf32>) -> tensor<672x1x1x672xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x7x7x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x7x7x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x672xf32>, tensor<672x1x1x672xf32>) outs(%7 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %4 = tensor.empty() : tensor<666x28x28x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<666x28x28x64xf32>) outs(%4 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x72xf32>) -> tensor<168x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x56x56x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<168x1x1x72xf32>) outs(%7 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x168xf32>) -> tensor<448x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x28x28x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<448x1x1x168xf32>) outs(%7 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %4 = tensor.empty() : tensor<666x19x19x728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x19x19x728xf32>, tensor<666x19x19x728xf32>) outs(%4 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x224xf32>) -> tensor<666x28x28x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x28x28x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x28x28x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1792xf32>) -> tensor<666x7x7x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1792xf32>) -> tensor<1x1x1x1792xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1792xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1792xf32>, tensor<1x1x1x1792xf32>) outs(%4 : tensor<666x7x7x1792xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x8x8x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<24x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<24x1x1x96xf32>) -> tensor<24x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<24xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<24xf32>) -> tensor<24xf32>\n    %6 = tensor.empty() : tensor<666x56x56x24xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<24xf32>) outs(%6 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x24xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<24x1x1x96xf32>) outs(%7 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<72x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<72x1x1x32xf32>) -> tensor<72x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<72xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<72xf32>) -> tensor<72xf32>\n    %6 = tensor.empty() : tensor<666x112x112x72xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<72xf32>) outs(%6 : tensor<666x112x112x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x72xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<72x1x1x32xf32>) outs(%7 : tensor<666x112x112x72xf32>) -> tensor<666x112x112x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x560xf32>) -> tensor<666x28x28x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x560xf32>) -> tensor<1x1x1x560xf32>\n    %4 = tensor.empty() : tensor<666x28x28x560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x560xf32>, tensor<1x1x1x560xf32>) outs(%4 : tensor<666x28x28x560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = tensor.empty() : tensor<666x14x14x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x336xf32>) outs(%2 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x42xf32>) -> tensor<666x165x165x42xf32>\n    %2 = tensor.empty() : tensor<666x165x165x42xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x165x165x42xf32>) outs(%2 : tensor<666x165x165x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x165x165x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %4 = tensor.empty() : tensor<666x56x56x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<666x56x56x72xf32>) outs(%4 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x120xf32>) -> tensor<666x1x1x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %4 = tensor.empty() : tensor<666x28x28x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x120xf32>, tensor<666x28x28x120xf32>) outs(%4 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x232xf32>) -> tensor<666x1x1x232xf32>\n    %2 = tensor.empty() : tensor<666x1x1x232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x232xf32>) outs(%2 : tensor<666x1x1x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x174xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x174xf32>) -> tensor<666x1x1x174xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1392x1x1x174xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1392x1x1x174xf32>) -> tensor<1392x1x1x174xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1392xf32>) -> tensor<1392xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1392xf32>) outs(%6 : tensor<666x1x1x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x174xf32>, tensor<1392x1x1x174xf32>) outs(%7 : tensor<666x1x1x1392xf32>) -> tensor<666x1x1x1392xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %2 = tensor.empty() : tensor<666x7x2240xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x2240xf32>) -> tensor<666x7x2240xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x2240xf32>) outs(%3 : tensor<666x7x2240xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x2240xf32> into tensor<666x1x7x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1792xf32>) -> tensor<666x7x7x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1792xf32>) -> tensor<1x1x1x1792xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1792xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1792xf32>, tensor<1x1x1x1792xf32>) outs(%4 : tensor<666x7x7x1792xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1056xf32>) -> tensor<666x14x14x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1056xf32>) -> tensor<1x1x1x1056xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1056xf32>, tensor<1x1x1x1056xf32>) outs(%4 : tensor<666x14x14x1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x56x56x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x960xf32>) -> tensor<1x1x1x960xf32>\n    %4 = tensor.empty() : tensor<666x7x7x960xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x960xf32>, tensor<1x1x1x960xf32>) outs(%4 : tensor<666x7x7x960xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<888xf32>) -> tensor<888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<888xf32>, tensor<1xf32>) outs(%4 : tensor<888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = tensor.empty() : tensor<666x56x56x224xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x224xf32>) outs(%2 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1184xf32>) -> tensor<666x14x14x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1184xf32>) -> tensor<1x1x1x1184xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1184xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1184xf32>, tensor<1x1x1x1184xf32>) outs(%4 : tensor<666x14x14x1184xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x71x71x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x71x71x192xf32>) -> tensor<666x71x71x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x71x71x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x71x71x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x71x71x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x71x71x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1232x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1232x1x1x1232xf32>) -> tensor<1232x1x1x1232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1232xf32>) -> tensor<1232xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1232xf32>) outs(%6 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1232xf32>, tensor<1232x1x1x1232xf32>) outs(%7 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1280xf32>) -> tensor<666x14x14x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1280xf32>) -> tensor<128x1x1x1280xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1280xf32>, tensor<128x1x1x1280xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x256x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x256x1xf32>) -> tensor<3x3x256x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x74x74x256xf32> to tensor<666x76x76x256xf32>\n    %6 = tensor.empty() : tensor<666x74x74x256x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x74x74x256x1xf32>) -> tensor<666x74x74x256x1xf32>\n    %8 = tensor.empty() : tensor<666x74x74x256xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x76x76x256xf32>, tensor<3x3x256x1xf32>) outs(%7 : tensor<666x74x74x256x1xf32>) -> tensor<666x74x74x256x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x74x74x256x1xf32> into tensor<666x74x74x256xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<256xf32>, tensor<666x74x74x256xf32>) outs(%8 : tensor<666x74x74x256xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x74x74x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x128xf32>) -> tensor<512x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x14x14x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x128xf32>, tensor<512x1x1x128xf32>) outs(%7 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1152xf32>) -> tensor<666x14x14x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1152xf32>) -> tensor<1x1x1x1152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1152xf32>, tensor<1x1x1x1152xf32>) outs(%4 : tensor<666x14x14x1152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x144xf32>) -> tensor<666x28x28x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x144xf32>) -> tensor<32x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x28x28x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x28x28x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x144xf32>, tensor<32x1x1x144xf32>) outs(%7 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x3xf32>) -> tensor<1x1x1x3xf32>\n    %2 = tensor.empty() : tensor<1x1x1x3xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<1x1x1x3xf32>) outs(%2 : tensor<1x1x1x3xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.divf %cst_0, %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1x1x1x3xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x3x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x3x1x384xf32>) -> tensor<384x3x1x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 0, 0] high[0, 1, 0, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x8x8x384xf32> to tensor<666x10x8x384xf32>\n    %6 = tensor.empty() : tensor<666x8x8x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x8x8x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x10x8x384xf32>, tensor<384x3x1x384xf32>) outs(%7 : tensor<666x8x8x384xf32>) -> tensor<666x8x8x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1472xf32>) -> tensor<666x14x14x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1472xf32>) -> tensor<1x1x1x1472xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1472xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1472xf32>, tensor<1x1x1x1472xf32>) outs(%4 : tensor<666x14x14x1472xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x104xf32>) -> tensor<666x1x1x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<12x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<12x1x1x104xf32>) -> tensor<12x1x1x104xf32>\n    %4 = bufferization.alloc_tensor() : tensor<12xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<12xf32>) -> tensor<12xf32>\n    %6 = tensor.empty() : tensor<666x1x1x12xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<12xf32>) outs(%6 : tensor<666x1x1x12xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x12xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x104xf32>, tensor<12x1x1x104xf32>) outs(%7 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x71x71x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x71x71x192xf32>) -> tensor<666x71x71x192xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x35x35x192xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x71x71x192xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x17x17x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x17x17x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x336x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x336x1xf32>) -> tensor<3x3x336x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x21x21x336xf32> to tensor<666x23x23x336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %8 = tensor.empty() : tensor<666x21x21x336xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x23x23x336xf32>, tensor<3x3x336x1xf32>) outs(%7 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x21x21x336x1xf32> into tensor<666x21x21x336xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<336xf32>, tensor<666x21x21x336xf32>) outs(%8 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x120xf32>) -> tensor<666x1x1x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x120xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1696xf32>) -> tensor<666x14x14x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1696xf32>) -> tensor<1x1x1x1696xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1696xf32>, tensor<1x1x1x1696xf32>) outs(%4 : tensor<666x14x14x1696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x80xf32>) -> tensor<666x112x112x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x112x112x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x112x112x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x80xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = tensor.empty() : tensor<666x56x224xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x224xf32>) -> tensor<666x56x224xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x224xf32>) outs(%3 : tensor<666x56x224xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x224xf32> into tensor<666x1x56x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<16xf32>) -> tensor<16xf32>\n    %2 = tensor.empty() : tensor<16xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<16xf32>) outs(%2 : tensor<16xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = tensor.empty() : tensor<666x14x14x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x384xf32>) outs(%2 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x112x112x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x112x112x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x147x147x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x147x147x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<3024xf32>) -> tensor<3024xf32>\n    %2 = tensor.empty() : tensor<3024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<3024xf32>) outs(%2 : tensor<3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x3x3x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x3x3x96xf32>) -> tensor<96x3x3x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x17x17x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x17x17x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x96xf32>, tensor<96x3x3x96xf32>) outs(%7 : tensor<666x17x17x96xf32>) -> tensor<666x17x17x96xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = tensor.empty() : tensor<666x7x7xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7xf32>) -> tensor<666x7x7xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x2048xf32>) outs(%3 : tensor<666x7x7xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x7x7xf32> into tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x256xf32>) -> tensor<666x1x1x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x256xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x256xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = tensor.empty() : tensor<666x14x14xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14xf32>) -> tensor<666x14x14xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x384xf32>) outs(%3 : tensor<666x14x14xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x14x14xf32> into tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1504xf32>) -> tensor<666x7x7x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1504xf32>) -> tensor<1x1x1x1504xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1504xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1504xf32>, tensor<1x1x1x1504xf32>) outs(%4 : tensor<666x7x7x1504xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x32xf32>) -> tensor<224x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x56x56x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<224x1x1x32xf32>) outs(%7 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x8x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x8x1536xf32>) -> tensor<666x1x8x1536xf32>\n    %2 = tensor.empty() : tensor<666x1x1536xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1536xf32>) -> tensor<666x1x1536xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x8x1536xf32>) outs(%3 : tensor<666x1x1536xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1536xf32> into tensor<666x1x1x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x80xf32>) -> tensor<666x56x56x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<240x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<240x1x1x80xf32>) -> tensor<240x1x1x80xf32>\n    %4 = bufferization.alloc_tensor() : tensor<240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<240xf32>) -> tensor<240xf32>\n    %6 = tensor.empty() : tensor<666x28x28x240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<240xf32>) outs(%6 : tensor<666x28x28x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x80xf32>, tensor<240x1x1x80xf32>) outs(%7 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<544xf32>) -> tensor<544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<544xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<544xf32>, tensor<1xf32>) outs(%4 : tensor<544xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %4 = tensor.empty() : tensor<666x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x2048xf32>, tensor<666x2048xf32>) outs(%4 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x528xf32>) -> tensor<666x14x14x528xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x528xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x528xf32>) -> tensor<1x1x1x528xf32>\n    %4 = tensor.empty() : tensor<666x14x14x528xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x528xf32>, tensor<1x1x1x528xf32>) outs(%4 : tensor<666x14x14x528xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x528xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x352xf32>) -> tensor<666x28x28x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x352xf32>) -> tensor<1x1x1x352xf32>\n    %4 = tensor.empty() : tensor<666x28x28x352xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x352xf32>, tensor<1x1x1x352xf32>) outs(%4 : tensor<666x28x28x352xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x48xf32>) -> tensor<666x112x112x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x112x112x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x112x112x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x104xf32>) -> tensor<666x1x1x104xf32>\n    %2 = tensor.empty() : tensor<666x1x1x104xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x104xf32>) outs(%2 : tensor<666x1x1x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<54x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<54x1x1x576xf32>) -> tensor<54x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<54xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<54xf32>) -> tensor<54xf32>\n    %6 = tensor.empty() : tensor<666x1x1x54xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<54xf32>) outs(%6 : tensor<666x1x1x54xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x54xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x576xf32>, tensor<54x1x1x576xf32>) outs(%7 : tensor<666x1x1x54xf32>) -> tensor<666x1x1x54xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x384xf32>) -> tensor<128x1x1x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<128x1x1x384xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x21x21x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x21x21x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x7x7x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x7x7x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x672xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1088xf32>) -> tensor<666x1x7x1088xf32>\n    %2 = tensor.empty() : tensor<666x1x1088xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1088xf32>) -> tensor<666x1x1088xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1088xf32>) outs(%3 : tensor<666x1x1088xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1088xf32> into tensor<666x1x1x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x832xf32>) -> tensor<666x7x7x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x832xf32>) -> tensor<1x1x1x832xf32>\n    %4 = tensor.empty() : tensor<666x7x7x832xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x832xf32>, tensor<1x1x1x832xf32>) outs(%4 : tensor<666x7x7x832xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    %2 = tensor.empty() : tensor<666x8x8x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x192xf32>) outs(%2 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x960xf32>) -> tensor<1x1x1x960xf32>\n    %4 = tensor.empty() : tensor<666x7x7x960xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x960xf32>, tensor<1x1x1x960xf32>) outs(%4 : tensor<666x7x7x960xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x960xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x440xf32>) -> tensor<666x1x7x440xf32>\n    %2 = tensor.empty() : tensor<666x1x440xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x440xf32>) -> tensor<666x1x440xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x440xf32>) outs(%3 : tensor<666x1x440xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x440xf32> into tensor<666x1x1x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x768xf32>) -> tensor<666x1x1x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x768xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x544xf32>) -> tensor<666x7x7x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x544xf32>) -> tensor<1x1x1x544xf32>\n    %4 = tensor.empty() : tensor<666x7x7x544xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x544xf32>, tensor<1x1x1x544xf32>) outs(%4 : tensor<666x7x7x544xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x14xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x14xf32>) -> tensor<666x1x1x14xf32>\n    %2 = tensor.empty() : tensor<666x1x1x14xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x14xf32>) outs(%2 : tensor<666x1x1x14xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x14xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1624xf32>) -> tensor<666x14x14x1624xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1624xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1624xf32>) outs(%2 : tensor<666x14x14x1624xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x57x57x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x57x57x22xf32>) -> tensor<666x57x57x22xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x28x28x22xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x57x57x22xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %c1 = arith.constant 1 : index\n    %c28 = arith.constant 28 : index\n    %c2 = arith.constant 2 : index\n    %c28_1 = arith.constant 28 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c28, %c1_2 : index\n    %7 = arith.subi %c28_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x28x28x22xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x28x28x22xf32>) outs(%8 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x800xf32>) -> tensor<666x14x14x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x800xf32>) -> tensor<128x1x1x800xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x800xf32>, tensor<128x1x1x800xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = tensor.empty() : tensor<666x112x112x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x32xf32>) outs(%2 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<784x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<784x1x1x392xf32>) -> tensor<784x1x1x392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<784xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<784xf32>) -> tensor<784xf32>\n    %6 = tensor.empty() : tensor<666x14x14x784xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<784xf32>) outs(%6 : tensor<666x14x14x784xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x784xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x392xf32>, tensor<784x1x1x392xf32>) outs(%7 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1568xf32>) -> tensor<666x7x7x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1568xf32>) -> tensor<1x1x1x1568xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1568xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1568xf32>, tensor<1x1x1x1568xf32>) outs(%4 : tensor<666x7x7x1568xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x149x149x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x149x149x32xf32>) -> tensor<666x149x149x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x149x149x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x149x149x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x149x149x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x149x149x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    %2 = tensor.empty() : tensor<666x8x8x320xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x320xf32>) outs(%2 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1248xf32>) -> tensor<666x14x14x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1248xf32>) -> tensor<128x1x1x1248xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1248xf32>, tensor<128x1x1x1248xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x224xf32>) -> tensor<666x8x8x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x8x8x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x8x8x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1376xf32>) -> tensor<666x14x14x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1376xf32>) -> tensor<128x1x1x1376xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1376xf32>, tensor<128x1x1x1376xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x24xf32>) -> tensor<666x1x56x24xf32>\n    %2 = tensor.empty() : tensor<666x1x24xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x24xf32>) -> tensor<666x1x24xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x24xf32>) outs(%3 : tensor<666x1x24xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x24xf32> into tensor<666x1x1x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<666x14x14x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x7x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x7x128xf32>) -> tensor<160x1x7x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 3, 0] high[0, 0, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x128xf32> to tensor<666x17x23x128xf32>\n    %6 = tensor.empty() : tensor<666x17x17x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x17x23x128xf32>, tensor<160x1x7x128xf32>) outs(%7 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x256xf32>) -> tensor<128x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<128x1x1x256xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = tensor.empty() : tensor<666x56x56x72xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x72xf32>) outs(%2 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x56xf32>) -> tensor<666x56x56x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x56xf32>) -> tensor<1x1x1x56xf32>\n    %4 = tensor.empty() : tensor<666x56x56x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x56xf32>, tensor<1x1x1x56xf32>) outs(%4 : tensor<666x56x56x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1024xf32>) -> tensor<666x28x28x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1024xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x44x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x44x1xf32>) -> tensor<3x3x44x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<44xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<44xf32>) -> tensor<44xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x44xf32> to tensor<666x30x30x44xf32>\n    %6 = tensor.empty() : tensor<666x28x28x44x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x28x28x44x1xf32>) -> tensor<666x28x28x44x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x44xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x30x30x44xf32>, tensor<3x3x44x1xf32>) outs(%7 : tensor<666x28x28x44x1xf32>) -> tensor<666x28x28x44x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x44x1xf32> into tensor<666x28x28x44xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<44xf32>, tensor<666x28x28x44xf32>) outs(%8 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<24xf32>) -> tensor<24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<24xf32>, tensor<1xf32>) outs(%4 : tensor<24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1088xf32>) -> tensor<666x1x1x1088xf32>\n    %2 = tensor.empty() : tensor<666x1x1x1088xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x1088xf32>) outs(%2 : tensor<666x1x1x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x1088xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = tensor.empty() : tensor<666x28x192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x192xf32>) -> tensor<666x28x192xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x192xf32>) outs(%3 : tensor<666x28x192xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x192xf32> into tensor<666x1x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %4 = tensor.empty() : tensor<666x56x56x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<666x56x56x144xf32>) outs(%4 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1920x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1920x1x1x720xf32>) -> tensor<1920x1x1x720xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1920xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1920xf32>) -> tensor<1920xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1920xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1920xf32>) outs(%6 : tensor<666x7x7x1920xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1920xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x720xf32>, tensor<1920x1x1x720xf32>) outs(%7 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1296xf32>) -> tensor<1x1x1x1296xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1296xf32>, tensor<1x1x1x1296xf32>) outs(%4 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = tensor.empty() : tensor<666x56x56x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x512xf32>) outs(%2 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = tensor.empty() : tensor<666x56x56x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x256xf32>) outs(%2 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1312xf32>) -> tensor<666x7x7x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1312xf32>) -> tensor<1x1x1x1312xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1312xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1312xf32>, tensor<1x1x1x1312xf32>) outs(%4 : tensor<666x7x7x1312xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x44xf32>) -> tensor<666x56x56x44xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x28x28x44xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x56x56x44xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %c1 = arith.constant 1 : index\n    %c28 = arith.constant 28 : index\n    %c2 = arith.constant 2 : index\n    %c28_1 = arith.constant 28 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c28, %c1_2 : index\n    %7 = arith.subi %c28_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x28x28x44xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x28x28x44xf32>) outs(%8 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x331x331x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x331x331x3xf32>) -> tensor<666x331x331x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x3x3x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x3x3x3xf32>) -> tensor<96x3x3x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x165x165x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x165x165x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x165x165x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x331x331x3xf32>, tensor<96x3x3x3xf32>) outs(%7 : tensor<666x165x165x96xf32>) -> tensor<666x165x165x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x192xf32>) -> tensor<512x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<512x1x1x192xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x11x4032xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x11x4032xf32>) -> tensor<666x1x11x4032xf32>\n    %2 = tensor.empty() : tensor<666x1x4032xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x4032xf32>) -> tensor<666x1x4032xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x11x4032xf32>) outs(%3 : tensor<666x1x4032xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x4032xf32> into tensor<666x1x1x4032xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x288xf32>) -> tensor<666x1x1x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<72x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<72x1x1x288xf32>) -> tensor<72x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<72xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<72xf32>) -> tensor<72xf32>\n    %6 = tensor.empty() : tensor<666x1x1x72xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<72xf32>) outs(%6 : tensor<666x1x1x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x72xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x288xf32>, tensor<72x1x1x288xf32>) outs(%7 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x58xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x58xf32>) -> tensor<666x1x1x58xf32>\n    %2 = tensor.empty() : tensor<666x1x1x58xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x58xf32>) outs(%2 : tensor<666x1x1x58xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x58xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1344x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1344x1x1x672xf32>) -> tensor<1344x1x1x672xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1344xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1344xf32>) -> tensor<1344xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1344xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1344xf32>) outs(%6 : tensor<666x14x14x1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1344xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x672xf32>, tensor<1344x1x1x672xf32>) outs(%7 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x192xf32>) -> tensor<128x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<128x1x1x192xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1624xf32>) -> tensor<666x14x14x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1624xf32>) -> tensor<1x1x1x1624xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1624xf32>, tensor<1x1x1x1624xf32>) outs(%4 : tensor<666x14x14x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x3xf32>) -> tensor<32x3x3x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 0, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x224x224x3xf32> to tensor<666x225x225x3xf32>\n    %6 = tensor.empty() : tensor<666x112x112x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%padded, %3 : tensor<666x225x225x3xf32>, tensor<32x3x3x3xf32>) outs(%7 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3072xf32>) -> tensor<666x7x7x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3072xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x192xf32>, tensor<666x28x28x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x112xf32>) -> tensor<666x56x56x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x112xf32>) -> tensor<1x1x1x112xf32>\n    %4 = tensor.empty() : tensor<666x56x56x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x112xf32>, tensor<1x1x1x112xf32>) outs(%4 : tensor<666x56x56x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x32xf32>) -> tensor<192x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x28x28x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x32xf32>, tensor<192x1x1x32xf32>) outs(%7 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x37x37x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x37x37x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x37x37x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x32xf32>) -> tensor<32x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x56x56x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<32x1x1x32xf32>) outs(%7 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x544xf32>) -> tensor<666x7x7x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x544xf32>) -> tensor<1x1x1x544xf32>\n    %4 = tensor.empty() : tensor<666x7x7x544xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x544xf32>, tensor<1x1x1x544xf32>) outs(%4 : tensor<666x7x7x544xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x544xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x224xf32>) -> tensor<666x1x56x224xf32>\n    %2 = tensor.empty() : tensor<666x1x224xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x224xf32>) -> tensor<666x1x224xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x224xf32>) outs(%3 : tensor<666x1x224xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x224xf32> into tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x24xf32>) -> tensor<666x112x112x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x24xf32>) -> tensor<1x1x1x24xf32>\n    %4 = tensor.empty() : tensor<666x112x112x24xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x24xf32>, tensor<1x1x1x24xf32>) outs(%4 : tensor<666x112x112x24xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<152x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<152x1x1x56xf32>) -> tensor<152x1x1x56xf32>\n    %4 = bufferization.alloc_tensor() : tensor<152xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<152xf32>) -> tensor<152xf32>\n    %6 = tensor.empty() : tensor<666x28x28x152xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<152xf32>) outs(%6 : tensor<666x28x28x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x152xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x56xf32>, tensor<152x1x1x56xf32>) outs(%7 : tensor<666x28x28x152xf32>) -> tensor<666x28x28x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1392xf32>) -> tensor<666x28x28x1392xf32>\n    %2 = tensor.empty() : tensor<666x28x28x1392xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x1392xf32>) outs(%2 : tensor<666x28x28x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x56xf32>) -> tensor<666x56x56x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x56xf32>) -> tensor<1x1x1x56xf32>\n    %4 = tensor.empty() : tensor<666x56x56x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x56xf32>, tensor<1x1x1x56xf32>) outs(%4 : tensor<666x56x56x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x56xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1296xf32>) -> tensor<666x1x7x1296xf32>\n    %2 = tensor.empty() : tensor<666x1x1296xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1296xf32>) -> tensor<666x1x1296xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1296xf32>) outs(%3 : tensor<666x1x1296xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1296xf32> into tensor<666x1x1x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x560xf32>) -> tensor<666x28x28x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x560xf32>) -> tensor<1x1x1x560xf32>\n    %4 = tensor.empty() : tensor<666x28x28x560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x560xf32>, tensor<1x1x1x560xf32>) outs(%4 : tensor<666x28x28x560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x2016xf32>) -> tensor<666x1x1x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x2016xf32>) -> tensor<224x1x1x2016xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x1x1x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x2016xf32>, tensor<224x1x1x2016xf32>) outs(%7 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x704xf32>) -> tensor<666x7x7x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x704xf32>) -> tensor<1x1x1x704xf32>\n    %4 = tensor.empty() : tensor<666x7x7x704xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x704xf32>, tensor<1x1x1x704xf32>) outs(%4 : tensor<666x7x7x704xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x896xf32>) -> tensor<666x1x1x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x896xf32>) -> tensor<112x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x1x1x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x896xf32>, tensor<112x1x1x896xf32>) outs(%7 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = tensor.empty() : tensor<666x14x14x720xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x720xf32>) outs(%2 : tensor<666x14x14x720xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x576xf32>) -> tensor<666x7x7x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x576xf32>) -> tensor<1x1x1x576xf32>\n    %4 = tensor.empty() : tensor<666x7x7x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x576xf32>, tensor<1x1x1x576xf32>) outs(%4 : tensor<666x7x7x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1232xf32>) -> tensor<666x28x28x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1232xf32>) -> tensor<1x1x1x1232xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1232xf32>, tensor<1x1x1x1232xf32>) outs(%4 : tensor<666x28x28x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1232xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = tensor.empty() : tensor<666x14x14xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14xf32>) -> tensor<666x14x14xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x768xf32>) outs(%3 : tensor<666x14x14xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x14x14xf32> into tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x120xf32>) -> tensor<666x1x28x120xf32>\n    %2 = tensor.empty() : tensor<666x1x120xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x120xf32>) -> tensor<666x1x120xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x120xf32>) outs(%3 : tensor<666x1x120xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x120xf32> into tensor<666x1x1x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %2 = tensor.empty() : tensor<666x7x7x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x512xf32>) outs(%2 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3712x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3712x1x1x3712xf32>) -> tensor<3712x1x1x3712xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3712xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3712xf32>) -> tensor<3712xf32>\n    %6 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3712xf32>) outs(%6 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x3712xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x3712xf32>, tensor<3712x1x1x3712xf32>) outs(%7 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<704xf32>) -> tensor<704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<704xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<704xf32>, tensor<1xf32>) outs(%4 : tensor<704xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1512xf32>) -> tensor<1512xf32>\n    %2 = tensor.empty() : tensor<1512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1512xf32>) outs(%2 : tensor<1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1624xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1624xf32>) outs(%2 : tensor<666x7x7x1624xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x448xf32>) -> tensor<666x56x56x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x56x56x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x56x56x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x448xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x152xf32>) -> tensor<666x1x14x152xf32>\n    %2 = tensor.empty() : tensor<666x1x152xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x152xf32>) -> tensor<666x1x152xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x152xf32>) outs(%3 : tensor<666x1x152xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x152xf32> into tensor<666x1x1x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x320xf32>) -> tensor<666x28x28x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x28x28x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x28x28x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1920xf32>) -> tensor<1920xf32>\n    %2 = tensor.empty() : tensor<1920xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1920xf32>) outs(%2 : tensor<1920xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x224xf32>) -> tensor<666x28x28x224xf32>\n    %2 = tensor.empty() : tensor<666x28x28x224xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x224xf32>) outs(%2 : tensor<666x28x28x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x896xf32>) -> tensor<666x28x28x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x28x28x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x28x28x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x272xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x272xf32>) -> tensor<666x1x1x272xf32>\n    %2 = tensor.empty() : tensor<666x1x1x272xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x272xf32>) outs(%2 : tensor<666x1x1x272xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x272xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x440xf32>) -> tensor<666x14x14x440xf32>\n    %2 = tensor.empty() : tensor<666x14x14x440xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x440xf32>) outs(%2 : tensor<666x14x14x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x96xf32>) -> tensor<666x28x28x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x28x28x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x28x28x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<120x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<120x1x1x120xf32>) -> tensor<120x1x1x120xf32>\n    %4 = bufferization.alloc_tensor() : tensor<120xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<120xf32>) -> tensor<120xf32>\n    %6 = tensor.empty() : tensor<666x28x28x120xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<120xf32>) outs(%6 : tensor<666x28x28x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x120xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x120xf32>, tensor<120x1x1x120xf32>) outs(%7 : tensor<666x28x28x120xf32>) -> tensor<666x28x28x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x3xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x3xf32>) -> tensor<666x224x224x3xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x3xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x3xf32>) -> tensor<64x3x3x3xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x224x224x3xf32> to tensor<666x226x226x3xf32>\n    %6 = tensor.empty() : tensor<666x224x224x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x224x224x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x224x224x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x226x226x3xf32>, tensor<64x3x3x3xf32>) outs(%7 : tensor<666x224x224x64xf32>) -> tensor<666x224x224x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x784xf32>) -> tensor<666x28x28x784xf32>\n    %2 = tensor.empty() : tensor<666x28x28x784xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x784xf32>) outs(%2 : tensor<666x28x28x784xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x784xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = tensor.empty() : tensor<666x56x64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x64xf32>) -> tensor<666x56x64xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x64xf32>) outs(%3 : tensor<666x56x64xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x64xf32> into tensor<666x1x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x736xf32>) -> tensor<666x14x14x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x736xf32>) -> tensor<1x1x1x736xf32>\n    %4 = tensor.empty() : tensor<666x14x14x736xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x736xf32>, tensor<1x1x1x736xf32>) outs(%4 : tensor<666x14x14x736xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x736xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = tensor.empty() : tensor<666x14x14xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14xf32>) -> tensor<666x14x14xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x1024xf32>) outs(%3 : tensor<666x14x14xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x14x14xf32> into tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x56xf32>) -> tensor<1x1x1x56xf32>\n    %4 = tensor.empty() : tensor<666x28x28x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x56xf32>, tensor<1x1x1x56xf32>) outs(%4 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x52xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x52xf32>) -> tensor<666x1x1x52xf32>\n    %2 = bufferization.alloc_tensor() : tensor<440x1x1x52xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<440x1x1x52xf32>) -> tensor<440x1x1x52xf32>\n    %4 = bufferization.alloc_tensor() : tensor<440xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<440xf32>) -> tensor<440xf32>\n    %6 = tensor.empty() : tensor<666x1x1x440xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<440xf32>) outs(%6 : tensor<666x1x1x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x440xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x52xf32>, tensor<440x1x1x52xf32>) outs(%7 : tensor<666x1x1x440xf32>) -> tensor<666x1x1x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x14x14x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x14x14x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x43x43x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x43x43x336xf32>) -> tensor<666x43x43x336xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x21x21x336xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x43x43x336xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %c1 = arith.constant 1 : index\n    %c21 = arith.constant 21 : index\n    %c2 = arith.constant 2 : index\n    %c21_1 = arith.constant 21 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c21, %c1_2 : index\n    %7 = arith.subi %c21_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x21x21x336xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x21x21x336xf32>) outs(%8 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<608x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<608x1x1x608xf32>) -> tensor<608x1x1x608xf32>\n    %4 = bufferization.alloc_tensor() : tensor<608xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<608xf32>) -> tensor<608xf32>\n    %6 = tensor.empty() : tensor<666x7x7x608xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<608xf32>) outs(%6 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x608xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x608xf32>, tensor<608x1x1x608xf32>) outs(%7 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x128xf32>) -> tensor<320x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x14x14x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<320x1x1x128xf32>) outs(%7 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x2048xf32>) -> tensor<1x130536x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2048x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2048x512xf32>) -> tensor<1x2048x512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x512xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x512xf32>) -> tensor<1x130536x512xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x2048xf32>, tensor<1x2048x512xf32>) outs(%5 : tensor<1x130536x512xf32>) -> tensor<1x130536x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = tensor.empty() : tensor<666x14x14x432xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x432xf32>) outs(%2 : tensor<666x14x14x432xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x72xf32>) -> tensor<666x112x112x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x72xf32>) -> tensor<1x1x1x72xf32>\n    %4 = tensor.empty() : tensor<666x112x112x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x72xf32>, tensor<1x1x1x72xf32>) outs(%4 : tensor<666x112x112x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x28x28x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = tensor.empty() : tensor<666x28x56xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x56xf32>) -> tensor<666x28x56xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x56xf32>) outs(%3 : tensor<666x28x56xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x56xf32> into tensor<666x1x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    %4 = tensor.empty() : tensor<666x7x7x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x160xf32>, tensor<666x7x7x160xf32>) outs(%4 : tensor<666x7x7x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<224xf32>) -> tensor<224xf32>\n    %2 = tensor.empty() : tensor<224xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<224xf32>) outs(%2 : tensor<224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1296xf32>) -> tensor<666x14x14x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1296xf32>) -> tensor<1x1x1x1296xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1296xf32>, tensor<1x1x1x1296xf32>) outs(%4 : tensor<666x14x14x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x448xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x8192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x8192xf32>) -> tensor<666x7x7x8192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x8192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x8192xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x8192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x8192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1600xf32>) -> tensor<666x7x7x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1600xf32>) -> tensor<1x1x1x1600xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1600xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1600xf32>, tensor<1x1x1x1600xf32>) outs(%4 : tensor<666x7x7x1600xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1536xf32>) -> tensor<1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1536xf32>, tensor<1xf32>) outs(%4 : tensor<1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %4 = tensor.empty() : tensor<666x28x28x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x56xf32>, tensor<666x28x28x56xf32>) outs(%4 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<896xf32>) -> tensor<896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<896xf32>, tensor<1xf32>) outs(%4 : tensor<896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1296xf32>) -> tensor<666x14x14x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1296xf32>) -> tensor<1x1x1x1296xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1296xf32>, tensor<1x1x1x1296xf32>) outs(%4 : tensor<666x14x14x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x408xf32>) -> tensor<666x28x28x408xf32>\n    %2 = tensor.empty() : tensor<666x28x28x408xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x408xf32>) outs(%2 : tensor<666x28x28x408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x192xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x192xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x25088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x25088xf32>) -> tensor<1x666x25088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x25088x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x25088x4096xf32>) -> tensor<1x25088x4096xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x4096xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x4096xf32>) -> tensor<1x666x4096xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x25088xf32>, tensor<1x25088x4096xf32>) outs(%5 : tensor<1x666x4096xf32>) -> tensor<1x666x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1312xf32>) -> tensor<1312xf32>\n    %2 = tensor.empty() : tensor<1312xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1312xf32>) outs(%2 : tensor<1312xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1312xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x256xf32>) -> tensor<666x7x7x256xf32>\n    %2 = tensor.empty() : tensor<666x7x7x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x256xf32>) outs(%2 : tensor<666x7x7x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x192xf32>) -> tensor<128x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<128x1x1x192xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1568xf32>) -> tensor<1568xf32>\n    %2 = tensor.empty() : tensor<1568xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1568xf32>) outs(%2 : tensor<1568xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1600xf32>) -> tensor<666x14x14x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1600xf32>) -> tensor<1x1x1x1600xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1600xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1600xf32>, tensor<1x1x1x1600xf32>) outs(%4 : tensor<666x14x14x1600xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1728xf32>) -> tensor<666x14x14x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1728xf32>) -> tensor<1x1x1x1728xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1728xf32>, tensor<1x1x1x1728xf32>) outs(%4 : tensor<666x14x14x1728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x992xf32>) -> tensor<666x7x7x992xf32>\n    %2 = tensor.empty() : tensor<666x7x7x992xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x992xf32>) outs(%2 : tensor<666x7x7x992xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x7x7x1024xf32>, tensor<666x7x7x1024xf32>) outs(%2 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x176xf32>) -> tensor<666x14x14x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x176xf32>) -> tensor<1x1x1x176xf32>\n    %4 = tensor.empty() : tensor<666x14x14x176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x176xf32>, tensor<1x1x1x176xf32>) outs(%4 : tensor<666x14x14x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x480xf32>) -> tensor<666x14x14x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x480xf32>) -> tensor<1x1x1x480xf32>\n    %4 = tensor.empty() : tensor<666x14x14x480xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x480xf32>, tensor<1x1x1x480xf32>) outs(%4 : tensor<666x14x14x480xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<176x1x1x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<176x1x1x176xf32>) -> tensor<176x1x1x176xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<176xf32>) outs(%6 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x176xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x176xf32>, tensor<176x1x1x176xf32>) outs(%7 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = tensor.empty() : tensor<666x42x42x168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x42x42x168xf32>) outs(%2 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x152xf32>, tensor<666x14x14x152xf32>) outs(%4 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1024xf32>) -> tensor<666x28x28x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1024xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = tensor.empty() : tensor<666x28x28x44xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x44xf32>) outs(%2 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x672xf32>) -> tensor<666x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x672xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x224xf32>) -> tensor<666x8x8x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x8x8x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x8x8x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x56xf32>) -> tensor<1x1x1x56xf32>\n    %4 = tensor.empty() : tensor<666x28x28x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x56xf32>, tensor<1x1x1x56xf32>) outs(%4 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x1024xf32>) -> tensor<256x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x14x14x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<256x1x1x1024xf32>) outs(%7 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x232xf32>) -> tensor<666x112x112x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x232xf32>) -> tensor<1x1x1x232xf32>\n    %4 = tensor.empty() : tensor<666x112x112x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x232xf32>, tensor<1x1x1x232xf32>) outs(%4 : tensor<666x112x112x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x232xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x72xf32>) -> tensor<666x1x56x72xf32>\n    %2 = tensor.empty() : tensor<666x1x72xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x72xf32>) -> tensor<666x1x72xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x72xf32>) outs(%3 : tensor<666x1x72xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x72xf32> into tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x152xf32>) -> tensor<1x1x1x152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x152xf32>, tensor<1x1x1x152xf32>) outs(%4 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1056xf32>) -> tensor<666x7x7x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1056xf32>) -> tensor<1x1x1x1056xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1056xf32>, tensor<1x1x1x1056xf32>) outs(%4 : tensor<666x7x7x1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x128xf32>) -> tensor<32x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x128xf32> to tensor<666x30x30x128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x28x28x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x30x30x128xf32>, tensor<32x3x3x128xf32>) outs(%7 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x320xf32>) -> tensor<666x28x28x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x28x28x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x28x28x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<36x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<36x1x1x144xf32>) -> tensor<36x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<36xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<36xf32>) -> tensor<36xf32>\n    %6 = tensor.empty() : tensor<666x1x1x36xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<36xf32>) outs(%6 : tensor<666x1x1x36xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x36xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x144xf32>, tensor<36x1x1x144xf32>) outs(%7 : tensor<666x1x1x36xf32>) -> tensor<666x1x1x36xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x2520xf32>) -> tensor<1x666x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2520x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2520x1000xf32>) -> tensor<1x2520x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x2520xf32>, tensor<1x2520x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x4096xf32>) -> tensor<1x130536x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x4096x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x4096x1024xf32>) -> tensor<1x4096x1024xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x1024xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x1024xf32>) -> tensor<1x130536x1024xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x4096xf32>, tensor<1x4096x1024xf32>) outs(%5 : tensor<1x130536x1024xf32>) -> tensor<1x130536x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<666x56x56x1xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x12xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x12xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x12xf32>) -> tensor<112x1x1x12xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x1x1x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x1x1x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x12xf32>, tensor<112x1x1x12xf32>) outs(%7 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<608xf32>) -> tensor<608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<608xf32>, tensor<1xf32>) outs(%4 : tensor<608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x432xf32>) -> tensor<666x28x28x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x432xf32>) -> tensor<1x1x1x432xf32>\n    %4 = tensor.empty() : tensor<666x28x28x432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x432xf32>, tensor<1x1x1x432xf32>) outs(%4 : tensor<666x28x28x432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x23x23x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x23x23x672xf32>) -> tensor<666x23x23x672xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x11x11x672xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x23x23x672xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %c1 = arith.constant 1 : index\n    %c11 = arith.constant 11 : index\n    %c2 = arith.constant 2 : index\n    %c11_1 = arith.constant 11 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c11, %c1_2 : index\n    %7 = arith.subi %c11_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x11x11x672xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x11x11x672xf32>) outs(%8 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c3, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c3 : index\n      %c2_4 = arith.constant 2 : index\n      %c3_5 = arith.constant 3 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_4 : index\n      %19 = arith.muli %17, %c2_4 : index\n      %20 = arith.cmpi slt, %c3_5, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c3_5 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x3x3x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x3x3x64xf32>) -> tensor<96x3x3x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x64xf32> to tensor<666x37x37x64xf32>\n    %6 = tensor.empty() : tensor<666x35x35x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x35x35x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x37x37x64xf32>, tensor<96x3x3x64xf32>) outs(%7 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x17x17x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x256xf32>) -> tensor<666x8x8x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x8x8x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x8x8x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x224xf32>) -> tensor<1x1x1x224xf32>\n    %4 = tensor.empty() : tensor<666x56x56x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<1x1x1x224xf32>) outs(%4 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    %2 = tensor.empty() : tensor<666x7x1296xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1296xf32>) -> tensor<666x7x1296xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1296xf32>) outs(%3 : tensor<666x7x1296xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1296xf32> into tensor<666x1x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x35x35x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x35x35x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x336xf32>) -> tensor<666x28x28x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x28x28x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x28x28x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1664xf32>) -> tensor<666x14x14x1664xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1664xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1664xf32>) -> tensor<1x1x1x1664xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1664xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1664xf32>, tensor<1x1x1x1664xf32>) outs(%4 : tensor<666x14x14x1664xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1120xf32>) -> tensor<666x7x7x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1120xf32>) -> tensor<1x1x1x1120xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1120xf32>, tensor<1x1x1x1120xf32>) outs(%4 : tensor<666x7x7x1120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x56xf32>) -> tensor<666x28x28x56xf32>\n    %4 = tensor.empty() : tensor<666x28x28x56xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x56xf32>, tensor<666x28x28x56xf32>) outs(%4 : tensor<666x28x28x56xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<666x56x56x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x42xf32>) -> tensor<666x165x165x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x42xf32>) -> tensor<1x1x1x42xf32>\n    %4 = tensor.empty() : tensor<666x165x165x42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x165x165x42xf32>, tensor<1x1x1x42xf32>) outs(%4 : tensor<666x165x165x42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x165x165x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x24xf32>) -> tensor<144x1x1x24xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x56x56x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<144x1x1x24xf32>) outs(%7 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x84xf32>) -> tensor<666x83x83x84xf32>\n    %2 = tensor.empty() : tensor<666x83x83x84xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x83x83x84xf32>) outs(%2 : tensor<666x83x83x84xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x83x83x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x14x14x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x22xf32>) -> tensor<666x56x56x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x22xf32>) -> tensor<1x1x1x22xf32>\n    %4 = tensor.empty() : tensor<666x56x56x22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x22xf32>, tensor<1x1x1x22xf32>) outs(%4 : tensor<666x56x56x22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x336xf32>) -> tensor<336x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x21x21x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x21x21x336xf32>, tensor<336x1x1x336xf32>) outs(%7 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x3x3x128xf32>) -> tensor<256x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x128xf32> to tensor<666x58x58x128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x128xf32>, tensor<256x3x3x128xf32>) outs(%7 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x117x117x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x117x117x32xf32>) -> tensor<666x117x117x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x32x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x32x1xf32>) -> tensor<7x7x32x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x56x56x32x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x56x56x32x1xf32>) -> tensor<666x56x56x32x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x32xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x117x117x32xf32>, tensor<7x7x32x1xf32>) outs(%7 : tensor<666x56x56x32x1xf32>) -> tensor<666x56x56x32x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x32x1xf32> into tensor<666x56x56x32xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<32xf32>, tensor<666x56x56x32xf32>) outs(%8 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x800xf32>) -> tensor<666x7x7x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x800xf32>) -> tensor<1x1x1x800xf32>\n    %4 = tensor.empty() : tensor<666x7x7x800xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x800xf32>, tensor<1x1x1x800xf32>) outs(%4 : tensor<666x7x7x800xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<666x28x28x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<666x56x56x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x704xf32>) -> tensor<666x14x14x704xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x704xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x704xf32>) -> tensor<1x1x1x704xf32>\n    %4 = tensor.empty() : tensor<666x14x14x704xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x704xf32>, tensor<1x1x1x704xf32>) outs(%4 : tensor<666x14x14x704xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x192xf32>) -> tensor<666x14x14x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x192xf32>) -> tensor<64x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x14x14x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x14x14x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x192xf32>, tensor<64x1x1x192xf32>) outs(%7 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1624xf32>) -> tensor<666x1x7x1624xf32>\n    %2 = tensor.empty() : tensor<666x1x1624xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1624xf32>) -> tensor<666x1x1624xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1624xf32>) outs(%3 : tensor<666x1x1624xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1624xf32> into tensor<666x1x1x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x3x3x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x3x3x320xf32>) -> tensor<384x3x3x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x17x17x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x17x17x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x320xf32>, tensor<384x3x3x320xf32>) outs(%7 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x56x56x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3712xf32>) -> tensor<666x1x1x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x3712xf32>, tensor<666x7x7x3712xf32>) outs(%4 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x149x149x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x149x149x32xf32>) -> tensor<666x149x149x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x149x149x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x149x149x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x149x149x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x149x149x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %2 = tensor.empty() : tensor<666x7x7x888xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x888xf32>) outs(%2 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x352xf32>) -> tensor<666x14x14x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x352xf32>) -> tensor<1x1x1x352xf32>\n    %4 = tensor.empty() : tensor<666x14x14x352xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x352xf32>, tensor<1x1x1x352xf32>) outs(%4 : tensor<666x14x14x352xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3024xf32>) -> tensor<666x14x14x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3024xf32>) -> tensor<1x1x1x3024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3024xf32>, tensor<1x1x1x3024xf32>) outs(%4 : tensor<666x14x14x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x4032xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x4032xf32>) -> tensor<666x11x11x4032xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x4032xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x4032xf32>) -> tensor<672x1x1x4032xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x11x11x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x11x11x4032xf32>, tensor<672x1x1x4032xf32>) outs(%7 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3024xf32>) -> tensor<666x1x1x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<308x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<308x1x1x3024xf32>) -> tensor<308x1x1x3024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<308xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<308xf32>) -> tensor<308xf32>\n    %6 = tensor.empty() : tensor<666x1x1x308xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<308xf32>) outs(%6 : tensor<666x1x1x308xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x308xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x3024xf32>, tensor<308x1x1x3024xf32>) outs(%7 : tensor<666x1x1x308xf32>) -> tensor<666x1x1x308xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = tensor.empty() : tensor<666x56x232xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x232xf32>) -> tensor<666x56x232xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x232xf32>) outs(%3 : tensor<666x56x232xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x232xf32> into tensor<666x1x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1624x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1624x1x1x784xf32>) -> tensor<1624x1x1x784xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1624xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1624xf32>) -> tensor<1624xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1624xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1624xf32>) outs(%6 : tensor<666x14x14x1624xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1624xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x784xf32>, tensor<1624x1x1x784xf32>) outs(%7 : tensor<666x14x14x1624xf32>) -> tensor<666x14x14x1624xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x1536xf32>) -> tensor<1x130536x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1536x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1536x384xf32>) -> tensor<1x1536x384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x384xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x384xf32>) -> tensor<1x130536x384xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x1536xf32>, tensor<1x1536x384xf32>) outs(%5 : tensor<1x130536x384xf32>) -> tensor<1x130536x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %4 = tensor.empty() : tensor<666x14x14x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<666x14x14x288xf32>) outs(%4 : tensor<666x14x14x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x960xf32>) -> tensor<666x14x14x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x960xf32>) -> tensor<128x1x1x960xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x960xf32>, tensor<128x1x1x960xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = tensor.empty() : tensor<666x1x1x144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x144xf32>) outs(%2 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x544xf32>) -> tensor<666x14x14x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x544xf32>) -> tensor<1x1x1x544xf32>\n    %4 = tensor.empty() : tensor<666x14x14x544xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x544xf32>, tensor<1x1x1x544xf32>) outs(%4 : tensor<666x14x14x544xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<512xf32>) -> tensor<512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<512xf32>, tensor<1xf32>) outs(%4 : tensor<512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x368xf32>) -> tensor<1x666x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x368x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x368x1000xf32>) -> tensor<1x368x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x368xf32>, tensor<1x368x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1280xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1280xf32>) outs(%2 : tensor<666x7x7x1280xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x256xf32>) -> tensor<128x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<128x1x1x256xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x768xf32>) -> tensor<1x32634x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x768x3072xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x768x3072xf32>) -> tensor<1x768x3072xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x3072xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x3072xf32>) -> tensor<1x32634x3072xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x768xf32>, tensor<1x768x3072xf32>) outs(%5 : tensor<1x32634x3072xf32>) -> tensor<1x32634x3072xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x14x14x512xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x28x28x512xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x113x113x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x113x113x11xf32>) -> tensor<666x113x113x11xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x56x56x11xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x113x113x11xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %4 = tensor.empty() : tensor<666x28x28x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x672xf32>, tensor<666x28x28x672xf32>) outs(%4 : tensor<666x28x28x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x408xf32>) -> tensor<1x1x1x408xf32>\n    %4 = tensor.empty() : tensor<666x14x14x408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x408xf32>, tensor<1x1x1x408xf32>) outs(%4 : tensor<666x14x14x408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2080xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2080xf32>) -> tensor<666x8x8x2080xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1536x1x1x2080xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1536x1x1x2080xf32>) -> tensor<1536x1x1x2080xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1536xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1536xf32>) -> tensor<1536xf32>\n    %6 = tensor.empty() : tensor<666x8x8x1536xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1536xf32>) outs(%6 : tensor<666x8x8x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x1536xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x2080xf32>, tensor<1536x1x1x2080xf32>) outs(%7 : tensor<666x8x8x1536xf32>) -> tensor<666x8x8x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x672xf32>) -> tensor<666x28x28x672xf32>\n    %2 = tensor.empty() : tensor<666x28x28x672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x672xf32>) outs(%2 : tensor<666x28x28x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1248xf32>) -> tensor<666x7x7x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1248xf32>) -> tensor<1x1x1x1248xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1248xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1248xf32>, tensor<1x1x1x1248xf32>) outs(%4 : tensor<666x7x7x1248xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x640xf32>) -> tensor<666x7x7x640xf32>\n    %2 = tensor.empty() : tensor<666x7x7x640xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x640xf32>) outs(%2 : tensor<666x7x7x640xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = tensor.empty() : tensor<666x28x28x512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x28x28x512xf32>, tensor<666x28x28x512xf32>) outs(%2 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x576xf32>) -> tensor<128x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<128x1x1x576xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1216xf32>) -> tensor<666x14x14x1216xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1216xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1216xf32>) outs(%2 : tensor<666x14x14x1216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1216xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1024xf32>) -> tensor<1x666x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1024x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1024x1000xf32>) -> tensor<1x1024x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1024xf32>, tensor<1x1024x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x17x17x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x17x17x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x216xf32>) -> tensor<666x1x1x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %4 = tensor.empty() : tensor<666x28x28x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x216xf32>, tensor<666x28x28x216xf32>) outs(%4 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x256xf32>) -> tensor<666x1x1x256xf32>\n    %2 = tensor.empty() : tensor<666x1x1x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x256xf32>) outs(%2 : tensor<666x1x1x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1376xf32>) -> tensor<1376xf32>\n    %2 = tensor.empty() : tensor<1376xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1376xf32>) outs(%2 : tensor<1376xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1376xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = tensor.empty() : tensor<666x56x48xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x48xf32>) -> tensor<666x56x48xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x48xf32>) outs(%3 : tensor<666x56x48xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x48xf32> into tensor<666x1x56x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1888xf32>) -> tensor<1888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1888xf32>, tensor<1xf32>) outs(%4 : tensor<1888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<104xf32>) -> tensor<104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<104xf32>, tensor<1xf32>) outs(%4 : tensor<104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<104xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1536xf32>) -> tensor<1x666x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1536x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1536x1000xf32>) -> tensor<1x1536x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1536xf32>, tensor<1x1536x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = tensor.empty() : tensor<666x14x14x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x384xf32>) outs(%2 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x3x3x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x3x3x512xf32>) -> tensor<512x3x3x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x512xf32> to tensor<666x30x30x512xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x30x30x512xf32>, tensor<512x3x3x512xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1296xf32>) -> tensor<666x14x14x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1296xf32>) -> tensor<1x1x1x1296xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1296xf32>, tensor<1x1x1x1296xf32>) outs(%4 : tensor<666x14x14x1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x928xf32>) -> tensor<666x7x7x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x928xf32>) -> tensor<1x1x1x928xf32>\n    %4 = tensor.empty() : tensor<666x7x7x928xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x928xf32>, tensor<1x1x1x928xf32>) outs(%4 : tensor<666x7x7x928xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (0, d1)>\n#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x2048xf32>) -> tensor<1x2048xf32>\n    %4 = tensor.empty() : tensor<666x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<1x2048xf32>) outs(%4 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x320xf32>) -> tensor<666x1x1x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %4 = tensor.empty() : tensor<666x14x14x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x320xf32>, tensor<666x14x14x320xf32>) outs(%4 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x512xf32>) -> tensor<1x522144x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x512x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x512x2048xf32>) -> tensor<1x512x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x2048xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x2048xf32>) -> tensor<1x522144x2048xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x512xf32>, tensor<1x512x2048xf32>) outs(%5 : tensor<1x522144x2048xf32>) -> tensor<1x522144x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1856xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1856xf32>) -> tensor<666x7x7x1856xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1856xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1856xf32>) outs(%2 : tensor<666x7x7x1856xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1856xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x672xf32>) -> tensor<666x56x56x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x56x56x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x56x56x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %4 = tensor.empty() : tensor<666x56x56x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x256xf32>, tensor<666x56x56x256xf32>) outs(%4 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x288xf32>) -> tensor<576x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x28x28x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x28x28x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<576x1x1x288xf32>) outs(%7 : tensor<666x28x28x576xf32>) -> tensor<666x28x28x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x560xf32>) -> tensor<1x1x1x560xf32>\n    %4 = tensor.empty() : tensor<666x14x14x560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x560xf32>, tensor<1x1x1x560xf32>) outs(%4 : tensor<666x14x14x560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x7x7x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1624x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1624x1x1x784xf32>) -> tensor<1624x1x1x784xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1624xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1624xf32>) -> tensor<1624xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1624xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1624xf32>) outs(%6 : tensor<666x7x7x1624xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1624xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x784xf32>, tensor<1624x1x1x784xf32>) outs(%7 : tensor<666x7x7x1624xf32>) -> tensor<666x7x7x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x992xf32>) -> tensor<666x14x14x992xf32>\n    %2 = tensor.empty() : tensor<666x14x14x992xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x992xf32>) outs(%2 : tensor<666x14x14x992xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x888xf32>, tensor<666x7x7x888xf32>) outs(%4 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x7x7x896xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x896xf32>) -> tensor<666x7x7x896xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x14x14x896xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x7x7x896xf32>) -> tensor<666x7x7x896xf32>\n    %c1 = arith.constant 1 : index\n    %c7 = arith.constant 7 : index\n    %c2 = arith.constant 2 : index\n    %c7_1 = arith.constant 7 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c7, %c1_2 : index\n    %7 = arith.subi %c7_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x7x7x896xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x7x7x896xf32>) outs(%8 : tensor<666x7x7x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c2_4 = arith.constant 2 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c2_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c2_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c2_6 = arith.constant 2 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c2_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c2_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x7x7x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1280xf32>) -> tensor<666x8x8x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x1280xf32>) -> tensor<448x1x1x1280xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x8x8x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x8x8x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x1280xf32>, tensor<448x1x1x1280xf32>) outs(%7 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1824xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1824xf32>) -> tensor<1824xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1824xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1824xf32>, tensor<1xf32>) outs(%4 : tensor<1824xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1824xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1888xf32>) -> tensor<666x7x7x1888xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1888xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1888xf32>) outs(%2 : tensor<666x7x7x1888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x288xf32>) -> tensor<666x8x8x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x8x8x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x8x8x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    %2 = tensor.empty() : tensor<666x1x1x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x192xf32>) outs(%2 : tensor<666x1x1x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x896xf32>) -> tensor<666x7x7x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x896xf32>) -> tensor<1x1x1x896xf32>\n    %4 = tensor.empty() : tensor<666x7x7x896xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x896xf32>, tensor<1x1x1x896xf32>) outs(%4 : tensor<666x7x7x896xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<666x14x14x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x832xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x832xf32>) -> tensor<666x7x7x832xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x832xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x832xf32>) -> tensor<1x1x1x832xf32>\n    %4 = tensor.empty() : tensor<666x7x7x832xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x832xf32>, tensor<1x1x1x832xf32>) outs(%4 : tensor<666x7x7x832xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x832xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x348xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x348xf32>) -> tensor<666x1x1x348xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3712x1x1x348xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3712x1x1x348xf32>) -> tensor<3712x1x1x348xf32>\n    %4 = bufferization.alloc_tensor() : tensor<3712xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<3712xf32>) -> tensor<3712xf32>\n    %6 = tensor.empty() : tensor<666x1x1x3712xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<3712xf32>) outs(%6 : tensor<666x1x1x3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x3712xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x348xf32>, tensor<3712x1x1x348xf32>) outs(%7 : tensor<666x1x1x3712xf32>) -> tensor<666x1x1x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x24xf32>) -> tensor<666x112x112x24xf32>\n    %2 = tensor.empty() : tensor<666x112x112x24xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x24xf32>) outs(%2 : tensor<666x112x112x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x480xf32>) -> tensor<666x28x28x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x480xf32>) -> tensor<1x1x1x480xf32>\n    %4 = tensor.empty() : tensor<666x28x28x480xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x480xf32>, tensor<1x1x1x480xf32>) outs(%4 : tensor<666x28x28x480xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<216x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<216x1x1x72xf32>) -> tensor<216x1x1x72xf32>\n    %4 = bufferization.alloc_tensor() : tensor<216xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<216xf32>) -> tensor<216xf32>\n    %6 = tensor.empty() : tensor<666x56x56x216xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<216xf32>) outs(%6 : tensor<666x56x56x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x216xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x72xf32>, tensor<216x1x1x72xf32>) outs(%7 : tensor<666x56x56x216xf32>) -> tensor<666x56x56x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1312xf32>) -> tensor<666x14x14x1312xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1312xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1312xf32>) outs(%2 : tensor<666x14x14x1312xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1312xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = tensor.empty() : tensor<666x14x14x88xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x88xf32>) outs(%2 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1624xf32>) -> tensor<666x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1624xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x144xf32>) -> tensor<288x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x28x28x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<288x1x1x144xf32>) outs(%7 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1888xf32>) -> tensor<1888xf32>\n    %2 = tensor.empty() : tensor<1888xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1888xf32>) outs(%2 : tensor<1888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1088xf32>) -> tensor<1x1x1x1088xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1088xf32>, tensor<1x1x1x1088xf32>) outs(%4 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x256xf32>) -> tensor<666x8x8x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x8x8x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x8x8x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x128xf32>) -> tensor<666x1x1x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %4 = tensor.empty() : tensor<666x28x28x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x128xf32>, tensor<666x28x28x128xf32>) outs(%4 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x72xf32>) -> tensor<666x112x112x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x72xf32>) -> tensor<1x1x1x72xf32>\n    %4 = tensor.empty() : tensor<666x112x112x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x72xf32>, tensor<1x1x1x72xf32>) outs(%4 : tensor<666x112x112x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x59x59x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x59x59x22xf32>) -> tensor<666x59x59x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x22x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x22x1xf32>) -> tensor<5x5x22x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %6 = tensor.empty() : tensor<666x28x28x22x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x22xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x59x59x22xf32>, tensor<5x5x22x1xf32>) outs(%7 : tensor<666x28x28x22x1xf32>) -> tensor<666x28x28x22x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x22x1xf32> into tensor<666x28x28x22xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<22xf32>, tensor<666x28x28x22xf32>) outs(%8 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x960xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x1x960xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x1x960xf32>) -> tensor<160x1x1x960xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %6 = tensor.empty() : tensor<666x7x7x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x7x7x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x960xf32>, tensor<160x1x1x960xf32>) outs(%7 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<232x3x3x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<232x3x3x232xf32>) -> tensor<232x3x3x232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<232xf32>) -> tensor<232xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x232xf32> to tensor<666x58x58x232xf32>\n    %6 = tensor.empty() : tensor<666x56x56x232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<232xf32>) outs(%6 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x232xf32>, tensor<232x3x3x232xf32>) outs(%7 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x11x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x11x1xf32>) -> tensor<7x7x11x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<11xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<11xf32>) -> tensor<11xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x11xf32> to tensor<666x62x62x11xf32>\n    %6 = tensor.empty() : tensor<666x56x56x11x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x11xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x62x62x11xf32>, tensor<7x7x11x1xf32>) outs(%7 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x11x1xf32> into tensor<666x56x56x11xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<11xf32>, tensor<666x56x56x11xf32>) outs(%8 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1344xf32>) -> tensor<666x7x7x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1344xf32>) -> tensor<128x1x1x1344xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1344xf32>, tensor<128x1x1x1344xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1888xf32>) -> tensor<666x7x7x1888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1888xf32>) -> tensor<128x1x1x1888xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1888xf32>, tensor<128x1x1x1888xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x58x58x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x58x58x64xf32>) -> tensor<666x58x58x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x64xf32>) -> tensor<64x3x3x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x28x28x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x58x58x64xf32>, tensor<64x3x3x64xf32>) outs(%7 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x42xf32>) -> tensor<666x1x1x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x42xf32>) -> tensor<168x1x1x42xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x1x1x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x1x1x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x42xf32>, tensor<168x1x1x42xf32>) outs(%7 : tensor<666x1x1x168xf32>) -> tensor<666x1x1x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x448xf32>) -> tensor<666x14x14x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x14x14x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x14x14x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1312xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1312xf32>) -> tensor<666x7x7x1312xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1312xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1312xf32>) -> tensor<128x1x1x1312xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1312xf32>, tensor<128x1x1x1312xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x888xf32>) -> tensor<666x14x14x888xf32>\n    %2 = tensor.empty() : tensor<666x14x14x888xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x888xf32>) outs(%2 : tensor<666x14x14x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2048xf32>) -> tensor<2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<2048xf32>, tensor<1xf32>) outs(%4 : tensor<2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<2048xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %2 = tensor.empty() : tensor<666x7x3712xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x3712xf32>) -> tensor<666x7x3712xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x3712xf32>) outs(%3 : tensor<666x7x3712xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x3712xf32> into tensor<666x1x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x1x7x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x1x7x160xf32>) -> tensor<160x1x7x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 3, 0] high[0, 0, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x160xf32> to tensor<666x17x23x160xf32>\n    %6 = tensor.empty() : tensor<666x17x17x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x17x23x160xf32>, tensor<160x1x7x160xf32>) outs(%7 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x320xf32>) -> tensor<666x7x7x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1280x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1280x1x1x320xf32>) -> tensor<1280x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1280xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1280xf32>) -> tensor<1280xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1280xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1280xf32>) outs(%6 : tensor<666x7x7x1280xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1280xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x320xf32>, tensor<1280x1x1x320xf32>) outs(%7 : tensor<666x7x7x1280xf32>) -> tensor<666x7x7x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x1088xf32>) -> tensor<256x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x17x17x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x17x17x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x1088xf32>, tensor<256x1x1x1088xf32>) outs(%7 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<666x28x28x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<232x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<232x1x1x232xf32>) -> tensor<232x1x1x232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<232xf32>) -> tensor<232xf32>\n    %6 = tensor.empty() : tensor<666x56x56x232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<232xf32>) outs(%6 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x232xf32>, tensor<232x1x1x232xf32>) outs(%7 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x208xf32>) -> tensor<1x1x1x208xf32>\n    %4 = tensor.empty() : tensor<666x14x14x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x208xf32>, tensor<1x1x1x208xf32>) outs(%4 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x384xf32>) -> tensor<666x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x384xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x120xf32>) -> tensor<666x56x56x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x120xf32>) -> tensor<1x1x1x120xf32>\n    %4 = tensor.empty() : tensor<666x56x56x120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x120xf32>, tensor<1x1x1x120xf32>) outs(%4 : tensor<666x56x56x120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x120xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x14x14x1024xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x37x37x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x37x37x256xf32>) -> tensor<666x37x37x256xf32>\n    %4 = tensor.empty() : tensor<666x37x37x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x37x37x256xf32>, tensor<666x37x37x256xf32>) outs(%4 : tensor<666x37x37x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x37x37x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x928xf32>) -> tensor<666x14x14x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x928xf32>) -> tensor<1x1x1x928xf32>\n    %4 = tensor.empty() : tensor<666x14x14x928xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x928xf32>, tensor<1x1x1x928xf32>) outs(%4 : tensor<666x14x14x928xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x96xf32>) -> tensor<666x112x112x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x112x112x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x112x112x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1296x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1296x1x1x576xf32>) -> tensor<1296x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1296xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1296xf32>) -> tensor<1296xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1296xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1296xf32>) outs(%6 : tensor<666x7x7x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1296xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<1296x1x1x576xf32>) outs(%7 : tensor<666x7x7x1296xf32>) -> tensor<666x7x7x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x74x74x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x74x74x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x74x74x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x112xf32>) -> tensor<1x1x1x112xf32>\n    %4 = tensor.empty() : tensor<666x28x28x112xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x112xf32>, tensor<1x1x1x112xf32>) outs(%4 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x56x48xf32>) -> tensor<666x1x56x48xf32>\n    %2 = tensor.empty() : tensor<666x1x48xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x48xf32>) -> tensor<666x1x48xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x56x48xf32>) outs(%3 : tensor<666x1x48xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x48xf32> into tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x110xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x110xf32>) -> tensor<666x1x1x110xf32>\n    %2 = tensor.empty() : tensor<666x1x1x110xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x110xf32>) outs(%2 : tensor<666x1x1x110xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x110xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x192xf32>) -> tensor<32x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x28x28x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x28x28x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<32x1x1x192xf32>) outs(%7 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x4096xf32>) -> tensor<666x14x14x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x4096xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x4096xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x4096xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1344xf32>) -> tensor<666x7x7x1344xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1344xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1344xf32>) outs(%2 : tensor<666x7x7x1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<666x7x7x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x336xf32>) -> tensor<666x28x28x336xf32>\n    %2 = tensor.empty() : tensor<666x28x28x336xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x336xf32>) outs(%2 : tensor<666x28x28x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x96xf32>) -> tensor<666x165x165x96xf32>\n    %2 = tensor.empty() : tensor<666x165x165x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x165x165x96xf32>) outs(%2 : tensor<666x165x165x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x165x165x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %4 = tensor.empty() : tensor<666x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<666x1024xf32>) outs(%4 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x3x3x256xf32>) -> tensor<256x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x256xf32> to tensor<666x16x16x256xf32>\n    %6 = tensor.empty() : tensor<666x14x14x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x16x16x256xf32>, tensor<256x3x3x256xf32>) outs(%7 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3712xf32>) -> tensor<666x1x1x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<348x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<348x1x1x3712xf32>) -> tensor<348x1x1x3712xf32>\n    %4 = bufferization.alloc_tensor() : tensor<348xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<348xf32>) -> tensor<348xf32>\n    %6 = tensor.empty() : tensor<666x1x1x348xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<348xf32>) outs(%6 : tensor<666x1x1x348xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x348xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x3712xf32>, tensor<348x1x1x3712xf32>) outs(%7 : tensor<666x1x1x348xf32>) -> tensor<666x1x1x348xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %4 = tensor.empty() : tensor<666x56x56x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x144xf32>, tensor<666x56x56x144xf32>) outs(%4 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1088x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1088x1x1x384xf32>) -> tensor<1088x1x1x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1088xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1088xf32>) -> tensor<1088xf32>\n    %6 = tensor.empty() : tensor<666x17x17x1088xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1088xf32>) outs(%6 : tensor<666x17x17x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x1088xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x384xf32>, tensor<1088x1x1x384xf32>) outs(%7 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = tensor.empty() : tensor<666x1x1x48xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x48xf32>) outs(%2 : tensor<666x1x1x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x56x56x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x408xf32>) -> tensor<666x28x28x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x408xf32>) -> tensor<1x1x1x408xf32>\n    %4 = tensor.empty() : tensor<666x28x28x408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x408xf32>, tensor<1x1x1x408xf32>) outs(%4 : tensor<666x28x28x408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x928xf32>) -> tensor<666x14x14x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x928xf32>) -> tensor<1x1x1x928xf32>\n    %4 = tensor.empty() : tensor<666x14x14x928xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x928xf32>, tensor<1x1x1x928xf32>) outs(%4 : tensor<666x14x14x928xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x160xf32>) -> tensor<666x28x28x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x28x28x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x28x28x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x3x3x256xf32>) -> tensor<288x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x256xf32> to tensor<666x19x19x256xf32>\n    %6 = tensor.empty() : tensor<666x17x17x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x17x17x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x19x19x256xf32>, tensor<288x3x3x256xf32>) outs(%7 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<22x1x1x44xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<22x1x1x44xf32>) -> tensor<22x1x1x44xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %6 = tensor.empty() : tensor<666x28x28x22xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<22xf32>) outs(%6 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x22xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x44xf32>, tensor<22x1x1x44xf32>) outs(%7 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1056xf32>) -> tensor<666x7x7x1056xf32>\n    %2 = tensor.empty() : tensor<666x7x1056xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1056xf32>) -> tensor<666x7x1056xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1056xf32>) outs(%3 : tensor<666x7x1056xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1056xf32> into tensor<666x1x7x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1232xf32>) -> tensor<666x1x1x1232xf32>\n    %2 = tensor.empty() : tensor<666x1x1x1232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x1232xf32>) outs(%2 : tensor<666x1x1x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x14x14x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x14x14x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x416xf32>) -> tensor<666x28x28x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x416xf32>) -> tensor<128x1x1x416xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x416xf32>, tensor<128x1x1x416xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x14x14x256xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x28x28x256xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %c1 = arith.constant 1 : index\n    %c14 = arith.constant 14 : index\n    %c2 = arith.constant 2 : index\n    %c14_1 = arith.constant 14 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c14, %c1_2 : index\n    %7 = arith.subi %c14_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x14x14x256xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x14x14x256xf32>) outs(%8 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c2_4 = arith.constant 2 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c2_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c2_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c2_6 = arith.constant 2 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c2_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c2_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x512xf32>) -> tensor<128x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x512xf32>, tensor<128x1x1x512xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x96xf32>) -> tensor<666x17x17x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x17x17x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x17x17x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x696xf32>) -> tensor<666x56x56x696xf32>\n    %2 = tensor.empty() : tensor<666x56x56x696xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x696xf32>) outs(%2 : tensor<666x56x56x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x168xf32>) -> tensor<1x1x1x168xf32>\n    %4 = tensor.empty() : tensor<666x56x56x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<1x1x1x168xf32>) outs(%4 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = tensor.empty() : tensor<666x28x28x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x192xf32>) outs(%2 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x696xf32>) -> tensor<1x1x1x696xf32>\n    %4 = tensor.empty() : tensor<666x28x28x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x696xf32>, tensor<1x1x1x696xf32>) outs(%4 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x348xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x348xf32>) -> tensor<666x1x1x348xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1392x1x1x348xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1392x1x1x348xf32>) -> tensor<1392x1x1x348xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1392xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1392xf32>) -> tensor<1392xf32>\n    %6 = tensor.empty() : tensor<666x1x1x1392xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1392xf32>) outs(%6 : tensor<666x1x1x1392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x1392xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x348xf32>, tensor<1392x1x1x348xf32>) outs(%7 : tensor<666x1x1x1392xf32>) -> tensor<666x1x1x1392xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x130536x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x130536x1024xf32>) -> tensor<1x130536x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1024x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1024x4096xf32>) -> tensor<1x1024x4096xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x130536x4096xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x130536x4096xf32>) -> tensor<1x130536x4096xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x130536x1024xf32>, tensor<1x1024x4096xf32>) outs(%5 : tensor<1x130536x4096xf32>) -> tensor<1x130536x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x32xf32>) -> tensor<666x111x111x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x111x111x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x111x111x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x111x111x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x111x111x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1248xf32>) -> tensor<666x14x14x1248xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1248xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1248xf32>) -> tensor<1x1x1x1248xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1248xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1248xf32>, tensor<1x1x1x1248xf32>) outs(%4 : tensor<666x14x14x1248xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x17x17x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<666x28x28x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x800xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x800xf32>) -> tensor<666x7x7x800xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x800xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x800xf32>) -> tensor<1x1x1x800xf32>\n    %4 = tensor.empty() : tensor<666x7x7x800xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x800xf32>, tensor<1x1x1x800xf32>) outs(%4 : tensor<666x7x7x800xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x800xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x576xf32>) -> tensor<666x7x7x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x576xf32>) -> tensor<128x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x576xf32>, tensor<128x1x1x576xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x288xf32>) -> tensor<576x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x14x14x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<576x1x1x288xf32>) outs(%7 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<24x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<24x1x1x144xf32>) -> tensor<24x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<24xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<24xf32>) -> tensor<24xf32>\n    %6 = tensor.empty() : tensor<666x56x56x24xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<24xf32>) outs(%6 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x24xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<24x1x1x144xf32>) outs(%7 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1376xf32>) -> tensor<666x7x7x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1376xf32>) -> tensor<1x1x1x1376xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1376xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1376xf32>, tensor<1x1x1x1376xf32>) outs(%4 : tensor<666x7x7x1376xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %4 = tensor.empty() : tensor<666x28x28x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<666x28x28x448xf32>) outs(%4 : tensor<666x28x28x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x576x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x576x1xf32>) -> tensor<3x3x576x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x576xf32> to tensor<666x16x16x576xf32>\n    %6 = tensor.empty() : tensor<666x14x14x576x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x14x14x576x1xf32>) -> tensor<666x14x14x576x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x576xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x16x16x576xf32>, tensor<3x3x576x1xf32>) outs(%7 : tensor<666x14x14x576x1xf32>) -> tensor<666x14x14x576x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x576x1xf32> into tensor<666x14x14x576xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<576xf32>, tensor<666x14x14x576xf32>) outs(%8 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x11xf32> to tensor<666x58x58x11xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x56x56x11xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x58x58x11xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %c1 = arith.constant 1 : index\n    %c56 = arith.constant 56 : index\n    %c2 = arith.constant 2 : index\n    %c56_2 = arith.constant 56 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c56, %c1_3 : index\n    %7 = arith.subi %c56_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x56x56x11xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x56x56x11xf32>) outs(%8 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1440xf32>) -> tensor<666x7x7x1440xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1440xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1440xf32>) outs(%2 : tensor<666x7x7x1440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1696xf32>) -> tensor<666x7x7x1696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1696xf32>) -> tensor<1x1x1x1696xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1696xf32>, tensor<1x1x1x1696xf32>) outs(%4 : tensor<666x7x7x1696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x720xf32>) -> tensor<666x28x28x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x720xf32>) -> tensor<1x1x1x720xf32>\n    %4 = tensor.empty() : tensor<666x28x28x720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x720xf32>, tensor<1x1x1x720xf32>) outs(%4 : tensor<666x28x28x720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x7x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x7x1x160xf32>) -> tensor<192x7x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 0, 0] high[0, 3, 0, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x160xf32> to tensor<666x23x17x160xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x23x17x160xf32>, tensor<192x7x1x160xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1xf32>) outs(%2 : tensor<666x7x7x1xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<408x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<408x1x1x408xf32>) -> tensor<408x1x1x408xf32>\n    %4 = bufferization.alloc_tensor() : tensor<408xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<408xf32>) -> tensor<408xf32>\n    %6 = tensor.empty() : tensor<666x14x14x408xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<408xf32>) outs(%6 : tensor<666x14x14x408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x408xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x408xf32>, tensor<408x1x1x408xf32>) outs(%7 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x2016xf32>) -> tensor<666x11x11x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x2016xf32>) -> tensor<336x1x1x2016xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x11x11x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x11x11x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x11x11x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x11x11x2016xf32>, tensor<336x1x1x2016xf32>) outs(%7 : tensor<666x11x11x336xf32>) -> tensor<666x11x11x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x147x147x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x147x147x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x352xf32>) -> tensor<666x28x28x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x352xf32>) -> tensor<1x1x1x352xf32>\n    %4 = tensor.empty() : tensor<666x28x28x352xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x352xf32>, tensor<1x1x1x352xf32>) outs(%4 : tensor<666x28x28x352xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %2 = tensor.empty() : tensor<666x7x7x440xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x440xf32>) outs(%2 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x28x28x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x384xf32>) -> tensor<666x56x56x384xf32>\n    %2 = tensor.empty() : tensor<666x56x56x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x384xf32>) outs(%2 : tensor<666x56x56x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x384xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %2 = tensor.empty() : tensor<666x7x1512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1512xf32>) -> tensor<666x7x1512xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1512xf32>) outs(%3 : tensor<666x7x1512xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1512xf32> into tensor<666x1x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1232xf32>) -> tensor<666x1x1x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1232xf32>, tensor<666x14x14x1232xf32>) outs(%4 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x2048xf32>) -> tensor<666x10x10x2048xf32>\n    %2 = tensor.empty() : tensor<666x10x10x2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x10x10x2048xf32>) outs(%2 : tensor<666x10x10x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x10x10x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x728xf32>) -> tensor<1x1x1x728xf32>\n    %4 = tensor.empty() : tensor<666x37x37x728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x37x37x728xf32>, tensor<1x1x1x728xf32>) outs(%4 : tensor<666x37x37x728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x37x37x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x56x56x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x288xf32>) -> tensor<288x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x14x14x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x14x14x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<288x1x1x288xf32>) outs(%7 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1536xf32>, tensor<666x7x7x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    %2 = tensor.empty() : tensor<666x1x1x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x192xf32>) outs(%2 : tensor<666x1x1x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<240xf32>) -> tensor<240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<240xf32>, tensor<1xf32>) outs(%4 : tensor<240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<240xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x3712xf32>) -> tensor<1x666x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x3712x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x3712x1000xf32>) -> tensor<1x3712x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x3712xf32>, tensor<1x3712x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2520xf32>) -> tensor<666x14x14x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2520xf32>) -> tensor<1x1x1x2520xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2520xf32>, tensor<1x1x1x2520xf32>) outs(%4 : tensor<666x14x14x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2520xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x43x43x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x43x43x336xf32>) -> tensor<666x43x43x336xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x21x21x336xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x43x43x336xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1360xf32>) -> tensor<666x1x7x1360xf32>\n    %2 = tensor.empty() : tensor<666x1x1360xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1360xf32>) -> tensor<666x1x1360xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1360xf32>) outs(%3 : tensor<666x1x1360xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1360xf32> into tensor<666x1x1x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1024xf32>) -> tensor<666x56x56x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1024xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x768xf32>) -> tensor<666x56x56x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x768xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x44xf32>) -> tensor<666x56x56x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<22x1x1x44xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<22x1x1x44xf32>) -> tensor<22x1x1x44xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %6 = tensor.empty() : tensor<666x56x56x22xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<22xf32>) outs(%6 : tensor<666x56x56x22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x22xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x44xf32>, tensor<22x1x1x44xf32>) outs(%7 : tensor<666x56x56x22xf32>) -> tensor<666x56x56x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x512xf32>) -> tensor<512x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x14x14x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<512x1x1x512xf32>) outs(%7 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1632xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1632xf32>) -> tensor<1632xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1632xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1632xf32>, tensor<1xf32>) outs(%4 : tensor<1632xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1632xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x168xf32>) -> tensor<168x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x28x28x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x28x28x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x168xf32>, tensor<168x1x1x168xf32>) outs(%7 : tensor<666x28x28x168xf32>) -> tensor<666x28x28x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %4 = tensor.empty() : tensor<666x56x56x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<666x56x56x64xf32>) outs(%4 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x2048xf32>) -> tensor<666x10x10x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2048xf32>) -> tensor<1x1x1x2048xf32>\n    %4 = tensor.empty() : tensor<666x10x10x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x2048xf32>, tensor<1x1x1x2048xf32>) outs(%4 : tensor<666x10x10x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x2048xf32>) -> tensor<512x1x1x2048xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x7x7x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<512x1x1x2048xf32>) outs(%7 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %2 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x3024xf32>) outs(%2 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1536xf32>) -> tensor<666x10x10x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1536xf32>) -> tensor<1x1x1x1536xf32>\n    %4 = tensor.empty() : tensor<666x10x10x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x1536xf32>, tensor<1x1x1x1536xf32>) outs(%4 : tensor<666x10x10x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x11xf32>) -> tensor<1x1x1x11xf32>\n    %4 = tensor.empty() : tensor<666x56x56x11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x11xf32>, tensor<1x1x1x11xf32>) outs(%4 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<666x7x7x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x48xf32>) -> tensor<512x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x1x1x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x1x1x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x48xf32>, tensor<512x1x1x48xf32>) outs(%7 : tensor<666x1x1x512xf32>) -> tensor<666x1x1x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1408xf32>) -> tensor<1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1408xf32>, tensor<1xf32>) outs(%4 : tensor<1408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x576xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x216xf32>) -> tensor<666x56x56x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x216xf32>) -> tensor<1x1x1x216xf32>\n    %4 = tensor.empty() : tensor<666x56x56x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x216xf32>, tensor<1x1x1x216xf32>) outs(%4 : tensor<666x56x56x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1280xf32>) -> tensor<666x14x14x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<640x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<640x1x1x1280xf32>) -> tensor<640x1x1x1280xf32>\n    %4 = bufferization.alloc_tensor() : tensor<640xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<640xf32>) -> tensor<640xf32>\n    %6 = tensor.empty() : tensor<666x14x14x640xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<640xf32>) outs(%6 : tensor<666x14x14x640xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x640xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1280xf32>, tensor<640x1x1x1280xf32>) outs(%7 : tensor<666x14x14x640xf32>) -> tensor<666x14x14x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<720x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<720x1x1x240xf32>) -> tensor<720x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<720xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<720xf32>) -> tensor<720xf32>\n    %6 = tensor.empty() : tensor<666x28x28x720xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<720xf32>) outs(%6 : tensor<666x28x28x720xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x720xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<720x1x1x240xf32>) outs(%7 : tensor<666x28x28x720xf32>) -> tensor<666x28x28x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1280xf32>) -> tensor<666x14x14x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1280xf32>, tensor<1x1x1x1280xf32>) outs(%4 : tensor<666x14x14x1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<666x14x14x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %4 = tensor.empty() : tensor<666x14x14x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<666x14x14x256xf32>) outs(%4 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %2 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x3712xf32>) outs(%2 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1152xf32>) -> tensor<666x7x7x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1152xf32>) -> tensor<1x1x1x1152xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1152xf32>, tensor<1x1x1x1152xf32>) outs(%4 : tensor<666x7x7x1152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x11xf32>) -> tensor<1x1x1x11xf32>\n    %4 = tensor.empty() : tensor<666x56x56x11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x11xf32>, tensor<1x1x1x11xf32>) outs(%4 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x32xf32>) -> tensor<64x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x28x28x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<64x1x1x32xf32>) outs(%7 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = tensor.empty() : tensor<666x28x28x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x28x28x384xf32>, tensor<666x28x28x384xf32>) outs(%2 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1728xf32>) -> tensor<666x14x14x1728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1728xf32>) -> tensor<128x1x1x1728xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1728xf32>, tensor<128x1x1x1728xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x1x1x728xf32>) -> tensor<1024x1x1x728xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x10x10x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x10x10x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x10x10x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x19x19x728xf32>, tensor<1024x1x1x728xf32>) outs(%7 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x47x47x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x47x47x336xf32>) -> tensor<666x47x47x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x336x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x336x1xf32>) -> tensor<7x7x336x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %8 = tensor.empty() : tensor<666x21x21x336xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x47x47x336xf32>, tensor<7x7x336x1xf32>) outs(%7 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x21x21x336x1xf32> into tensor<666x21x21x336xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<336xf32>, tensor<666x21x21x336xf32>) outs(%8 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %2 = tensor.empty() : tensor<666x1024xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x1024xf32>, tensor<666x1024xf32>) outs(%2 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x448xf32>) -> tensor<666x56x56x448xf32>\n    %2 = tensor.empty() : tensor<666x56x56x448xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x448xf32>) outs(%2 : tensor<666x56x56x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %4 = tensor.empty() : tensor<666x14x14x576xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<666x14x14x576xf32>) outs(%4 : tensor<666x14x14x576xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x440xf32>) -> tensor<666x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x440xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x440xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x28x28x256xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x56x56x256xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x320xf32>) -> tensor<666x8x8x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x8x8x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x8x8x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x176xf32>) -> tensor<666x14x14x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x176xf32>) -> tensor<1x1x1x176xf32>\n    %4 = tensor.empty() : tensor<666x14x14x176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x176xf32>, tensor<1x1x1x176xf32>) outs(%4 : tensor<666x14x14x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = tensor.empty() : tensor<666x14x14x320xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x320xf32>) outs(%2 : tensor<666x14x14x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x768xf32>) -> tensor<666x56x56x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x768xf32>) -> tensor<1x1x1x768xf32>\n    %4 = tensor.empty() : tensor<666x56x56x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x768xf32>, tensor<1x1x1x768xf32>) outs(%4 : tensor<666x56x56x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<232x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<232x1x1x32xf32>) -> tensor<232x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<232xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<232xf32>) -> tensor<232xf32>\n    %6 = tensor.empty() : tensor<666x56x56x232xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<232xf32>) outs(%6 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x232xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<232x1x1x32xf32>) outs(%7 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<666x56x56x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<168xf32>) -> tensor<168xf32>\n    %2 = tensor.empty() : tensor<168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<168xf32>) outs(%2 : tensor<168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x192xf32>) -> tensor<1x1x1x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x192xf32>, tensor<1x1x1x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x224xf32>) -> tensor<128x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<128x1x1x224xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1120xf32>) -> tensor<666x14x14x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1120xf32>) -> tensor<1x1x1x1120xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1120xf32>, tensor<1x1x1x1120xf32>) outs(%4 : tensor<666x14x14x1120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = tensor.empty() : tensor<666x1xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1 : tensor<666x1xf32>) outs(%2 : tensor<666x1xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.divf %cst_0, %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<168x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<168x1x1x168xf32>) -> tensor<168x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %6 = tensor.empty() : tensor<666x42x42x168xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<168xf32>) outs(%6 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x42x42x168xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x42x42x168xf32>, tensor<168x1x1x168xf32>) outs(%7 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x7x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x7x1x192xf32>) -> tensor<192x7x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 0, 0] high[0, 3, 0, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x192xf32> to tensor<666x23x17x192xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x23x17x192xf32>, tensor<192x7x1x192xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x864xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x864xf32>) -> tensor<666x7x7x864xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x864xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x864xf32>) -> tensor<1x1x1x864xf32>\n    %4 = tensor.empty() : tensor<666x7x7x864xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x864xf32>, tensor<1x1x1x864xf32>) outs(%4 : tensor<666x7x7x864xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x864xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x736xf32>) -> tensor<666x14x14x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x736xf32>) -> tensor<128x1x1x736xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x736xf32>, tensor<128x1x1x736xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1296xf32>) -> tensor<1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1296xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1296xf32>, tensor<1xf32>) outs(%4 : tensor<1296xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x32xf32>) -> tensor<32x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x112x112x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<32x1x1x32xf32>) outs(%7 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1824xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1824xf32>) -> tensor<666x7x7x1824xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1824xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1824xf32>) outs(%2 : tensor<666x7x7x1824xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1824xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %2 = tensor.empty() : tensor<666x2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x2048xf32>, tensor<666x2048xf32>) outs(%2 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x416xf32>) -> tensor<666x14x14x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x416xf32>) -> tensor<128x1x1x416xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x416xf32>, tensor<128x1x1x416xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x112x112x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x112x112x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x112xf32>) -> tensor<448x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x1x1x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x1x1x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x112xf32>, tensor<448x1x1x112xf32>) outs(%7 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x2x2x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x2x2x128xf32>) -> tensor<256x2x2x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x28x28x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x128xf32>, tensor<256x2x2x128xf32>) outs(%7 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %4 = tensor.empty() : tensor<666x42x42x168xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x42x42x168xf32>, tensor<666x42x42x168xf32>) outs(%4 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2520xf32>) -> tensor<666x14x14x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2520xf32>) -> tensor<1x1x1x2520xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2520xf32>, tensor<1x1x1x2520xf32>) outs(%4 : tensor<666x14x14x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x256xf32>) -> tensor<128x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x256xf32>, tensor<128x1x1x256xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x92xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x92xf32>) -> tensor<666x1x1x92xf32>\n    %2 = bufferization.alloc_tensor() : tensor<368x1x1x92xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<368x1x1x92xf32>) -> tensor<368x1x1x92xf32>\n    %4 = bufferization.alloc_tensor() : tensor<368xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<368xf32>) -> tensor<368xf32>\n    %6 = tensor.empty() : tensor<666x1x1x368xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<368xf32>) outs(%6 : tensor<666x1x1x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x368xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x92xf32>, tensor<368x1x1x92xf32>) outs(%7 : tensor<666x1x1x368xf32>) -> tensor<666x1x1x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1536xf32>, tensor<666x7x7x1536xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<666x7x7x1xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x45x45x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x45x45x336xf32>) -> tensor<666x45x45x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x336x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x336x1xf32>) -> tensor<5x5x336x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %8 = tensor.empty() : tensor<666x21x21x336xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x45x45x336xf32>, tensor<5x5x336x1xf32>) outs(%7 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x21x21x336x1xf32> into tensor<666x21x21x336xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<336xf32>, tensor<666x21x21x336xf32>) outs(%8 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x440xf32>) -> tensor<1x1x1x440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x440xf32>, tensor<1x1x1x440xf32>) outs(%4 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1024xf32>) -> tensor<128x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<128x1x1x1024xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1232xf32>) -> tensor<1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1232xf32>, tensor<1xf32>) outs(%4 : tensor<1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x28x28x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x8192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x8192xf32>) -> tensor<666x7x7x8192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x8192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x8192xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x8192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x8192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x128xf32>) -> tensor<32x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x128xf32> to tensor<666x16x16x128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x14x14x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x16x16x128xf32>, tensor<32x3x3x128xf32>) outs(%7 : tensor<666x14x14x32xf32>) -> tensor<666x14x14x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1120xf32>) -> tensor<666x14x14x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1120xf32>) -> tensor<1x1x1x1120xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1120xf32>, tensor<1x1x1x1120xf32>) outs(%4 : tensor<666x14x14x1120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1600xf32>) -> tensor<666x7x7x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1600xf32>) -> tensor<1x1x1x1600xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1600xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1600xf32>, tensor<1x1x1x1600xf32>) outs(%4 : tensor<666x7x7x1600xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = tensor.empty() : tensor<666x1x1x48xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x48xf32>) outs(%2 : tensor<666x1x1x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1440xf32>) -> tensor<666x14x14x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1440xf32>) -> tensor<1x1x1x1440xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1440xf32>, tensor<1x1x1x1440xf32>) outs(%4 : tensor<666x14x14x1440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x56x56x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x10x10x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x10x10x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x10x10x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x10x10x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1008xf32>) -> tensor<1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1008xf32>, tensor<1xf32>) outs(%4 : tensor<1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x448xf32>) -> tensor<666x14x14x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x14x14x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x14x14x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1216xf32>) -> tensor<666x7x7x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1216xf32>) -> tensor<1x1x1x1216xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1216xf32>, tensor<1x1x1x1216xf32>) outs(%4 : tensor<666x7x7x1216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x16xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x16xf32>) -> tensor<666x112x112x16xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x16xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x16xf32>) -> tensor<1x1x1x16xf32>\n    %4 = tensor.empty() : tensor<666x112x112x16xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x16xf32>, tensor<1x1x1x16xf32>) outs(%4 : tensor<666x112x112x16xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2080xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2080xf32>) -> tensor<666x8x8x2080xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x8x8x2080xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x8x8x2080xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x8x8x2080xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x8x8x2080xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x37x37x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x37x37x728xf32>) -> tensor<666x37x37x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x728xf32>) -> tensor<1x1x1x728xf32>\n    %4 = tensor.empty() : tensor<666x37x37x728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x37x37x728xf32>, tensor<1x1x1x728xf32>) outs(%4 : tensor<666x37x37x728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x37x37x728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1504xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1504xf32>) -> tensor<666x7x7x1504xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1504xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1504xf32>) -> tensor<1x1x1x1504xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1504xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1504xf32>, tensor<1x1x1x1504xf32>) outs(%4 : tensor<666x7x7x1504xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1504xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x128xf32>) -> tensor<32x3x3x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x7x7x128xf32> to tensor<666x9x9x128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x7x7x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x9x9x128xf32>, tensor<32x3x3x128xf32>) outs(%7 : tensor<666x7x7x32xf32>) -> tensor<666x7x7x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x14x14x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x14x14x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    %2 = tensor.empty() : tensor<666x1x1x448xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x448xf32>) outs(%2 : tensor<666x1x1x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x512xf32>) -> tensor<666x56x56x512xf32>\n    %4 = tensor.empty() : tensor<666x56x56x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x512xf32>, tensor<666x56x56x512xf32>) outs(%4 : tensor<666x56x56x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x28x28x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x7x7x512xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x14x14x512xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %c1 = arith.constant 1 : index\n    %c7 = arith.constant 7 : index\n    %c2 = arith.constant 2 : index\n    %c7_1 = arith.constant 7 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c7, %c1_2 : index\n    %7 = arith.subi %c7_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x7x7x512xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x7x7x512xf32>) outs(%8 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c2_4 = arith.constant 2 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c2_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c2_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c2_6 = arith.constant 2 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c2_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c2_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x2x2x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x2x2x512xf32>) -> tensor<1024x2x2x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<1024x2x2x512xf32>) outs(%7 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x640xf32>) -> tensor<666x7x7x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x640xf32>) -> tensor<1x1x1x640xf32>\n    %4 = tensor.empty() : tensor<666x7x7x640xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x640xf32>, tensor<1x1x1x640xf32>) outs(%4 : tensor<666x7x7x640xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1472xf32>) -> tensor<666x7x7x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1472xf32>) -> tensor<1x1x1x1472xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1472xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1472xf32>, tensor<1x1x1x1472xf32>) outs(%4 : tensor<666x7x7x1472xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1408xf32>) -> tensor<666x7x7x1408xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1408xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1408xf32>) outs(%2 : tensor<666x7x7x1408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x672x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x672x1xf32>) -> tensor<7x7x672x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x11x11x672xf32> to tensor<666x17x17x672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %8 = tensor.empty() : tensor<666x11x11x672xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x17x17x672xf32>, tensor<7x7x672x1xf32>) outs(%7 : tensor<666x11x11x672x1xf32>) -> tensor<666x11x11x672x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x11x11x672x1xf32> into tensor<666x11x11x672xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<672xf32>, tensor<666x11x11x672xf32>) outs(%8 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1600xf32>) -> tensor<666x7x7x1600xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1600xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1600xf32>) outs(%2 : tensor<666x7x7x1600xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1600xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x48xf32>) -> tensor<96x1x1x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x56x56x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<96x1x1x48xf32>) outs(%7 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1152xf32>) -> tensor<666x14x14x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1152xf32>) -> tensor<1x1x1x1152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1152xf32>, tensor<1x1x1x1152xf32>) outs(%4 : tensor<666x14x14x1152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x216xf32>) -> tensor<1x1x1x216xf32>\n    %4 = tensor.empty() : tensor<666x28x28x216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x216xf32>, tensor<1x1x1x216xf32>) outs(%4 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x64xf32>) -> tensor<64x3x3x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x64xf32> to tensor<666x58x58x64xf32>\n    %6 = tensor.empty() : tensor<666x56x56x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x64xf32>, tensor<64x3x3x64xf32>) outs(%7 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x1008xf32>) -> tensor<666x42x42x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x1008xf32>) -> tensor<336x1x1x1008xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x42x42x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x42x42x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x42x42x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x42x42x1008xf32>, tensor<336x1x1x1008xf32>) outs(%7 : tensor<666x42x42x336xf32>) -> tensor<666x42x42x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x544xf32>) -> tensor<666x14x14x544xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x544xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x544xf32>) -> tensor<1x1x1x544xf32>\n    %4 = tensor.empty() : tensor<666x14x14x544xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x544xf32>, tensor<1x1x1x544xf32>) outs(%4 : tensor<666x14x14x544xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1760xf32>) -> tensor<666x7x7x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1760xf32>) -> tensor<1x1x1x1760xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1760xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1760xf32>, tensor<1x1x1x1760xf32>) outs(%4 : tensor<666x7x7x1760xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x96xf32>) -> tensor<666x83x83x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<42x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<42x1x1x96xf32>) -> tensor<42x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %6 = tensor.empty() : tensor<666x83x83x42xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<42xf32>) outs(%6 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x83x83x42xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x83x83x96xf32>, tensor<42x1x1x96xf32>) outs(%7 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x896xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2240x1x1x896xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2240x1x1x896xf32>) -> tensor<2240x1x1x896xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2240xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2240xf32>) -> tensor<2240xf32>\n    %6 = tensor.empty() : tensor<666x14x14x2240xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2240xf32>) outs(%6 : tensor<666x14x14x2240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x2240xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x896xf32>, tensor<2240x1x1x896xf32>) outs(%7 : tensor<666x14x14x2240xf32>) -> tensor<666x14x14x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = tensor.empty() : tensor<666x28x28x216xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x216xf32>) outs(%2 : tensor<666x28x28x216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<912xf32>) -> tensor<912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<912xf32>, tensor<1xf32>) outs(%4 : tensor<912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1408xf32>) -> tensor<666x14x14x1408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1408xf32>) -> tensor<128x1x1x1408xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1408xf32>, tensor<128x1x1x1408xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1376xf32>) -> tensor<666x7x7x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1376xf32>) -> tensor<1x1x1x1376xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1376xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1376xf32>, tensor<1x1x1x1376xf32>) outs(%4 : tensor<666x7x7x1376xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x21x21x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x21x21x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x144xf32>) -> tensor<666x28x28x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x28x28x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x28x28x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x288xf32>) -> tensor<666x17x17x288xf32>\n    %2 = tensor.empty() : tensor<666x17x17x288xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x288xf32>) outs(%2 : tensor<666x17x17x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x35x35x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x35x35x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x768xf32>, tensor<666x7x7x1xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x912xf32>) -> tensor<666x14x14x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x912xf32>) -> tensor<1x1x1x912xf32>\n    %4 = tensor.empty() : tensor<666x14x14x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x912xf32>, tensor<1x1x1x912xf32>) outs(%4 : tensor<666x14x14x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1440xf32>) -> tensor<666x7x7x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1440xf32>) -> tensor<1x1x1x1440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1440xf32>, tensor<1x1x1x1440xf32>) outs(%4 : tensor<666x7x7x1440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x384xf32>) -> tensor<64x1x1x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x14x14x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x14x14x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<64x1x1x384xf32>) outs(%7 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %2 = tensor.empty() : tensor<666x7x608xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x608xf32>) -> tensor<666x7x608xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x608xf32>) outs(%3 : tensor<666x7x608xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x608xf32> into tensor<666x1x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x512xf32>) -> tensor<666x1x1x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x512xf32>) -> tensor<48x1x1x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x1x1x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x1x1x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x512xf32>, tensor<48x1x1x512xf32>) outs(%7 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<392xf32>) -> tensor<392xf32>\n    %2 = tensor.empty() : tensor<392xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<392xf32>) outs(%2 : tensor<392xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = tensor.empty() : tensor<666x28x28x288xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x288xf32>) outs(%2 : tensor<666x28x28x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x448xf32>) -> tensor<666x56x56x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x448xf32>) -> tensor<1x1x1x448xf32>\n    %4 = tensor.empty() : tensor<666x56x56x448xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x448xf32>, tensor<1x1x1x448xf32>) outs(%4 : tensor<666x56x56x448xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x11x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x11x1xf32>) -> tensor<3x3x11x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<11xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<11xf32>) -> tensor<11xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x11xf32> to tensor<666x58x58x11xf32>\n    %6 = tensor.empty() : tensor<666x56x56x11x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x11xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x11xf32>, tensor<3x3x11x1xf32>) outs(%7 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x11x1xf32> into tensor<666x56x56x11xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<11xf32>, tensor<666x56x56x11xf32>) outs(%8 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1824xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1824xf32>) -> tensor<666x7x7x1824xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1824xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1824xf32>) -> tensor<1x1x1x1824xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1824xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1824xf32>, tensor<1x1x1x1824xf32>) outs(%4 : tensor<666x7x7x1824xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1824xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x992xf32>) -> tensor<666x7x7x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x992xf32>) -> tensor<1x1x1x992xf32>\n    %4 = tensor.empty() : tensor<666x7x7x992xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x992xf32>, tensor<1x1x1x992xf32>) outs(%4 : tensor<666x7x7x992xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<11x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<11x1x1x32xf32>) -> tensor<11x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<11xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<11xf32>) -> tensor<11xf32>\n    %6 = tensor.empty() : tensor<666x56x56x11xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<11xf32>) outs(%6 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x11xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<11x1x1x32xf32>) outs(%7 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x768xf32>) -> tensor<666x17x17x768xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x768xf32> to tensor<666x19x19x768xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x17x17x768xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x17x17x768xf32>) -> tensor<666x17x17x768xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x19x19x768xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x17x17x768xf32>) -> tensor<666x17x17x768xf32>\n    %c1 = arith.constant 1 : index\n    %c17 = arith.constant 17 : index\n    %c2 = arith.constant 2 : index\n    %c17_2 = arith.constant 17 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c17, %c1_3 : index\n    %7 = arith.subi %c17_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x17x17x768xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x17x17x768xf32>) outs(%8 : tensor<666x17x17x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x17x17x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1920xf32>) -> tensor<666x14x14x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1920xf32>) -> tensor<1x1x1x1920xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1920xf32>, tensor<1x1x1x1920xf32>) outs(%4 : tensor<666x14x14x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x84xf32>) -> tensor<666x83x83x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x84xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x84xf32>) -> tensor<1x1x1x84xf32>\n    %4 = tensor.empty() : tensor<666x83x83x84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x83x83x84xf32>, tensor<1x1x1x84xf32>) outs(%4 : tensor<666x83x83x84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x83x83x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<888xf32>) -> tensor<888xf32>\n    %2 = tensor.empty() : tensor<888xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<888xf32>) outs(%2 : tensor<888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x224xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x912xf32>) -> tensor<1x1x1x912xf32>\n    %4 = tensor.empty() : tensor<666x7x7x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x912xf32>, tensor<1x1x1x912xf32>) outs(%4 : tensor<666x7x7x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x912xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x2048xf32>) -> tensor<666x10x10x2048xf32>\n    %2 = tensor.empty() : tensor<666x10x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x10x2048xf32>) -> tensor<666x10x2048xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x10x10x2048xf32>) outs(%3 : tensor<666x10x2048xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x10x2048xf32> into tensor<666x1x10x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<768x2x2x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<768x2x2x384xf32>) -> tensor<768x2x2x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<768xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<768xf32>) -> tensor<768xf32>\n    %6 = tensor.empty() : tensor<666x14x14x768xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<768xf32>) outs(%6 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x768xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<768x2x2x384xf32>) outs(%7 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x56x56x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = tensor.empty() : tensor<666x1xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1 : tensor<666x1xf32>) outs(%2 : tensor<666x1xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1232xf32>) -> tensor<666x28x28x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1232xf32>) -> tensor<1x1x1x1232xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1232xf32>, tensor<1x1x1x1232xf32>) outs(%4 : tensor<666x28x28x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %4 = tensor.empty() : tensor<666x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<666x1536xf32>) outs(%4 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2016xf32>) -> tensor<2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<2016xf32>, tensor<1xf32>) outs(%4 : tensor<2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<2016xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = tensor.empty() : tensor<666x28x696xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x696xf32>) -> tensor<666x28x696xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x696xf32>) outs(%3 : tensor<666x28x696xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x696xf32> into tensor<666x1x28x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x368xf32>) -> tensor<666x1x1x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x368xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x128xf32>) -> tensor<256x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x74x74x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x74x74x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x74x74x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x74x74x128xf32>, tensor<256x1x1x128xf32>) outs(%7 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1376xf32>) -> tensor<666x14x14x1376xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1376xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1376xf32>) outs(%2 : tensor<666x14x14x1376xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x2688xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x2688xf32>) -> tensor<666x11x11x2688xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x2688xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x2688xf32>) -> tensor<672x1x1x2688xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x11x11x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x11x11x2688xf32>, tensor<672x1x1x2688xf32>) outs(%7 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x208xf32>) -> tensor<666x1x1x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %4 = tensor.empty() : tensor<666x14x14x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x208xf32>, tensor<666x14x14x208xf32>) outs(%4 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1088xf32>) -> tensor<666x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1088xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x320xf32>) -> tensor<666x1x1x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x320xf32>) -> tensor<32x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x1x1x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x1x1x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x320xf32>, tensor<32x1x1x320xf32>) outs(%7 : tensor<666x1x1x32xf32>) -> tensor<666x1x1x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1536xf32>) -> tensor<666x1536xf32>\n    %4 = tensor.empty() : tensor<666x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1536xf32>, tensor<666x1536xf32>) outs(%4 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<11xf32>) -> tensor<11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<11xf32>, tensor<1xf32>) outs(%4 : tensor<11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<11xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x768xf32>) -> tensor<666x768xf32>\n    %2 = tensor.empty() : tensor<666xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666xf32>) -> tensor<666xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x768xf32>) outs(%3 : tensor<666xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0, 1]] : tensor<666xf32> into tensor<666x1xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x28x448xf32>) -> tensor<666x1x28x448xf32>\n    %2 = tensor.empty() : tensor<666x1x448xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x448xf32>) -> tensor<666x1x448xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x28x448xf32>) outs(%3 : tensor<666x1x448xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x448xf32> into tensor<666x1x1x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x176xf32>) -> tensor<666x17x17x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x176x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x176x1xf32>) -> tensor<5x5x176x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %8 = tensor.empty() : tensor<666x7x7x176xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x176xf32>, tensor<5x5x176x1xf32>) outs(%7 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x7x7x176x1xf32> into tensor<666x7x7x176xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<176xf32>, tensor<666x7x7x176xf32>) outs(%8 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x32xf32>) -> tensor<666x1x1x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x32xf32>) -> tensor<192x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x1x1x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x1x1x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x32xf32>, tensor<192x1x1x32xf32>) outs(%7 : tensor<666x1x1x192xf32>) -> tensor<666x1x1x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1056xf32>) -> tensor<666x7x7x1056xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1056xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1056xf32>) outs(%2 : tensor<666x7x7x1056xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1120xf32>) -> tensor<666x7x7x1120xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1120xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1120xf32>) outs(%2 : tensor<666x7x7x1120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x352xf32>) -> tensor<666x14x14x352xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x352xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x352xf32>) -> tensor<1x1x1x352xf32>\n    %4 = tensor.empty() : tensor<666x14x14x352xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x352xf32>, tensor<1x1x1x352xf32>) outs(%4 : tensor<666x14x14x352xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x192xf32>) -> tensor<192x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x28x28x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<192x1x1x192xf32>) outs(%7 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x8xf32>) -> tensor<224x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x1x1x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<224x1x1x8xf32>) outs(%7 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1760xf32>) -> tensor<666x7x7x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1760xf32>) -> tensor<1x1x1x1760xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1760xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1760xf32>, tensor<1x1x1x1760xf32>) outs(%4 : tensor<666x7x7x1760xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x888xf32>) -> tensor<666x1x1x888xf32>\n    %2 = tensor.empty() : tensor<666x1x1x888xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x888xf32>) outs(%2 : tensor<666x1x1x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x1088xf32>) -> tensor<192x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x17x17x1088xf32>, tensor<192x1x1x1088xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x2240xf32>) -> tensor<666x1x7x2240xf32>\n    %2 = tensor.empty() : tensor<666x1x2240xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x2240xf32>) -> tensor<666x1x2240xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x2240xf32>) outs(%3 : tensor<666x1x2240xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x2240xf32> into tensor<666x1x1x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1624xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1624xf32>) -> tensor<666x14x14x1624xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1624xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1624xf32>) -> tensor<1x1x1x1624xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1624xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1624xf32>, tensor<1x1x1x1624xf32>) outs(%4 : tensor<666x14x14x1624xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1624xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<48x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<48x1x1x256xf32>) -> tensor<48x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<48xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<48xf32>) -> tensor<48xf32>\n    %6 = tensor.empty() : tensor<666x35x35x48xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<48xf32>) outs(%6 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x48xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x256xf32>, tensor<48x1x1x256xf32>) outs(%7 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1184xf32>) -> tensor<666x14x14x1184xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1184xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1184xf32>) -> tensor<1x1x1x1184xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1184xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1184xf32>, tensor<1x1x1x1184xf32>) outs(%4 : tensor<666x14x14x1184xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x768xf32>) -> tensor<666x1x1x768xf32>\n    %2 = tensor.empty() : tensor<666x1x1x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x768xf32>) outs(%2 : tensor<666x1x1x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<144xf32>) -> tensor<144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<144xf32>, tensor<1xf32>) outs(%4 : tensor<144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x288xf32>) -> tensor<666x28x28x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x288xf32>) -> tensor<128x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x288xf32>, tensor<128x1x1x288xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x88x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x88x1xf32>) -> tensor<5x5x88x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x88xf32> to tensor<666x18x18x88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x88xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x18x18x88xf32>, tensor<5x5x88x1xf32>) outs(%7 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x88x1xf32> into tensor<666x14x14x88xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<88xf32>, tensor<666x14x14x88xf32>) outs(%8 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<640xf32>) -> tensor<640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<640xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<640xf32>, tensor<1xf32>) outs(%4 : tensor<640xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1856xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1856xf32>) -> tensor<1856xf32>\n    %2 = tensor.empty() : tensor<1856xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1856xf32>) outs(%2 : tensor<1856xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1856xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<128xf32>) -> tensor<128xf32>\n    %2 = tensor.empty() : tensor<128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<128xf32>) outs(%2 : tensor<128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x336xf32>) -> tensor<666x56x56x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x56x56x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x56x56x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x7x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x7x192xf32>) -> tensor<192x1x7x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 3, 0] high[0, 0, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x192xf32> to tensor<666x17x23x192xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x17x23x192xf32>, tensor<192x1x7x192xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x147x147x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x147x147x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    %2 = tensor.empty() : tensor<666x35x35x48xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x35x35x48xf32>) outs(%2 : tensor<666x35x35x48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x35x35x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x56xf32>) -> tensor<224x1x1x56xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x1x1x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x1x1x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x56xf32>, tensor<224x1x1x56xf32>) outs(%7 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<560xf32>) -> tensor<560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<560xf32>, tensor<1xf32>) outs(%4 : tensor<560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x42xf32>) -> tensor<1x1x1x42xf32>\n    %4 = tensor.empty() : tensor<666x83x83x42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x83x83x42xf32>, tensor<1x1x1x42xf32>) outs(%4 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x52xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x52xf32>) -> tensor<666x1x1x52xf32>\n    %2 = bufferization.alloc_tensor() : tensor<208x1x1x52xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<208x1x1x52xf32>) -> tensor<208x1x1x52xf32>\n    %4 = bufferization.alloc_tensor() : tensor<208xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<208xf32>) -> tensor<208xf32>\n    %6 = tensor.empty() : tensor<666x1x1x208xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<208xf32>) outs(%6 : tensor<666x1x1x208xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x208xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x52xf32>, tensor<208x1x1x52xf32>) outs(%7 : tensor<666x1x1x208xf32>) -> tensor<666x1x1x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<24xf32>) -> tensor<24xf32>\n    %2 = tensor.empty() : tensor<24xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<24xf32>) outs(%2 : tensor<24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<64xf32>) -> tensor<64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<64xf32>, tensor<1xf32>) outs(%4 : tensor<64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1152xf32>) -> tensor<666x14x14x1152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1152xf32>) -> tensor<128x1x1x1152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1152xf32>, tensor<128x1x1x1152xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x928xf32>) -> tensor<666x14x14x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x928xf32>) -> tensor<128x1x1x928xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x928xf32>, tensor<128x1x1x928xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x2016xf32>) -> tensor<666x21x21x2016xf32>\n    %2 = tensor.empty() : tensor<666x21x21x2016xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x21x21x2016xf32>) outs(%2 : tensor<666x21x21x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x21x21x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x56xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x56xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x56xf32>) -> tensor<448x1x1x56xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x1x1x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x1x1x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x56xf32>, tensor<448x1x1x56xf32>) outs(%7 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3712xf32>) -> tensor<666x14x14x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3712xf32>) -> tensor<1x1x1x3712xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3712xf32>, tensor<1x1x1x3712xf32>) outs(%4 : tensor<666x14x14x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<192xf32>) -> tensor<192xf32>\n    %2 = tensor.empty() : tensor<192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<192xf32>) outs(%2 : tensor<192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x56x56x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x672xf32>) -> tensor<666x14x14x672xf32>\n    %2 = tensor.empty() : tensor<666x14x14x672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x672xf32>) outs(%2 : tensor<666x14x14x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x128xf32>) -> tensor<320x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x28x28x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x28x28x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<320x1x1x128xf32>) outs(%7 : tensor<666x28x28x320xf32>) -> tensor<666x28x28x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x8192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x8192xf32>) -> tensor<666x7x7x8192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x8192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x8192xf32>) -> tensor<1x1x1x8192xf32>\n    %4 = tensor.empty() : tensor<666x7x7x8192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x8192xf32>, tensor<1x1x1x8192xf32>) outs(%4 : tensor<666x7x7x8192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x8192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<768xf32>) -> tensor<768xf32>\n    %2 = tensor.empty() : tensor<768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<768xf32>) outs(%2 : tensor<768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3072xf32>) -> tensor<666x14x14x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3072xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x384xf32>) -> tensor<666x14x14x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x384xf32>) -> tensor<1x1x1x384xf32>\n    %4 = tensor.empty() : tensor<666x14x14x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x384xf32>, tensor<1x1x1x384xf32>) outs(%4 : tensor<666x14x14x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x432xf32>) -> tensor<1x1x1x432xf32>\n    %4 = tensor.empty() : tensor<666x14x14x432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x432xf32>, tensor<1x1x1x432xf32>) outs(%4 : tensor<666x14x14x432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1888xf32>) -> tensor<666x7x7x1888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1888xf32>) -> tensor<1x1x1x1888xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1888xf32>, tensor<1x1x1x1888xf32>) outs(%4 : tensor<666x7x7x1888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x128xf32>) -> tensor<666x35x35x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<320x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<320x1x1x128xf32>) -> tensor<320x1x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<320xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<320xf32>) -> tensor<320xf32>\n    %6 = tensor.empty() : tensor<666x35x35x320xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<320xf32>) outs(%6 : tensor<666x35x35x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x320xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x128xf32>, tensor<320x1x1x128xf32>) outs(%7 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x3x3x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x3x3x32xf32>) -> tensor<32x3x3x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x32xf32> to tensor<666x37x37x32xf32>\n    %6 = tensor.empty() : tensor<666x35x35x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x35x35x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x37x37x32xf32>, tensor<32x3x3x32xf32>) outs(%7 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %4 = tensor.empty() : tensor<666x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x2048xf32>, tensor<666x1xf32>) outs(%4 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x72xf32>) -> tensor<666x112x112x72xf32>\n    %2 = tensor.empty() : tensor<666x112x112x72xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x112x112x72xf32>) outs(%2 : tensor<666x112x112x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x112x112x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x928xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x928xf32>) -> tensor<666x14x14x928xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x928xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x928xf32>) -> tensor<1x1x1x928xf32>\n    %4 = tensor.empty() : tensor<666x14x14x928xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x928xf32>, tensor<1x1x1x928xf32>) outs(%4 : tensor<666x14x14x928xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x928xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3072xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3072xf32>) -> tensor<666x14x14x3072xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3072xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3072xf32>) -> tensor<1x1x1x3072xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3072xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3072xf32>, tensor<1x1x1x3072xf32>) outs(%4 : tensor<666x14x14x3072xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3072xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1008x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1008x1x1x432xf32>) -> tensor<1008x1x1x432xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1008xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1008xf32>) -> tensor<1008xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1008xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1008xf32>) outs(%6 : tensor<666x7x7x1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1008xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x432xf32>, tensor<1008x1x1x432xf32>) outs(%7 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = tensor.empty() : tensor<666x28x28xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28xf32>) -> tensor<666x28x28xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x384xf32>) outs(%3 : tensor<666x28x28xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x28x28xf32> into tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x672xf32>) -> tensor<666x1x7x672xf32>\n    %2 = tensor.empty() : tensor<666x1x672xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x672xf32>) -> tensor<666x1x672xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x672xf32>) outs(%3 : tensor<666x1x672xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x672xf32> into tensor<666x1x1x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x144xf32>) -> tensor<666x112x112x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x144xf32>) -> tensor<1x1x1x144xf32>\n    %4 = tensor.empty() : tensor<666x112x112x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x144xf32>, tensor<1x1x1x144xf32>) outs(%4 : tensor<666x112x112x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1216xf32>) -> tensor<666x14x14x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1216xf32>) -> tensor<128x1x1x1216xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1216xf32>, tensor<128x1x1x1216xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x768xf32>) -> tensor<666x1x1x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    %4 = tensor.empty() : tensor<666x7x7x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x768xf32>, tensor<666x7x7x768xf32>) outs(%4 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x336x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x336x1xf32>) -> tensor<7x7x336x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x21x21x336xf32> to tensor<666x27x27x336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %8 = tensor.empty() : tensor<666x21x21x336xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x27x27x336xf32>, tensor<7x7x336x1xf32>) outs(%7 : tensor<666x21x21x336x1xf32>) -> tensor<666x21x21x336x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x21x21x336x1xf32> into tensor<666x21x21x336xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<336xf32>, tensor<666x21x21x336xf32>) outs(%8 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1008xf32>) -> tensor<1x1x1x1008xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1008xf32>, tensor<1x1x1x1008xf32>) outs(%4 : tensor<666x7x7x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x240xf32>) -> tensor<666x56x56x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x240xf32>) -> tensor<1x1x1x240xf32>\n    %4 = tensor.empty() : tensor<666x56x56x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x240xf32>, tensor<1x1x1x240xf32>) outs(%4 : tensor<666x56x56x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x1x1x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x1x1x2048xf32>) -> tensor<2048x1x1x2048xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x2048xf32>, tensor<2048x1x1x2048xf32>) outs(%7 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x28xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x28xf32>) -> tensor<666x1x1x28xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x28xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x28xf32>) -> tensor<256x1x1x28xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x1x1x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x1x1x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x28xf32>, tensor<256x1x1x28xf32>) outs(%7 : tensor<666x1x1x256xf32>) -> tensor<666x1x1x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x440xf32>) -> tensor<666x14x14x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x440xf32>) -> tensor<1x1x1x440xf32>\n    %4 = tensor.empty() : tensor<666x14x14x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x440xf32>, tensor<1x1x1x440xf32>) outs(%4 : tensor<666x14x14x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<666x14x14x1xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x512xf32>, tensor<666x14x14x1xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1512xf32>) -> tensor<666x1x7x1512xf32>\n    %2 = tensor.empty() : tensor<666x1x1512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1512xf32>) -> tensor<666x1x1512xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1512xf32>) outs(%3 : tensor<666x1x1512xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1512xf32> into tensor<666x1x1x1512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x768xf32>) -> tensor<1x666x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x768x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x768x1000xf32>) -> tensor<1x768x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x768xf32>, tensor<1x768x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x16x16x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x16x16x256xf32>) -> tensor<666x16x16x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x3x3x256xf32>) -> tensor<256x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x7x7x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x7x7x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x16x16x256xf32>, tensor<256x3x3x256xf32>) outs(%7 : tensor<666x7x7x256xf32>) -> tensor<666x7x7x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x416xf32>) -> tensor<666x28x28x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x416xf32>) -> tensor<1x1x1x416xf32>\n    %4 = tensor.empty() : tensor<666x28x28x416xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x416xf32>, tensor<1x1x1x416xf32>) outs(%4 : tensor<666x28x28x416xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x9x9x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x9x9x512xf32>) -> tensor<666x9x9x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x3x3x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x3x3x512xf32>) -> tensor<512x3x3x512xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x7x7x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x9x9x512xf32>, tensor<512x3x3x512xf32>) outs(%7 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x640xf32>) -> tensor<666x14x14x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x640xf32>) -> tensor<128x1x1x640xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x640xf32>, tensor<128x1x1x640xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1216xf32>) -> tensor<666x7x7x1216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1216xf32>) -> tensor<1x1x1x1216xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1216xf32>, tensor<1x1x1x1216xf32>) outs(%4 : tensor<666x7x7x1216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = tensor.empty() : tensor<666x14x14x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x14x14x768xf32>, tensor<666x14x14x768xf32>) outs(%2 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x576xf32>) -> tensor<666x1x14x576xf32>\n    %2 = tensor.empty() : tensor<666x1x576xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x576xf32>) -> tensor<666x1x576xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x576xf32>) outs(%3 : tensor<666x1x576xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x576xf32> into tensor<666x1x1x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<38x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<38x1x1x152xf32>) -> tensor<38x1x1x152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<38xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<38xf32>) -> tensor<38xf32>\n    %6 = tensor.empty() : tensor<666x1x1x38xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<38xf32>) outs(%6 : tensor<666x1x1x38xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x38xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x152xf32>, tensor<38x1x1x152xf32>) outs(%7 : tensor<666x1x1x38xf32>) -> tensor<666x1x1x38xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x152xf32>, tensor<666x14x14x152xf32>) outs(%4 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3024xf32>) -> tensor<666x1x1x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x3024xf32>) -> tensor<666x7x7x3024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x3024xf32>, tensor<666x7x7x3024xf32>) outs(%4 : tensor<666x7x7x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x176xf32>) -> tensor<666x19x19x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x176x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x176x1xf32>) -> tensor<7x7x176x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %8 = tensor.empty() : tensor<666x7x7x176xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x19x19x176xf32>, tensor<7x7x176x1xf32>) outs(%7 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x7x7x176x1xf32> into tensor<666x7x7x176xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<176xf32>, tensor<666x7x7x176xf32>) outs(%8 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x440xf32>) -> tensor<666x1x1x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x440xf32>) -> tensor<666x7x7x440xf32>\n    %4 = tensor.empty() : tensor<666x7x7x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x440xf32>, tensor<666x7x7x440xf32>) outs(%4 : tensor<666x7x7x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x160xf32>) -> tensor<666x28x28x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x28x28x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x28x28x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x320xf32>) -> tensor<666x35x35x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x320xf32>) -> tensor<32x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x35x35x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x35x35x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x320xf32>, tensor<32x1x1x320xf32>) outs(%7 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1344xf32>) -> tensor<666x28x28x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1344xf32>) -> tensor<1x1x1x1344xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1344xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1344xf32>, tensor<1x1x1x1344xf32>) outs(%4 : tensor<666x28x28x1344xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x22xf32>) -> tensor<666x56x56x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x22xf32>) -> tensor<1x1x1x22xf32>\n    %4 = tensor.empty() : tensor<666x56x56x22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x22xf32>, tensor<1x1x1x22xf32>) outs(%4 : tensor<666x56x56x22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %4 = tensor.empty() : tensor<666x28x28x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x512xf32>, tensor<1x1x1x512xf32>) outs(%4 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x640xf32>) -> tensor<666x7x7x640xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x640xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x640xf32>) -> tensor<1x1x1x640xf32>\n    %4 = tensor.empty() : tensor<666x7x7x640xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x640xf32>, tensor<1x1x1x640xf32>) outs(%4 : tensor<666x7x7x640xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x608xf32>) -> tensor<666x1x1x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x608xf32>) -> tensor<666x7x7x608xf32>\n    %4 = tensor.empty() : tensor<666x7x7x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x608xf32>, tensor<666x7x7x608xf32>) outs(%4 : tensor<666x7x7x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1232xf32>) -> tensor<666x1x1x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1232xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<12x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<12x1x1x112xf32>) -> tensor<12x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<12xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<12xf32>) -> tensor<12xf32>\n    %6 = tensor.empty() : tensor<666x1x1x12xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<12xf32>) outs(%6 : tensor<666x1x1x12xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x12xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x112xf32>, tensor<12x1x1x112xf32>) outs(%7 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<2048xf32>) -> tensor<2048xf32>\n    %2 = tensor.empty() : tensor<2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<2048xf32>) outs(%2 : tensor<2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1472xf32>) -> tensor<666x14x14x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1472xf32>) -> tensor<1x1x1x1472xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1472xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1472xf32>, tensor<1x1x1x1472xf32>) outs(%4 : tensor<666x14x14x1472xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1536xf32>) -> tensor<666x14x14x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1536xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1536xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x128xf32>) -> tensor<666x112x112x128xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x56x56x128xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x112x112x128xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<120xf32>) -> tensor<120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<120xf32>, tensor<1xf32>) outs(%4 : tensor<120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %2 = tensor.empty() : tensor<666x7x7x2520xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x2520xf32>) outs(%2 : tensor<666x7x7x2520xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x96xf32>) -> tensor<128x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x56x56x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x56x56x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<128x1x1x96xf32>) outs(%7 : tensor<666x56x56x128xf32>) -> tensor<666x56x56x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = tensor.empty() : tensor<666x14x336xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x336xf32>) -> tensor<666x14x336xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x336xf32>) outs(%3 : tensor<666x14x336xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x336xf32> into tensor<666x1x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x56x56x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1664xf32>) -> tensor<666x14x14x1664xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1664xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1664xf32>) outs(%2 : tensor<666x14x14x1664xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1664xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x64xf32>) -> tensor<666x147x147x64xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x73x73x64xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x73x73x64xf32>) -> tensor<666x73x73x64xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x147x147x64xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x73x73x64xf32>) -> tensor<666x73x73x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x608xf32>) -> tensor<666x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x608xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x608xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x608xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x672xf32>) -> tensor<672x1x1x672xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x11x11x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x11x11x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x11x11x672xf32>, tensor<672x1x1x672xf32>) outs(%7 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1120xf32>) -> tensor<666x7x7x1120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1120xf32>) -> tensor<1x1x1x1120xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1120xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1120xf32>, tensor<1x1x1x1120xf32>) outs(%4 : tensor<666x7x7x1120xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x768xf32>) -> tensor<666x28x28x768xf32>\n    %2 = tensor.empty() : tensor<666x28x28x768xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x768xf32>) outs(%2 : tensor<666x28x28x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1792xf32>) -> tensor<666x14x14x1792xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x1792xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x1792xf32>) -> tensor<896x1x1x1792xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x14x14x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x14x14x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1792xf32>, tensor<896x1x1x1792xf32>) outs(%7 : tensor<666x14x14x896xf32>) -> tensor<666x14x14x896xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x256xf32>) -> tensor<666x1x14x256xf32>\n    %2 = tensor.empty() : tensor<666x1x256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x256xf32>) -> tensor<666x1x256xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x256xf32>) outs(%3 : tensor<666x1x256xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x256xf32> into tensor<666x1x1x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2016xf32>) -> tensor<666x14x14x2016xf32>\n    %2 = tensor.empty() : tensor<666x14x14x2016xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x2016xf32>) outs(%2 : tensor<666x14x14x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x256xf32>) -> tensor<666x7x7x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1024x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1024x1x1x256xf32>) -> tensor<1024x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1024xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1024xf32>) -> tensor<1024xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1024xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1024xf32>) outs(%6 : tensor<666x7x7x1024xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1024xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x256xf32>, tensor<1024x1x1x256xf32>) outs(%7 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<216xf32>) -> tensor<216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<216xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<216xf32>, tensor<1xf32>) outs(%4 : tensor<216xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<888x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<888x1x1x336xf32>) -> tensor<888x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<888xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<888xf32>) -> tensor<888xf32>\n    %6 = tensor.empty() : tensor<666x7x7x888xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<888xf32>) outs(%6 : tensor<666x7x7x888xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x888xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x336xf32>, tensor<888x1x1x336xf32>) outs(%7 : tensor<666x7x7x888xf32>) -> tensor<666x7x7x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x96xf32>) -> tensor<666x165x165x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<42x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<42x1x1x96xf32>) -> tensor<42x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %6 = tensor.empty() : tensor<666x165x165x42xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<42xf32>) outs(%6 : tensor<666x165x165x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x165x165x42xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x165x165x96xf32>, tensor<42x1x1x96xf32>) outs(%7 : tensor<666x165x165x42xf32>) -> tensor<666x165x165x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3712xf32>) -> tensor<666x14x14x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3712xf32>) -> tensor<1x1x1x3712xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3712xf32>, tensor<1x1x1x3712xf32>) outs(%4 : tensor<666x14x14x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x48xf32>) -> tensor<666x56x56x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x48xf32>) -> tensor<1x1x1x48xf32>\n    %4 = tensor.empty() : tensor<666x56x56x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x48xf32>, tensor<1x1x1x48xf32>) outs(%4 : tensor<666x56x56x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x48xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x8x8x1088xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x8x8x1088xf32>) -> tensor<666x8x8x1088xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x17x17x1088xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x8x8x1088xf32>) -> tensor<666x8x8x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<416xf32>) -> tensor<416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<416xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<416xf32>, tensor<1xf32>) outs(%4 : tensor<416xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x448xf32>) -> tensor<666x28x28x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x448xf32>) -> tensor<128x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x448xf32>, tensor<128x1x1x448xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = tensor.empty() : tensor<666x28x28x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x28x28x256xf32>, tensor<666x28x28x256xf32>) outs(%2 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<224xf32>) -> tensor<224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<224xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<224xf32>, tensor<1xf32>) outs(%4 : tensor<224xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<224xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1088xf32>) -> tensor<128x1x1x1088xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1088xf32>, tensor<128x1x1x1088xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1008xf32>) -> tensor<666x1x7x1008xf32>\n    %2 = tensor.empty() : tensor<666x1x1008xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1008xf32>) -> tensor<666x1x1008xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1008xf32>) outs(%3 : tensor<666x1x1008xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1008xf32> into tensor<666x1x1x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x112xf32>) -> tensor<666x1x1x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<896x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<896x1x1x112xf32>) -> tensor<896x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<896xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<896xf32>) -> tensor<896xf32>\n    %6 = tensor.empty() : tensor<666x1x1x896xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<896xf32>) outs(%6 : tensor<666x1x1x896xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x896xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x112xf32>, tensor<896x1x1x112xf32>) outs(%7 : tensor<666x1x1x896xf32>) -> tensor<666x1x1x896xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x22xf32>) -> tensor<1x1x1x22xf32>\n    %4 = tensor.empty() : tensor<666x28x28x22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x22xf32>, tensor<1x1x1x22xf32>) outs(%4 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x288xf32>) -> tensor<666x35x35x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<384x3x3x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<384x3x3x288xf32>) -> tensor<384x3x3x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<384xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<384xf32>) -> tensor<384xf32>\n    %6 = tensor.empty() : tensor<666x17x17x384xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<384xf32>) outs(%6 : tensor<666x17x17x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x384xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x288xf32>, tensor<384x3x3x288xf32>) outs(%7 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %2 = tensor.empty() : tensor<666x7x7x912xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x912xf32>) outs(%2 : tensor<666x7x7x912xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<22xf32>) -> tensor<22xf32>\n    %2 = tensor.empty() : tensor<22xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<22xf32>) outs(%2 : tensor<22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<784xf32>) -> tensor<784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<784xf32>, tensor<1xf32>) outs(%4 : tensor<784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x440xf32>) -> tensor<666x1x1x440xf32>\n    %2 = tensor.empty() : tensor<666x1x1x440xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x440xf32>) outs(%2 : tensor<666x1x1x440xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1440xf32>) -> tensor<666x14x14x1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1440xf32>) -> tensor<128x1x1x1440xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1440xf32>, tensor<128x1x1x1440xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x144x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x144x1xf32>) -> tensor<3x3x144x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x144xf32> to tensor<666x58x58x144xf32>\n    %6 = tensor.empty() : tensor<666x56x56x144x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x56x56x144x1xf32>) -> tensor<666x56x56x144x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x144xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x58x58x144xf32>, tensor<3x3x144x1xf32>) outs(%7 : tensor<666x56x56x144x1xf32>) -> tensor<666x56x56x144x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x144x1xf32> into tensor<666x56x56x144xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<144xf32>, tensor<666x56x56x144xf32>) outs(%8 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1xf32>) -> tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1056xf32>) -> tensor<666x14x14x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1056xf32>) -> tensor<128x1x1x1056xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1056xf32>, tensor<128x1x1x1056xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x232xf32>) -> tensor<666x1x1x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %4 = tensor.empty() : tensor<666x56x56x232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x232xf32>, tensor<666x56x56x232xf32>) outs(%4 : tensor<666x56x56x232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1760xf32>) -> tensor<666x14x14x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1760xf32>) -> tensor<1x1x1x1760xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1760xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1760xf32>, tensor<1x1x1x1760xf32>) outs(%4 : tensor<666x14x14x1760xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x84xf32>) -> tensor<666x42x42x84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x84x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x84x1xf32>) -> tensor<5x5x84x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<84xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<84xf32>) -> tensor<84xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x42x42x84xf32> to tensor<666x46x46x84xf32>\n    %6 = tensor.empty() : tensor<666x42x42x84x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %8 = tensor.empty() : tensor<666x42x42x84xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x46x46x84xf32>, tensor<5x5x84x1xf32>) outs(%7 : tensor<666x42x42x84x1xf32>) -> tensor<666x42x42x84x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x42x42x84x1xf32> into tensor<666x42x42x84xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<84xf32>, tensor<666x42x42x84xf32>) outs(%8 : tensor<666x42x42x84xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x42x42x84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x35x35x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x35x35x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<3x3x168x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<3x3x168x1xf32>) -> tensor<3x3x168x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<168xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<168xf32>) -> tensor<168xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x42x42x168xf32> to tensor<666x44x44x168xf32>\n    %6 = tensor.empty() : tensor<666x42x42x168x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x42x42x168x1xf32>) -> tensor<666x42x42x168x1xf32>\n    %8 = tensor.empty() : tensor<666x42x42x168xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x44x44x168xf32>, tensor<3x3x168x1xf32>) outs(%7 : tensor<666x42x42x168x1xf32>) -> tensor<666x42x42x168x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x42x42x168x1xf32> into tensor<666x42x42x168xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<168xf32>, tensor<666x42x42x168xf32>) outs(%8 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x224x224x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x224x224x64xf32>) -> tensor<666x224x224x64xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x112x112x64xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x224x224x64xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x112x112x64xf32>) -> tensor<666x112x112x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x168xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x168xf32>) -> tensor<448x1x1x168xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x56x56x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x56x56x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x168xf32>, tensor<448x1x1x168xf32>) outs(%7 : tensor<666x56x56x448xf32>) -> tensor<666x56x56x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1232xf32>) -> tensor<1x1x1x1232xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1232xf32>, tensor<1x1x1x1232xf32>) outs(%4 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x608xf32>) -> tensor<666x1x1x608xf32>\n    %2 = tensor.empty() : tensor<666x1x1x608xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x608xf32>) outs(%2 : tensor<666x1x1x608xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x608xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x174xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x174xf32>) -> tensor<666x1x1x174xf32>\n    %2 = bufferization.alloc_tensor() : tensor<696x1x1x174xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<696x1x1x174xf32>) -> tensor<696x1x1x174xf32>\n    %4 = bufferization.alloc_tensor() : tensor<696xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<696xf32>) -> tensor<696xf32>\n    %6 = tensor.empty() : tensor<666x1x1x696xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<696xf32>) outs(%6 : tensor<666x1x1x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x696xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x174xf32>, tensor<696x1x1x174xf32>) outs(%7 : tensor<666x1x1x696xf32>) -> tensor<666x1x1x696xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x32634x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x32634x1024xf32>) -> tensor<1x32634x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1024x4096xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1024x4096xf32>) -> tensor<1x1024x4096xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x32634x4096xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x32634x4096xf32>) -> tensor<1x32634x4096xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x32634x1024xf32>, tensor<1x1024x4096xf32>) outs(%5 : tensor<1x32634x4096xf32>) -> tensor<1x32634x4096xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1440xf32>) -> tensor<1440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1440xf32>, tensor<1xf32>) outs(%4 : tensor<1440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1536xf32>) -> tensor<666x7x7x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1xf32>) -> tensor<666x7x7x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1536xf32>, tensor<666x7x7x1xf32>) outs(%4 : tensor<666x7x7x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x22xf32>) -> tensor<1x1x1x22xf32>\n    %4 = tensor.empty() : tensor<666x28x28x22xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x22xf32>, tensor<1x1x1x22xf32>) outs(%4 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x128xf32>) -> tensor<666x147x147x128xf32>\n    %2 = tensor.empty() : tensor<666x147x147x128xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x147x147x128xf32>) outs(%2 : tensor<666x147x147x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x147x147x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x320xf32>) -> tensor<666x7x7x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x320xf32>) -> tensor<1x1x1x320xf32>\n    %4 = tensor.empty() : tensor<666x7x7x320xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x320xf32>, tensor<1x1x1x320xf32>) outs(%4 : tensor<666x7x7x320xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x104xf32>) -> tensor<666x1x1x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x104xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x10x10x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x10x10x1024xf32>) -> tensor<666x10x10x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1536x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1536x1x1x1024xf32>) -> tensor<1536x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1536xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1536xf32>) -> tensor<1536xf32>\n    %6 = tensor.empty() : tensor<666x10x10x1536xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1536xf32>) outs(%6 : tensor<666x10x10x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x10x10x1536xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x10x10x1024xf32>, tensor<1536x1x1x1024xf32>) outs(%7 : tensor<666x10x10x1536xf32>) -> tensor<666x10x10x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x14x14x1xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x256xf32>) -> tensor<666x56x56x256xf32>\n    %2 = tensor.empty() : tensor<666x56x56x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x56x56x256xf32>, tensor<666x56x56x256xf32>) outs(%2 : tensor<666x56x56x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.mulf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x56x56x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x17x17x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x17x17x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = tensor.empty() : tensor<666x83x83x42xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x83x83x42xf32>) outs(%2 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1296xf32>) -> tensor<666x1x1x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<324x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<324x1x1x1296xf32>) -> tensor<324x1x1x1296xf32>\n    %4 = bufferization.alloc_tensor() : tensor<324xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<324xf32>) -> tensor<324xf32>\n    %6 = tensor.empty() : tensor<666x1x1x324xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<324xf32>) outs(%6 : tensor<666x1x1x324xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x324xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1296xf32>, tensor<324x1x1x1296xf32>) outs(%7 : tensor<666x1x1x324xf32>) -> tensor<666x1x1x324xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1248xf32>) -> tensor<1248xf32>\n    %2 = tensor.empty() : tensor<1248xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1248xf32>) outs(%2 : tensor<1248xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x208xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x208xf32>) -> tensor<666x14x14x208xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x208xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x208xf32>) -> tensor<1x1x1x208xf32>\n    %4 = tensor.empty() : tensor<666x14x14x208xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x208xf32>, tensor<1x1x1x208xf32>) outs(%4 : tensor<666x14x14x208xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x208xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x768xf32>) -> tensor<666x14x14x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1xf32>) -> tensor<666x14x14x1xf32>\n    %4 = tensor.empty() : tensor<666x14x14x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x768xf32>, tensor<666x14x14x1xf32>) outs(%4 : tensor<666x14x14x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x256xf32>) -> tensor<666x1x1x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<28x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<28x1x1x256xf32>) -> tensor<28x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<28xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<28xf32>) -> tensor<28xf32>\n    %6 = tensor.empty() : tensor<666x1x1x28xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<28xf32>) outs(%6 : tensor<666x1x1x28xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x28xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x256xf32>, tensor<28x1x1x256xf32>) outs(%7 : tensor<666x1x1x28xf32>) -> tensor<666x1x1x28xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = tensor.empty() : tensor<666x56x56x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x64xf32>) outs(%2 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1512xf32>) -> tensor<1x666x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1512x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1512x1000xf32>) -> tensor<1x1512x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1512xf32>, tensor<1x1512x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1376xf32>) -> tensor<666x7x7x1376xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1376xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1376xf32>) outs(%2 : tensor<666x7x7x1376xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x416xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x416xf32>) -> tensor<666x28x28x416xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x416xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x416xf32>) -> tensor<1x1x1x416xf32>\n    %4 = tensor.empty() : tensor<666x28x28x416xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x416xf32>, tensor<1x1x1x416xf32>) outs(%4 : tensor<666x28x28x416xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x416xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x696xf32>) -> tensor<666x1x1x696xf32>\n    %2 = tensor.empty() : tensor<666x1x1x696xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x696xf32>) outs(%2 : tensor<666x1x1x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x56x56x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x736xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x736xf32>) -> tensor<666x7x7x736xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x736xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x736xf32>) -> tensor<128x1x1x736xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x736xf32>, tensor<128x1x1x736xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x104xf32>) -> tensor<666x56x56x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x104xf32>) -> tensor<1x1x1x104xf32>\n    %4 = tensor.empty() : tensor<666x56x56x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x104xf32>, tensor<1x1x1x104xf32>) outs(%4 : tensor<666x56x56x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (0, d1)>\n#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1536xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1536xf32>) -> tensor<1x1536xf32>\n    %4 = tensor.empty() : tensor<666x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<1x1536xf32>) outs(%4 : tensor<666x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1856xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1856xf32>) -> tensor<666x7x7x1856xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1856xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1856xf32>) -> tensor<1x1x1x1856xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1856xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1856xf32>, tensor<1x1x1x1856xf32>) outs(%4 : tensor<666x7x7x1856xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1856xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1280xf32>) -> tensor<666x8x8x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x1280xf32>) -> tensor<192x1x1x1280xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x8x8x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x1280xf32>, tensor<192x1x1x1280xf32>) outs(%7 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x11xf32>) -> tensor<666x56x56x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x11x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x11x1xf32>) -> tensor<5x5x11x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<11xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<11xf32>) -> tensor<11xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x56x56x11xf32> to tensor<666x60x60x11xf32>\n    %6 = tensor.empty() : tensor<666x56x56x11x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %8 = tensor.empty() : tensor<666x56x56x11xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x60x60x11xf32>, tensor<5x5x11x1xf32>) outs(%7 : tensor<666x56x56x11x1xf32>) -> tensor<666x56x56x11x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x56x56x11x1xf32> into tensor<666x56x56x11xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<11xf32>, tensor<666x56x56x11xf32>) outs(%8 : tensor<666x56x56x11xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x56x56x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = tensor.empty() : tensor<666x17x17x160xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x160xf32>) outs(%2 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x432xf32>) -> tensor<1x1x1x432xf32>\n    %4 = tensor.empty() : tensor<666x14x14x432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x432xf32>, tensor<1x1x1x432xf32>) outs(%4 : tensor<666x14x14x432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1664xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1664xf32>) -> tensor<666x7x7x1664xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1664xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1664xf32>) outs(%2 : tensor<666x7x7x1664xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1664xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x432xf32>) -> tensor<666x28x28x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x432xf32>) -> tensor<1x1x1x432xf32>\n    %4 = tensor.empty() : tensor<666x28x28x432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x432xf32>, tensor<1x1x1x432xf32>) outs(%4 : tensor<666x28x28x432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x6144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x6144xf32>) -> tensor<666x7x7x6144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x7x7x6144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x6144xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x7x7x6144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x6144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1360x1x1x1360xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1360x1x1x1360xf32>) -> tensor<1360x1x1x1360xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1360xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1360xf32>) -> tensor<1360xf32>\n    %6 = tensor.empty() : tensor<666x7x7x1360xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1360xf32>) outs(%6 : tensor<666x7x7x1360xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x1360xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1360xf32>, tensor<1360x1x1x1360xf32>) outs(%7 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x408xf32>) -> tensor<666x14x14x408xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x408xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x408xf32>) -> tensor<1x1x1x408xf32>\n    %4 = tensor.empty() : tensor<666x14x14x408xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x408xf32>, tensor<1x1x1x408xf32>) outs(%4 : tensor<666x14x14x408xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x160xf32>) -> tensor<666x14x14x160xf32>\n    %2 = tensor.empty() : tensor<666x14x14x160xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x160xf32>) outs(%2 : tensor<666x14x14x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    %2 = bufferization.alloc_tensor() : tensor<22x1x1x22xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<22x1x1x22xf32>) -> tensor<22x1x1x22xf32>\n    %4 = bufferization.alloc_tensor() : tensor<22xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<22xf32>) -> tensor<22xf32>\n    %6 = tensor.empty() : tensor<666x28x28x22xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<22xf32>) outs(%6 : tensor<666x28x28x22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x22xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x22xf32>, tensor<22x1x1x22xf32>) outs(%7 : tensor<666x28x28x22xf32>) -> tensor<666x28x28x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1512xf32>) -> tensor<666x1x1x1512xf32>\n    %2 = tensor.empty() : tensor<666x1x1x1512xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x1512xf32>) outs(%2 : tensor<666x1x1x1512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1056xf32>) -> tensor<666x14x14x1056xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1056xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1056xf32>) outs(%2 : tensor<666x14x14x1056xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1760xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1760xf32>) -> tensor<666x14x14x1760xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1760xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1760xf32>) -> tensor<1x1x1x1760xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1760xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1760xf32>, tensor<1x1x1x1760xf32>) outs(%4 : tensor<666x14x14x1760xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1760xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x64xf32>) -> tensor<666x14x14x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x64xf32>) -> tensor<1x1x1x64xf32>\n    %4 = tensor.empty() : tensor<666x14x14x64xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x64xf32>, tensor<1x1x1x64xf32>) outs(%4 : tensor<666x14x14x64xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x104xf32>) -> tensor<666x1x1x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %4 = tensor.empty() : tensor<666x28x28x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x104xf32>, tensor<666x28x28x104xf32>) outs(%4 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x3024xf32>) -> tensor<666x14x14x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3024xf32>) -> tensor<1x1x1x3024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x3024xf32>, tensor<1x1x1x3024xf32>) outs(%4 : tensor<666x14x14x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = tensor.empty() : tensor<666x14x14x152xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x152xf32>) outs(%2 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1512xf32>) -> tensor<666x7x7x1512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1512xf32>) -> tensor<1x1x1x1512xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1512xf32>, tensor<1x1x1x1512xf32>) outs(%4 : tensor<666x7x7x1512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x32xf32>) -> tensor<666x28x28x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x28x28x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x28x28x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x168xf32>) -> tensor<666x56x56x168xf32>\n    %2 = tensor.empty() : tensor<666x56x56x168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x168xf32>) outs(%2 : tensor<666x56x56x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x35x35x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x35x35x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x1024xf32>) -> tensor<512x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x14x14x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<512x1x1x1024xf32>) outs(%7 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = bufferization.alloc_tensor() : tensor<112x1x1x112xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<112x1x1x112xf32>) -> tensor<112x1x1x112xf32>\n    %4 = bufferization.alloc_tensor() : tensor<112xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<112xf32>) -> tensor<112xf32>\n    %6 = tensor.empty() : tensor<666x28x28x112xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<112xf32>) outs(%6 : tensor<666x28x28x112xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x112xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x112xf32>, tensor<112x1x1x112xf32>) outs(%7 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<672xf32>) -> tensor<672xf32>\n    %2 = tensor.empty() : tensor<672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<672xf32>) outs(%2 : tensor<672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<84xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<84xf32>) -> tensor<84xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<84xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<84xf32>, tensor<1xf32>) outs(%4 : tensor<84xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<84xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x88xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x88xf32>) -> tensor<666x14x14x88xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x88x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x88x1xf32>) -> tensor<7x7x88x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<88xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<88xf32>) -> tensor<88xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x14x14x88xf32> to tensor<666x20x20x88xf32>\n    %6 = tensor.empty() : tensor<666x14x14x88x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %8 = tensor.empty() : tensor<666x14x14x88xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x20x20x88xf32>, tensor<7x7x88x1xf32>) outs(%7 : tensor<666x14x14x88x1xf32>) -> tensor<666x14x14x88x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x14x14x88x1xf32> into tensor<666x14x14x88xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<88xf32>, tensor<666x14x14x88xf32>) outs(%8 : tensor<666x14x14x88xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x14x14x88xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<544xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<544xf32>) -> tensor<544xf32>\n    %2 = tensor.empty() : tensor<544xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<544xf32>) outs(%2 : tensor<544xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<544xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %2 = tensor.empty() : tensor<666x17x17x1088xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x1088xf32>) outs(%2 : tensor<666x17x17x1088xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x256xf32>) -> tensor<666x74x74x256xf32>\n    %2 = tensor.empty() : tensor<666x74x74x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x74x74x256xf32>) outs(%2 : tensor<666x74x74x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x74x74x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1344xf32>) -> tensor<128x1x1x1344xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<128x1x1x1344xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %4 = tensor.empty() : tensor<666x28x28x384xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<666x28x28x384xf32>) outs(%4 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x256xf32>) -> tensor<666x8x8x256xf32>\n    %2 = tensor.empty() : tensor<666x8x8x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x256xf32>) outs(%2 : tensor<666x8x8x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<408xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<408xf32>) -> tensor<408xf32>\n    %2 = tensor.empty() : tensor<408xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<408xf32>) outs(%2 : tensor<408xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<408xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x120xf32>) -> tensor<666x1x1x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<30x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<30x1x1x120xf32>) -> tensor<30x1x1x120xf32>\n    %4 = bufferization.alloc_tensor() : tensor<30xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<30xf32>) -> tensor<30xf32>\n    %6 = tensor.empty() : tensor<666x1x1x30xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<30xf32>) outs(%6 : tensor<666x1x1x30xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x30xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x120xf32>, tensor<30x1x1x120xf32>) outs(%7 : tensor<666x1x1x30xf32>) -> tensor<666x1x1x30xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1024xf32>) -> tensor<666x56x56x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x56x56x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1024xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x56x56x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1216xf32>) -> tensor<666x7x7x1216xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1216xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1216xf32>) outs(%2 : tensor<666x7x7x1216xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1216xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x64xf32>) -> tensor<64x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x28x28x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<64x1x1x64xf32>) outs(%7 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x152xf32>) -> tensor<666x28x28x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x152xf32>) -> tensor<1x1x1x152xf32>\n    %4 = tensor.empty() : tensor<666x28x28x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x152xf32>, tensor<1x1x1x152xf32>) outs(%4 : tensor<666x28x28x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x384xf32>) -> tensor<666x17x17x384xf32>\n    %2 = tensor.empty() : tensor<666x17x17x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x384xf32>) outs(%2 : tensor<666x17x17x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2520xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2520xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2520xf32>) -> tensor<1x1x1x2520xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2520xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2520xf32>, tensor<1x1x1x2520xf32>) outs(%4 : tensor<666x7x7x2520xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x2016xf32>) -> tensor<666x21x21x2016xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x11x11x2016xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x11x11x2016xf32>) -> tensor<666x11x11x2016xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x21x21x2016xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x11x11x2016xf32>) -> tensor<666x11x11x2016xf32>\n    %c1 = arith.constant 1 : index\n    %c11 = arith.constant 11 : index\n    %c2 = arith.constant 2 : index\n    %c11_1 = arith.constant 11 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c11, %c1_2 : index\n    %7 = arith.subi %c11_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x11x11x2016xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x11x11x2016xf32>) outs(%8 : tensor<666x11x11x2016xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x11x11x2016xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1024xf32>) -> tensor<666x7x7x1024xf32>\n    %2 = tensor.empty() : tensor<666x7x7xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7xf32>) -> tensor<666x7x7xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1024xf32>) outs(%3 : tensor<666x7x7xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x7x7xf32> into tensor<666x7x7x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<7x7x176x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<7x7x176x1xf32>) -> tensor<7x7x176x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<176xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<176xf32>) -> tensor<176xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 3, 0] high[0, 3, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x7x7x176xf32> to tensor<666x13x13x176xf32>\n    %6 = tensor.empty() : tensor<666x7x7x176x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %8 = tensor.empty() : tensor<666x7x7x176xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x13x13x176xf32>, tensor<7x7x176x1xf32>) outs(%7 : tensor<666x7x7x176x1xf32>) -> tensor<666x7x7x176x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x7x7x176x1xf32> into tensor<666x7x7x176xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<176xf32>, tensor<666x7x7x176xf32>) outs(%8 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %2 = tensor.empty() : tensor<666x11x11x672xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %1 : tensor<666x11x11x672xf32>, tensor<666x11x11x672xf32>) outs(%2 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %4 = arith.addf %in, %in_0 : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<56x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<56x1x1x448xf32>) -> tensor<56x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<56xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<56xf32>) -> tensor<56xf32>\n    %6 = tensor.empty() : tensor<666x1x1x56xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<56xf32>) outs(%6 : tensor<666x1x1x56xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x56xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x448xf32>, tensor<56x1x1x448xf32>) outs(%7 : tensor<666x1x1x56xf32>) -> tensor<666x1x1x56xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x336xf32>) -> tensor<666x1x1x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %4 = tensor.empty() : tensor<666x14x14x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x336xf32>, tensor<666x14x14x336xf32>) outs(%4 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x256xf32>) -> tensor<666x7x7x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x7x7x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x7x7x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<16x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<16x1x1x32xf32>) -> tensor<16x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<16xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<16xf32>) -> tensor<16xf32>\n    %6 = tensor.empty() : tensor<666x112x112x16xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<16xf32>) outs(%6 : tensor<666x112x112x16xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x16xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<16x1x1x32xf32>) outs(%7 : tensor<666x112x112x16xf32>) -> tensor<666x112x112x16xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x384xf32>) -> tensor<128x1x1x384xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x384xf32>, tensor<128x1x1x384xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x21x21x336xf32> to tensor<666x23x23x336xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x21x21x336xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x23x23x336xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    %c1 = arith.constant 1 : index\n    %c21 = arith.constant 21 : index\n    %c2 = arith.constant 2 : index\n    %c21_2 = arith.constant 21 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c21, %c1_3 : index\n    %7 = arith.subi %c21_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x21x21x336xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x21x21x336xf32>) outs(%8 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x24xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    %2 = bufferization.alloc_tensor() : tensor<24x1x1x24xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<24x1x1x24xf32>) -> tensor<24x1x1x24xf32>\n    %4 = bufferization.alloc_tensor() : tensor<24xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<24xf32>) -> tensor<24xf32>\n    %6 = tensor.empty() : tensor<666x56x56x24xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<24xf32>) outs(%6 : tensor<666x56x56x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x24xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x24xf32>, tensor<24x1x1x24xf32>) outs(%7 : tensor<666x56x56x24xf32>) -> tensor<666x56x56x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x256xf32>) -> tensor<666x1x1x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %4 = tensor.empty() : tensor<666x14x14x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x256xf32>, tensor<666x14x14x256xf32>) outs(%4 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x352xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x352xf32>) -> tensor<666x14x14x352xf32>\n    %2 = tensor.empty() : tensor<666x14x14x352xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x352xf32>) outs(%2 : tensor<666x14x14x352xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x352xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x160xf32>) -> tensor<666x28x28x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x160xf32>) -> tensor<128x1x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x28x28x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x160xf32>, tensor<128x1x1x160xf32>) outs(%7 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x96xf32>) -> tensor<666x35x35x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x35x35x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x35x35x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x35x35x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x35x35x96xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    %2 = tensor.empty() : tensor<666x56x72xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x56x72xf32>) -> tensor<666x56x72xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x56x56x72xf32>) outs(%3 : tensor<666x56x72xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x56x72xf32> into tensor<666x1x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x192xf32>) -> tensor<666x35x35x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x192xf32>) -> tensor<32x1x1x192xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x35x35x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x35x35x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x192xf32>, tensor<32x1x1x192xf32>) outs(%7 : tensor<666x35x35x32xf32>) -> tensor<666x35x35x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<720xf32>) -> tensor<720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<720xf32>, tensor<1xf32>) outs(%4 : tensor<720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x320xf32>) -> tensor<666x1x1x320xf32>\n    %2 = tensor.empty() : tensor<666x1x1x320xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x320xf32>) outs(%2 : tensor<666x1x1x320xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x288xf32>) -> tensor<666x35x35x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x288xf32>) -> tensor<64x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x35x35x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x35x35x288xf32>, tensor<64x1x1x288xf32>) outs(%7 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1472xf32>) -> tensor<666x7x7x1472xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1472xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1472xf32>) outs(%2 : tensor<666x7x7x1472xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x336xf32>) -> tensor<666x14x14x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x336xf32>) -> tensor<1x1x1x336xf32>\n    %4 = tensor.empty() : tensor<666x14x14x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x336xf32>, tensor<1x1x1x336xf32>) outs(%4 : tensor<666x14x14x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x14x14x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x14x14x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x120xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x120xf32>) -> tensor<666x1x1x120xf32>\n    %2 = bufferization.alloc_tensor() : tensor<12x1x1x120xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<12x1x1x120xf32>) -> tensor<12x1x1x120xf32>\n    %4 = bufferization.alloc_tensor() : tensor<12xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<12xf32>) -> tensor<12xf32>\n    %6 = tensor.empty() : tensor<666x1x1x12xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<12xf32>) outs(%6 : tensor<666x1x1x12xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x12xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x120xf32>, tensor<12x1x1x120xf32>) outs(%7 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, 0)>\n#map1 = affine_map<(d0, d1) -> (d0, d1)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x2048xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x2048xf32>) -> tensor<666x2048xf32>\n    %4 = tensor.empty() : tensor<666x2048xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1xf32>, tensor<666x2048xf32>) outs(%4 : tensor<666x2048xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1296xf32>) -> tensor<666x1x1x1296xf32>\n    %2 = tensor.empty() : tensor<666x1x1x1296xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x1296xf32>) outs(%2 : tensor<666x1x1x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x21x21x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x21x21x1344xf32>) -> tensor<666x21x21x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<336x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<336x1x1x1344xf32>) -> tensor<336x1x1x1344xf32>\n    %4 = bufferization.alloc_tensor() : tensor<336xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<336xf32>) -> tensor<336xf32>\n    %6 = tensor.empty() : tensor<666x21x21x336xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<336xf32>) outs(%6 : tensor<666x21x21x336xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x21x21x336xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x21x21x1344xf32>, tensor<336x1x1x1344xf32>) outs(%7 : tensor<666x21x21x336xf32>) -> tensor<666x21x21x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1184xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1184xf32>) -> tensor<1184xf32>\n    %2 = tensor.empty() : tensor<1184xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1184xf32>) outs(%2 : tensor<1184xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1184xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x1024xf32>) -> tensor<512x1x1x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x7x7x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x7x7x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<512x1x1x1024xf32>) outs(%7 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x32xf32>) -> tensor<666x1x1x32xf32>\n    %2 = tensor.empty() : tensor<666x1x1x32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x32xf32>) outs(%2 : tensor<666x1x1x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1024xf32>) -> tensor<666x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1024xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1024xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x7x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x7x1056xf32>) -> tensor<666x1x7x1056xf32>\n    %2 = tensor.empty() : tensor<666x1x1056xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x1056xf32>) -> tensor<666x1x1056xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x7x1056xf32>) outs(%3 : tensor<666x1x1056xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x1056xf32> into tensor<666x1x1x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x36xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x36xf32>) -> tensor<666x1x1x36xf32>\n    %2 = bufferization.alloc_tensor() : tensor<288x1x1x36xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<288x1x1x36xf32>) -> tensor<288x1x1x36xf32>\n    %4 = bufferization.alloc_tensor() : tensor<288xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<288xf32>) -> tensor<288xf32>\n    %6 = tensor.empty() : tensor<666x1x1x288xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<288xf32>) outs(%6 : tensor<666x1x1x288xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x288xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x36xf32>, tensor<288x1x1x36xf32>) outs(%7 : tensor<666x1x1x288xf32>) -> tensor<666x1x1x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x384xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x384xf32>) -> tensor<666x28x28x384xf32>\n    %2 = tensor.empty() : tensor<666x28x28x384xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x384xf32>) outs(%2 : tensor<666x28x28x384xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x12xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    %2 = bufferization.alloc_tensor() : tensor<120x1x1x12xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<120x1x1x12xf32>) -> tensor<120x1x1x12xf32>\n    %4 = bufferization.alloc_tensor() : tensor<120xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<120xf32>) -> tensor<120xf32>\n    %6 = tensor.empty() : tensor<666x1x1x120xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<120xf32>) outs(%6 : tensor<666x1x1x120xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x120xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x12xf32>, tensor<120x1x1x12xf32>) outs(%7 : tensor<666x1x1x120xf32>) -> tensor<666x1x1x120xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1376xf32>) -> tensor<1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<1376xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<1376xf32>, tensor<1xf32>) outs(%4 : tensor<1376xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x17x17x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x17x17x1088xf32>) -> tensor<666x17x17x1088xf32>\n    %4 = tensor.empty() : tensor<666x17x17x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x1088xf32>, tensor<666x17x17x1088xf32>) outs(%4 : tensor<666x17x17x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x368xf32>) -> tensor<666x14x14x368xf32>\n    %2 = tensor.empty() : tensor<666x14x14x368xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x368xf32>) outs(%2 : tensor<666x14x14x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<176xf32>) -> tensor<176xf32>\n    %2 = tensor.empty() : tensor<176xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<176xf32>) outs(%2 : tensor<176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x480xf32>) -> tensor<666x28x28x480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x480xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x480xf32>) -> tensor<1x1x1x480xf32>\n    %4 = tensor.empty() : tensor<666x28x28x480xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x480xf32>, tensor<1x1x1x480xf32>) outs(%4 : tensor<666x28x28x480xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<288xf32>) -> tensor<288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<288xf32>, tensor<1xf32>) outs(%4 : tensor<288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x169x169x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x169x169x42xf32>) -> tensor<666x169x169x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x42x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x42x1xf32>) -> tensor<5x5x42x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<42xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<42xf32>) -> tensor<42xf32>\n    %6 = tensor.empty() : tensor<666x83x83x42x1xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_0 : f32) outs(%6 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %8 = tensor.empty() : tensor<666x83x83x42xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x169x169x42xf32>, tensor<5x5x42x1xf32>) outs(%7 : tensor<666x83x83x42x1xf32>) -> tensor<666x83x83x42x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x83x83x42x1xf32> into tensor<666x83x83x42xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<42xf32>, tensor<666x83x83x42xf32>) outs(%8 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_1: f32, %out: f32):\n      %11 = arith.addf %in, %in_1 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<32xf32>) -> tensor<32xf32>\n    %2 = tensor.empty() : tensor<32xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<32xf32>) outs(%2 : tensor<32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x176xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x176xf32>) -> tensor<666x7x7x176xf32>\n    %4 = tensor.empty() : tensor<666x7x7x176xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x176xf32>, tensor<666x7x7x176xf32>) outs(%4 : tensor<666x7x7x176xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %4 = tensor.empty() : tensor<666x14x14x720xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x720xf32>, tensor<666x14x14x720xf32>) outs(%4 : tensor<666x14x14x720xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x1x1x256xf32>) -> tensor<512x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x256xf32>, tensor<512x1x1x256xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x1536xf32>) -> tensor<666x8x8x1536xf32>\n    %2 = tensor.empty() : tensor<666x8x8x1536xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x8x8x1536xf32>) outs(%2 : tensor<666x8x8x1536xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x8x8x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1392xf32>) -> tensor<666x1x1x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x1392xf32>, tensor<666x14x14x1392xf32>) outs(%4 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x256xf32>) -> tensor<666x17x17x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x17x17x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x17x17x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<672x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<672x1x1x288xf32>) -> tensor<672x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<672xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<672xf32>) -> tensor<672xf32>\n    %6 = tensor.empty() : tensor<666x7x7x672xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<672xf32>) outs(%6 : tensor<666x7x7x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x672xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<672x1x1x288xf32>) outs(%7 : tensor<666x7x7x672xf32>) -> tensor<666x7x7x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x48xf32>) -> tensor<666x35x35x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x3x3x48xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x3x3x48xf32>) -> tensor<64x3x3x48xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x35x35x48xf32> to tensor<666x37x37x48xf32>\n    %6 = tensor.empty() : tensor<666x35x35x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x35x35x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x35x35x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x37x37x48xf32>, tensor<64x3x3x48xf32>) outs(%7 : tensor<666x35x35x64xf32>) -> tensor<666x35x35x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1088xf32>) -> tensor<666x14x14x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1088xf32>) -> tensor<1x1x1x1088xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1088xf32>, tensor<1x1x1x1088xf32>) outs(%4 : tensor<666x14x14x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x392xf32>) -> tensor<1x1x1x392xf32>\n    %4 = tensor.empty() : tensor<666x28x28x392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x392xf32>, tensor<1x1x1x392xf32>) outs(%4 : tensor<666x28x28x392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2016xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2016xf32>) -> tensor<666x14x14x2016xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2016xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2016xf32>) -> tensor<1x1x1x2016xf32>\n    %4 = tensor.empty() : tensor<666x14x14x2016xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x2016xf32>, tensor<1x1x1x2016xf32>) outs(%4 : tensor<666x14x14x2016xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x2016xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1056xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1056xf32>) -> tensor<666x14x14x1056xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1056xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1056xf32>) -> tensor<1x1x1x1056xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1056xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1056xf32>, tensor<1x1x1x1056xf32>) outs(%4 : tensor<666x14x14x1056xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1056xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x448xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x448xf32>) -> tensor<666x8x8x448xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2080x1x1x448xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2080x1x1x448xf32>) -> tensor<2080x1x1x448xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2080xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2080xf32>) -> tensor<2080xf32>\n    %6 = tensor.empty() : tensor<666x8x8x2080xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2080xf32>) outs(%6 : tensor<666x8x8x2080xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x2080xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x448xf32>, tensor<2080x1x1x448xf32>) outs(%7 : tensor<666x8x8x2080xf32>) -> tensor<666x8x8x2080xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %4 = tensor.empty() : tensor<666x14x14x240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x240xf32>, tensor<666x14x14x240xf32>) outs(%4 : tensor<666x14x14x240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x240xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %2 = tensor.empty() : tensor<666x28x28xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x28xf32>) -> tensor<666x28x28xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x512xf32>) outs(%3 : tensor<666x28x28xf32>) dimensions = [3] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x28x28xf32> into tensor<666x28x28x1xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x71x71x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x71x71x192xf32>) -> tensor<666x71x71x192xf32>\n    %2 = tensor.empty() : tensor<666x71x71x192xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x71x71x192xf32>) outs(%2 : tensor<666x71x71x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x71x71x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x392xf32>) -> tensor<666x28x28x392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x392xf32>) -> tensor<1x1x1x392xf32>\n    %4 = tensor.empty() : tensor<666x28x28x392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x392xf32>, tensor<1x1x1x392xf32>) outs(%4 : tensor<666x28x28x392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<392xf32>) -> tensor<392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<392xf32>, tensor<1xf32>) outs(%4 : tensor<392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x784xf32>) -> tensor<666x14x14x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x784xf32>) -> tensor<1x1x1x784xf32>\n    %4 = tensor.empty() : tensor<666x14x14x784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x784xf32>, tensor<1x1x1x784xf32>) outs(%4 : tensor<666x14x14x784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1xf32>) -> tensor<666x56x56x1xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    %4 = tensor.empty() : tensor<666x56x56x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1xf32>, tensor<666x56x56x192xf32>) outs(%4 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1360xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1360xf32>) -> tensor<666x7x7x1360xf32>\n    %2 = tensor.empty() : tensor<666x7x1360xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1360xf32>) -> tensor<666x7x1360xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1360xf32>) outs(%3 : tensor<666x7x1360xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1360xf32> into tensor<666x1x7x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<3024xf32>) -> tensor<3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<3024xf32>, tensor<1xf32>) outs(%4 : tensor<3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x256xf32>) -> tensor<1x1x1x256xf32>\n    %4 = tensor.empty() : tensor<666x14x14x256xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x256xf32>, tensor<1x1x1x256xf32>) outs(%4 : tensor<666x14x14x256xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1296xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1296xf32>) -> tensor<666x1x1x1296xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x1296xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x1296xf32>) -> tensor<144x1x1x1296xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x1x1x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1296xf32>, tensor<144x1x1x1296xf32>) outs(%7 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1792xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1792xf32>) -> tensor<1792xf32>\n    %2 = tensor.empty() : tensor<1792xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1792xf32>) outs(%2 : tensor<1792xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1792xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1392xf32>) -> tensor<1x1x1x1392xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1392xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1392xf32>, tensor<1x1x1x1392xf32>) outs(%4 : tensor<666x14x14x1392xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<784xf32>) -> tensor<784xf32>\n    %2 = tensor.empty() : tensor<784xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<784xf32>) outs(%2 : tensor<784xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1376xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1376xf32>) -> tensor<666x14x14x1376xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1376xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1376xf32>) -> tensor<1x1x1x1376xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1376xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1376xf32>, tensor<1x1x1x1376xf32>) outs(%4 : tensor<666x14x14x1376xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1376xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x168xf32>) -> tensor<666x83x83x168xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x42x42x168xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %4 = tensor.empty() : tensor<1x1xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x83x83x168xf32>, tensor<1x1xf32>) outs(%3 : tensor<666x42x42x168xf32>) -> tensor<666x42x42x168xf32>\n    %c1 = arith.constant 1 : index\n    %c42 = arith.constant 42 : index\n    %c2 = arith.constant 2 : index\n    %c42_1 = arith.constant 42 : index\n    %c1_2 = arith.constant 1 : index\n    %6 = arith.subi %c42, %c1_2 : index\n    %7 = arith.subi %c42_1, %c1_2 : index\n    %8 = tensor.empty() : tensor<666x42x42x168xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x42x42x168xf32>) outs(%8 : tensor<666x42x42x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c2_3 = arith.constant 2 : index\n      %c1_4 = arith.constant 1 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c2_3 : index\n      %13 = arith.muli %11, %c2_3 : index\n      %14 = arith.cmpi slt, %c1_4, %c1_2 : index\n      %15 = arith.select %14, %c1_2, %c1_4 : index\n      %c2_5 = arith.constant 2 : index\n      %c1_6 = arith.constant 1 : index\n      %16 = linalg.index 2 : index\n      %17 = arith.subi %7, %16 : index\n      %18 = arith.muli %16, %c2_5 : index\n      %19 = arith.muli %17, %c2_5 : index\n      %20 = arith.cmpi slt, %c1_6, %c1_2 : index\n      %21 = arith.select %20, %c1_2, %c1_6 : index\n      %22 = arith.muli %15, %21 : index\n      %23 = arith.index_cast %22 : index to i32\n      %24 = arith.sitofp %23 : i32 to f32\n      %25 = arith.divf %in, %24 : f32\n      linalg.yield %25 : f32\n    } -> tensor<666x42x42x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x336xf32>) -> tensor<666x1x1x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x336xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x336xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x336xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x336xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x7x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x7x1x128xf32>) -> tensor<128x7x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 0, 0] high[0, 3, 0, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x128xf32> to tensor<666x23x17x128xf32>\n    %6 = tensor.empty() : tensor<666x17x17x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x17x17x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x23x17x128xf32>, tensor<128x7x1x128xf32>) outs(%7 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3712xf32>) -> tensor<666x1x1x3712xf32>\n    %2 = tensor.empty() : tensor<666x1x1x3712xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x3712xf32>) outs(%2 : tensor<666x1x1x3712xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1568xf32>) -> tensor<666x14x14x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1568xf32>) -> tensor<1x1x1x1568xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1568xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1568xf32>, tensor<1x1x1x1568xf32>) outs(%4 : tensor<666x14x14x1568xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x35x35x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x35x35x256xf32>) -> tensor<666x35x35x256xf32>\n    %2 = tensor.empty() : tensor<666x35x35x256xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x35x35x256xf32>) outs(%2 : tensor<666x35x35x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x35x35x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x144xf32>) -> tensor<144x1x1x144xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x56x56x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x56x56x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x144xf32>, tensor<144x1x1x144xf32>) outs(%7 : tensor<666x56x56x144xf32>) -> tensor<666x56x56x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<224x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<224x1x1x224xf32>) -> tensor<224x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<224xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<224xf32>) -> tensor<224xf32>\n    %6 = tensor.empty() : tensor<666x56x56x224xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<224xf32>) outs(%6 : tensor<666x56x56x224xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x224xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x224xf32>, tensor<224x1x1x224xf32>) outs(%7 : tensor<666x56x56x224xf32>) -> tensor<666x56x56x224xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x112xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x112xf32>) -> tensor<666x28x28x112xf32>\n    %2 = tensor.empty() : tensor<666x28x112xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x28x112xf32>) -> tensor<666x28x112xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x28x28x112xf32>) outs(%3 : tensor<666x28x112xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x28x112xf32> into tensor<666x1x28x112xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x104xf32>) -> tensor<666x56x56x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x104xf32>) -> tensor<1x1x1x104xf32>\n    %4 = tensor.empty() : tensor<666x56x56x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x104xf32>, tensor<1x1x1x104xf32>) outs(%4 : tensor<666x56x56x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x12xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x12xf32>) -> tensor<666x1x1x12xf32>\n    %2 = bufferization.alloc_tensor() : tensor<104x1x1x12xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<104x1x1x12xf32>) -> tensor<104x1x1x12xf32>\n    %4 = bufferization.alloc_tensor() : tensor<104xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<104xf32>) -> tensor<104xf32>\n    %6 = tensor.empty() : tensor<666x1x1x104xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<104xf32>) outs(%6 : tensor<666x1x1x104xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x104xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x12xf32>, tensor<104x1x1x12xf32>) outs(%7 : tensor<666x1x1x104xf32>) -> tensor<666x1x1x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x320xf32>) -> tensor<666x14x14x320xf32>\n    %2 = bufferization.alloc_tensor() : tensor<768x1x1x320xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<768x1x1x320xf32>) -> tensor<768x1x1x320xf32>\n    %4 = bufferization.alloc_tensor() : tensor<768xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<768xf32>) -> tensor<768xf32>\n    %6 = tensor.empty() : tensor<666x7x7x768xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<768xf32>) outs(%6 : tensor<666x7x7x768xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x768xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x320xf32>, tensor<768x1x1x320xf32>) outs(%7 : tensor<666x7x7x768xf32>) -> tensor<666x7x7x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x96xf32>) -> tensor<666x17x17x96xf32>\n    %2 = tensor.empty() : tensor<666x17x17x96xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x17x17x96xf32>) outs(%2 : tensor<666x17x17x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x17x17x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<368x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<368x1x1x152xf32>) -> tensor<368x1x1x152xf32>\n    %4 = bufferization.alloc_tensor() : tensor<368xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<368xf32>) -> tensor<368xf32>\n    %6 = tensor.empty() : tensor<666x14x14x368xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<368xf32>) outs(%6 : tensor<666x14x14x368xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x368xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x152xf32>, tensor<368x1x1x152xf32>) outs(%7 : tensor<666x14x14x368xf32>) -> tensor<666x14x14x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x8x8x2080xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x8x8x2080xf32>) -> tensor<666x8x8x2080xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x2080xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x2080xf32>) -> tensor<192x1x1x2080xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x8x8x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x8x8x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x8x8x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x8x8x2080xf32>, tensor<192x1x1x2080xf32>) outs(%7 : tensor<666x8x8x192xf32>) -> tensor<666x8x8x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<24x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<24x1x1x8xf32>) -> tensor<24x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<24xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<24xf32>) -> tensor<24xf32>\n    %6 = tensor.empty() : tensor<666x1x1x24xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<24xf32>) outs(%6 : tensor<666x1x1x24xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x24xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<24x1x1x8xf32>) outs(%7 : tensor<666x1x1x24xf32>) -> tensor<666x1x1x24xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x152xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x152xf32>) -> tensor<666x14x14x152xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x152xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x152xf32>) -> tensor<1x1x1x152xf32>\n    %4 = tensor.empty() : tensor<666x14x14x152xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x152xf32>, tensor<1x1x1x152xf32>) outs(%4 : tensor<666x14x14x152xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x348xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x348xf32>) -> tensor<666x1x1x348xf32>\n    %2 = tensor.empty() : tensor<666x1x1x348xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x348xf32>) outs(%2 : tensor<666x1x1x348xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x348xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x368xf32>) -> tensor<1x1x1x368xf32>\n    %4 = tensor.empty() : tensor<666x7x7x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x368xf32>, tensor<1x1x1x368xf32>) outs(%4 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x6144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x6144xf32>) -> tensor<666x7x7x6144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x6144xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x6144xf32>) -> tensor<1x1x1x6144xf32>\n    %4 = tensor.empty() : tensor<666x7x7x6144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x6144xf32>, tensor<1x1x1x6144xf32>) outs(%4 : tensor<666x7x7x6144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x6144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<96x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<96x1x1x32xf32>) -> tensor<96x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<96xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<96xf32>) -> tensor<96xf32>\n    %6 = tensor.empty() : tensor<666x56x56x96xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<96xf32>) outs(%6 : tensor<666x56x56x96xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x96xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<96x1x1x32xf32>) outs(%7 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1600xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1600xf32>) -> tensor<666x7x7x1600xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1600xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1600xf32>) -> tensor<128x1x1x1600xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x7x7x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x7x7x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x1600xf32>, tensor<128x1x1x1600xf32>) outs(%7 : tensor<666x7x7x128xf32>) -> tensor<666x7x7x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (d0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1000xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1000xf32>) -> tensor<666x1000xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x1xf32>) -> tensor<666x1xf32>\n    %4 = tensor.empty() : tensor<666x1000xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1000xf32>, tensor<666x1xf32>) outs(%4 : tensor<666x1000xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x8192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x8192xf32>) -> tensor<666x7x7x8192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x8192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x8192xf32>) -> tensor<666x7x7x8192xf32>\n    %4 = tensor.empty() : tensor<666x7x7x8192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x8192xf32>, tensor<666x7x7x8192xf32>) outs(%4 : tensor<666x7x7x8192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x8192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1536xf32>) -> tensor<666x28x28x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1536xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1536xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x28x28x1536xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1536xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<1x1x1x1024xf32>) outs(%4 : tensor<666x14x14x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x56x56x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x1392xf32>) -> tensor<666x1x1x1392xf32>\n    %2 = bufferization.alloc_tensor() : tensor<348x1x1x1392xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<348x1x1x1392xf32>) -> tensor<348x1x1x1392xf32>\n    %4 = bufferization.alloc_tensor() : tensor<348xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<348xf32>) -> tensor<348xf32>\n    %6 = tensor.empty() : tensor<666x1x1x348xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<348xf32>) outs(%6 : tensor<666x1x1x348xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x348xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x1392xf32>, tensor<348x1x1x1392xf32>) outs(%7 : tensor<666x1x1x348xf32>) -> tensor<666x1x1x348xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x440xf32>) -> tensor<666x14x14x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x440xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x440xf32>) -> tensor<1x1x1x440xf32>\n    %4 = tensor.empty() : tensor<666x14x14x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x440xf32>, tensor<1x1x1x440xf32>) outs(%4 : tensor<666x14x14x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x888xf32>) -> tensor<666x14x14x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x888xf32>) -> tensor<1x1x1x888xf32>\n    %4 = tensor.empty() : tensor<666x14x14x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x888xf32>, tensor<1x1x1x888xf32>) outs(%4 : tensor<666x14x14x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x19x19x728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x19x19x728xf32>) -> tensor<666x19x19x728xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x728xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x728xf32>) -> tensor<1x1x1x728xf32>\n    %4 = tensor.empty() : tensor<666x19x19x728xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x19x19x728xf32>, tensor<1x1x1x728xf32>) outs(%4 : tensor<666x19x19x728xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x19x19x728xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x522144x1536xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x522144x1536xf32>) -> tensor<1x522144x1536xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1536x384xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1536x384xf32>) -> tensor<1x1536x384xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x522144x384xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x522144x384xf32>) -> tensor<1x522144x384xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x522144x1536xf32>, tensor<1x1536x384xf32>) outs(%5 : tensor<1x522144x384xf32>) -> tensor<1x522144x384xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = tensor.empty() : tensor<666x28x28x64xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x64xf32>) outs(%2 : tensor<666x28x28x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x64xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x14x320xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x14x320xf32>) -> tensor<666x1x14x320xf32>\n    %2 = tensor.empty() : tensor<666x1x320xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x320xf32>) -> tensor<666x1x320xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x14x320xf32>) outs(%3 : tensor<666x1x320xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x320xf32> into tensor<666x1x1x320xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x96xf32>) -> tensor<666x14x14x96xf32>\n    %4 = tensor.empty() : tensor<666x14x14x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x96xf32>, tensor<666x14x14x96xf32>) outs(%4 : tensor<666x14x14x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x368xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x368xf32>) -> tensor<666x1x1x368xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x368xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x368xf32>) -> tensor<666x7x7x368xf32>\n    %4 = tensor.empty() : tensor<666x7x7x368xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x368xf32>, tensor<666x7x7x368xf32>) outs(%4 : tensor<666x7x7x368xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x368xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1024xf32>) -> tensor<666x14x14x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2048x2x2x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2048x2x2x1024xf32>) -> tensor<2048x2x2x1024xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2048xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2048xf32>) -> tensor<2048xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2048xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2048xf32>) outs(%6 : tensor<666x7x7x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2048xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1024xf32>, tensor<2048x2x2x1024xf32>) outs(%7 : tensor<666x7x7x2048xf32>) -> tensor<666x7x7x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x22xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x22xf32>) -> tensor<666x56x56x22xf32>\n    %2 = tensor.empty() : tensor<666x56x56x22xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x56x56x22xf32>) outs(%2 : tensor<666x56x56x22xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x56x56x22xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x576xf32>) -> tensor<666x7x7x576xf32>\n    %2 = tensor.empty() : tensor<666x7x7x576xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x576xf32>) outs(%2 : tensor<666x7x7x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x672xf32>) -> tensor<666x56x56x672xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x672xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x672xf32>) -> tensor<1x1x1x672xf32>\n    %4 = tensor.empty() : tensor<666x56x56x672xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x672xf32>, tensor<1x1x1x672xf32>) outs(%4 : tensor<666x56x56x672xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x1088xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x1088xf32>) -> tensor<666x7x7x1088xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1088xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1088xf32>, tensor<666x7x7x1088xf32>) outs(%4 : tensor<666x7x7x1088xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1088xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x288xf32>) -> tensor<666x56x56x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x288xf32>) -> tensor<1x1x1x288xf32>\n    %4 = tensor.empty() : tensor<666x56x56x288xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x288xf32>, tensor<1x1x1x288xf32>) outs(%4 : tensor<666x56x56x288xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x288xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x7x7x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x7x7x912xf32>) -> tensor<666x7x7x912xf32>\n    %4 = tensor.empty() : tensor<666x7x7x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x912xf32>, tensor<666x7x7x912xf32>) outs(%4 : tensor<666x7x7x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<160x7x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<160x7x1x160xf32>) -> tensor<160x7x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<160xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<160xf32>) -> tensor<160xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 0, 0] high[0, 3, 0, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x160xf32> to tensor<666x23x17x160xf32>\n    %6 = tensor.empty() : tensor<666x17x17x160xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<160xf32>) outs(%6 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x160xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x23x17x160xf32>, tensor<160x7x1x160xf32>) outs(%7 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x7x7x512xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x14x14x512xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x7x7x512xf32>) -> tensor<666x7x7x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x1008xf32>) -> tensor<1x666x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1008x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1008x1000xf32>) -> tensor<1x1008x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x1008xf32>, tensor<1x1008x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x216xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x216xf32>) -> tensor<666x28x28x216xf32>\n    %2 = bufferization.alloc_tensor() : tensor<576x1x1x216xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<576x1x1x216xf32>) -> tensor<576x1x1x216xf32>\n    %4 = bufferization.alloc_tensor() : tensor<576xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<576xf32>) -> tensor<576xf32>\n    %6 = tensor.empty() : tensor<666x28x28x576xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<576xf32>) outs(%6 : tensor<666x28x28x576xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x576xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x216xf32>, tensor<576x1x1x216xf32>) outs(%7 : tensor<666x28x28x576xf32>) -> tensor<666x28x28x576xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x720xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    %2 = bufferization.alloc_tensor() : tensor<720x1x1x720xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<720x1x1x720xf32>) -> tensor<720x1x1x720xf32>\n    %4 = bufferization.alloc_tensor() : tensor<720xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<720xf32>) -> tensor<720xf32>\n    %6 = tensor.empty() : tensor<666x14x14x720xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<720xf32>) outs(%6 : tensor<666x14x14x720xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x720xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x720xf32>, tensor<720x1x1x720xf32>) outs(%7 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x147x147x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x147x147x32xf32>) -> tensor<666x147x147x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x147x147x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x147x147x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x147x147x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x147x147x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<48xf32>) -> tensor<48xf32>\n    %2 = tensor.empty() : tensor<48xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<48xf32>) outs(%2 : tensor<48xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<48xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %2 = tensor.empty() : tensor<666x7x1920xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x7x1920xf32>) -> tensor<666x7x1920xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x7x7x1920xf32>) outs(%3 : tensor<666x7x1920xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x7x1920xf32> into tensor<666x1x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x72xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x72xf32>) -> tensor<666x112x112x72xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x72xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x72xf32>) -> tensor<1x1x1x72xf32>\n    %4 = tensor.empty() : tensor<666x112x112x72xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x72xf32>, tensor<1x1x1x72xf32>) outs(%4 : tensor<666x112x112x72xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x240xf32>) -> tensor<666x28x28x240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<720x1x1x240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<720x1x1x240xf32>) -> tensor<720x1x1x240xf32>\n    %4 = bufferization.alloc_tensor() : tensor<720xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<720xf32>) -> tensor<720xf32>\n    %6 = tensor.empty() : tensor<666x14x14x720xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<720xf32>) outs(%6 : tensor<666x14x14x720xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x720xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x240xf32>, tensor<720x1x1x240xf32>) outs(%7 : tensor<666x14x14x720xf32>) -> tensor<666x14x14x720xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<72x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<72x1x1x32xf32>) -> tensor<72x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<72xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<72xf32>) -> tensor<72xf32>\n    %6 = tensor.empty() : tensor<666x56x56x72xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<72xf32>) outs(%6 : tensor<666x56x56x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x72xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<72x1x1x32xf32>) outs(%7 : tensor<666x56x56x72xf32>) -> tensor<666x56x56x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x44xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x44xf32>) -> tensor<666x28x28x44xf32>\n    %2 = bufferization.alloc_tensor() : tensor<5x5x44x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<5x5x44x1xf32>) -> tensor<5x5x44x1xf32>\n    %4 = bufferization.alloc_tensor() : tensor<44xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<44xf32>) -> tensor<44xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 2, 2, 0] high[0, 2, 2, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x44xf32> to tensor<666x32x32x44xf32>\n    %6 = tensor.empty() : tensor<666x28x28x44x1xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %7 = linalg.fill ins(%cst_1 : f32) outs(%6 : tensor<666x28x28x44x1xf32>) -> tensor<666x28x28x44x1xf32>\n    %8 = tensor.empty() : tensor<666x28x28x44xf32>\n    %9 = linalg.depthwise_conv_2d_nhwc_hwcm {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x32x32x44xf32>, tensor<5x5x44x1xf32>) outs(%7 : tensor<666x28x28x44x1xf32>) -> tensor<666x28x28x44x1xf32>\n    %collapsed = tensor.collapse_shape %9 [[0], [1], [2], [3, 4]] : tensor<666x28x28x44x1xf32> into tensor<666x28x28x44xf32>\n    %10 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5, %collapsed : tensor<44xf32>, tensor<666x28x28x44xf32>) outs(%8 : tensor<666x28x28x44xf32>) {\n    ^bb0(%in: f32, %in_2: f32, %out: f32):\n      %11 = arith.addf %in, %in_2 : f32\n      linalg.yield %11 : f32\n    } -> tensor<666x28x28x44xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1568xf32>) -> tensor<666x14x14x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x1568xf32>) -> tensor<128x1x1x1568xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1568xf32>, tensor<128x1x1x1568xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x165x165x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x165x165x42xf32>) -> tensor<666x165x165x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x42xf32>) -> tensor<1x1x1x42xf32>\n    %4 = tensor.empty() : tensor<666x165x165x42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x165x165x42xf32>, tensor<1x1x1x42xf32>) outs(%4 : tensor<666x165x165x42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x165x165x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x111x111x11xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x111x111x11xf32>) -> tensor<666x111x111x11xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x11xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x11xf32>) -> tensor<1x1x1x11xf32>\n    %4 = tensor.empty() : tensor<666x111x111x11xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x111x111x11xf32>, tensor<1x1x1x11xf32>) outs(%4 : tensor<666x111x111x11xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x111x111x11xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x888xf32>) -> tensor<666x1x1x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<222x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<222x1x1x888xf32>) -> tensor<222x1x1x888xf32>\n    %4 = bufferization.alloc_tensor() : tensor<222xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<222xf32>) -> tensor<222xf32>\n    %6 = tensor.empty() : tensor<666x1x1x222xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<222xf32>) outs(%6 : tensor<666x1x1x222xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x222xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x888xf32>, tensor<222x1x1x888xf32>) outs(%7 : tensor<666x1x1x222xf32>) -> tensor<666x1x1x222xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x1x1x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x1x1x512xf32>) -> tensor<1x1x1x512xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x512xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %4 = tensor.empty() : tensor<666x14x14x512xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<1x1x1x512xf32>, tensor<666x14x14x512xf32>) outs(%4 : tensor<666x14x14x512xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1232xf32>) -> tensor<666x28x28x1232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1232xf32>) -> tensor<1x1x1x1232xf32>\n    %4 = tensor.empty() : tensor<666x28x28x1232xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x1232xf32>, tensor<1x1x1x1232xf32>) outs(%4 : tensor<666x28x28x1232xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x7x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x7x1x128xf32>) -> tensor<192x7x1x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 3, 0, 0] high[0, 3, 0, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x128xf32> to tensor<666x23x17x128xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x23x17x128xf32>, tensor<192x7x1x128xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x3024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x3024xf32>) -> tensor<666x1x1x3024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x3024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x3024xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x3024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x3024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x784xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x784xf32>) -> tensor<666x28x28x784xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x784xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x784xf32>) -> tensor<1x1x1x784xf32>\n    %4 = tensor.empty() : tensor<666x28x28x784xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x784xf32>, tensor<1x1x1x784xf32>) outs(%4 : tensor<666x28x28x784xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x784xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x128xf32>) -> tensor<666x28x28x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>\n    %4 = tensor.empty() : tensor<666x28x28x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x128xf32>, tensor<1x1x1x128xf32>) outs(%4 : tensor<666x28x28x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x144xf32>) -> tensor<666x1x1x144xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x144xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x144xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x144xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1920xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1920xf32>) -> tensor<666x7x7x1920xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1920xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1920xf32>) -> tensor<1x1x1x1920xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1920xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1920xf32>, tensor<1x1x1x1920xf32>) outs(%4 : tensor<666x7x7x1920xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1920xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x2240xf32>) -> tensor<666x7x7x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x2240xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x2240xf32>) -> tensor<1x1x1x2240xf32>\n    %4 = tensor.empty() : tensor<666x7x7x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x2240xf32>, tensor<1x1x1x2240xf32>) outs(%4 : tensor<666x7x7x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1232xf32>) -> tensor<1232xf32>\n    %2 = tensor.empty() : tensor<1232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1232xf32>) outs(%2 : tensor<1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x160xf32>) -> tensor<666x17x17x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x160xf32>) -> tensor<1x1x1x160xf32>\n    %4 = tensor.empty() : tensor<666x17x17x160xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x160xf32>, tensor<1x1x1x160xf32>) outs(%4 : tensor<666x17x17x160xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x160xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x42x42x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x42x42x1008xf32>) -> tensor<666x42x42x1008xf32>\n    %2 = tensor.empty() : tensor<666x42x42x1008xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x42x42x1008xf32>) outs(%2 : tensor<666x42x42x1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x42x42x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x3712xf32>) -> tensor<666x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x3712xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<32x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<32x1x1x32xf32>) -> tensor<32x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<32xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<32xf32>) -> tensor<32xf32>\n    %6 = tensor.empty() : tensor<666x56x56x32xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<32xf32>) outs(%6 : tensor<666x56x56x32xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x32xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<32x1x1x32xf32>) outs(%7 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x11x11x672xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x11x11x672xf32> to tensor<666x13x13x672xf32>\n    %cst_1 = arith.constant 0.000000e+00 : f32\n    %2 = tensor.empty() : tensor<666x11x11x672xf32>\n    %3 = linalg.fill ins(%cst_1 : f32) outs(%2 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_sum {dilations = dense<1> : vector<2xi64>, strides = dense<1> : vector<2xi64>} ins(%padded, %4 : tensor<666x13x13x672xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x11x11x672xf32>) -> tensor<666x11x11x672xf32>\n    %c1 = arith.constant 1 : index\n    %c11 = arith.constant 11 : index\n    %c2 = arith.constant 2 : index\n    %c11_2 = arith.constant 11 : index\n    %c1_3 = arith.constant 1 : index\n    %6 = arith.subi %c11, %c1_3 : index\n    %7 = arith.subi %c11_2, %c1_3 : index\n    %8 = tensor.empty() : tensor<666x11x11x672xf32>\n    %9 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<666x11x11x672xf32>) outs(%8 : tensor<666x11x11x672xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %c0 = arith.constant 0 : index\n      %c1_4 = arith.constant 1 : index\n      %c3 = arith.constant 3 : index\n      %10 = linalg.index 1 : index\n      %11 = arith.subi %6, %10 : index\n      %12 = arith.muli %10, %c1_4 : index\n      %13 = arith.muli %11, %c1_4 : index\n      %c1_5 = arith.constant 1 : index\n      %14 = arith.subi %12, %c1_5 : index\n      %15 = arith.cmpi slt, %14, %c0 : index\n      %16 = arith.select %15, %14, %c0 : index\n      %17 = arith.addi %c3, %16 : index\n      %c1_6 = arith.constant 1 : index\n      %18 = arith.subi %13, %c1_6 : index\n      %19 = arith.cmpi slt, %18, %c0 : index\n      %20 = arith.select %19, %18, %c0 : index\n      %21 = arith.addi %17, %20 : index\n      %22 = arith.cmpi slt, %21, %c1_3 : index\n      %23 = arith.select %22, %c1_3, %21 : index\n      %c1_7 = arith.constant 1 : index\n      %c3_8 = arith.constant 3 : index\n      %24 = linalg.index 2 : index\n      %25 = arith.subi %7, %24 : index\n      %26 = arith.muli %24, %c1_7 : index\n      %27 = arith.muli %25, %c1_7 : index\n      %c1_9 = arith.constant 1 : index\n      %28 = arith.subi %26, %c1_9 : index\n      %29 = arith.cmpi slt, %28, %c0 : index\n      %30 = arith.select %29, %28, %c0 : index\n      %31 = arith.addi %c3_8, %30 : index\n      %c1_10 = arith.constant 1 : index\n      %32 = arith.subi %27, %c1_10 : index\n      %33 = arith.cmpi slt, %32, %c0 : index\n      %34 = arith.select %33, %32, %c0 : index\n      %35 = arith.addi %31, %34 : index\n      %36 = arith.cmpi slt, %35, %c1_3 : index\n      %37 = arith.select %36, %c1_3, %35 : index\n      %38 = arith.muli %23, %37 : index\n      %39 = arith.index_cast %38 : index to i32\n      %40 = arith.sitofp %39 : i32 to f32\n      %41 = arith.divf %in, %40 : f32\n      linalg.yield %41 : f32\n    } -> tensor<666x11x11x672xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x80xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x80xf32>) -> tensor<666x112x112x80xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x80xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x80xf32>) -> tensor<1x1x1x80xf32>\n    %4 = tensor.empty() : tensor<666x112x112x80xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x80xf32>, tensor<1x1x1x80xf32>) outs(%4 : tensor<666x112x112x80xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x80xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x432xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x432xf32>) -> tensor<666x14x14x432xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x432xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x432xf32>) -> tensor<1x1x1x432xf32>\n    %4 = tensor.empty() : tensor<666x14x14x432xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x432xf32>, tensor<1x1x1x432xf32>) outs(%4 : tensor<666x14x14x432xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x432xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x608xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x608xf32>) -> tensor<666x14x14x608xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x608xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x608xf32>) -> tensor<128x1x1x608xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x608xf32>, tensor<128x1x1x608xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1x666x4096xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x666x4096xf32>) -> tensor<1x666x4096xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x4096x1000xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x4096x1000xf32>) -> tensor<1x4096x1000xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %4 = tensor.empty() : tensor<1x666x1000xf32>\n    %5 = linalg.fill ins(%cst_0 : f32) outs(%4 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    %6 = linalg.batch_matmul ins(%1, %3 : tensor<1x666x4096xf32>, tensor<1x4096x1000xf32>) outs(%5 : tensor<1x666x1000xf32>) -> tensor<1x666x1000xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x704xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x704xf32>) -> tensor<666x7x7x704xf32>\n    %2 = tensor.empty() : tensor<666x7x7x704xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x704xf32>) outs(%2 : tensor<666x7x7x704xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x704xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<1728xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1728xf32>) -> tensor<1728xf32>\n    %2 = tensor.empty() : tensor<1728xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<1728xf32>) outs(%2 : tensor<1728xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<1728xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x30xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x30xf32>) -> tensor<666x1x1x30xf32>\n    %2 = tensor.empty() : tensor<666x1x1x30xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x30xf32>) outs(%2 : tensor<666x1x1x30xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x30xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1008xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1008xf32>) outs(%2 : tensor<666x7x7x1008xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x256xf32>) -> tensor<666x1x1x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x256xf32>) -> tensor<64x1x1x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x1x1x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x1x1x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x256xf32>, tensor<64x1x1x256xf32>) outs(%7 : tensor<666x1x1x64xf32>) -> tensor<666x1x1x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x96xf32>) -> tensor<666x17x17x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x96xf32>) -> tensor<1x1x1x96xf32>\n    %4 = tensor.empty() : tensor<666x17x17x96xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x17x17x96xf32>, tensor<1x1x1x96xf32>) outs(%4 : tensor<666x17x17x96xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x17x17x96xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x232xf32>) -> tensor<666x56x56x232xf32>\n    %2 = bufferization.alloc_tensor() : tensor<696x1x1x232xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<696x1x1x232xf32>) -> tensor<696x1x1x232xf32>\n    %4 = bufferization.alloc_tensor() : tensor<696xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<696xf32>) -> tensor<696xf32>\n    %6 = tensor.empty() : tensor<666x56x56x696xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<696xf32>) outs(%6 : tensor<666x56x56x696xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x696xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x232xf32>, tensor<696x1x1x232xf32>) outs(%7 : tensor<666x56x56x696xf32>) -> tensor<666x56x56x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x440xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x440xf32>) -> tensor<666x1x1x440xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x440xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x440xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x440xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x440xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x992xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x992xf32>) -> tensor<666x14x14x992xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x992xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x992xf32>) -> tensor<1x1x1x992xf32>\n    %4 = tensor.empty() : tensor<666x14x14x992xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x992xf32>, tensor<1x1x1x992xf32>) outs(%4 : tensor<666x14x14x992xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x992xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x168xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x168xf32>) -> tensor<666x1x1x168xf32>\n    %2 = tensor.empty() : tensor<666x1x1x168xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x168xf32>) outs(%2 : tensor<666x1x1x168xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 1.000000e+00 : f32\n      %4 = arith.negf %in : f32\n      %5 = math.exp %4 : f32\n      %6 = arith.addf %5, %cst_0 : f32\n      %7 = arith.divf %cst_0, %6 : f32\n      linalg.yield %7 : f32\n    } -> tensor<666x1x1x168xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x160xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x160xf32>) -> tensor<666x7x7x160xf32>\n    %2 = bufferization.alloc_tensor() : tensor<960x1x1x160xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<960x1x1x160xf32>) -> tensor<960x1x1x160xf32>\n    %4 = bufferization.alloc_tensor() : tensor<960xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<960xf32>) -> tensor<960xf32>\n    %6 = tensor.empty() : tensor<666x7x7x960xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<960xf32>) outs(%6 : tensor<666x7x7x960xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x960xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x7x7x160xf32>, tensor<960x1x1x160xf32>) outs(%7 : tensor<666x7x7x960xf32>) -> tensor<666x7x7x960xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x696xf32>) -> tensor<666x1x1x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x696xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x696xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x576xf32>) -> tensor<666x1x1x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<72x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<72x1x1x576xf32>) -> tensor<72x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<72xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<72xf32>) -> tensor<72xf32>\n    %6 = tensor.empty() : tensor<666x1x1x72xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<72xf32>) outs(%6 : tensor<666x1x1x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x72xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x576xf32>, tensor<72x1x1x576xf32>) outs(%7 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x768xf32>) -> tensor<666x28x28x768xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x768xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x768xf32>) -> tensor<666x28x28x768xf32>\n    %4 = tensor.empty() : tensor<666x28x28x768xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x768xf32>, tensor<666x28x28x768xf32>) outs(%4 : tensor<666x28x28x768xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    %2 = bufferization.alloc_tensor() : tensor<512x3x3x256xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<512x3x3x256xf32>) -> tensor<512x3x3x256xf32>\n    %4 = bufferization.alloc_tensor() : tensor<512xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<512xf32>) -> tensor<512xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 1, 1, 0] high[0, 1, 1, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x28x28x256xf32> to tensor<666x30x30x256xf32>\n    %6 = tensor.empty() : tensor<666x28x28x512xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<512xf32>) outs(%6 : tensor<666x28x28x512xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x512xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x30x30x256xf32>, tensor<512x3x3x256xf32>) outs(%7 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x256xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x256xf32>) -> tensor<666x14x14x256xf32>\n    %2 = tensor.empty() : tensor<666x14x256xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x256xf32>) -> tensor<666x14x256xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x256xf32>) outs(%3 : tensor<666x14x256xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x256xf32> into tensor<666x1x14x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<640xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<640xf32>) -> tensor<640xf32>\n    %2 = tensor.empty() : tensor<640xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<640xf32>) outs(%2 : tensor<640xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<640xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x83x83x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x83x83x42xf32>) -> tensor<666x83x83x42xf32>\n    %4 = tensor.empty() : tensor<666x83x83x42xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x83x83x42xf32>, tensor<666x83x83x42xf32>) outs(%4 : tensor<666x83x83x42xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x83x83x42xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x696xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x696xf32>) -> tensor<666x28x28x696xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x696xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x696xf32>) -> tensor<1x1x1x696xf32>\n    %4 = tensor.empty() : tensor<666x28x28x696xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x696xf32>, tensor<1x1x1x696xf32>) outs(%4 : tensor<666x28x28x696xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x696xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1392xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1392xf32>) -> tensor<666x14x14x1392xf32>\n    %2 = tensor.empty() : tensor<666x14x1392xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x1392xf32>) -> tensor<666x14x1392xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x14x14x1392xf32>) outs(%3 : tensor<666x14x1392xf32>) dimensions = [1] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1, 2], [3]] : tensor<666x14x1392xf32> into tensor<666x1x14x1392xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x888xf32>) -> tensor<666x1x1x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x888xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x144xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x144xf32>) -> tensor<666x28x28x144xf32>\n    %2 = tensor.empty() : tensor<666x28x28x144xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x144xf32>) outs(%2 : tensor<666x28x28x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 6.000000e+00 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x336xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x336xf32>) -> tensor<666x1x1x336xf32>\n    %2 = bufferization.alloc_tensor() : tensor<30x1x1x336xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<30x1x1x336xf32>) -> tensor<30x1x1x336xf32>\n    %4 = bufferization.alloc_tensor() : tensor<30xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<30xf32>) -> tensor<30xf32>\n    %6 = tensor.empty() : tensor<666x1x1x30xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<30xf32>) outs(%6 : tensor<666x1x1x30xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x30xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x336xf32>, tensor<30x1x1x336xf32>) outs(%7 : tensor<666x1x1x30xf32>) -> tensor<666x1x1x30xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1568xf32>) -> tensor<666x7x7x1568xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1568xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1568xf32>) -> tensor<1x1x1x1568xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1568xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1568xf32>, tensor<1x1x1x1568xf32>) outs(%4 : tensor<666x7x7x1568xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x38xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x38xf32>) -> tensor<666x1x1x38xf32>\n    %2 = bufferization.alloc_tensor() : tensor<152x1x1x38xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<152x1x1x38xf32>) -> tensor<152x1x1x38xf32>\n    %4 = bufferization.alloc_tensor() : tensor<152xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<152xf32>) -> tensor<152xf32>\n    %6 = tensor.empty() : tensor<666x1x1x152xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<152xf32>) outs(%6 : tensor<666x1x1x152xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x152xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x38xf32>, tensor<152x1x1x38xf32>) outs(%7 : tensor<666x1x1x152xf32>) -> tensor<666x1x1x152xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x1344xf32>) -> tensor<666x28x28x1344xf32>\n    %2 = tensor.empty() : tensor<666x28x28x1344xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x28x28x1344xf32>) outs(%2 : tensor<666x28x28x1344xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x28x28x1344xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x224xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x224xf32>) -> tensor<666x1x1x224xf32>\n    %2 = bufferization.alloc_tensor() : tensor<8x1x1x224xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<8x1x1x224xf32>) -> tensor<8x1x1x224xf32>\n    %4 = bufferization.alloc_tensor() : tensor<8xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<8xf32>) -> tensor<8xf32>\n    %6 = tensor.empty() : tensor<666x1x1x8xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<8xf32>) outs(%6 : tensor<666x1x1x8xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x8xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x224xf32>, tensor<8x1x1x224xf32>) outs(%7 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x912xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x912xf32>) -> tensor<666x14x14x912xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x912xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x912xf32>) -> tensor<1x1x1x912xf32>\n    %4 = tensor.empty() : tensor<666x14x14x912xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x912xf32>, tensor<1x1x1x912xf32>) outs(%4 : tensor<666x14x14x912xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x912xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x176xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x176xf32>) -> tensor<666x14x14x176xf32>\n    %2 = tensor.empty() : tensor<666x14x14x176xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x176xf32>) outs(%2 : tensor<666x14x14x176xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x176xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x1024xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x1024xf32>) -> tensor<666x56x56x1024xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x56x56x1024xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x56x56x1024xf32>) -> tensor<666x56x56x1024xf32>\n    %4 = tensor.empty() : tensor<666x56x56x1024xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x56x56x1024xf32>, tensor<666x56x56x1024xf32>) outs(%4 : tensor<666x56x56x1024xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x56x56x1024xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<528xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<528xf32>) -> tensor<528xf32>\n    %2 = tensor.empty() : tensor<528xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\"]} ins(%1 : tensor<528xf32>) outs(%2 : tensor<528xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.rsqrt %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<528xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x10x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x10x2048xf32>) -> tensor<666x1x10x2048xf32>\n    %2 = tensor.empty() : tensor<666x1x2048xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x1x2048xf32>) -> tensor<666x1x2048xf32>\n    %reduced = linalg.reduce ins(%1 : tensor<666x1x10x2048xf32>) outs(%3 : tensor<666x1x2048xf32>) dimensions = [2] \n      (%in: f32, %init: f32) {\n        %4 = arith.addf %in, %init : f32\n        linalg.yield %4 : f32\n      }\n    %expanded = tensor.expand_shape %reduced [[0], [1], [2, 3]] : tensor<666x1x2048xf32> into tensor<666x1x1x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1360x1x1x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1360x1x1x560xf32>) -> tensor<1360x1x1x560xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1360xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1360xf32>) -> tensor<1360xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1360xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1360xf32>) outs(%6 : tensor<666x14x14x1360xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1360xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x560xf32>, tensor<1360x1x1x560xf32>) outs(%7 : tensor<666x14x14x1360xf32>) -> tensor<666x14x14x1360xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x192xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x192xf32>) -> tensor<666x28x28x192xf32>\n    %4 = tensor.empty() : tensor<666x28x28x192xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x192xf32>, tensor<666x28x28x192xf32>) outs(%4 : tensor<666x28x28x192xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<144x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<144x1x1x32xf32>) -> tensor<144x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<144xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<144xf32>) -> tensor<144xf32>\n    %6 = tensor.empty() : tensor<666x112x112x144xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<144xf32>) outs(%6 : tensor<666x112x112x144xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x112x112x144xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<144x1x1x32xf32>) outs(%7 : tensor<666x112x112x144xf32>) -> tensor<666x112x112x144xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x74x74x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x74x74x128xf32>) -> tensor<666x74x74x128xf32>\n    %4 = tensor.empty() : tensor<666x74x74x128xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x74x74x128xf32>, tensor<666x74x74x128xf32>) outs(%4 : tensor<666x74x74x128xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x74x74x128xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x512xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x512xf32>) -> tensor<666x28x28x512xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x14x14x512xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    %4 = tensor.empty() : tensor<2x2xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x28x28x512xf32>, tensor<2x2xf32>) outs(%3 : tensor<666x14x14x512xf32>) -> tensor<666x14x14x512xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x32xf32>) -> tensor<666x56x56x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<64x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<64x1x1x32xf32>) -> tensor<64x1x1x32xf32>\n    %4 = bufferization.alloc_tensor() : tensor<64xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<64xf32>) -> tensor<64xf32>\n    %6 = tensor.empty() : tensor<666x56x56x64xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<64xf32>) outs(%6 : tensor<666x56x56x64xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x64xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x32xf32>, tensor<64x1x1x32xf32>) outs(%7 : tensor<666x56x56x64xf32>) -> tensor<666x56x56x64xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x64xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x64xf32>) -> tensor<666x28x28x64xf32>\n    %2 = bufferization.alloc_tensor() : tensor<256x1x1x64xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<256x1x1x64xf32>) -> tensor<256x1x1x64xf32>\n    %4 = bufferization.alloc_tensor() : tensor<256xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<256xf32>) -> tensor<256xf32>\n    %6 = tensor.empty() : tensor<666x28x28x256xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<256xf32>) outs(%6 : tensor<666x28x28x256xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x28x28x256xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x28x28x64xf32>, tensor<256x1x1x64xf32>) outs(%7 : tensor<666x28x28x256xf32>) -> tensor<666x28x28x256xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, 0)>\n#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x48xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x48xf32>) -> tensor<666x1x1x48xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>\n    %4 = tensor.empty() : tensor<666x1x1x48xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x1x1x48xf32>, tensor<1x1x1x1xf32>) outs(%4 : tensor<666x1x1x48xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x1x1x48xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1) -> (d0, d1)>\n#map1 = affine_map<(d0, d1) -> (0, 0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x2240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x2240xf32>) -> tensor<666x2240xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1xf32>) -> tensor<1x1xf32>\n    %4 = tensor.empty() : tensor<666x2240xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x2240xf32>, tensor<1x1xf32>) outs(%4 : tensor<666x2240xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x2240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1280xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1280xf32>) -> tensor<666x14x14x1280xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1280xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1280xf32>) -> tensor<1x1x1x1280xf32>\n    %4 = tensor.empty() : tensor<666x14x14x1280xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x1280xf32>, tensor<1x1x1x1280xf32>) outs(%4 : tensor<666x14x14x1280xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x1280xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x112x112x32xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x112x112x32xf32>) -> tensor<666x112x112x32xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x32xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x32xf32>) -> tensor<1x1x1x32xf32>\n    %4 = tensor.empty() : tensor<666x112x112x32xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x112x112x32xf32>, tensor<1x1x1x32xf32>) outs(%4 : tensor<666x112x112x32xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x112x112x32xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1344xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1344xf32>) -> tensor<666x14x14x1344xf32>\n    %2 = bufferization.alloc_tensor() : tensor<2520x1x1x1344xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<2520x1x1x1344xf32>) -> tensor<2520x1x1x1344xf32>\n    %4 = bufferization.alloc_tensor() : tensor<2520xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<2520xf32>) -> tensor<2520xf32>\n    %6 = tensor.empty() : tensor<666x7x7x2520xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<2520xf32>) outs(%6 : tensor<666x7x7x2520xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x7x7x2520xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x1344xf32>, tensor<2520x1x1x1344xf32>) outs(%7 : tensor<666x7x7x2520xf32>) -> tensor<666x7x7x2520xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x56x56x96xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x56x56x96xf32>) -> tensor<666x56x56x96xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x1x96xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x1x96xf32>) -> tensor<192x1x1x96xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %6 = tensor.empty() : tensor<666x56x56x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x56x56x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x56x56x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x56x56x96xf32>, tensor<192x1x1x96xf32>) outs(%7 : tensor<666x56x56x192xf32>) -> tensor<666x56x56x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x3712xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x3712xf32>) -> tensor<666x7x7x3712xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x3712xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x3712xf32>) -> tensor<1x1x1x3712xf32>\n    %4 = tensor.empty() : tensor<666x7x7x3712xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x3712xf32>, tensor<1x1x1x3712xf32>) outs(%4 : tensor<666x7x7x3712xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x3712xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x42xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x42xf32>) -> tensor<666x1x1x42xf32>\n    %2 = bufferization.alloc_tensor() : tensor<448x1x1x42xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<448x1x1x42xf32>) -> tensor<448x1x1x42xf32>\n    %4 = bufferization.alloc_tensor() : tensor<448xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<448xf32>) -> tensor<448xf32>\n    %6 = tensor.empty() : tensor<666x1x1x448xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<448xf32>) outs(%6 : tensor<666x1x1x448xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x448xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x42xf32>, tensor<448x1x1x42xf32>) outs(%7 : tensor<666x1x1x448xf32>) -> tensor<666x1x1x448xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x288xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x288xf32>) -> tensor<666x14x14x288xf32>\n    %2 = bufferization.alloc_tensor() : tensor<128x1x1x288xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<128x1x1x288xf32>) -> tensor<128x1x1x288xf32>\n    %4 = bufferization.alloc_tensor() : tensor<128xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<128xf32>) -> tensor<128xf32>\n    %6 = tensor.empty() : tensor<666x14x14x128xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<128xf32>) outs(%6 : tensor<666x14x14x128xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x128xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x288xf32>, tensor<128x1x1x288xf32>) outs(%7 : tensor<666x14x14x128xf32>) -> tensor<666x14x14x128xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, 0, 0, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x38xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x38xf32>) -> tensor<666x1x1x38xf32>\n    %2 = tensor.empty() : tensor<666x1x1x38xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x1x1x38xf32>) outs(%2 : tensor<666x1x1x38xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x1x1x38xf32>\n    return\n  }\n}\n\n", "module {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x768xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x768xf32>) -> tensor<666x17x17x768xf32>\n    %cst_0 = arith.constant -3.40282347E+38 : f32\n    %2 = tensor.empty() : tensor<666x8x8x768xf32>\n    %3 = linalg.fill ins(%cst_0 : f32) outs(%2 : tensor<666x8x8x768xf32>) -> tensor<666x8x8x768xf32>\n    %4 = tensor.empty() : tensor<3x3xf32>\n    %5 = linalg.pooling_nhwc_max {dilations = dense<1> : vector<2xi64>, strides = dense<2> : vector<2xi64>} ins(%1, %4 : tensor<666x17x17x768xf32>, tensor<3x3xf32>) outs(%3 : tensor<666x8x8x768xf32>) -> tensor<666x8x8x768xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1232xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1232xf32>) -> tensor<666x14x14x1232xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1232xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1232xf32>) outs(%2 : tensor<666x14x14x1232xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1232xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x576xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x576xf32>) -> tensor<666x14x14x576xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1296x1x1x576xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1296x1x1x576xf32>) -> tensor<1296x1x1x576xf32>\n    %4 = bufferization.alloc_tensor() : tensor<1296xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1296xf32>) -> tensor<1296xf32>\n    %6 = tensor.empty() : tensor<666x14x14x1296xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<1296xf32>) outs(%6 : tensor<666x14x14x1296xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x14x14x1296xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x14x14x576xf32>, tensor<1296x1x1x576xf32>) outs(%7 : tensor<666x14x14x1296xf32>) -> tensor<666x14x14x1296xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0) -> (d0)>\n#map1 = affine_map<(d0) -> (0)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<480xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<480xf32>) -> tensor<480xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1xf32>) -> tensor<1xf32>\n    %4 = tensor.empty() : tensor<480xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\"]} ins(%1, %3 : tensor<480xf32>, tensor<1xf32>) outs(%4 : tensor<480xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<480xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x240xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x240xf32>) -> tensor<666x14x14x240xf32>\n    %2 = tensor.empty() : tensor<666x14x14x240xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x240xf32>) outs(%2 : tensor<666x14x14x240xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x240xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1472xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1472xf32>) -> tensor<666x7x7x1472xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1472xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1472xf32>) -> tensor<1x1x1x1472xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1472xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1472xf32>, tensor<1x1x1x1472xf32>) outs(%4 : tensor<666x7x7x1472xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1472xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x17x17x128xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x17x17x128xf32>) -> tensor<666x17x17x128xf32>\n    %2 = bufferization.alloc_tensor() : tensor<192x1x7x128xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<192x1x7x128xf32>) -> tensor<192x1x7x128xf32>\n    %4 = bufferization.alloc_tensor() : tensor<192xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<192xf32>) -> tensor<192xf32>\n    %cst_0 = arith.constant 0.000000e+00 : f32\n    %padded = tensor.pad %1 low[0, 0, 3, 0] high[0, 0, 3, 0] {\n    ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index):\n      tensor.yield %cst_0 : f32\n    } : tensor<666x17x17x128xf32> to tensor<666x17x23x128xf32>\n    %6 = tensor.empty() : tensor<666x17x17x192xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<192xf32>) outs(%6 : tensor<666x17x17x192xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x17x17x192xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%padded, %3 : tensor<666x17x23x128xf32>, tensor<192x1x7x128xf32>) outs(%7 : tensor<666x17x17x192xf32>) -> tensor<666x17x17x192xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x1568xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x1568xf32>) -> tensor<666x14x14x1568xf32>\n    %2 = tensor.empty() : tensor<666x14x14x1568xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x1568xf32>) outs(%2 : tensor<666x14x14x1568xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x14x14x1568xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x888xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x888xf32>) -> tensor<666x14x14x888xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x888xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x888xf32>) -> tensor<1x1x1x888xf32>\n    %4 = tensor.empty() : tensor<666x14x14x888xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x888xf32>, tensor<1x1x1x888xf32>) outs(%4 : tensor<666x14x14x888xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.mulf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x888xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x14x14x560xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x14x14x560xf32>) -> tensor<666x14x14x560xf32>\n    %4 = tensor.empty() : tensor<666x14x14x560xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x14x14x560xf32>, tensor<666x14x14x560xf32>) outs(%4 : tensor<666x14x14x560xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x14x14x560xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1248xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1248xf32>) -> tensor<666x7x7x1248xf32>\n    %2 = tensor.empty() : tensor<666x7x7x1248xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x7x7x1248xf32>) outs(%2 : tensor<666x7x7x1248xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %cst_0 = arith.constant 0.000000e+00 : f32\n      %cst_1 = arith.constant 3.40282347E+38 : f32\n      %4 = arith.minimumf %in, %cst_1 : f32\n      %5 = arith.maximumf %4, %cst_0 : f32\n      linalg.yield %5 : f32\n    } -> tensor<666x7x7x1248xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x14x14x2048xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x14x14x2048xf32>) -> tensor<666x14x14x2048xf32>\n    %2 = tensor.empty() : tensor<666x14x14x2048xf32>\n    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1 : tensor<666x14x14x2048xf32>) outs(%2 : tensor<666x14x14x2048xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      %4 = math.erf %in : f32\n      linalg.yield %4 : f32\n    } -> tensor<666x14x14x2048xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x7x7x1008xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x7x7x1008xf32>) -> tensor<666x7x7x1008xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x1008xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x1008xf32>) -> tensor<1x1x1x1008xf32>\n    %4 = tensor.empty() : tensor<666x7x7x1008xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x7x7x1008xf32>, tensor<1x1x1x1008xf32>) outs(%4 : tensor<666x7x7x1008xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x7x7x1008xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (0, 0, 0, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<1x1x1x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<1x1x1x104xf32>) -> tensor<1x1x1x104xf32>\n    %4 = tensor.empty() : tensor<666x28x28x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x104xf32>, tensor<1x1x1x104xf32>) outs(%4 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.subf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %2 = bufferization.alloc_tensor() : tensor<666x28x28x104xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<666x28x28x104xf32>) -> tensor<666x28x28x104xf32>\n    %4 = tensor.empty() : tensor<666x28x28x104xf32>\n    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%1, %3 : tensor<666x28x28x104xf32>, tensor<666x28x28x104xf32>) outs(%4 : tensor<666x28x28x104xf32>) {\n    ^bb0(%in: f32, %in_0: f32, %out: f32):\n      %6 = arith.addf %in, %in_0 : f32\n      linalg.yield %6 : f32\n    } -> tensor<666x28x28x104xf32>\n    return\n  }\n}\n\n", "#map = affine_map<(d0, d1, d2, d3) -> (d3)>\n#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\nmodule {\n  func.func @wrapper() {\n    %cst = arith.constant 2.000000e+00 : f32\n    %0 = bufferization.alloc_tensor() : tensor<666x1x1x8xf32>\n    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<666x1x1x8xf32>) -> tensor<666x1x1x8xf32>\n    %2 = bufferization.alloc_tensor() : tensor<72x1x1x8xf32>\n    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<72x1x1x8xf32>) -> tensor<72x1x1x8xf32>\n    %4 = bufferization.alloc_tensor() : tensor<72xf32>\n    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<72xf32>) -> tensor<72xf32>\n    %6 = tensor.empty() : tensor<666x1x1x72xf32>\n    %7 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%5 : tensor<72xf32>) outs(%6 : tensor<666x1x1x72xf32>) {\n    ^bb0(%in: f32, %out: f32):\n      linalg.yield %in : f32\n    } -> tensor<666x1x1x72xf32>\n    %8 = linalg.conv_2d_nhwc_fhwc {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins(%1, %3 : tensor<666x1x1x8xf32>, tensor<72x1x1x8xf32>) outs(%7 : tensor<666x1x1x72xf32>) -> tensor<666x1x1x72xf32>\n    return\n  }\n}\n\n"]}