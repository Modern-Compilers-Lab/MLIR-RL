{
  "linalg.add ins(%arg0, %arg1: tensor<28x150x7x130xf32>, tensor<28x150x7x130xf32>) outs(%arg2: tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x150x7x130xf32>, tensor<28x150x7x130xf32>) outs(%arg2: tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x150x7x130xf32>, %arg1: tensor<28x150x7x130xf32>, %arg2: tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x150x7x130xf32>, tensor<28x150x7x130xf32>) outs(%arg2: tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32>\n  return %ret : tensor<28x150x7x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x150x7x130xf32>, %arg1: tensor<28x150x7x130xf32>, %arg2: tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x150x7x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x150x7x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x150x7x130xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x150x7x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x150x7x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x150x7x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x150x7x130xf32>\n    return %2 : tensor<28x150x7x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x150x7x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x150x7x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x150x7x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x150x7x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x150x7x130xf32>, tensor<28x150x7x130xf32>) outs(%arg2: tensor<28x150x7x130xf32>) -> tensor<28x150x7x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x150x7x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x150x7x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3638296
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x56x7x112xf32>, tensor<7x56x7x112xf32>) outs(%arg2: tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x56x7x112xf32>, tensor<7x56x7x112xf32>) outs(%arg2: tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x56x7x112xf32>, %arg1: tensor<7x56x7x112xf32>, %arg2: tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x56x7x112xf32>, tensor<7x56x7x112xf32>) outs(%arg2: tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32>\n  return %ret : tensor<7x56x7x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x56x7x112xf32>, %arg1: tensor<7x56x7x112xf32>, %arg2: tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x56x7x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x56x7x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x56x7x112xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x56x7x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x56x7x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x56x7x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x56x7x112xf32>\n    return %2 : tensor<7x56x7x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x56x7x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x56x7x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x56x7x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x56x7x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x56x7x112xf32>, tensor<7x56x7x112xf32>) outs(%arg2: tensor<7x56x7x112xf32>) -> tensor<7x56x7x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x56x7x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x56x7x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 243195
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x56x224x7xf32>, tensor<56x56x224x7xf32>) outs(%arg2: tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x56x224x7xf32>, tensor<56x56x224x7xf32>) outs(%arg2: tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x56x224x7xf32>, %arg1: tensor<56x56x224x7xf32>, %arg2: tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x56x224x7xf32>, tensor<56x56x224x7xf32>) outs(%arg2: tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32>\n  return %ret : tensor<56x56x224x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x56x224x7xf32>, %arg1: tensor<56x56x224x7xf32>, %arg2: tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x56x224x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x56x224x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x56x224x7xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x56x224x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x56x224x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x56x224x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x56x224x7xf32>\n    return %2 : tensor<56x56x224x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x56x224x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x56x224x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x56x224x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x56x224x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x56x224x7xf32>, tensor<56x56x224x7xf32>) outs(%arg2: tensor<56x56x224x7xf32>) -> tensor<56x56x224x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x56x224x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x56x224x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5546318
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x240x228x150xf32>, tensor<112x240x228x150xf32>) outs(%arg2: tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x240x228x150xf32>, tensor<112x240x228x150xf32>) outs(%arg2: tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x240x228x150xf32>, %arg1: tensor<112x240x228x150xf32>, %arg2: tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x240x228x150xf32>, tensor<112x240x228x150xf32>) outs(%arg2: tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32>\n  return %ret : tensor<112x240x228x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x240x228x150xf32>, %arg1: tensor<112x240x228x150xf32>, %arg2: tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x240x228x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x240x228x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x240x228x150xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x240x228x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x240x228x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x240x228x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x240x228x150xf32>\n    return %2 : tensor<112x240x228x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x240x228x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x240x228x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x240x228x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x240x228x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x240x228x150xf32>, tensor<112x240x228x150xf32>) outs(%arg2: tensor<112x240x228x150xf32>) -> tensor<112x240x228x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x240x228x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x240x228x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1110781695
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x28x150x130xf32>, tensor<14x28x150x130xf32>) outs(%arg2: tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x28x150x130xf32>, tensor<14x28x150x130xf32>) outs(%arg2: tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x28x150x130xf32>, %arg1: tensor<14x28x150x130xf32>, %arg2: tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x28x150x130xf32>, tensor<14x28x150x130xf32>) outs(%arg2: tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32>\n  return %ret : tensor<14x28x150x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x28x150x130xf32>, %arg1: tensor<14x28x150x130xf32>, %arg2: tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x28x150x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x28x150x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x28x150x130xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x28x150x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x28x150x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x28x150x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x28x150x130xf32>\n    return %2 : tensor<14x28x150x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x28x150x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x28x150x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x28x150x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x28x150x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x28x150x130xf32>, tensor<14x28x150x130xf32>) outs(%arg2: tensor<14x28x150x130xf32>) -> tensor<14x28x150x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x28x150x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x28x150x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8708677
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x28x7x228xf32>, tensor<130x28x7x228xf32>) outs(%arg2: tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x28x7x228xf32>, tensor<130x28x7x228xf32>) outs(%arg2: tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x28x7x228xf32>, %arg1: tensor<130x28x7x228xf32>, %arg2: tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x28x7x228xf32>, tensor<130x28x7x228xf32>) outs(%arg2: tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32>\n  return %ret : tensor<130x28x7x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x28x7x228xf32>, %arg1: tensor<130x28x7x228xf32>, %arg2: tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x28x7x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x28x7x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x28x7x228xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x28x7x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x28x7x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x28x7x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x28x7x228xf32>\n    return %2 : tensor<130x28x7x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x28x7x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x28x7x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x28x7x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x28x7x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x28x7x228xf32>, tensor<130x28x7x228xf32>) outs(%arg2: tensor<130x28x7x228xf32>) -> tensor<130x28x7x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x28x7x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x28x7x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6306978
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x120x130x56xf32>, tensor<112x120x130x56xf32>) outs(%arg2: tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x120x130x56xf32>, tensor<112x120x130x56xf32>) outs(%arg2: tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x120x130x56xf32>, %arg1: tensor<112x120x130x56xf32>, %arg2: tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x120x130x56xf32>, tensor<112x120x130x56xf32>) outs(%arg2: tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32>\n  return %ret : tensor<112x120x130x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x120x130x56xf32>, %arg1: tensor<112x120x130x56xf32>, %arg2: tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x120x130x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x120x130x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x120x130x56xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x120x130x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x120x130x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x120x130x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x120x130x56xf32>\n    return %2 : tensor<112x120x130x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x120x130x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x120x130x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x120x130x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x120x130x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x120x130x56xf32>, tensor<112x120x130x56xf32>) outs(%arg2: tensor<112x120x130x56xf32>) -> tensor<112x120x130x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x120x130x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x120x130x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 117123136
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x240x130x14xf32>, tensor<130x240x130x14xf32>) outs(%arg2: tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x240x130x14xf32>, tensor<130x240x130x14xf32>) outs(%arg2: tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x240x130x14xf32>, %arg1: tensor<130x240x130x14xf32>, %arg2: tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x240x130x14xf32>, tensor<130x240x130x14xf32>) outs(%arg2: tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32>\n  return %ret : tensor<130x240x130x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x240x130x14xf32>, %arg1: tensor<130x240x130x14xf32>, %arg2: tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x240x130x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x240x130x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x240x130x14xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x240x130x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x240x130x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x240x130x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x240x130x14xf32>\n    return %2 : tensor<130x240x130x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x240x130x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x240x130x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x240x130x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x240x130x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x240x130x14xf32>, tensor<130x240x130x14xf32>) outs(%arg2: tensor<130x240x130x14xf32>) -> tensor<130x240x130x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x240x130x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x240x130x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 69248129
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x56x240x120xf32>, tensor<28x56x240x120xf32>) outs(%arg2: tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x56x240x120xf32>, tensor<28x56x240x120xf32>) outs(%arg2: tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x56x240x120xf32>, %arg1: tensor<28x56x240x120xf32>, %arg2: tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x56x240x120xf32>, tensor<28x56x240x120xf32>) outs(%arg2: tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32>\n  return %ret : tensor<28x56x240x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x56x240x120xf32>, %arg1: tensor<28x56x240x120xf32>, %arg2: tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x56x240x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x56x240x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x56x240x120xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x56x240x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x56x240x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x56x240x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x56x240x120xf32>\n    return %2 : tensor<28x56x240x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x56x240x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x56x240x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x56x240x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x56x240x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x56x240x120xf32>, tensor<28x56x240x120xf32>) outs(%arg2: tensor<28x56x240x120xf32>) -> tensor<28x56x240x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x56x240x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x56x240x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 54233963
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x240x150x14xf32>, tensor<15x240x150x14xf32>) outs(%arg2: tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x240x150x14xf32>, tensor<15x240x150x14xf32>) outs(%arg2: tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x240x150x14xf32>, %arg1: tensor<15x240x150x14xf32>, %arg2: tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x240x150x14xf32>, tensor<15x240x150x14xf32>) outs(%arg2: tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32>\n  return %ret : tensor<15x240x150x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x240x150x14xf32>, %arg1: tensor<15x240x150x14xf32>, %arg2: tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x240x150x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x240x150x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x240x150x14xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x240x150x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x240x150x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x240x150x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x240x150x14xf32>\n    return %2 : tensor<15x240x150x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x240x150x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x240x150x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x240x150x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x240x150x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x240x150x14xf32>, tensor<15x240x150x14xf32>) outs(%arg2: tensor<15x240x150x14xf32>) -> tensor<15x240x150x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x240x150x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x240x150x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8699090
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x228x224x14xf32>, tensor<14x228x224x14xf32>) outs(%arg2: tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x228x224x14xf32>, tensor<14x228x224x14xf32>) outs(%arg2: tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x228x224x14xf32>, %arg1: tensor<14x228x224x14xf32>, %arg2: tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x228x224x14xf32>, tensor<14x228x224x14xf32>) outs(%arg2: tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32>\n  return %ret : tensor<14x228x224x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x228x224x14xf32>, %arg1: tensor<14x228x224x14xf32>, %arg2: tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x228x224x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x228x224x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x228x224x14xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x228x224x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x228x224x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x228x224x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x228x224x14xf32>\n    return %2 : tensor<14x228x224x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x228x224x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x228x224x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x228x224x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x228x224x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x228x224x14xf32>, tensor<14x228x224x14xf32>) outs(%arg2: tensor<14x228x224x14xf32>) -> tensor<14x228x224x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x228x224x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x228x224x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12345013
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x130x28x228xf32>, tensor<228x130x28x228xf32>) outs(%arg2: tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x130x28x228xf32>, tensor<228x130x28x228xf32>) outs(%arg2: tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x130x28x228xf32>, %arg1: tensor<228x130x28x228xf32>, %arg2: tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x130x28x228xf32>, tensor<228x130x28x228xf32>) outs(%arg2: tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32>\n  return %ret : tensor<228x130x28x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x130x28x228xf32>, %arg1: tensor<228x130x28x228xf32>, %arg2: tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x130x28x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x130x28x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x130x28x228xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x130x28x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x130x28x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x130x28x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x130x28x228xf32>\n    return %2 : tensor<228x130x28x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x130x28x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x130x28x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x130x28x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x130x28x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x130x28x228xf32>, tensor<228x130x28x228xf32>) outs(%arg2: tensor<228x130x28x228xf32>) -> tensor<228x130x28x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x130x28x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x130x28x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 225201220
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x28x14x240xf32>, tensor<228x28x14x240xf32>) outs(%arg2: tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x28x14x240xf32>, tensor<228x28x14x240xf32>) outs(%arg2: tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x28x14x240xf32>, %arg1: tensor<228x28x14x240xf32>, %arg2: tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x28x14x240xf32>, tensor<228x28x14x240xf32>) outs(%arg2: tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32>\n  return %ret : tensor<228x28x14x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x28x14x240xf32>, %arg1: tensor<228x28x14x240xf32>, %arg2: tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x28x14x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x28x14x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x28x14x240xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x28x14x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x28x14x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x28x14x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x28x14x240xf32>\n    return %2 : tensor<228x28x14x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x28x14x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x28x14x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x28x14x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x28x14x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x28x14x240xf32>, tensor<228x28x14x240xf32>) outs(%arg2: tensor<228x28x14x240xf32>) -> tensor<228x28x14x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x28x14x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x28x14x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25808165
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x56x228x15xf32>, tensor<130x56x228x15xf32>) outs(%arg2: tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x56x228x15xf32>, tensor<130x56x228x15xf32>) outs(%arg2: tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x56x228x15xf32>, %arg1: tensor<130x56x228x15xf32>, %arg2: tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x56x228x15xf32>, tensor<130x56x228x15xf32>) outs(%arg2: tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32>\n  return %ret : tensor<130x56x228x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x56x228x15xf32>, %arg1: tensor<130x56x228x15xf32>, %arg2: tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x56x228x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x56x228x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x56x228x15xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x56x228x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x56x228x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x56x228x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x56x228x15xf32>\n    return %2 : tensor<130x56x228x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x56x228x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x56x228x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x56x228x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x56x228x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x56x228x15xf32>, tensor<130x56x228x15xf32>) outs(%arg2: tensor<130x56x228x15xf32>) -> tensor<130x56x228x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x56x228x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x56x228x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 30621674
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x112x112x120xf32>, tensor<56x112x112x120xf32>) outs(%arg2: tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x112x112x120xf32>, tensor<56x112x112x120xf32>) outs(%arg2: tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x112x112x120xf32>, %arg1: tensor<56x112x112x120xf32>, %arg2: tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x112x112x120xf32>, tensor<56x112x112x120xf32>) outs(%arg2: tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32>\n  return %ret : tensor<56x112x112x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x112x112x120xf32>, %arg1: tensor<56x112x112x120xf32>, %arg2: tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x112x112x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x112x112x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x112x112x120xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x112x112x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x112x112x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x112x112x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x112x112x120xf32>\n    return %2 : tensor<56x112x112x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x112x112x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x112x112x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x112x112x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x112x112x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x112x112x120xf32>, tensor<56x112x112x120xf32>) outs(%arg2: tensor<56x112x112x120xf32>) -> tensor<56x112x112x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x112x112x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x112x112x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 100746421
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x56x120x14xf32>, tensor<7x56x120x14xf32>) outs(%arg2: tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x56x120x14xf32>, tensor<7x56x120x14xf32>) outs(%arg2: tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x56x120x14xf32>, %arg1: tensor<7x56x120x14xf32>, %arg2: tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x56x120x14xf32>, tensor<7x56x120x14xf32>) outs(%arg2: tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32>\n  return %ret : tensor<7x56x120x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x56x120x14xf32>, %arg1: tensor<7x56x120x14xf32>, %arg2: tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x56x120x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x56x120x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x56x120x14xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x56x120x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x56x120x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x56x120x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x56x120x14xf32>\n    return %2 : tensor<7x56x120x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x56x120x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x56x120x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x56x120x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x56x120x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x56x120x14xf32>, tensor<7x56x120x14xf32>) outs(%arg2: tensor<7x56x120x14xf32>) -> tensor<7x56x120x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x56x120x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x56x120x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 613349
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x240x150x14xf32>, tensor<130x240x150x14xf32>) outs(%arg2: tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x240x150x14xf32>, tensor<130x240x150x14xf32>) outs(%arg2: tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x240x150x14xf32>, %arg1: tensor<130x240x150x14xf32>, %arg2: tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x240x150x14xf32>, tensor<130x240x150x14xf32>) outs(%arg2: tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32>\n  return %ret : tensor<130x240x150x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x240x150x14xf32>, %arg1: tensor<130x240x150x14xf32>, %arg2: tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x240x150x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x240x150x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x240x150x14xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x240x150x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x240x150x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x240x150x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x240x150x14xf32>\n    return %2 : tensor<130x240x150x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x240x150x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x240x150x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x240x150x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x240x150x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x240x150x14xf32>, tensor<130x240x150x14xf32>) outs(%arg2: tensor<130x240x150x14xf32>) -> tensor<130x240x150x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x240x150x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x240x150x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 80145403
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x130x112x240xf32>, tensor<56x130x112x240xf32>) outs(%arg2: tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x130x112x240xf32>, tensor<56x130x112x240xf32>) outs(%arg2: tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x130x112x240xf32>, %arg1: tensor<56x130x112x240xf32>, %arg2: tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x130x112x240xf32>, tensor<56x130x112x240xf32>) outs(%arg2: tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32>\n  return %ret : tensor<56x130x112x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x130x112x240xf32>, %arg1: tensor<56x130x112x240xf32>, %arg2: tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x130x112x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x130x112x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x130x112x240xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x130x112x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x130x112x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x130x112x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x130x112x240xf32>\n    return %2 : tensor<56x130x112x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x130x112x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x130x112x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x130x112x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x130x112x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x130x112x240xf32>, tensor<56x130x112x240xf32>) outs(%arg2: tensor<56x130x112x240xf32>) -> tensor<56x130x112x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x130x112x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x130x112x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 235958698
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x15x56x228xf32>, tensor<7x15x56x228xf32>) outs(%arg2: tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x15x56x228xf32>, tensor<7x15x56x228xf32>) outs(%arg2: tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x15x56x228xf32>, %arg1: tensor<7x15x56x228xf32>, %arg2: tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x15x56x228xf32>, tensor<7x15x56x228xf32>) outs(%arg2: tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32>\n  return %ret : tensor<7x15x56x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x15x56x228xf32>, %arg1: tensor<7x15x56x228xf32>, %arg2: tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x15x56x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x15x56x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x15x56x228xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x15x56x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x15x56x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x15x56x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x15x56x228xf32>\n    return %2 : tensor<7x15x56x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x15x56x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x15x56x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x15x56x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x15x56x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x15x56x228xf32>, tensor<7x15x56x228xf32>) outs(%arg2: tensor<7x15x56x228xf32>) -> tensor<7x15x56x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x15x56x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x15x56x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1057996
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x56x56x15xf32>, tensor<150x56x56x15xf32>) outs(%arg2: tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x56x56x15xf32>, tensor<150x56x56x15xf32>) outs(%arg2: tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x56x56x15xf32>, %arg1: tensor<150x56x56x15xf32>, %arg2: tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x56x56x15xf32>, tensor<150x56x56x15xf32>) outs(%arg2: tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32>\n  return %ret : tensor<150x56x56x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x56x56x15xf32>, %arg1: tensor<150x56x56x15xf32>, %arg2: tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x56x56x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x56x56x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x56x56x15xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x56x56x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x56x56x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x56x56x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x56x56x15xf32>\n    return %2 : tensor<150x56x56x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x56x56x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x56x56x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x56x56x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x56x56x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x56x56x15xf32>, tensor<150x56x56x15xf32>) outs(%arg2: tensor<150x56x56x15xf32>) -> tensor<150x56x56x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x56x56x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x56x56x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7830058
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x240x14x14xf32>, tensor<240x240x14x14xf32>) outs(%arg2: tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x240x14x14xf32>, tensor<240x240x14x14xf32>) outs(%arg2: tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x240x14x14xf32>, %arg1: tensor<240x240x14x14xf32>, %arg2: tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x240x14x14xf32>, tensor<240x240x14x14xf32>) outs(%arg2: tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32>\n  return %ret : tensor<240x240x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x240x14x14xf32>, %arg1: tensor<240x240x14x14xf32>, %arg2: tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x240x14x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x240x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x240x14x14xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x240x14x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x240x14x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x240x14x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x240x14x14xf32>\n    return %2 : tensor<240x240x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x240x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x240x14x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x240x14x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x240x14x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x240x14x14xf32>, tensor<240x240x14x14xf32>) outs(%arg2: tensor<240x240x14x14xf32>) -> tensor<240x240x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x240x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x240x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14430628
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x7x7x56xf32>, tensor<224x7x7x56xf32>) outs(%arg2: tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x7x7x56xf32>, tensor<224x7x7x56xf32>) outs(%arg2: tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x7x7x56xf32>, %arg1: tensor<224x7x7x56xf32>, %arg2: tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x7x7x56xf32>, tensor<224x7x7x56xf32>) outs(%arg2: tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32>\n  return %ret : tensor<224x7x7x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x7x7x56xf32>, %arg1: tensor<224x7x7x56xf32>, %arg2: tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x7x7x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x7x7x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x7x7x56xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x7x7x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x7x7x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x7x7x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x7x7x56xf32>\n    return %2 : tensor<224x7x7x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x7x7x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x7x7x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x7x7x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x7x7x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x7x7x56xf32>, tensor<224x7x7x56xf32>) outs(%arg2: tensor<224x7x7x56xf32>) -> tensor<224x7x7x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x7x7x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x7x7x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 596348
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x150x240x15xf32>, tensor<56x150x240x15xf32>) outs(%arg2: tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x150x240x15xf32>, tensor<56x150x240x15xf32>) outs(%arg2: tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x150x240x15xf32>, %arg1: tensor<56x150x240x15xf32>, %arg2: tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x150x240x15xf32>, tensor<56x150x240x15xf32>) outs(%arg2: tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32>\n  return %ret : tensor<56x150x240x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x150x240x15xf32>, %arg1: tensor<56x150x240x15xf32>, %arg2: tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x150x240x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x150x240x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x150x240x15xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x150x240x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x150x240x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x150x240x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x150x240x15xf32>\n    return %2 : tensor<56x150x240x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x150x240x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x150x240x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x150x240x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x150x240x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x150x240x15xf32>, tensor<56x150x240x15xf32>) outs(%arg2: tensor<56x150x240x15xf32>) -> tensor<56x150x240x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x150x240x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x150x240x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 35821378
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x224x240x15xf32>, tensor<56x224x240x15xf32>) outs(%arg2: tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x224x240x15xf32>, tensor<56x224x240x15xf32>) outs(%arg2: tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x224x240x15xf32>, %arg1: tensor<56x224x240x15xf32>, %arg2: tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x224x240x15xf32>, tensor<56x224x240x15xf32>) outs(%arg2: tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32>\n  return %ret : tensor<56x224x240x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x224x240x15xf32>, %arg1: tensor<56x224x240x15xf32>, %arg2: tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x224x240x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x224x240x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x224x240x15xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x224x240x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x224x240x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x224x240x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x224x240x15xf32>\n    return %2 : tensor<56x224x240x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x224x240x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x224x240x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x224x240x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x224x240x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x224x240x15xf32>, tensor<56x224x240x15xf32>) outs(%arg2: tensor<56x224x240x15xf32>) -> tensor<56x224x240x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x224x240x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x224x240x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 54211405
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x224x28x150xf32>, tensor<120x224x28x150xf32>) outs(%arg2: tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x224x28x150xf32>, tensor<120x224x28x150xf32>) outs(%arg2: tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x224x28x150xf32>, %arg1: tensor<120x224x28x150xf32>, %arg2: tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x224x28x150xf32>, tensor<120x224x28x150xf32>) outs(%arg2: tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32>\n  return %ret : tensor<120x224x28x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x224x28x150xf32>, %arg1: tensor<120x224x28x150xf32>, %arg2: tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x224x28x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x224x28x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x224x28x150xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x224x28x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x224x28x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x224x28x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x224x28x150xf32>\n    return %2 : tensor<120x224x28x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x224x28x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x224x28x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x224x28x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x224x28x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x224x28x150xf32>, tensor<120x224x28x150xf32>) outs(%arg2: tensor<120x224x28x150xf32>) -> tensor<120x224x28x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x224x28x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x224x28x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 137056722
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x112x56x150xf32>, tensor<224x112x56x150xf32>) outs(%arg2: tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x112x56x150xf32>, tensor<224x112x56x150xf32>) outs(%arg2: tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x112x56x150xf32>, %arg1: tensor<224x112x56x150xf32>, %arg2: tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x112x56x150xf32>, tensor<224x112x56x150xf32>) outs(%arg2: tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32>\n  return %ret : tensor<224x112x56x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x112x56x150xf32>, %arg1: tensor<224x112x56x150xf32>, %arg2: tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x112x56x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x112x56x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x112x56x150xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x112x56x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x112x56x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x112x56x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x112x56x150xf32>\n    return %2 : tensor<224x112x56x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x112x56x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x112x56x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x112x56x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x112x56x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x112x56x150xf32>, tensor<224x112x56x150xf32>) outs(%arg2: tensor<224x112x56x150xf32>) -> tensor<224x112x56x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x112x56x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x112x56x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 251874543
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x112x15x240xf32>, tensor<112x112x15x240xf32>) outs(%arg2: tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x112x15x240xf32>, tensor<112x112x15x240xf32>) outs(%arg2: tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x112x15x240xf32>, %arg1: tensor<112x112x15x240xf32>, %arg2: tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x112x15x240xf32>, tensor<112x112x15x240xf32>) outs(%arg2: tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32>\n  return %ret : tensor<112x112x15x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x112x15x240xf32>, %arg1: tensor<112x112x15x240xf32>, %arg2: tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x112x15x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x112x15x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x112x15x240xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x112x15x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x112x15x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x112x15x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x112x15x240xf32>\n    return %2 : tensor<112x112x15x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x112x15x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x112x15x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x112x15x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x112x15x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x112x15x240xf32>, tensor<112x112x15x240xf32>) outs(%arg2: tensor<112x112x15x240xf32>) -> tensor<112x112x15x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x112x15x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x112x15x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 54677429
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x15x130x228xf32>, tensor<28x15x130x228xf32>) outs(%arg2: tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x15x130x228xf32>, tensor<28x15x130x228xf32>) outs(%arg2: tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x15x130x228xf32>, %arg1: tensor<28x15x130x228xf32>, %arg2: tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x15x130x228xf32>, tensor<28x15x130x228xf32>) outs(%arg2: tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32>\n  return %ret : tensor<28x15x130x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x15x130x228xf32>, %arg1: tensor<28x15x130x228xf32>, %arg2: tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x15x130x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x15x130x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x15x130x228xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x15x130x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x15x130x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x15x130x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x15x130x228xf32>\n    return %2 : tensor<28x15x130x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x15x130x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x15x130x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x15x130x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x15x130x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x15x130x228xf32>, tensor<28x15x130x228xf32>) outs(%arg2: tensor<28x15x130x228xf32>) -> tensor<28x15x130x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x15x130x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x15x130x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 15400916
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x228x7x15xf32>, tensor<240x228x7x15xf32>) outs(%arg2: tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x228x7x15xf32>, tensor<240x228x7x15xf32>) outs(%arg2: tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x228x7x15xf32>, %arg1: tensor<240x228x7x15xf32>, %arg2: tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x228x7x15xf32>, tensor<240x228x7x15xf32>) outs(%arg2: tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32>\n  return %ret : tensor<240x228x7x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x228x7x15xf32>, %arg1: tensor<240x228x7x15xf32>, %arg2: tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x228x7x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x228x7x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x228x7x15xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x228x7x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x228x7x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x228x7x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x228x7x15xf32>\n    return %2 : tensor<240x228x7x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x228x7x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x228x7x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x228x7x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x228x7x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x228x7x15xf32>, tensor<240x228x7x15xf32>) outs(%arg2: tensor<240x228x7x15xf32>) -> tensor<240x228x7x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x228x7x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x228x7x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6503936
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x112x14x228xf32>, tensor<228x112x14x228xf32>) outs(%arg2: tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x112x14x228xf32>, tensor<228x112x14x228xf32>) outs(%arg2: tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x112x14x228xf32>, %arg1: tensor<228x112x14x228xf32>, %arg2: tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x112x14x228xf32>, tensor<228x112x14x228xf32>) outs(%arg2: tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32>\n  return %ret : tensor<228x112x14x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x112x14x228xf32>, %arg1: tensor<228x112x14x228xf32>, %arg2: tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x112x14x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x112x14x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x112x14x228xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x112x14x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x112x14x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x112x14x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x112x14x228xf32>\n    return %2 : tensor<228x112x14x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x112x14x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x112x14x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x112x14x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x112x14x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x112x14x228xf32>, tensor<228x112x14x228xf32>) outs(%arg2: tensor<228x112x14x228xf32>) -> tensor<228x112x14x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x112x14x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x112x14x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 97955389
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x120x240x120xf32>, tensor<14x120x240x120xf32>) outs(%arg2: tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x120x240x120xf32>, tensor<14x120x240x120xf32>) outs(%arg2: tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x120x240x120xf32>, %arg1: tensor<14x120x240x120xf32>, %arg2: tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x120x240x120xf32>, tensor<14x120x240x120xf32>) outs(%arg2: tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32>\n  return %ret : tensor<14x120x240x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x120x240x120xf32>, %arg1: tensor<14x120x240x120xf32>, %arg2: tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x120x240x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x120x240x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x120x240x120xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x120x240x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x120x240x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x120x240x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x120x240x120xf32>\n    return %2 : tensor<14x120x240x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x120x240x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x120x240x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x120x240x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x120x240x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x120x240x120xf32>, tensor<14x120x240x120xf32>) outs(%arg2: tensor<14x120x240x120xf32>) -> tensor<14x120x240x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x120x240x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x120x240x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 58048558
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x14x15x150xf32>, tensor<15x14x15x150xf32>) outs(%arg2: tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x14x15x150xf32>, tensor<15x14x15x150xf32>) outs(%arg2: tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x14x15x150xf32>, %arg1: tensor<15x14x15x150xf32>, %arg2: tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x14x15x150xf32>, tensor<15x14x15x150xf32>) outs(%arg2: tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32>\n  return %ret : tensor<15x14x15x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x14x15x150xf32>, %arg1: tensor<15x14x15x150xf32>, %arg2: tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x14x15x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x14x15x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x14x15x150xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x14x15x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x14x15x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x14x15x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x14x15x150xf32>\n    return %2 : tensor<15x14x15x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x14x15x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x14x15x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x14x15x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x14x15x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x14x15x150xf32>, tensor<15x14x15x150xf32>) outs(%arg2: tensor<15x14x15x150xf32>) -> tensor<15x14x15x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x14x15x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x14x15x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 387390
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x15x120x112xf32>, tensor<228x15x120x112xf32>) outs(%arg2: tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x15x120x112xf32>, tensor<228x15x120x112xf32>) outs(%arg2: tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x15x120x112xf32>, %arg1: tensor<228x15x120x112xf32>, %arg2: tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x15x120x112xf32>, tensor<228x15x120x112xf32>) outs(%arg2: tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32>\n  return %ret : tensor<228x15x120x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x15x120x112xf32>, %arg1: tensor<228x15x120x112xf32>, %arg2: tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x15x120x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x15x120x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x15x120x112xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x15x120x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x15x120x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x15x120x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x15x120x112xf32>\n    return %2 : tensor<228x15x120x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x15x120x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x15x120x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x15x120x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x15x120x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x15x120x112xf32>, tensor<228x15x120x112xf32>) outs(%arg2: tensor<228x15x120x112xf32>) -> tensor<228x15x120x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x15x120x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x15x120x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 56750911
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x15x130x228xf32>, tensor<130x15x130x228xf32>) outs(%arg2: tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x15x130x228xf32>, tensor<130x15x130x228xf32>) outs(%arg2: tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x15x130x228xf32>, %arg1: tensor<130x15x130x228xf32>, %arg2: tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x15x130x228xf32>, tensor<130x15x130x228xf32>) outs(%arg2: tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32>\n  return %ret : tensor<130x15x130x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x15x130x228xf32>, %arg1: tensor<130x15x130x228xf32>, %arg2: tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x15x130x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x15x130x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x15x130x228xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x15x130x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x15x130x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x15x130x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x15x130x228xf32>\n    return %2 : tensor<130x15x130x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x15x130x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x15x130x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x15x130x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x15x130x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x15x130x228xf32>, tensor<130x15x130x228xf32>) outs(%arg2: tensor<130x15x130x228xf32>) -> tensor<130x15x130x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x15x130x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x15x130x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 68789015
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x240x15x14xf32>, tensor<28x240x15x14xf32>) outs(%arg2: tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x240x15x14xf32>, tensor<28x240x15x14xf32>) outs(%arg2: tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x240x15x14xf32>, %arg1: tensor<28x240x15x14xf32>, %arg2: tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x240x15x14xf32>, tensor<28x240x15x14xf32>) outs(%arg2: tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32>\n  return %ret : tensor<28x240x15x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x240x15x14xf32>, %arg1: tensor<28x240x15x14xf32>, %arg2: tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x240x15x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x240x15x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x240x15x14xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x240x15x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x240x15x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x240x15x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x240x15x14xf32>\n    return %2 : tensor<28x240x15x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x240x15x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x240x15x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x240x15x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x240x15x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x240x15x14xf32>, tensor<28x240x15x14xf32>) outs(%arg2: tensor<28x240x15x14xf32>) -> tensor<28x240x15x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x240x15x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x240x15x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1370289
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x56x240x224xf32>, tensor<14x56x240x224xf32>) outs(%arg2: tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x56x240x224xf32>, tensor<14x56x240x224xf32>) outs(%arg2: tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x56x240x224xf32>, %arg1: tensor<14x56x240x224xf32>, %arg2: tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x56x240x224xf32>, tensor<14x56x240x224xf32>) outs(%arg2: tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32>\n  return %ret : tensor<14x56x240x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x56x240x224xf32>, %arg1: tensor<14x56x240x224xf32>, %arg2: tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x56x240x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x56x240x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x56x240x224xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x56x240x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x56x240x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x56x240x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x56x240x224xf32>\n    return %2 : tensor<14x56x240x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x56x240x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x56x240x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x56x240x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x56x240x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x56x240x224xf32>, tensor<14x56x240x224xf32>) outs(%arg2: tensor<14x56x240x224xf32>) -> tensor<14x56x240x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x56x240x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x56x240x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 51224349
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x130x28x120xf32>, tensor<130x130x28x120xf32>) outs(%arg2: tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x130x28x120xf32>, tensor<130x130x28x120xf32>) outs(%arg2: tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x130x28x120xf32>, %arg1: tensor<130x130x28x120xf32>, %arg2: tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x130x28x120xf32>, tensor<130x130x28x120xf32>) outs(%arg2: tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32>\n  return %ret : tensor<130x130x28x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x130x28x120xf32>, %arg1: tensor<130x130x28x120xf32>, %arg2: tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x130x28x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x130x28x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x130x28x120xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x130x28x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x130x28x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x130x28x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x130x28x120xf32>\n    return %2 : tensor<130x130x28x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x130x28x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x130x28x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x130x28x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x130x28x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x130x28x120xf32>, tensor<130x130x28x120xf32>) outs(%arg2: tensor<130x130x28x120xf32>) -> tensor<130x130x28x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x130x28x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x130x28x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 68954020
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x150x14x150xf32>, tensor<150x150x14x150xf32>) outs(%arg2: tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x150x14x150xf32>, tensor<150x150x14x150xf32>) outs(%arg2: tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x150x14x150xf32>, %arg1: tensor<150x150x14x150xf32>, %arg2: tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x150x14x150xf32>, tensor<150x150x14x150xf32>) outs(%arg2: tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32>\n  return %ret : tensor<150x150x14x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x150x14x150xf32>, %arg1: tensor<150x150x14x150xf32>, %arg2: tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x150x14x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x150x14x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x150x14x150xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x150x14x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x150x14x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x150x14x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x150x14x150xf32>\n    return %2 : tensor<150x150x14x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x150x14x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x150x14x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x150x14x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x150x14x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x150x14x150xf32>, tensor<150x150x14x150xf32>) outs(%arg2: tensor<150x150x14x150xf32>) -> tensor<150x150x14x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x150x14x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x150x14x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 56754889
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x240x28x150xf32>, tensor<28x240x28x150xf32>) outs(%arg2: tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x240x28x150xf32>, tensor<28x240x28x150xf32>) outs(%arg2: tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x240x28x150xf32>, %arg1: tensor<28x240x28x150xf32>, %arg2: tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x240x28x150xf32>, tensor<28x240x28x150xf32>) outs(%arg2: tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32>\n  return %ret : tensor<28x240x28x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x240x28x150xf32>, %arg1: tensor<28x240x28x150xf32>, %arg2: tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x240x28x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x240x28x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x240x28x150xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x240x28x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x240x28x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x240x28x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x240x28x150xf32>\n    return %2 : tensor<28x240x28x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x240x28x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x240x28x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x240x28x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x240x28x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x240x28x150xf32>, tensor<28x240x28x150xf32>) outs(%arg2: tensor<28x240x28x150xf32>) -> tensor<28x240x28x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x240x28x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x240x28x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 34664294
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x14x7x28xf32>, tensor<130x14x7x28xf32>) outs(%arg2: tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x14x7x28xf32>, tensor<130x14x7x28xf32>) outs(%arg2: tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x14x7x28xf32>, %arg1: tensor<130x14x7x28xf32>, %arg2: tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x14x7x28xf32>, tensor<130x14x7x28xf32>) outs(%arg2: tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32>\n  return %ret : tensor<130x14x7x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x14x7x28xf32>, %arg1: tensor<130x14x7x28xf32>, %arg2: tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x14x7x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x14x7x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x14x7x28xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x14x7x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x14x7x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x14x7x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x14x7x28xf32>\n    return %2 : tensor<130x14x7x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x14x7x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x14x7x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x14x7x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x14x7x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x14x7x28xf32>, tensor<130x14x7x28xf32>) outs(%arg2: tensor<130x14x7x28xf32>) -> tensor<130x14x7x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x14x7x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x14x7x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 335915
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x120x56x28xf32>, tensor<112x120x56x28xf32>) outs(%arg2: tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x120x56x28xf32>, tensor<112x120x56x28xf32>) outs(%arg2: tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x120x56x28xf32>, %arg1: tensor<112x120x56x28xf32>, %arg2: tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x120x56x28xf32>, tensor<112x120x56x28xf32>) outs(%arg2: tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32>\n  return %ret : tensor<112x120x56x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x120x56x28xf32>, %arg1: tensor<112x120x56x28xf32>, %arg2: tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x120x56x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x120x56x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x120x56x28xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x120x56x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x120x56x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x120x56x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x120x56x28xf32>\n    return %2 : tensor<112x120x56x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x120x56x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x120x56x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x120x56x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x120x56x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x120x56x28xf32>, tensor<112x120x56x28xf32>) outs(%arg2: tensor<112x120x56x28xf32>) -> tensor<112x120x56x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x120x56x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x120x56x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25957680
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x14x240x150xf32>, tensor<15x14x240x150xf32>) outs(%arg2: tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x14x240x150xf32>, tensor<15x14x240x150xf32>) outs(%arg2: tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x14x240x150xf32>, %arg1: tensor<15x14x240x150xf32>, %arg2: tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x14x240x150xf32>, tensor<15x14x240x150xf32>) outs(%arg2: tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32>\n  return %ret : tensor<15x14x240x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x14x240x150xf32>, %arg1: tensor<15x14x240x150xf32>, %arg2: tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x14x240x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x14x240x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x14x240x150xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x14x240x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x14x240x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x14x240x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x14x240x150xf32>\n    return %2 : tensor<15x14x240x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x14x240x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x14x240x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x14x240x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x14x240x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x14x240x150xf32>, tensor<15x14x240x150xf32>) outs(%arg2: tensor<15x14x240x150xf32>) -> tensor<15x14x240x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x14x240x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x14x240x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8543329
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x130x56x228xf32>, tensor<150x130x56x228xf32>) outs(%arg2: tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x130x56x228xf32>, tensor<150x130x56x228xf32>) outs(%arg2: tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x130x56x228xf32>, %arg1: tensor<150x130x56x228xf32>, %arg2: tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x130x56x228xf32>, tensor<150x130x56x228xf32>) outs(%arg2: tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32>\n  return %ret : tensor<150x130x56x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x130x56x228xf32>, %arg1: tensor<150x130x56x228xf32>, %arg2: tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x130x56x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x130x56x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x130x56x228xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x130x56x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x130x56x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x130x56x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x130x56x228xf32>\n    return %2 : tensor<150x130x56x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x130x56x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x130x56x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x130x56x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x130x56x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x130x56x228xf32>, tensor<150x130x56x228xf32>) outs(%arg2: tensor<150x130x56x228xf32>) -> tensor<150x130x56x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x130x56x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x130x56x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 297619864
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x130x130x224xf32>, tensor<7x130x130x224xf32>) outs(%arg2: tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x130x130x224xf32>, tensor<7x130x130x224xf32>) outs(%arg2: tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x130x130x224xf32>, %arg1: tensor<7x130x130x224xf32>, %arg2: tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x130x130x224xf32>, tensor<7x130x130x224xf32>) outs(%arg2: tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32>\n  return %ret : tensor<7x130x130x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x130x130x224xf32>, %arg1: tensor<7x130x130x224xf32>, %arg2: tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x130x130x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x130x130x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x130x130x224xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x130x130x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x130x130x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x130x130x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x130x130x224xf32>\n    return %2 : tensor<7x130x130x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x130x130x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x130x130x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x130x130x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x130x130x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x130x130x224xf32>, tensor<7x130x130x224xf32>) outs(%arg2: tensor<7x130x130x224xf32>) -> tensor<7x130x130x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x130x130x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x130x130x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 32157432
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x15x224x150xf32>, tensor<120x15x224x150xf32>) outs(%arg2: tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x15x224x150xf32>, tensor<120x15x224x150xf32>) outs(%arg2: tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x15x224x150xf32>, %arg1: tensor<120x15x224x150xf32>, %arg2: tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x15x224x150xf32>, tensor<120x15x224x150xf32>) outs(%arg2: tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32>\n  return %ret : tensor<120x15x224x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x15x224x150xf32>, %arg1: tensor<120x15x224x150xf32>, %arg2: tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x15x224x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x15x224x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x15x224x150xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x15x224x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x15x224x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x15x224x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x15x224x150xf32>\n    return %2 : tensor<120x15x224x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x15x224x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x15x224x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x15x224x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x15x224x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x15x224x150xf32>, tensor<120x15x224x150xf32>) outs(%arg2: tensor<120x15x224x150xf32>) -> tensor<120x15x224x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x15x224x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x15x224x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 73507484
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x7x228x14xf32>, tensor<112x7x228x14xf32>) outs(%arg2: tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x7x228x14xf32>, tensor<112x7x228x14xf32>) outs(%arg2: tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x7x228x14xf32>, %arg1: tensor<112x7x228x14xf32>, %arg2: tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x7x228x14xf32>, tensor<112x7x228x14xf32>) outs(%arg2: tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32>\n  return %ret : tensor<112x7x228x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x7x228x14xf32>, %arg1: tensor<112x7x228x14xf32>, %arg2: tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x7x228x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x7x228x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x7x228x14xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x7x228x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x7x228x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x7x228x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x7x228x14xf32>\n    return %2 : tensor<112x7x228x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x7x228x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x7x228x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x7x228x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x7x228x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x7x228x14xf32>, tensor<112x7x228x14xf32>) outs(%arg2: tensor<112x7x228x14xf32>) -> tensor<112x7x228x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x7x228x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x7x228x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1887409
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x228x130x28xf32>, tensor<14x228x130x28xf32>) outs(%arg2: tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x228x130x28xf32>, tensor<14x228x130x28xf32>) outs(%arg2: tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x228x130x28xf32>, %arg1: tensor<14x228x130x28xf32>, %arg2: tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x228x130x28xf32>, tensor<14x228x130x28xf32>) outs(%arg2: tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32>\n  return %ret : tensor<14x228x130x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x228x130x28xf32>, %arg1: tensor<14x228x130x28xf32>, %arg2: tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x228x130x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x228x130x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x228x130x28xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x228x130x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x228x130x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x228x130x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x228x130x28xf32>\n    return %2 : tensor<14x228x130x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x228x130x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x228x130x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x228x130x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x228x130x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x228x130x28xf32>, tensor<14x228x130x28xf32>) outs(%arg2: tensor<14x228x130x28xf32>) -> tensor<14x228x130x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x228x130x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x228x130x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14253989
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x228x224x7xf32>, tensor<224x228x224x7xf32>) outs(%arg2: tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x228x224x7xf32>, tensor<224x228x224x7xf32>) outs(%arg2: tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x228x224x7xf32>, %arg1: tensor<224x228x224x7xf32>, %arg2: tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x228x224x7xf32>, tensor<224x228x224x7xf32>) outs(%arg2: tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32>\n  return %ret : tensor<224x228x224x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x228x224x7xf32>, %arg1: tensor<224x228x224x7xf32>, %arg2: tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x228x224x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x228x224x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x228x224x7xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x228x224x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x228x224x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x228x224x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x228x224x7xf32>\n    return %2 : tensor<224x228x224x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x228x224x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x228x224x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x228x224x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x228x224x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x228x224x7xf32>, tensor<224x228x224x7xf32>) outs(%arg2: tensor<224x228x224x7xf32>) -> tensor<224x228x224x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x228x224x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x228x224x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 100484257
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x224x14x240xf32>, tensor<7x224x14x240xf32>) outs(%arg2: tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x224x14x240xf32>, tensor<7x224x14x240xf32>) outs(%arg2: tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x224x14x240xf32>, %arg1: tensor<7x224x14x240xf32>, %arg2: tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x224x14x240xf32>, tensor<7x224x14x240xf32>) outs(%arg2: tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32>\n  return %ret : tensor<7x224x14x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x224x14x240xf32>, %arg1: tensor<7x224x14x240xf32>, %arg2: tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x224x14x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x224x14x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x224x14x240xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x224x14x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x224x14x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x224x14x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x224x14x240xf32>\n    return %2 : tensor<7x224x14x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x224x14x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x224x14x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x224x14x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x224x14x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x224x14x240xf32>, tensor<7x224x14x240xf32>) outs(%arg2: tensor<7x224x14x240xf32>) -> tensor<7x224x14x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x224x14x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x224x14x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5991655
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x15x150x28xf32>, tensor<28x15x150x28xf32>) outs(%arg2: tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x15x150x28xf32>, tensor<28x15x150x28xf32>) outs(%arg2: tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x15x150x28xf32>, %arg1: tensor<28x15x150x28xf32>, %arg2: tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x15x150x28xf32>, tensor<28x15x150x28xf32>) outs(%arg2: tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32>\n  return %ret : tensor<28x15x150x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x15x150x28xf32>, %arg1: tensor<28x15x150x28xf32>, %arg2: tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x15x150x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x15x150x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x15x150x28xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x15x150x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x15x150x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x15x150x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x15x150x28xf32>\n    return %2 : tensor<28x15x150x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x15x150x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x15x150x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x15x150x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x15x150x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x15x150x28xf32>, tensor<28x15x150x28xf32>) outs(%arg2: tensor<28x15x150x28xf32>) -> tensor<28x15x150x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x15x150x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x15x150x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1206027
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x240x112x14xf32>, tensor<224x240x112x14xf32>) outs(%arg2: tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x240x112x14xf32>, tensor<224x240x112x14xf32>) outs(%arg2: tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x240x112x14xf32>, %arg1: tensor<224x240x112x14xf32>, %arg2: tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x240x112x14xf32>, tensor<224x240x112x14xf32>) outs(%arg2: tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32>\n  return %ret : tensor<224x240x112x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x240x112x14xf32>, %arg1: tensor<224x240x112x14xf32>, %arg2: tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x240x112x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x240x112x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x240x112x14xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x240x112x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x240x112x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x240x112x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x240x112x14xf32>\n    return %2 : tensor<224x240x112x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x240x112x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x240x112x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x240x112x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x240x112x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x240x112x14xf32>, tensor<224x240x112x14xf32>) outs(%arg2: tensor<224x240x112x14xf32>) -> tensor<224x240x112x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x240x112x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x240x112x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 102757568
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x228x56x224xf32>, tensor<7x228x56x224xf32>) outs(%arg2: tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x228x56x224xf32>, tensor<7x228x56x224xf32>) outs(%arg2: tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x228x56x224xf32>, %arg1: tensor<7x228x56x224xf32>, %arg2: tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x228x56x224xf32>, tensor<7x228x56x224xf32>) outs(%arg2: tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32>\n  return %ret : tensor<7x228x56x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x228x56x224xf32>, %arg1: tensor<7x228x56x224xf32>, %arg2: tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x228x56x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x228x56x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x228x56x224xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x228x56x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x228x56x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x228x56x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x228x56x224xf32>\n    return %2 : tensor<7x228x56x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x228x56x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x228x56x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x228x56x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x228x56x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x228x56x224xf32>, tensor<7x228x56x224xf32>) outs(%arg2: tensor<7x228x56x224xf32>) -> tensor<7x228x56x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x228x56x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x228x56x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25054555
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x15x14x224xf32>, tensor<112x15x14x224xf32>) outs(%arg2: tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x15x14x224xf32>, tensor<112x15x14x224xf32>) outs(%arg2: tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x15x14x224xf32>, %arg1: tensor<112x15x14x224xf32>, %arg2: tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x15x14x224xf32>, tensor<112x15x14x224xf32>) outs(%arg2: tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32>\n  return %ret : tensor<112x15x14x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x15x14x224xf32>, %arg1: tensor<112x15x14x224xf32>, %arg2: tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x15x14x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x15x14x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x15x14x224xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x15x14x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x15x14x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x15x14x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x15x14x224xf32>\n    return %2 : tensor<112x15x14x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x15x14x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x15x14x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x15x14x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x15x14x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x15x14x224xf32>, tensor<112x15x14x224xf32>) outs(%arg2: tensor<112x15x14x224xf32>) -> tensor<112x15x14x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x15x14x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x15x14x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5989690
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x120x112x7xf32>, tensor<112x120x112x7xf32>) outs(%arg2: tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x120x112x7xf32>, tensor<112x120x112x7xf32>) outs(%arg2: tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x120x112x7xf32>, %arg1: tensor<112x120x112x7xf32>, %arg2: tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x120x112x7xf32>, tensor<112x120x112x7xf32>) outs(%arg2: tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32>\n  return %ret : tensor<112x120x112x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x120x112x7xf32>, %arg1: tensor<112x120x112x7xf32>, %arg2: tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x120x112x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x120x112x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x120x112x7xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x120x112x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x120x112x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x120x112x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x120x112x7xf32>\n    return %2 : tensor<112x120x112x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x120x112x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x120x112x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x120x112x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x120x112x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x120x112x7xf32>, tensor<112x120x112x7xf32>) outs(%arg2: tensor<112x120x112x7xf32>) -> tensor<112x120x112x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x120x112x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x120x112x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13597769
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x228x15x224xf32>, tensor<130x228x15x224xf32>) outs(%arg2: tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x228x15x224xf32>, tensor<130x228x15x224xf32>) outs(%arg2: tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x228x15x224xf32>, %arg1: tensor<130x228x15x224xf32>, %arg2: tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x228x15x224xf32>, tensor<130x228x15x224xf32>) outs(%arg2: tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32>\n  return %ret : tensor<130x228x15x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x228x15x224xf32>, %arg1: tensor<130x228x15x224xf32>, %arg2: tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x228x15x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x228x15x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x228x15x224xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x228x15x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x228x15x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x228x15x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x228x15x224xf32>\n    return %2 : tensor<130x228x15x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x228x15x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x228x15x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x228x15x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x228x15x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x228x15x224xf32>, tensor<130x228x15x224xf32>) outs(%arg2: tensor<130x228x15x224xf32>) -> tensor<130x228x15x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x228x15x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x228x15x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 118201635
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x56x228x120xf32>, tensor<7x56x228x120xf32>) outs(%arg2: tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x56x228x120xf32>, tensor<7x56x228x120xf32>) outs(%arg2: tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x56x228x120xf32>, %arg1: tensor<7x56x228x120xf32>, %arg2: tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x56x228x120xf32>, tensor<7x56x228x120xf32>) outs(%arg2: tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32>\n  return %ret : tensor<7x56x228x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x56x228x120xf32>, %arg1: tensor<7x56x228x120xf32>, %arg2: tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x56x228x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x56x228x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x56x228x120xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x56x228x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x56x228x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x56x228x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x56x228x120xf32>\n    return %2 : tensor<7x56x228x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x56x228x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x56x228x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x56x228x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x56x228x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x56x228x120xf32>, tensor<7x56x228x120xf32>) outs(%arg2: tensor<7x56x228x120xf32>) -> tensor<7x56x228x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x56x228x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x56x228x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12961339
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x7x56x14xf32>, tensor<112x7x56x14xf32>) outs(%arg2: tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x7x56x14xf32>, tensor<112x7x56x14xf32>) outs(%arg2: tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x7x56x14xf32>, %arg1: tensor<112x7x56x14xf32>, %arg2: tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x7x56x14xf32>, tensor<112x7x56x14xf32>) outs(%arg2: tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32>\n  return %ret : tensor<112x7x56x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x7x56x14xf32>, %arg1: tensor<112x7x56x14xf32>, %arg2: tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x7x56x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x7x56x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x7x56x14xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x7x56x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x7x56x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x7x56x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x7x56x14xf32>\n    return %2 : tensor<112x7x56x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x7x56x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x7x56x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x7x56x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x7x56x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x7x56x14xf32>, tensor<112x7x56x14xf32>) outs(%arg2: tensor<112x7x56x14xf32>) -> tensor<112x7x56x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x7x56x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x7x56x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 582756
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x7x224x130xf32>, tensor<228x7x224x130xf32>) outs(%arg2: tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x7x224x130xf32>, tensor<228x7x224x130xf32>) outs(%arg2: tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x7x224x130xf32>, %arg1: tensor<228x7x224x130xf32>, %arg2: tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x7x224x130xf32>, tensor<228x7x224x130xf32>) outs(%arg2: tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32>\n  return %ret : tensor<228x7x224x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x7x224x130xf32>, %arg1: tensor<228x7x224x130xf32>, %arg2: tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x7x224x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x7x224x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x7x224x130xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x7x224x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x7x224x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x7x224x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x7x224x130xf32>\n    return %2 : tensor<228x7x224x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x7x224x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x7x224x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x7x224x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x7x224x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x7x224x130xf32>, tensor<228x7x224x130xf32>) outs(%arg2: tensor<228x7x224x130xf32>) -> tensor<228x7x224x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x7x224x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x7x224x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 55723900
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x112x14x7xf32>, tensor<228x112x14x7xf32>) outs(%arg2: tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x112x14x7xf32>, tensor<228x112x14x7xf32>) outs(%arg2: tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x112x14x7xf32>, %arg1: tensor<228x112x14x7xf32>, %arg2: tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x112x14x7xf32>, tensor<228x112x14x7xf32>) outs(%arg2: tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32>\n  return %ret : tensor<228x112x14x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x112x14x7xf32>, %arg1: tensor<228x112x14x7xf32>, %arg2: tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x112x14x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x112x14x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x112x14x7xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x112x14x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x112x14x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x112x14x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x112x14x7xf32>\n    return %2 : tensor<228x112x14x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x112x14x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x112x14x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x112x14x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x112x14x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x112x14x7xf32>, tensor<228x112x14x7xf32>) outs(%arg2: tensor<228x112x14x7xf32>) -> tensor<228x112x14x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x112x14x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x112x14x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2645785
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x240x120x56xf32>, tensor<56x240x120x56xf32>) outs(%arg2: tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x240x120x56xf32>, tensor<56x240x120x56xf32>) outs(%arg2: tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x240x120x56xf32>, %arg1: tensor<56x240x120x56xf32>, %arg2: tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x240x120x56xf32>, tensor<56x240x120x56xf32>) outs(%arg2: tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32>\n  return %ret : tensor<56x240x120x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x240x120x56xf32>, %arg1: tensor<56x240x120x56xf32>, %arg2: tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x240x120x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x240x120x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x240x120x56xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x240x120x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x240x120x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x240x120x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x240x120x56xf32>\n    return %2 : tensor<56x240x120x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x240x120x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x240x120x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x240x120x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x240x120x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x240x120x56xf32>, tensor<56x240x120x56xf32>) outs(%arg2: tensor<56x240x120x56xf32>) -> tensor<56x240x120x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x240x120x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x240x120x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 106773145
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x28x130x14xf32>, tensor<150x28x130x14xf32>) outs(%arg2: tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x28x130x14xf32>, tensor<150x28x130x14xf32>) outs(%arg2: tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x28x130x14xf32>, %arg1: tensor<150x28x130x14xf32>, %arg2: tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x28x130x14xf32>, tensor<150x28x130x14xf32>) outs(%arg2: tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32>\n  return %ret : tensor<150x28x130x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x28x130x14xf32>, %arg1: tensor<150x28x130x14xf32>, %arg2: tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x28x130x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x28x130x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x28x130x14xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x28x130x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x28x130x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x28x130x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x28x130x14xf32>\n    return %2 : tensor<150x28x130x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x28x130x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x28x130x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x28x130x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x28x130x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x28x130x14xf32>, tensor<150x28x130x14xf32>) outs(%arg2: tensor<150x28x130x14xf32>) -> tensor<150x28x130x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x28x130x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x28x130x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8748309
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x15x120x56xf32>, tensor<130x15x120x56xf32>) outs(%arg2: tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x15x120x56xf32>, tensor<130x15x120x56xf32>) outs(%arg2: tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x15x120x56xf32>, %arg1: tensor<130x15x120x56xf32>, %arg2: tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x15x120x56xf32>, tensor<130x15x120x56xf32>) outs(%arg2: tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32>\n  return %ret : tensor<130x15x120x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x15x120x56xf32>, %arg1: tensor<130x15x120x56xf32>, %arg2: tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x15x120x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x15x120x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x15x120x56xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x15x120x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x15x120x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x15x120x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x15x120x56xf32>\n    return %2 : tensor<130x15x120x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x15x120x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x15x120x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x15x120x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x15x120x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x15x120x56xf32>, tensor<130x15x120x56xf32>) outs(%arg2: tensor<130x15x120x56xf32>) -> tensor<130x15x120x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x15x120x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x15x120x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 16957877
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x15x7x28xf32>, tensor<28x15x7x28xf32>) outs(%arg2: tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x15x7x28xf32>, tensor<28x15x7x28xf32>) outs(%arg2: tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x15x7x28xf32>, %arg1: tensor<28x15x7x28xf32>, %arg2: tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x15x7x28xf32>, tensor<28x15x7x28xf32>) outs(%arg2: tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32>\n  return %ret : tensor<28x15x7x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x15x7x28xf32>, %arg1: tensor<28x15x7x28xf32>, %arg2: tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x15x7x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x15x7x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x15x7x28xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x15x7x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x15x7x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x15x7x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x15x7x28xf32>\n    return %2 : tensor<28x15x7x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x15x7x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x15x7x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x15x7x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x15x7x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x15x7x28xf32>, tensor<28x15x7x28xf32>) outs(%arg2: tensor<28x15x7x28xf32>) -> tensor<28x15x7x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x15x7x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x15x7x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 76906
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x120x7x228xf32>, tensor<120x120x7x228xf32>) outs(%arg2: tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x120x7x228xf32>, tensor<120x120x7x228xf32>) outs(%arg2: tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x120x7x228xf32>, %arg1: tensor<120x120x7x228xf32>, %arg2: tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x120x7x228xf32>, tensor<120x120x7x228xf32>) outs(%arg2: tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32>\n  return %ret : tensor<120x120x7x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x120x7x228xf32>, %arg1: tensor<120x120x7x228xf32>, %arg2: tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x120x7x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x120x7x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x120x7x228xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x120x7x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x120x7x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x120x7x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x120x7x228xf32>\n    return %2 : tensor<120x120x7x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x120x7x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x120x7x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x120x7x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x120x7x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x120x7x228xf32>, tensor<120x120x7x228xf32>) outs(%arg2: tensor<120x120x7x228xf32>) -> tensor<120x120x7x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x120x7x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x120x7x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 27811496
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x120x240x14xf32>, tensor<120x120x240x14xf32>) outs(%arg2: tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x120x240x14xf32>, tensor<120x120x240x14xf32>) outs(%arg2: tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x120x240x14xf32>, %arg1: tensor<120x120x240x14xf32>, %arg2: tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x120x240x14xf32>, tensor<120x120x240x14xf32>) outs(%arg2: tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32>\n  return %ret : tensor<120x120x240x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x120x240x14xf32>, %arg1: tensor<120x120x240x14xf32>, %arg2: tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x120x240x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x120x240x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x120x240x14xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x120x240x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x120x240x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x120x240x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x120x240x14xf32>\n    return %2 : tensor<120x120x240x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x120x240x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x120x240x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x120x240x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x120x240x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x120x240x14xf32>, tensor<120x120x240x14xf32>) outs(%arg2: tensor<120x120x240x14xf32>) -> tensor<120x120x240x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x120x240x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x120x240x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 57474421
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x7x130x7xf32>, tensor<224x7x130x7xf32>) outs(%arg2: tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x7x130x7xf32>, tensor<224x7x130x7xf32>) outs(%arg2: tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x7x130x7xf32>, %arg1: tensor<224x7x130x7xf32>, %arg2: tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x7x130x7xf32>, tensor<224x7x130x7xf32>) outs(%arg2: tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32>\n  return %ret : tensor<224x7x130x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x7x130x7xf32>, %arg1: tensor<224x7x130x7xf32>, %arg2: tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x7x130x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x7x130x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x7x130x7xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x7x130x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x7x130x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x7x130x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x7x130x7xf32>\n    return %2 : tensor<224x7x130x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x7x130x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x7x130x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x7x130x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x7x130x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x7x130x7xf32>, tensor<224x7x130x7xf32>) outs(%arg2: tensor<224x7x130x7xf32>) -> tensor<224x7x130x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x7x130x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x7x130x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1472222
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x15x7x7xf32>, tensor<224x15x7x7xf32>) outs(%arg2: tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x15x7x7xf32>, tensor<224x15x7x7xf32>) outs(%arg2: tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x15x7x7xf32>, %arg1: tensor<224x15x7x7xf32>, %arg2: tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x15x7x7xf32>, tensor<224x15x7x7xf32>) outs(%arg2: tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32>\n  return %ret : tensor<224x15x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x15x7x7xf32>, %arg1: tensor<224x15x7x7xf32>, %arg2: tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x15x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x15x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x15x7x7xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x15x7x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x15x7x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x15x7x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x15x7x7xf32>\n    return %2 : tensor<224x15x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x15x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x15x7x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x15x7x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x15x7x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x15x7x7xf32>, tensor<224x15x7x7xf32>) outs(%arg2: tensor<224x15x7x7xf32>) -> tensor<224x15x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x15x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x15x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 179693
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x224x15x15xf32>, tensor<112x224x15x15xf32>) outs(%arg2: tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x224x15x15xf32>, tensor<112x224x15x15xf32>) outs(%arg2: tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x224x15x15xf32>, %arg1: tensor<112x224x15x15xf32>, %arg2: tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x224x15x15xf32>, tensor<112x224x15x15xf32>) outs(%arg2: tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32>\n  return %ret : tensor<112x224x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x224x15x15xf32>, %arg1: tensor<112x224x15x15xf32>, %arg2: tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x224x15x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x224x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x224x15x15xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x224x15x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x224x15x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x224x15x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x224x15x15xf32>\n    return %2 : tensor<112x224x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x224x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x224x15x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x224x15x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x224x15x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x224x15x15xf32>, tensor<112x224x15x15xf32>) outs(%arg2: tensor<112x224x15x15xf32>) -> tensor<112x224x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x224x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x224x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6136826
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x56x15x224xf32>, tensor<112x56x15x224xf32>) outs(%arg2: tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x56x15x224xf32>, tensor<112x56x15x224xf32>) outs(%arg2: tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x56x15x224xf32>, %arg1: tensor<112x56x15x224xf32>, %arg2: tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x56x15x224xf32>, tensor<112x56x15x224xf32>) outs(%arg2: tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32>\n  return %ret : tensor<112x56x15x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x56x15x224xf32>, %arg1: tensor<112x56x15x224xf32>, %arg2: tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x56x15x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x56x15x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x56x15x224xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x56x15x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x56x15x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x56x15x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x56x15x224xf32>\n    return %2 : tensor<112x56x15x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x56x15x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x56x15x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x56x15x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x56x15x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x56x15x224xf32>, tensor<112x56x15x224xf32>) outs(%arg2: tensor<112x56x15x224xf32>) -> tensor<112x56x15x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x56x15x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x56x15x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25572661
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x224x14x150xf32>, tensor<7x224x14x150xf32>) outs(%arg2: tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x224x14x150xf32>, tensor<7x224x14x150xf32>) outs(%arg2: tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x224x14x150xf32>, %arg1: tensor<7x224x14x150xf32>, %arg2: tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x224x14x150xf32>, tensor<7x224x14x150xf32>) outs(%arg2: tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32>\n  return %ret : tensor<7x224x14x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x224x14x150xf32>, %arg1: tensor<7x224x14x150xf32>, %arg2: tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x224x14x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x224x14x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x224x14x150xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x224x14x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x224x14x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x224x14x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x224x14x150xf32>\n    return %2 : tensor<7x224x14x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x224x14x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x224x14x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x224x14x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x224x14x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x224x14x150xf32>, tensor<7x224x14x150xf32>) outs(%arg2: tensor<7x224x14x150xf32>) -> tensor<7x224x14x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x224x14x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x224x14x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2950287
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x28x112x150xf32>, tensor<56x28x112x150xf32>) outs(%arg2: tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x28x112x150xf32>, tensor<56x28x112x150xf32>) outs(%arg2: tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x28x112x150xf32>, %arg1: tensor<56x28x112x150xf32>, %arg2: tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x28x112x150xf32>, tensor<56x28x112x150xf32>) outs(%arg2: tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32>\n  return %ret : tensor<56x28x112x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x28x112x150xf32>, %arg1: tensor<56x28x112x150xf32>, %arg2: tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x28x112x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x28x112x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x28x112x150xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x28x112x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x28x112x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x28x112x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x28x112x150xf32>\n    return %2 : tensor<56x28x112x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x28x112x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x28x112x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x28x112x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x28x112x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x28x112x150xf32>, tensor<56x28x112x150xf32>) outs(%arg2: tensor<56x28x112x150xf32>) -> tensor<56x28x112x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x28x112x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x28x112x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 32228536
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x240x112x112xf32>, tensor<15x240x112x112xf32>) outs(%arg2: tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x240x112x112xf32>, tensor<15x240x112x112xf32>) outs(%arg2: tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x240x112x112xf32>, %arg1: tensor<15x240x112x112xf32>, %arg2: tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x240x112x112xf32>, tensor<15x240x112x112xf32>) outs(%arg2: tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32>\n  return %ret : tensor<15x240x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x240x112x112xf32>, %arg1: tensor<15x240x112x112xf32>, %arg2: tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x240x112x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x240x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x240x112x112xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x240x112x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x240x112x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x240x112x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x240x112x112xf32>\n    return %2 : tensor<15x240x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x240x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x240x112x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x240x112x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x240x112x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x240x112x112xf32>, tensor<15x240x112x112xf32>) outs(%arg2: tensor<15x240x112x112xf32>) -> tensor<15x240x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x240x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x240x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 54349386
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x240x228x112xf32>, tensor<15x240x228x112xf32>) outs(%arg2: tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x240x228x112xf32>, tensor<15x240x228x112xf32>) outs(%arg2: tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x240x228x112xf32>, %arg1: tensor<15x240x228x112xf32>, %arg2: tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x240x228x112xf32>, tensor<15x240x228x112xf32>) outs(%arg2: tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32>\n  return %ret : tensor<15x240x228x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x240x228x112xf32>, %arg1: tensor<15x240x228x112xf32>, %arg2: tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x240x228x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x240x228x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x240x228x112xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x240x228x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x240x228x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x240x228x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x240x228x112xf32>\n    return %2 : tensor<15x240x228x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x240x228x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x240x228x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x240x228x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x240x228x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x240x228x112xf32>, tensor<15x240x228x112xf32>) outs(%arg2: tensor<15x240x228x112xf32>) -> tensor<15x240x228x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x240x228x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x240x228x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 113069784
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x130x112x56xf32>, tensor<130x130x112x56xf32>) outs(%arg2: tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x130x112x56xf32>, tensor<130x130x112x56xf32>) outs(%arg2: tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x130x112x56xf32>, %arg1: tensor<130x130x112x56xf32>, %arg2: tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x130x112x56xf32>, tensor<130x130x112x56xf32>) outs(%arg2: tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32>\n  return %ret : tensor<130x130x112x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x130x112x56xf32>, %arg1: tensor<130x130x112x56xf32>, %arg2: tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x130x112x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x130x112x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x130x112x56xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x130x112x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x130x112x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x130x112x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x130x112x56xf32>\n    return %2 : tensor<130x130x112x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x130x112x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x130x112x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x130x112x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x130x112x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x130x112x56xf32>, tensor<130x130x112x56xf32>) outs(%arg2: tensor<130x130x112x56xf32>) -> tensor<130x130x112x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x130x112x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x130x112x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 131647299
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x130x120x240xf32>, tensor<224x130x120x240xf32>) outs(%arg2: tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x130x120x240xf32>, tensor<224x130x120x240xf32>) outs(%arg2: tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x130x120x240xf32>, %arg1: tensor<224x130x120x240xf32>, %arg2: tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x130x120x240xf32>, tensor<224x130x120x240xf32>) outs(%arg2: tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32>\n  return %ret : tensor<224x130x120x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x130x120x240xf32>, %arg1: tensor<224x130x120x240xf32>, %arg2: tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x130x120x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x130x120x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x130x120x240xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x130x120x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x130x120x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x130x120x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x130x120x240xf32>\n    return %2 : tensor<224x130x120x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x130x120x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x130x120x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x130x120x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x130x120x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x130x120x240xf32>, tensor<224x130x120x240xf32>) outs(%arg2: tensor<224x130x120x240xf32>) -> tensor<224x130x120x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x130x120x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x130x120x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1000583666
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x120x28x7xf32>, tensor<28x120x28x7xf32>) outs(%arg2: tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x120x28x7xf32>, tensor<28x120x28x7xf32>) outs(%arg2: tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x120x28x7xf32>, %arg1: tensor<28x120x28x7xf32>, %arg2: tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x120x28x7xf32>, tensor<28x120x28x7xf32>) outs(%arg2: tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32>\n  return %ret : tensor<28x120x28x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x120x28x7xf32>, %arg1: tensor<28x120x28x7xf32>, %arg2: tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x120x28x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x120x28x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x120x28x7xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x120x28x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x120x28x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x120x28x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x120x28x7xf32>\n    return %2 : tensor<28x120x28x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x120x28x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x120x28x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x120x28x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x120x28x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x120x28x7xf32>, tensor<28x120x28x7xf32>) outs(%arg2: tensor<28x120x28x7xf32>) -> tensor<28x120x28x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x120x28x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x120x28x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 698676
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x15x130x130xf32>, tensor<28x15x130x130xf32>) outs(%arg2: tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x15x130x130xf32>, tensor<28x15x130x130xf32>) outs(%arg2: tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x15x130x130xf32>, %arg1: tensor<28x15x130x130xf32>, %arg2: tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x15x130x130xf32>, tensor<28x15x130x130xf32>) outs(%arg2: tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32>\n  return %ret : tensor<28x15x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x15x130x130xf32>, %arg1: tensor<28x15x130x130xf32>, %arg2: tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x15x130x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x15x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x15x130x130xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x15x130x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x15x130x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x15x130x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x15x130x130xf32>\n    return %2 : tensor<28x15x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x15x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x15x130x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x15x130x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x15x130x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x15x130x130xf32>, tensor<28x15x130x130xf32>) outs(%arg2: tensor<28x15x130x130xf32>) -> tensor<28x15x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x15x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x15x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7944946
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x14x112x130xf32>, tensor<14x14x112x130xf32>) outs(%arg2: tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x14x112x130xf32>, tensor<14x14x112x130xf32>) outs(%arg2: tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x14x112x130xf32>, %arg1: tensor<14x14x112x130xf32>, %arg2: tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x14x112x130xf32>, tensor<14x14x112x130xf32>) outs(%arg2: tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32>\n  return %ret : tensor<14x14x112x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x14x112x130xf32>, %arg1: tensor<14x14x112x130xf32>, %arg2: tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x14x112x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x14x112x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x14x112x130xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x14x112x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x14x112x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x14x112x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x14x112x130xf32>\n    return %2 : tensor<14x14x112x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x14x112x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x14x112x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x14x112x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x14x112x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x14x112x130xf32>, tensor<14x14x112x130xf32>) outs(%arg2: tensor<14x14x112x130xf32>) -> tensor<14x14x112x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x14x112x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x14x112x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2499885
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x28x130x112xf32>, tensor<14x28x130x112xf32>) outs(%arg2: tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x28x130x112xf32>, tensor<14x28x130x112xf32>) outs(%arg2: tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x28x130x112xf32>, %arg1: tensor<14x28x130x112xf32>, %arg2: tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x28x130x112xf32>, tensor<14x28x130x112xf32>) outs(%arg2: tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32>\n  return %ret : tensor<14x28x130x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x28x130x112xf32>, %arg1: tensor<14x28x130x112xf32>, %arg2: tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x28x130x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x28x130x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x28x130x112xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x28x130x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x28x130x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x28x130x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x28x130x112xf32>\n    return %2 : tensor<14x28x130x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x28x130x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x28x130x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x28x130x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x28x130x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x28x130x112xf32>, tensor<14x28x130x112xf32>) outs(%arg2: tensor<14x28x130x112xf32>) -> tensor<14x28x130x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x28x130x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x28x130x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6170324
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x228x120x224xf32>, tensor<7x228x120x224xf32>) outs(%arg2: tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x228x120x224xf32>, tensor<7x228x120x224xf32>) outs(%arg2: tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x228x120x224xf32>, %arg1: tensor<7x228x120x224xf32>, %arg2: tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x228x120x224xf32>, tensor<7x228x120x224xf32>) outs(%arg2: tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32>\n  return %ret : tensor<7x228x120x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x228x120x224xf32>, %arg1: tensor<7x228x120x224xf32>, %arg2: tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x228x120x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x228x120x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x228x120x224xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x228x120x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x228x120x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x228x120x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x228x120x224xf32>\n    return %2 : tensor<7x228x120x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x228x120x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x228x120x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x228x120x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x228x120x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x228x120x224xf32>, tensor<7x228x120x224xf32>) outs(%arg2: tensor<7x228x120x224xf32>) -> tensor<7x228x120x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x228x120x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x228x120x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 51642346
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x14x150x150xf32>, tensor<28x14x150x150xf32>) outs(%arg2: tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x14x150x150xf32>, tensor<28x14x150x150xf32>) outs(%arg2: tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x14x150x150xf32>, %arg1: tensor<28x14x150x150xf32>, %arg2: tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x14x150x150xf32>, tensor<28x14x150x150xf32>) outs(%arg2: tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32>\n  return %ret : tensor<28x14x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x14x150x150xf32>, %arg1: tensor<28x14x150x150xf32>, %arg2: tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x14x150x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x14x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x14x150x150xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x14x150x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x14x150x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x14x150x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x14x150x150xf32>\n    return %2 : tensor<28x14x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x14x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x14x150x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x14x150x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x14x150x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x14x150x150xf32>, tensor<28x14x150x150xf32>) outs(%arg2: tensor<28x14x150x150xf32>) -> tensor<28x14x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x14x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x14x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 11212168
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x28x15x7xf32>, tensor<14x28x15x7xf32>) outs(%arg2: tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x28x15x7xf32>, tensor<14x28x15x7xf32>) outs(%arg2: tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x28x15x7xf32>, %arg1: tensor<14x28x15x7xf32>, %arg2: tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x28x15x7xf32>, tensor<14x28x15x7xf32>) outs(%arg2: tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32>\n  return %ret : tensor<14x28x15x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x28x15x7xf32>, %arg1: tensor<14x28x15x7xf32>, %arg2: tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x28x15x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x28x15x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x28x15x7xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x28x15x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x28x15x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x28x15x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x28x15x7xf32>\n    return %2 : tensor<14x28x15x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x28x15x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x28x15x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x28x15x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x28x15x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x28x15x7xf32>, tensor<14x28x15x7xf32>) outs(%arg2: tensor<14x28x15x7xf32>) -> tensor<14x28x15x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x28x15x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x28x15x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 46282
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x150x228x7xf32>, tensor<28x150x228x7xf32>) outs(%arg2: tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x150x228x7xf32>, tensor<28x150x228x7xf32>) outs(%arg2: tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x150x228x7xf32>, %arg1: tensor<28x150x228x7xf32>, %arg2: tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x150x228x7xf32>, tensor<28x150x228x7xf32>) outs(%arg2: tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32>\n  return %ret : tensor<28x150x228x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x150x228x7xf32>, %arg1: tensor<28x150x228x7xf32>, %arg2: tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x150x228x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x150x228x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x150x228x7xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x150x228x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x150x228x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x150x228x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x150x228x7xf32>\n    return %2 : tensor<28x150x228x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x150x228x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x150x228x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x150x228x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x150x228x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x150x228x7xf32>, tensor<28x150x228x7xf32>) outs(%arg2: tensor<28x150x228x7xf32>) -> tensor<28x150x228x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x150x228x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x150x228x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7446409
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x56x15x150xf32>, tensor<120x56x15x150xf32>) outs(%arg2: tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x56x15x150xf32>, tensor<120x56x15x150xf32>) outs(%arg2: tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x56x15x150xf32>, %arg1: tensor<120x56x15x150xf32>, %arg2: tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x56x15x150xf32>, tensor<120x56x15x150xf32>) outs(%arg2: tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32>\n  return %ret : tensor<120x56x15x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x56x15x150xf32>, %arg1: tensor<120x56x15x150xf32>, %arg2: tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x56x15x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x56x15x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x56x15x150xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x56x15x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x56x15x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x56x15x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x56x15x150xf32>\n    return %2 : tensor<120x56x15x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x56x15x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x56x15x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x56x15x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x56x15x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x56x15x150xf32>, tensor<120x56x15x150xf32>) outs(%arg2: tensor<120x56x15x150xf32>) -> tensor<120x56x15x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x56x15x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x56x15x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 19093898
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x28x120x224xf32>, tensor<228x28x120x224xf32>) outs(%arg2: tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x28x120x224xf32>, tensor<228x28x120x224xf32>) outs(%arg2: tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x28x120x224xf32>, %arg1: tensor<228x28x120x224xf32>, %arg2: tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x28x120x224xf32>, tensor<228x28x120x224xf32>) outs(%arg2: tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32>\n  return %ret : tensor<228x28x120x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x28x120x224xf32>, %arg1: tensor<228x28x120x224xf32>, %arg2: tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x28x120x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x28x120x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x28x120x224xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x28x120x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x28x120x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x28x120x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x28x120x224xf32>\n    return %2 : tensor<228x28x120x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x28x120x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x28x120x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x28x120x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x28x120x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x28x120x224xf32>, tensor<228x28x120x224xf32>) outs(%arg2: tensor<228x28x120x224xf32>) -> tensor<228x28x120x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x28x120x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x28x120x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 204102605
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x120x120x224xf32>, tensor<120x120x120x224xf32>) outs(%arg2: tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x120x120x224xf32>, tensor<120x120x120x224xf32>) outs(%arg2: tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x120x120x224xf32>, %arg1: tensor<120x120x120x224xf32>, %arg2: tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x120x120x224xf32>, tensor<120x120x120x224xf32>) outs(%arg2: tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32>\n  return %ret : tensor<120x120x120x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x120x120x224xf32>, %arg1: tensor<120x120x120x224xf32>, %arg2: tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x120x120x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x120x120x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x120x120x224xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x120x120x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x120x120x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x120x120x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x120x120x224xf32>\n    return %2 : tensor<120x120x120x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x120x120x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x120x120x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x120x120x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x120x120x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x120x120x224xf32>, tensor<120x120x120x224xf32>) outs(%arg2: tensor<120x120x120x224xf32>) -> tensor<120x120x120x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x120x120x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x120x120x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 466925228
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x56x240x15xf32>, tensor<112x56x240x15xf32>) outs(%arg2: tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x56x240x15xf32>, tensor<112x56x240x15xf32>) outs(%arg2: tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x56x240x15xf32>, %arg1: tensor<112x56x240x15xf32>, %arg2: tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x56x240x15xf32>, tensor<112x56x240x15xf32>) outs(%arg2: tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32>\n  return %ret : tensor<112x56x240x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x56x240x15xf32>, %arg1: tensor<112x56x240x15xf32>, %arg2: tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x56x240x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x56x240x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x56x240x15xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x56x240x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x56x240x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x56x240x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x56x240x15xf32>\n    return %2 : tensor<112x56x240x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x56x240x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x56x240x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x56x240x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x56x240x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x56x240x15xf32>, tensor<112x56x240x15xf32>) outs(%arg2: tensor<112x56x240x15xf32>) -> tensor<112x56x240x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x56x240x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x56x240x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 26994377
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x228x228x15xf32>, tensor<56x228x228x15xf32>) outs(%arg2: tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x228x228x15xf32>, tensor<56x228x228x15xf32>) outs(%arg2: tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x228x228x15xf32>, %arg1: tensor<56x228x228x15xf32>, %arg2: tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x228x228x15xf32>, tensor<56x228x228x15xf32>) outs(%arg2: tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32>\n  return %ret : tensor<56x228x228x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x228x228x15xf32>, %arg1: tensor<56x228x228x15xf32>, %arg2: tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x228x228x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x228x228x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x228x228x15xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x228x228x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x228x228x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x228x228x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x228x228x15xf32>\n    return %2 : tensor<56x228x228x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x228x228x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x228x228x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x228x228x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x228x228x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x228x228x15xf32>, tensor<56x228x228x15xf32>) outs(%arg2: tensor<56x228x228x15xf32>) -> tensor<56x228x228x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x228x228x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x228x228x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 52120591
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x15x15x150xf32>, tensor<228x15x15x150xf32>) outs(%arg2: tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x15x15x150xf32>, tensor<228x15x15x150xf32>) outs(%arg2: tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x15x15x150xf32>, %arg1: tensor<228x15x15x150xf32>, %arg2: tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x15x15x150xf32>, tensor<228x15x15x150xf32>) outs(%arg2: tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32>\n  return %ret : tensor<228x15x15x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x15x15x150xf32>, %arg1: tensor<228x15x15x150xf32>, %arg2: tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x15x15x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x15x15x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x15x15x150xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x15x15x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x15x15x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x15x15x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x15x15x150xf32>\n    return %2 : tensor<228x15x15x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x15x15x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x15x15x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x15x15x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x15x15x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x15x15x150xf32>, tensor<228x15x15x150xf32>) outs(%arg2: tensor<228x15x15x150xf32>) -> tensor<228x15x15x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x15x15x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x15x15x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8715664
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x56x112x130xf32>, tensor<112x56x112x130xf32>) outs(%arg2: tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x56x112x130xf32>, tensor<112x56x112x130xf32>) outs(%arg2: tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x56x112x130xf32>, %arg1: tensor<112x56x112x130xf32>, %arg2: tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x56x112x130xf32>, tensor<112x56x112x130xf32>) outs(%arg2: tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32>\n  return %ret : tensor<112x56x112x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x56x112x130xf32>, %arg1: tensor<112x56x112x130xf32>, %arg2: tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x56x112x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x56x112x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x56x112x130xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x56x112x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x56x112x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x56x112x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x56x112x130xf32>\n    return %2 : tensor<112x56x112x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x56x112x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x56x112x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x56x112x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x56x112x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x56x112x130xf32>, tensor<112x56x112x130xf32>) outs(%arg2: tensor<112x56x112x130xf32>) -> tensor<112x56x112x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x56x112x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x56x112x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 110600748
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x130x15x14xf32>, tensor<120x130x15x14xf32>) outs(%arg2: tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x130x15x14xf32>, tensor<120x130x15x14xf32>) outs(%arg2: tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x130x15x14xf32>, %arg1: tensor<120x130x15x14xf32>, %arg2: tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x130x15x14xf32>, tensor<120x130x15x14xf32>) outs(%arg2: tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32>\n  return %ret : tensor<120x130x15x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x130x15x14xf32>, %arg1: tensor<120x130x15x14xf32>, %arg2: tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x130x15x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x130x15x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x130x15x14xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x130x15x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x130x15x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x130x15x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x130x15x14xf32>\n    return %2 : tensor<120x130x15x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x130x15x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x130x15x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x130x15x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x130x15x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x130x15x14xf32>, tensor<120x130x15x14xf32>) outs(%arg2: tensor<120x130x15x14xf32>) -> tensor<120x130x15x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x130x15x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x130x15x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3348395
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x28x7x228xf32>, tensor<224x28x7x228xf32>) outs(%arg2: tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x28x7x228xf32>, tensor<224x28x7x228xf32>) outs(%arg2: tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x28x7x228xf32>, %arg1: tensor<224x28x7x228xf32>, %arg2: tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x28x7x228xf32>, tensor<224x28x7x228xf32>) outs(%arg2: tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32>\n  return %ret : tensor<224x28x7x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x28x7x228xf32>, %arg1: tensor<224x28x7x228xf32>, %arg2: tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x28x7x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x28x7x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x28x7x228xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x28x7x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x28x7x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x28x7x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x28x7x228xf32>\n    return %2 : tensor<224x28x7x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x28x7x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x28x7x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x28x7x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x28x7x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x28x7x228xf32>, tensor<224x28x7x228xf32>) outs(%arg2: tensor<224x28x7x228xf32>) -> tensor<224x28x7x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x28x7x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x28x7x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12406541
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x228x228x120xf32>, tensor<224x228x228x120xf32>) outs(%arg2: tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x228x228x120xf32>, tensor<224x228x228x120xf32>) outs(%arg2: tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x228x228x120xf32>, %arg1: tensor<224x228x228x120xf32>, %arg2: tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x228x228x120xf32>, tensor<224x228x228x120xf32>) outs(%arg2: tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32>\n  return %ret : tensor<224x228x228x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x228x228x120xf32>, %arg1: tensor<224x228x228x120xf32>, %arg2: tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x228x228x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x228x228x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x228x228x120xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x228x228x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x228x228x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x228x228x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x228x228x120xf32>\n    return %2 : tensor<224x228x228x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x228x228x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x228x228x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x228x228x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x228x228x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x228x228x120xf32>, tensor<224x228x228x120xf32>) outs(%arg2: tensor<224x228x228x120xf32>) -> tensor<224x228x228x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x228x228x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x228x228x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1678658847
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x112x28x228xf32>, tensor<15x112x28x228xf32>) outs(%arg2: tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x112x28x228xf32>, tensor<15x112x28x228xf32>) outs(%arg2: tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x112x28x228xf32>, %arg1: tensor<15x112x28x228xf32>, %arg2: tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x112x28x228xf32>, tensor<15x112x28x228xf32>) outs(%arg2: tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32>\n  return %ret : tensor<15x112x28x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x112x28x228xf32>, %arg1: tensor<15x112x28x228xf32>, %arg2: tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x112x28x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x112x28x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x112x28x228xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x112x28x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x112x28x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x112x28x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x112x28x228xf32>\n    return %2 : tensor<15x112x28x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x112x28x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x112x28x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x112x28x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x112x28x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x112x28x228xf32>, tensor<15x112x28x228xf32>) outs(%arg2: tensor<15x112x28x228xf32>) -> tensor<15x112x28x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x112x28x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x112x28x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13281910
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x130x28x14xf32>, tensor<7x130x28x14xf32>) outs(%arg2: tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x130x28x14xf32>, tensor<7x130x28x14xf32>) outs(%arg2: tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x130x28x14xf32>, %arg1: tensor<7x130x28x14xf32>, %arg2: tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x130x28x14xf32>, tensor<7x130x28x14xf32>) outs(%arg2: tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32>\n  return %ret : tensor<7x130x28x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x130x28x14xf32>, %arg1: tensor<7x130x28x14xf32>, %arg2: tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x130x28x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x130x28x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x130x28x14xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x130x28x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x130x28x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x130x28x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x130x28x14xf32>\n    return %2 : tensor<7x130x28x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x130x28x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x130x28x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x130x28x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x130x28x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x130x28x14xf32>, tensor<7x130x28x14xf32>) outs(%arg2: tensor<7x130x28x14xf32>) -> tensor<7x130x28x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x130x28x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x130x28x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 343271
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x240x224x15xf32>, tensor<228x240x224x15xf32>) outs(%arg2: tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x240x224x15xf32>, tensor<228x240x224x15xf32>) outs(%arg2: tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x240x224x15xf32>, %arg1: tensor<228x240x224x15xf32>, %arg2: tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x240x224x15xf32>, tensor<228x240x224x15xf32>) outs(%arg2: tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32>\n  return %ret : tensor<228x240x224x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x240x224x15xf32>, %arg1: tensor<228x240x224x15xf32>, %arg2: tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x240x224x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x240x224x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x240x224x15xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x240x224x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x240x224x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x240x224x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x240x224x15xf32>\n    return %2 : tensor<228x240x224x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x240x224x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x240x224x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x240x224x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x240x224x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x240x224x15xf32>, tensor<228x240x224x15xf32>) outs(%arg2: tensor<228x240x224x15xf32>) -> tensor<228x240x224x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x240x224x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x240x224x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 224091878
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x112x7x112xf32>, tensor<224x112x7x112xf32>) outs(%arg2: tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x112x7x112xf32>, tensor<224x112x7x112xf32>) outs(%arg2: tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x112x7x112xf32>, %arg1: tensor<224x112x7x112xf32>, %arg2: tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x112x7x112xf32>, tensor<224x112x7x112xf32>) outs(%arg2: tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32>\n  return %ret : tensor<224x112x7x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x112x7x112xf32>, %arg1: tensor<224x112x7x112xf32>, %arg2: tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x112x7x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x112x7x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x112x7x112xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x112x7x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x112x7x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x112x7x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x112x7x112xf32>\n    return %2 : tensor<224x112x7x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x112x7x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x112x7x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x112x7x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x112x7x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x112x7x112xf32>, tensor<224x112x7x112xf32>) outs(%arg2: tensor<224x112x7x112xf32>) -> tensor<224x112x7x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x112x7x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x112x7x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 23938442
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x14x228x28xf32>, tensor<28x14x228x28xf32>) outs(%arg2: tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x14x228x28xf32>, tensor<28x14x228x28xf32>) outs(%arg2: tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x14x228x28xf32>, %arg1: tensor<28x14x228x28xf32>, %arg2: tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x14x228x28xf32>, tensor<28x14x228x28xf32>) outs(%arg2: tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32>\n  return %ret : tensor<28x14x228x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x14x228x28xf32>, %arg1: tensor<28x14x228x28xf32>, %arg2: tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x14x228x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x14x228x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x14x228x28xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x14x228x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x14x228x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x14x228x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x14x228x28xf32>\n    return %2 : tensor<28x14x228x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x14x228x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x14x228x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x14x228x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x14x228x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x14x228x28xf32>, tensor<28x14x228x28xf32>) outs(%arg2: tensor<28x14x228x28xf32>) -> tensor<28x14x228x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x14x228x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x14x228x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1812562
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x240x130x7xf32>, tensor<240x240x130x7xf32>) outs(%arg2: tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x240x130x7xf32>, tensor<240x240x130x7xf32>) outs(%arg2: tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x240x130x7xf32>, %arg1: tensor<240x240x130x7xf32>, %arg2: tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x240x130x7xf32>, tensor<240x240x130x7xf32>) outs(%arg2: tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32>\n  return %ret : tensor<240x240x130x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x240x130x7xf32>, %arg1: tensor<240x240x130x7xf32>, %arg2: tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x240x130x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x240x130x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x240x130x7xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x240x130x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x240x130x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x240x130x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x240x130x7xf32>\n    return %2 : tensor<240x240x130x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x240x130x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x240x130x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x240x130x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x240x130x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x240x130x7xf32>, tensor<240x240x130x7xf32>) outs(%arg2: tensor<240x240x130x7xf32>) -> tensor<240x240x130x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x240x130x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x240x130x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 65472267
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x120x224x228xf32>, tensor<150x120x224x228xf32>) outs(%arg2: tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x120x224x228xf32>, tensor<150x120x224x228xf32>) outs(%arg2: tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x120x224x228xf32>, %arg1: tensor<150x120x224x228xf32>, %arg2: tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x120x224x228xf32>, tensor<150x120x224x228xf32>) outs(%arg2: tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32>\n  return %ret : tensor<150x120x224x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x120x224x228xf32>, %arg1: tensor<150x120x224x228xf32>, %arg2: tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x120x224x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x120x224x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x120x224x228xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x120x224x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x120x224x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x120x224x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x120x224x228xf32>\n    return %2 : tensor<150x120x224x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x120x224x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x120x224x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x120x224x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x120x224x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x120x224x228xf32>, tensor<150x120x224x228xf32>) outs(%arg2: tensor<150x120x224x228xf32>) -> tensor<150x120x224x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x120x224x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x120x224x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1094838541
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x7x240x28xf32>, tensor<28x7x240x28xf32>) outs(%arg2: tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x7x240x28xf32>, tensor<28x7x240x28xf32>) outs(%arg2: tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x7x240x28xf32>, %arg1: tensor<28x7x240x28xf32>, %arg2: tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x7x240x28xf32>, tensor<28x7x240x28xf32>) outs(%arg2: tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32>\n  return %ret : tensor<28x7x240x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x7x240x28xf32>, %arg1: tensor<28x7x240x28xf32>, %arg2: tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x7x240x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x7x240x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x7x240x28xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x7x240x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x7x240x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x7x240x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x7x240x28xf32>\n    return %2 : tensor<28x7x240x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x7x240x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x7x240x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x7x240x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x7x240x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x7x240x28xf32>, tensor<28x7x240x28xf32>) outs(%arg2: tensor<28x7x240x28xf32>) -> tensor<28x7x240x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x7x240x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x7x240x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 896243
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x224x14x224xf32>, tensor<112x224x14x224xf32>) outs(%arg2: tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x224x14x224xf32>, tensor<112x224x14x224xf32>) outs(%arg2: tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x224x14x224xf32>, %arg1: tensor<112x224x14x224xf32>, %arg2: tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x224x14x224xf32>, tensor<112x224x14x224xf32>) outs(%arg2: tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32>\n  return %ret : tensor<112x224x14x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x224x14x224xf32>, %arg1: tensor<112x224x14x224xf32>, %arg2: tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x224x14x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x224x14x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x224x14x224xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x224x14x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x224x14x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x224x14x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x224x14x224xf32>\n    return %2 : tensor<112x224x14x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x224x14x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x224x14x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x224x14x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x224x14x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x224x14x224xf32>, tensor<112x224x14x224xf32>) outs(%arg2: tensor<112x224x14x224xf32>) -> tensor<112x224x14x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x224x14x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x224x14x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 95730216
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x130x14x14xf32>, tensor<28x130x14x14xf32>) outs(%arg2: tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x130x14x14xf32>, tensor<28x130x14x14xf32>) outs(%arg2: tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x130x14x14xf32>, %arg1: tensor<28x130x14x14xf32>, %arg2: tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x130x14x14xf32>, tensor<28x130x14x14xf32>) outs(%arg2: tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32>\n  return %ret : tensor<28x130x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x130x14x14xf32>, %arg1: tensor<28x130x14x14xf32>, %arg2: tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x130x14x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x130x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x130x14x14xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x130x14x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x130x14x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x130x14x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x130x14x14xf32>\n    return %2 : tensor<28x130x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x130x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x130x14x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x130x14x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x130x14x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x130x14x14xf32>, tensor<28x130x14x14xf32>) outs(%arg2: tensor<28x130x14x14xf32>) -> tensor<28x130x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x130x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x130x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 696788
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x112x150x15xf32>, tensor<150x112x150x15xf32>) outs(%arg2: tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x112x150x15xf32>, tensor<150x112x150x15xf32>) outs(%arg2: tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x112x150x15xf32>, %arg1: tensor<150x112x150x15xf32>, %arg2: tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x112x150x15xf32>, tensor<150x112x150x15xf32>) outs(%arg2: tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32>\n  return %ret : tensor<150x112x150x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x112x150x15xf32>, %arg1: tensor<150x112x150x15xf32>, %arg2: tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x112x150x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x112x150x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x112x150x15xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x112x150x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x112x150x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x112x150x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x112x150x15xf32>\n    return %2 : tensor<150x112x150x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x112x150x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x112x150x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x112x150x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x112x150x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x112x150x15xf32>, tensor<150x112x150x15xf32>) outs(%arg2: tensor<150x112x150x15xf32>) -> tensor<150x112x150x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x112x150x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x112x150x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 46378216
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x28x130x120xf32>, tensor<228x28x130x120xf32>) outs(%arg2: tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x28x130x120xf32>, tensor<228x28x130x120xf32>) outs(%arg2: tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x28x130x120xf32>, %arg1: tensor<228x28x130x120xf32>, %arg2: tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x28x130x120xf32>, tensor<228x28x130x120xf32>) outs(%arg2: tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32>\n  return %ret : tensor<228x28x130x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x28x130x120xf32>, %arg1: tensor<228x28x130x120xf32>, %arg2: tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x28x130x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x28x130x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x28x130x120xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x28x130x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x28x130x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x28x130x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x28x130x120xf32>\n    return %2 : tensor<228x28x130x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x28x130x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x28x130x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x28x130x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x28x130x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x28x130x120xf32>, tensor<228x28x130x120xf32>) outs(%arg2: tensor<228x28x130x120xf32>) -> tensor<228x28x130x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x28x130x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x28x130x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 120364653
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x28x28x224xf32>, tensor<150x28x28x224xf32>) outs(%arg2: tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x28x28x224xf32>, tensor<150x28x28x224xf32>) outs(%arg2: tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x28x28x224xf32>, %arg1: tensor<150x28x28x224xf32>, %arg2: tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x28x28x224xf32>, tensor<150x28x28x224xf32>) outs(%arg2: tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32>\n  return %ret : tensor<150x28x28x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x28x28x224xf32>, %arg1: tensor<150x28x28x224xf32>, %arg2: tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x28x28x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x28x28x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x28x28x224xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x28x28x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x28x28x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x28x28x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x28x28x224xf32>\n    return %2 : tensor<150x28x28x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x28x28x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x28x28x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x28x28x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x28x28x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x28x28x224xf32>, tensor<150x28x28x224xf32>) outs(%arg2: tensor<150x28x28x224xf32>) -> tensor<150x28x28x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x28x28x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x28x28x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31526379
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x14x240x14xf32>, tensor<120x14x240x14xf32>) outs(%arg2: tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x14x240x14xf32>, tensor<120x14x240x14xf32>) outs(%arg2: tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x14x240x14xf32>, %arg1: tensor<120x14x240x14xf32>, %arg2: tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x14x240x14xf32>, tensor<120x14x240x14xf32>) outs(%arg2: tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32>\n  return %ret : tensor<120x14x240x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x14x240x14xf32>, %arg1: tensor<120x14x240x14xf32>, %arg2: tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x14x240x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x14x240x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x14x240x14xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x14x240x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x14x240x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x14x240x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x14x240x14xf32>\n    return %2 : tensor<120x14x240x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x14x240x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x14x240x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x14x240x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x14x240x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x14x240x14xf32>, tensor<120x14x240x14xf32>) outs(%arg2: tensor<120x14x240x14xf32>) -> tensor<120x14x240x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x14x240x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x14x240x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6172370
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x15x240x150xf32>, tensor<7x15x240x150xf32>) outs(%arg2: tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x15x240x150xf32>, tensor<7x15x240x150xf32>) outs(%arg2: tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x15x240x150xf32>, %arg1: tensor<7x15x240x150xf32>, %arg2: tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x15x240x150xf32>, tensor<7x15x240x150xf32>) outs(%arg2: tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32>\n  return %ret : tensor<7x15x240x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x15x240x150xf32>, %arg1: tensor<7x15x240x150xf32>, %arg2: tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x15x240x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x15x240x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x15x240x150xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x15x240x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x15x240x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x15x240x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x15x240x150xf32>\n    return %2 : tensor<7x15x240x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x15x240x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x15x240x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x15x240x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x15x240x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x15x240x150xf32>, tensor<7x15x240x150xf32>) outs(%arg2: tensor<7x15x240x150xf32>) -> tensor<7x15x240x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x15x240x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x15x240x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3535127
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x28x112x228xf32>, tensor<56x28x112x228xf32>) outs(%arg2: tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x28x112x228xf32>, tensor<56x28x112x228xf32>) outs(%arg2: tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x28x112x228xf32>, %arg1: tensor<56x28x112x228xf32>, %arg2: tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x28x112x228xf32>, tensor<56x28x112x228xf32>) outs(%arg2: tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32>\n  return %ret : tensor<56x28x112x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x28x112x228xf32>, %arg1: tensor<56x28x112x228xf32>, %arg2: tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x28x112x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x28x112x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x28x112x228xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x28x112x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x28x112x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x28x112x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x28x112x228xf32>\n    return %2 : tensor<56x28x112x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x28x112x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x28x112x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x28x112x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x28x112x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x28x112x228xf32>, tensor<56x28x112x228xf32>) outs(%arg2: tensor<56x28x112x228xf32>) -> tensor<56x28x112x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x28x112x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x28x112x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 48929043
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x224x240x228xf32>, tensor<228x224x240x228xf32>) outs(%arg2: tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x224x240x228xf32>, tensor<228x224x240x228xf32>) outs(%arg2: tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x224x240x228xf32>, %arg1: tensor<228x224x240x228xf32>, %arg2: tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x224x240x228xf32>, tensor<228x224x240x228xf32>) outs(%arg2: tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32>\n  return %ret : tensor<228x224x240x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x224x240x228xf32>, %arg1: tensor<228x224x240x228xf32>, %arg2: tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x224x240x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x224x240x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x224x240x228xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x224x240x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x224x240x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x224x240x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x224x240x228xf32>\n    return %2 : tensor<228x224x240x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x224x240x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x224x240x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x224x240x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x224x240x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x224x240x228xf32>, tensor<228x224x240x228xf32>) outs(%arg2: tensor<228x224x240x228xf32>) -> tensor<228x224x240x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x224x240x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x224x240x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3303166853
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x56x130x228xf32>, tensor<224x56x130x228xf32>) outs(%arg2: tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x56x130x228xf32>, tensor<224x56x130x228xf32>) outs(%arg2: tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x56x130x228xf32>, %arg1: tensor<224x56x130x228xf32>, %arg2: tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x56x130x228xf32>, tensor<224x56x130x228xf32>) outs(%arg2: tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32>\n  return %ret : tensor<224x56x130x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x56x130x228xf32>, %arg1: tensor<224x56x130x228xf32>, %arg2: tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x56x130x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x56x130x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x56x130x228xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x56x130x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x56x130x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x56x130x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x56x130x228xf32>\n    return %2 : tensor<224x56x130x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x56x130x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x56x130x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x56x130x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x56x130x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x56x130x228xf32>, tensor<224x56x130x228xf32>) outs(%arg2: tensor<224x56x130x228xf32>) -> tensor<224x56x130x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x56x130x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x56x130x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 440156907
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x130x228x14xf32>, tensor<130x130x228x14xf32>) outs(%arg2: tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x130x228x14xf32>, tensor<130x130x228x14xf32>) outs(%arg2: tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x130x228x14xf32>, %arg1: tensor<130x130x228x14xf32>, %arg2: tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x130x228x14xf32>, tensor<130x130x228x14xf32>) outs(%arg2: tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32>\n  return %ret : tensor<130x130x228x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x130x228x14xf32>, %arg1: tensor<130x130x228x14xf32>, %arg2: tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x130x228x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x130x228x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x130x228x14xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x130x228x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x130x228x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x130x228x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x130x228x14xf32>\n    return %2 : tensor<130x130x228x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x130x228x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x130x228x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x130x228x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x130x228x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x130x228x14xf32>, tensor<130x130x228x14xf32>) outs(%arg2: tensor<130x130x228x14xf32>) -> tensor<130x130x228x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x130x228x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x130x228x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 66120776
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x224x150x56xf32>, tensor<14x224x150x56xf32>) outs(%arg2: tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x224x150x56xf32>, tensor<14x224x150x56xf32>) outs(%arg2: tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x224x150x56xf32>, %arg1: tensor<14x224x150x56xf32>, %arg2: tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x224x150x56xf32>, tensor<14x224x150x56xf32>) outs(%arg2: tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32>\n  return %ret : tensor<14x224x150x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x224x150x56xf32>, %arg1: tensor<14x224x150x56xf32>, %arg2: tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x224x150x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x224x150x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x224x150x56xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x224x150x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x224x150x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x224x150x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x224x150x56xf32>\n    return %2 : tensor<14x224x150x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x224x150x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x224x150x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x224x150x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x224x150x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x224x150x56xf32>, tensor<14x224x150x56xf32>) outs(%arg2: tensor<14x224x150x56xf32>) -> tensor<14x224x150x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x224x150x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x224x150x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31566667
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x240x7x56xf32>, tensor<150x240x7x56xf32>) outs(%arg2: tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x240x7x56xf32>, tensor<150x240x7x56xf32>) outs(%arg2: tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x240x7x56xf32>, %arg1: tensor<150x240x7x56xf32>, %arg2: tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x240x7x56xf32>, tensor<150x240x7x56xf32>) outs(%arg2: tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32>\n  return %ret : tensor<150x240x7x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x240x7x56xf32>, %arg1: tensor<150x240x7x56xf32>, %arg2: tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x240x7x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x240x7x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x240x7x56xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x240x7x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x240x7x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x240x7x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x240x7x56xf32>\n    return %2 : tensor<150x240x7x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x240x7x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x240x7x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x240x7x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x240x7x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x240x7x56xf32>, tensor<150x240x7x56xf32>) outs(%arg2: tensor<150x240x7x56xf32>) -> tensor<150x240x7x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x240x7x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x240x7x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 18371746
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x28x224x240xf32>, tensor<14x28x224x240xf32>) outs(%arg2: tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x28x224x240xf32>, tensor<14x28x224x240xf32>) outs(%arg2: tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x28x224x240xf32>, %arg1: tensor<14x28x224x240xf32>, %arg2: tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x28x224x240xf32>, tensor<14x28x224x240xf32>) outs(%arg2: tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32>\n  return %ret : tensor<14x28x224x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x28x224x240xf32>, %arg1: tensor<14x28x224x240xf32>, %arg2: tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x28x224x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x28x224x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x28x224x240xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x28x224x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x28x224x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x28x224x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x28x224x240xf32>\n    return %2 : tensor<14x28x224x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x28x224x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x28x224x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x28x224x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x28x224x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x28x224x240xf32>, tensor<14x28x224x240xf32>) outs(%arg2: tensor<14x28x224x240xf32>) -> tensor<14x28x224x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x28x224x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x28x224x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25759670
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x15x14x14xf32>, tensor<15x15x14x14xf32>) outs(%arg2: tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x15x14x14xf32>, tensor<15x15x14x14xf32>) outs(%arg2: tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x15x14x14xf32>, %arg1: tensor<15x15x14x14xf32>, %arg2: tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x15x14x14xf32>, tensor<15x15x14x14xf32>) outs(%arg2: tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32>\n  return %ret : tensor<15x15x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x15x14x14xf32>, %arg1: tensor<15x15x14x14xf32>, %arg2: tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x15x14x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x15x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x15x14x14xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x15x14x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x15x14x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x15x14x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x15x14x14xf32>\n    return %2 : tensor<15x15x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x15x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x15x14x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x15x14x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x15x14x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x15x14x14xf32>, tensor<15x15x14x14xf32>) outs(%arg2: tensor<15x15x14x14xf32>) -> tensor<15x15x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x15x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x15x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 43916
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x56x7x150xf32>, tensor<150x56x7x150xf32>) outs(%arg2: tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x56x7x150xf32>, tensor<150x56x7x150xf32>) outs(%arg2: tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x56x7x150xf32>, %arg1: tensor<150x56x7x150xf32>, %arg2: tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x56x7x150xf32>, tensor<150x56x7x150xf32>) outs(%arg2: tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32>\n  return %ret : tensor<150x56x7x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x56x7x150xf32>, %arg1: tensor<150x56x7x150xf32>, %arg2: tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x56x7x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x56x7x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x56x7x150xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x56x7x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x56x7x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x56x7x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x56x7x150xf32>\n    return %2 : tensor<150x56x7x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x56x7x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x56x7x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x56x7x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x56x7x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x56x7x150xf32>, tensor<150x56x7x150xf32>) outs(%arg2: tensor<150x56x7x150xf32>) -> tensor<150x56x7x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x56x7x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x56x7x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 11086197
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x14x28x120xf32>, tensor<120x14x28x120xf32>) outs(%arg2: tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x14x28x120xf32>, tensor<120x14x28x120xf32>) outs(%arg2: tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x14x28x120xf32>, %arg1: tensor<120x14x28x120xf32>, %arg2: tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x14x28x120xf32>, tensor<120x14x28x120xf32>) outs(%arg2: tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32>\n  return %ret : tensor<120x14x28x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x14x28x120xf32>, %arg1: tensor<120x14x28x120xf32>, %arg2: tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x14x28x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x14x28x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x14x28x120xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x14x28x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x14x28x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x14x28x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x14x28x120xf32>\n    return %2 : tensor<120x14x28x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x14x28x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x14x28x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x14x28x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x14x28x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x14x28x120xf32>, tensor<120x14x28x120xf32>) outs(%arg2: tensor<120x14x28x120xf32>) -> tensor<120x14x28x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x14x28x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x14x28x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6013538
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x15x112x56xf32>, tensor<7x15x112x56xf32>) outs(%arg2: tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x15x112x56xf32>, tensor<7x15x112x56xf32>) outs(%arg2: tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x15x112x56xf32>, %arg1: tensor<7x15x112x56xf32>, %arg2: tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x15x112x56xf32>, tensor<7x15x112x56xf32>) outs(%arg2: tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32>\n  return %ret : tensor<7x15x112x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x15x112x56xf32>, %arg1: tensor<7x15x112x56xf32>, %arg2: tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x15x112x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x15x112x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x15x112x56xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x15x112x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x15x112x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x15x112x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x15x112x56xf32>\n    return %2 : tensor<7x15x112x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x15x112x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x15x112x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x15x112x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x15x112x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x15x112x56xf32>, tensor<7x15x112x56xf32>) outs(%arg2: tensor<7x15x112x56xf32>) -> tensor<7x15x112x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x15x112x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x15x112x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 538037
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x224x56x7xf32>, tensor<28x224x56x7xf32>) outs(%arg2: tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x224x56x7xf32>, tensor<28x224x56x7xf32>) outs(%arg2: tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x224x56x7xf32>, %arg1: tensor<28x224x56x7xf32>, %arg2: tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x224x56x7xf32>, tensor<28x224x56x7xf32>) outs(%arg2: tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32>\n  return %ret : tensor<28x224x56x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x224x56x7xf32>, %arg1: tensor<28x224x56x7xf32>, %arg2: tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x224x56x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x224x56x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x224x56x7xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x224x56x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x224x56x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x224x56x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x224x56x7xf32>\n    return %2 : tensor<28x224x56x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x224x56x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x224x56x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x224x56x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x224x56x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x224x56x7xf32>, tensor<28x224x56x7xf32>) outs(%arg2: tensor<28x224x56x7xf32>) -> tensor<28x224x56x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x224x56x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x224x56x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2603298
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x240x130x15xf32>, tensor<150x240x130x15xf32>) outs(%arg2: tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x240x130x15xf32>, tensor<150x240x130x15xf32>) outs(%arg2: tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x240x130x15xf32>, %arg1: tensor<150x240x130x15xf32>, %arg2: tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x240x130x15xf32>, tensor<150x240x130x15xf32>) outs(%arg2: tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32>\n  return %ret : tensor<150x240x130x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x240x130x15xf32>, %arg1: tensor<150x240x130x15xf32>, %arg2: tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x240x130x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x240x130x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x240x130x15xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x240x130x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x240x130x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x240x130x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x240x130x15xf32>\n    return %2 : tensor<150x240x130x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x240x130x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x240x130x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x240x130x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x240x130x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x240x130x15xf32>, tensor<150x240x130x15xf32>) outs(%arg2: tensor<150x240x130x15xf32>) -> tensor<150x240x130x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x240x130x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x240x130x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 85637456
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x130x120x228xf32>, tensor<240x130x120x228xf32>) outs(%arg2: tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x130x120x228xf32>, tensor<240x130x120x228xf32>) outs(%arg2: tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x130x120x228xf32>, %arg1: tensor<240x130x120x228xf32>, %arg2: tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x130x120x228xf32>, tensor<240x130x120x228xf32>) outs(%arg2: tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32>\n  return %ret : tensor<240x130x120x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x130x120x228xf32>, %arg1: tensor<240x130x120x228xf32>, %arg2: tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x130x120x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x130x120x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x130x120x228xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x130x120x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x130x120x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x130x120x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x130x120x228xf32>\n    return %2 : tensor<240x130x120x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x130x120x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x130x120x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x130x120x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x130x120x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x130x120x228xf32>, tensor<240x130x120x228xf32>) outs(%arg2: tensor<240x130x120x228xf32>) -> tensor<240x130x120x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x130x120x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x130x120x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1021524308
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x130x15x112xf32>, tensor<130x130x15x112xf32>) outs(%arg2: tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x130x15x112xf32>, tensor<130x130x15x112xf32>) outs(%arg2: tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x130x15x112xf32>, %arg1: tensor<130x130x15x112xf32>, %arg2: tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x130x15x112xf32>, tensor<130x130x15x112xf32>) outs(%arg2: tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32>\n  return %ret : tensor<130x130x15x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x130x15x112xf32>, %arg1: tensor<130x130x15x112xf32>, %arg2: tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x130x15x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x130x15x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x130x15x112xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x130x15x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x130x15x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x130x15x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x130x15x112xf32>\n    return %2 : tensor<130x130x15x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x130x15x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x130x15x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x130x15x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x130x15x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x130x15x112xf32>, tensor<130x130x15x112xf32>) outs(%arg2: tensor<130x130x15x112xf32>) -> tensor<130x130x15x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x130x15x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x130x15x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 35154911
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x56x150x14xf32>, tensor<7x56x150x14xf32>) outs(%arg2: tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x56x150x14xf32>, tensor<7x56x150x14xf32>) outs(%arg2: tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x56x150x14xf32>, %arg1: tensor<7x56x150x14xf32>, %arg2: tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x56x150x14xf32>, tensor<7x56x150x14xf32>) outs(%arg2: tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32>\n  return %ret : tensor<7x56x150x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x56x150x14xf32>, %arg1: tensor<7x56x150x14xf32>, %arg2: tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x56x150x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x56x150x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x56x150x14xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x56x150x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x56x150x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x56x150x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x56x150x14xf32>\n    return %2 : tensor<7x56x150x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x56x150x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x56x150x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x56x150x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x56x150x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x56x150x14xf32>, tensor<7x56x150x14xf32>) outs(%arg2: tensor<7x56x150x14xf32>) -> tensor<7x56x150x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x56x150x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x56x150x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 587129
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x150x150x150xf32>, tensor<7x150x150x150xf32>) outs(%arg2: tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x150x150x150xf32>, tensor<7x150x150x150xf32>) outs(%arg2: tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x150x150x150xf32>, %arg1: tensor<7x150x150x150xf32>, %arg2: tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x150x150x150xf32>, tensor<7x150x150x150xf32>) outs(%arg2: tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32>\n  return %ret : tensor<7x150x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x150x150x150xf32>, %arg1: tensor<7x150x150x150xf32>, %arg2: tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x150x150x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x150x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x150x150x150xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x150x150x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x150x150x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x150x150x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x150x150x150xf32>\n    return %2 : tensor<7x150x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x150x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x150x150x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x150x150x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x150x150x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x150x150x150xf32>, tensor<7x150x150x150xf32>) outs(%arg2: tensor<7x150x150x150xf32>) -> tensor<7x150x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x150x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x150x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 29274660
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x14x112x15xf32>, tensor<224x14x112x15xf32>) outs(%arg2: tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x14x112x15xf32>, tensor<224x14x112x15xf32>) outs(%arg2: tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x14x112x15xf32>, %arg1: tensor<224x14x112x15xf32>, %arg2: tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x14x112x15xf32>, tensor<224x14x112x15xf32>) outs(%arg2: tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32>\n  return %ret : tensor<224x14x112x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x14x112x15xf32>, %arg1: tensor<224x14x112x15xf32>, %arg2: tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x14x112x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x14x112x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x14x112x15xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x14x112x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x14x112x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x14x112x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x14x112x15xf32>\n    return %2 : tensor<224x14x112x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x14x112x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x14x112x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x14x112x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x14x112x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x14x112x15xf32>, tensor<224x14x112x15xf32>) outs(%arg2: tensor<224x14x112x15xf32>) -> tensor<224x14x112x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x14x112x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x14x112x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5938501
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x130x120x150xf32>, tensor<15x130x120x150xf32>) outs(%arg2: tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x130x120x150xf32>, tensor<15x130x120x150xf32>) outs(%arg2: tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x130x120x150xf32>, %arg1: tensor<15x130x120x150xf32>, %arg2: tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x130x120x150xf32>, tensor<15x130x120x150xf32>) outs(%arg2: tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32>\n  return %ret : tensor<15x130x120x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x130x120x150xf32>, %arg1: tensor<15x130x120x150xf32>, %arg2: tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x130x120x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x130x120x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x130x120x150xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x130x120x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x130x120x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x130x120x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x130x120x150xf32>\n    return %2 : tensor<15x130x120x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x130x120x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x130x120x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x130x120x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x130x120x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x130x120x150xf32>, tensor<15x130x120x150xf32>) outs(%arg2: tensor<15x130x120x150xf32>) -> tensor<15x130x120x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x130x120x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x130x120x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 42860542
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x7x130x120xf32>, tensor<14x7x130x120xf32>) outs(%arg2: tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x7x130x120xf32>, tensor<14x7x130x120xf32>) outs(%arg2: tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x7x130x120xf32>, %arg1: tensor<14x7x130x120xf32>, %arg2: tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x7x130x120xf32>, tensor<14x7x130x120xf32>) outs(%arg2: tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32>\n  return %ret : tensor<14x7x130x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x7x130x120xf32>, %arg1: tensor<14x7x130x120xf32>, %arg2: tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x7x130x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x7x130x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x7x130x120xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x7x130x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x7x130x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x7x130x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x7x130x120xf32>\n    return %2 : tensor<14x7x130x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x7x130x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x7x130x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x7x130x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x7x130x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x7x130x120xf32>, tensor<14x7x130x120xf32>) outs(%arg2: tensor<14x7x130x120xf32>) -> tensor<14x7x130x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x7x130x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x7x130x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1164001
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x15x240x130xf32>, tensor<7x15x240x130xf32>) outs(%arg2: tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x15x240x130xf32>, tensor<7x15x240x130xf32>) outs(%arg2: tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x15x240x130xf32>, %arg1: tensor<7x15x240x130xf32>, %arg2: tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x15x240x130xf32>, tensor<7x15x240x130xf32>) outs(%arg2: tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32>\n  return %ret : tensor<7x15x240x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x15x240x130xf32>, %arg1: tensor<7x15x240x130xf32>, %arg2: tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x15x240x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x15x240x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x15x240x130xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x15x240x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x15x240x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x15x240x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x15x240x130xf32>\n    return %2 : tensor<7x15x240x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x15x240x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x15x240x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x15x240x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x15x240x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x15x240x130xf32>, tensor<7x15x240x130xf32>) outs(%arg2: tensor<7x15x240x130xf32>) -> tensor<7x15x240x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x15x240x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x15x240x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2986638
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x150x14x15xf32>, tensor<28x150x14x15xf32>) outs(%arg2: tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x150x14x15xf32>, tensor<28x150x14x15xf32>) outs(%arg2: tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x150x14x15xf32>, %arg1: tensor<28x150x14x15xf32>, %arg2: tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x150x14x15xf32>, tensor<28x150x14x15xf32>) outs(%arg2: tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32>\n  return %ret : tensor<28x150x14x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x150x14x15xf32>, %arg1: tensor<28x150x14x15xf32>, %arg2: tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x150x14x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x150x14x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x150x14x15xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x150x14x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x150x14x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x150x14x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x150x14x15xf32>\n    return %2 : tensor<28x150x14x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x150x14x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x150x14x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x150x14x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x150x14x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x150x14x15xf32>, tensor<28x150x14x15xf32>) outs(%arg2: tensor<28x150x14x15xf32>) -> tensor<28x150x14x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x150x14x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x150x14x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 852363
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x130x130x14xf32>, tensor<130x130x130x14xf32>) outs(%arg2: tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x130x130x14xf32>, tensor<130x130x130x14xf32>) outs(%arg2: tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x130x130x14xf32>, %arg1: tensor<130x130x130x14xf32>, %arg2: tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x130x130x14xf32>, tensor<130x130x130x14xf32>) outs(%arg2: tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32>\n  return %ret : tensor<130x130x130x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x130x130x14xf32>, %arg1: tensor<130x130x130x14xf32>, %arg2: tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x130x130x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x130x130x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x130x130x14xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x130x130x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x130x130x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x130x130x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x130x130x14xf32>\n    return %2 : tensor<130x130x130x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x130x130x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x130x130x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x130x130x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x130x130x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x130x130x14xf32>, tensor<130x130x130x14xf32>) outs(%arg2: tensor<130x130x130x14xf32>) -> tensor<130x130x130x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x130x130x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x130x130x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 37701548
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x130x56x28xf32>, tensor<224x130x56x28xf32>) outs(%arg2: tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x130x56x28xf32>, tensor<224x130x56x28xf32>) outs(%arg2: tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x130x56x28xf32>, %arg1: tensor<224x130x56x28xf32>, %arg2: tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x130x56x28xf32>, tensor<224x130x56x28xf32>) outs(%arg2: tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32>\n  return %ret : tensor<224x130x56x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x130x56x28xf32>, %arg1: tensor<224x130x56x28xf32>, %arg2: tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x130x56x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x130x56x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x130x56x28xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x130x56x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x130x56x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x130x56x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x130x56x28xf32>\n    return %2 : tensor<224x130x56x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x130x56x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x130x56x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x130x56x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x130x56x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x130x56x28xf32>, tensor<224x130x56x28xf32>) outs(%arg2: tensor<224x130x56x28xf32>) -> tensor<224x130x56x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x130x56x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x130x56x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 55680426
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x224x112x56xf32>, tensor<15x224x112x56xf32>) outs(%arg2: tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x224x112x56xf32>, tensor<15x224x112x56xf32>) outs(%arg2: tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x224x112x56xf32>, %arg1: tensor<15x224x112x56xf32>, %arg2: tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x224x112x56xf32>, tensor<15x224x112x56xf32>) outs(%arg2: tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32>\n  return %ret : tensor<15x224x112x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x224x112x56xf32>, %arg1: tensor<15x224x112x56xf32>, %arg2: tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x224x112x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x224x112x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x224x112x56xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x224x112x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x224x112x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x224x112x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x224x112x56xf32>\n    return %2 : tensor<15x224x112x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x224x112x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x224x112x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x224x112x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x224x112x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x224x112x56xf32>, tensor<15x224x112x56xf32>) outs(%arg2: tensor<15x224x112x56xf32>) -> tensor<15x224x112x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x224x112x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x224x112x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25343837
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x56x56x224xf32>, tensor<120x56x56x224xf32>) outs(%arg2: tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x56x56x224xf32>, tensor<120x56x56x224xf32>) outs(%arg2: tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x56x56x224xf32>, %arg1: tensor<120x56x56x224xf32>, %arg2: tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x56x56x224xf32>, tensor<120x56x56x224xf32>) outs(%arg2: tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32>\n  return %ret : tensor<120x56x56x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x56x56x224xf32>, %arg1: tensor<120x56x56x224xf32>, %arg2: tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x56x56x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x56x56x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x56x56x224xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x56x56x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x56x56x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x56x56x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x56x56x224xf32>\n    return %2 : tensor<120x56x56x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x56x56x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x56x56x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x56x56x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x56x56x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x56x56x224xf32>, tensor<120x56x56x224xf32>) outs(%arg2: tensor<120x56x56x224xf32>) -> tensor<120x56x56x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x56x56x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x56x56x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 101460806
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x28x224x56xf32>, tensor<28x28x224x56xf32>) outs(%arg2: tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x28x224x56xf32>, tensor<28x28x224x56xf32>) outs(%arg2: tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x28x224x56xf32>, %arg1: tensor<28x28x224x56xf32>, %arg2: tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x28x224x56xf32>, tensor<28x28x224x56xf32>) outs(%arg2: tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32>\n  return %ret : tensor<28x28x224x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x28x224x56xf32>, %arg1: tensor<28x28x224x56xf32>, %arg2: tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x28x224x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x28x224x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x28x224x56xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x28x224x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x28x224x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x28x224x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x28x224x56xf32>\n    return %2 : tensor<28x28x224x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x28x224x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x28x224x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x28x224x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x28x224x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x28x224x56xf32>, tensor<28x28x224x56xf32>) outs(%arg2: tensor<28x28x224x56xf32>) -> tensor<28x28x224x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x28x224x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x28x224x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 11966494
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x120x224x7xf32>, tensor<15x120x224x7xf32>) outs(%arg2: tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x120x224x7xf32>, tensor<15x120x224x7xf32>) outs(%arg2: tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x120x224x7xf32>, %arg1: tensor<15x120x224x7xf32>, %arg2: tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x120x224x7xf32>, tensor<15x120x224x7xf32>) outs(%arg2: tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32>\n  return %ret : tensor<15x120x224x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x120x224x7xf32>, %arg1: tensor<15x120x224x7xf32>, %arg2: tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x120x224x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x120x224x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x120x224x7xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x120x224x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x120x224x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x120x224x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x120x224x7xf32>\n    return %2 : tensor<15x120x224x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x120x224x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x120x224x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x120x224x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x120x224x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x120x224x7xf32>, tensor<15x120x224x7xf32>) outs(%arg2: tensor<15x120x224x7xf32>) -> tensor<15x120x224x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x120x224x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x120x224x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2366896
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x56x15x130xf32>, tensor<120x56x15x130xf32>) outs(%arg2: tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x56x15x130xf32>, tensor<120x56x15x130xf32>) outs(%arg2: tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x56x15x130xf32>, %arg1: tensor<120x56x15x130xf32>, %arg2: tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x56x15x130xf32>, tensor<120x56x15x130xf32>) outs(%arg2: tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32>\n  return %ret : tensor<120x56x15x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x56x15x130xf32>, %arg1: tensor<120x56x15x130xf32>, %arg2: tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x56x15x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x56x15x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x56x15x130xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x56x15x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x56x15x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x56x15x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x56x15x130xf32>\n    return %2 : tensor<120x56x15x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x56x15x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x56x15x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x56x15x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x56x15x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x56x15x130xf32>, tensor<120x56x15x130xf32>) outs(%arg2: tensor<120x56x15x130xf32>) -> tensor<120x56x15x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x56x15x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x56x15x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 16587485
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x112x28x28xf32>, tensor<112x112x28x28xf32>) outs(%arg2: tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x112x28x28xf32>, tensor<112x112x28x28xf32>) outs(%arg2: tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x112x28x28xf32>, %arg1: tensor<112x112x28x28xf32>, %arg2: tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x112x28x28xf32>, tensor<112x112x28x28xf32>) outs(%arg2: tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32>\n  return %ret : tensor<112x112x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x112x28x28xf32>, %arg1: tensor<112x112x28x28xf32>, %arg2: tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x112x28x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x112x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x112x28x28xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x112x28x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x112x28x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x112x28x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x112x28x28xf32>\n    return %2 : tensor<112x112x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x112x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x112x28x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x112x28x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x112x28x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x112x28x28xf32>, tensor<112x112x28x28xf32>) outs(%arg2: tensor<112x112x28x28xf32>) -> tensor<112x112x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x112x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x112x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12174126
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x28x14x224xf32>, tensor<120x28x14x224xf32>) outs(%arg2: tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x28x14x224xf32>, tensor<120x28x14x224xf32>) outs(%arg2: tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x28x14x224xf32>, %arg1: tensor<120x28x14x224xf32>, %arg2: tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x28x14x224xf32>, tensor<120x28x14x224xf32>) outs(%arg2: tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32>\n  return %ret : tensor<120x28x14x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x28x14x224xf32>, %arg1: tensor<120x28x14x224xf32>, %arg2: tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x28x14x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x28x14x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x28x14x224xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x28x14x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x28x14x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x28x14x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x28x14x224xf32>\n    return %2 : tensor<120x28x14x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x28x14x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x28x14x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x28x14x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x28x14x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x28x14x224xf32>, tensor<120x28x14x224xf32>) outs(%arg2: tensor<120x28x14x224xf32>) -> tensor<120x28x14x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x28x14x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x28x14x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13123557
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x7x150x14xf32>, tensor<150x7x150x14xf32>) outs(%arg2: tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x7x150x14xf32>, tensor<150x7x150x14xf32>) outs(%arg2: tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x7x150x14xf32>, %arg1: tensor<150x7x150x14xf32>, %arg2: tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x7x150x14xf32>, tensor<150x7x150x14xf32>) outs(%arg2: tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32>\n  return %ret : tensor<150x7x150x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x7x150x14xf32>, %arg1: tensor<150x7x150x14xf32>, %arg2: tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x7x150x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x7x150x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x7x150x14xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x7x150x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x7x150x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x7x150x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x7x150x14xf32>\n    return %2 : tensor<150x7x150x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x7x150x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x7x150x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x7x150x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x7x150x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x7x150x14xf32>, tensor<150x7x150x14xf32>) outs(%arg2: tensor<150x7x150x14xf32>) -> tensor<150x7x150x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x7x150x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x7x150x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2084838
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x28x14x14xf32>, tensor<240x28x14x14xf32>) outs(%arg2: tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x28x14x14xf32>, tensor<240x28x14x14xf32>) outs(%arg2: tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x28x14x14xf32>, %arg1: tensor<240x28x14x14xf32>, %arg2: tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x28x14x14xf32>, tensor<240x28x14x14xf32>) outs(%arg2: tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32>\n  return %ret : tensor<240x28x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x28x14x14xf32>, %arg1: tensor<240x28x14x14xf32>, %arg2: tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x28x14x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x28x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x28x14x14xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x28x14x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x28x14x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x28x14x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x28x14x14xf32>\n    return %2 : tensor<240x28x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x28x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x28x14x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x28x14x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x28x14x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x28x14x14xf32>, tensor<240x28x14x14xf32>) outs(%arg2: tensor<240x28x14x14xf32>) -> tensor<240x28x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x28x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x28x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1296297
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x150x28x240xf32>, tensor<56x150x28x240xf32>) outs(%arg2: tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x150x28x240xf32>, tensor<56x150x28x240xf32>) outs(%arg2: tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x150x28x240xf32>, %arg1: tensor<56x150x28x240xf32>, %arg2: tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x150x28x240xf32>, tensor<56x150x28x240xf32>) outs(%arg2: tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32>\n  return %ret : tensor<56x150x28x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x150x28x240xf32>, %arg1: tensor<56x150x28x240xf32>, %arg2: tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x150x28x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x150x28x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x150x28x240xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x150x28x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x150x28x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x150x28x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x150x28x240xf32>\n    return %2 : tensor<56x150x28x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x150x28x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x150x28x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x150x28x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x150x28x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x150x28x240xf32>, tensor<56x150x28x240xf32>) outs(%arg2: tensor<56x150x28x240xf32>) -> tensor<56x150x28x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x150x28x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x150x28x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 68204991
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x224x56x28xf32>, tensor<112x224x56x28xf32>) outs(%arg2: tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x224x56x28xf32>, tensor<112x224x56x28xf32>) outs(%arg2: tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x224x56x28xf32>, %arg1: tensor<112x224x56x28xf32>, %arg2: tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x224x56x28xf32>, tensor<112x224x56x28xf32>) outs(%arg2: tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32>\n  return %ret : tensor<112x224x56x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x224x56x28xf32>, %arg1: tensor<112x224x56x28xf32>, %arg2: tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x224x56x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x224x56x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x224x56x28xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x224x56x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x224x56x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x224x56x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x224x56x28xf32>\n    return %2 : tensor<112x224x56x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x224x56x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x224x56x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x224x56x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x224x56x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x224x56x28xf32>, tensor<112x224x56x28xf32>) outs(%arg2: tensor<112x224x56x28xf32>) -> tensor<112x224x56x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x224x56x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x224x56x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 47739306
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x56x14x224xf32>, tensor<28x56x14x224xf32>) outs(%arg2: tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x56x14x224xf32>, tensor<28x56x14x224xf32>) outs(%arg2: tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x56x14x224xf32>, %arg1: tensor<28x56x14x224xf32>, %arg2: tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x56x14x224xf32>, tensor<28x56x14x224xf32>) outs(%arg2: tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32>\n  return %ret : tensor<28x56x14x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x56x14x224xf32>, %arg1: tensor<28x56x14x224xf32>, %arg2: tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x56x14x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x56x14x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x56x14x224xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x56x14x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x56x14x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x56x14x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x56x14x224xf32>\n    return %2 : tensor<28x56x14x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x56x14x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x56x14x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x56x14x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x56x14x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x56x14x224xf32>, tensor<28x56x14x224xf32>) outs(%arg2: tensor<28x56x14x224xf32>) -> tensor<28x56x14x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x56x14x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x56x14x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5473336
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x7x7x15xf32>, tensor<130x7x7x15xf32>) outs(%arg2: tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x7x7x15xf32>, tensor<130x7x7x15xf32>) outs(%arg2: tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x7x7x15xf32>, %arg1: tensor<130x7x7x15xf32>, %arg2: tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x7x7x15xf32>, tensor<130x7x7x15xf32>) outs(%arg2: tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32>\n  return %ret : tensor<130x7x7x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x7x7x15xf32>, %arg1: tensor<130x7x7x15xf32>, %arg2: tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x7x7x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x7x7x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x7x7x15xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x7x7x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x7x7x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x7x7x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x7x7x15xf32>\n    return %2 : tensor<130x7x7x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x7x7x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x7x7x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x7x7x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x7x7x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x7x7x15xf32>, tensor<130x7x7x15xf32>) outs(%arg2: tensor<130x7x7x15xf32>) -> tensor<130x7x7x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x7x7x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x7x7x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 97159
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x28x7x228xf32>, tensor<7x28x7x228xf32>) outs(%arg2: tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x28x7x228xf32>, tensor<7x28x7x228xf32>) outs(%arg2: tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x28x7x228xf32>, %arg1: tensor<7x28x7x228xf32>, %arg2: tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x28x7x228xf32>, tensor<7x28x7x228xf32>) outs(%arg2: tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32>\n  return %ret : tensor<7x28x7x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x28x7x228xf32>, %arg1: tensor<7x28x7x228xf32>, %arg2: tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x28x7x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x28x7x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x28x7x228xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x28x7x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x28x7x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x28x7x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x28x7x228xf32>\n    return %2 : tensor<7x28x7x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x28x7x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x28x7x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x28x7x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x28x7x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x28x7x228xf32>, tensor<7x28x7x228xf32>) outs(%arg2: tensor<7x28x7x228xf32>) -> tensor<7x28x7x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x28x7x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x28x7x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 250061
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x112x14x14xf32>, tensor<240x112x14x14xf32>) outs(%arg2: tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x112x14x14xf32>, tensor<240x112x14x14xf32>) outs(%arg2: tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x112x14x14xf32>, %arg1: tensor<240x112x14x14xf32>, %arg2: tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x112x14x14xf32>, tensor<240x112x14x14xf32>) outs(%arg2: tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32>\n  return %ret : tensor<240x112x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x112x14x14xf32>, %arg1: tensor<240x112x14x14xf32>, %arg2: tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x112x14x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x112x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x112x14x14xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x112x14x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x112x14x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x112x14x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x112x14x14xf32>\n    return %2 : tensor<240x112x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x112x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x112x14x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x112x14x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x112x14x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x112x14x14xf32>, tensor<240x112x14x14xf32>) outs(%arg2: tensor<240x112x14x14xf32>) -> tensor<240x112x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x112x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x112x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5949441
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x14x28x7xf32>, tensor<28x14x28x7xf32>) outs(%arg2: tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x14x28x7xf32>, tensor<28x14x28x7xf32>) outs(%arg2: tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x14x28x7xf32>, %arg1: tensor<28x14x28x7xf32>, %arg2: tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x14x28x7xf32>, tensor<28x14x28x7xf32>) outs(%arg2: tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32>\n  return %ret : tensor<28x14x28x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x14x28x7xf32>, %arg1: tensor<28x14x28x7xf32>, %arg2: tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x14x28x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x14x28x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x14x28x7xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x14x28x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x14x28x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x14x28x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x14x28x7xf32>\n    return %2 : tensor<28x14x28x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x14x28x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x14x28x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x14x28x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x14x28x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x14x28x7xf32>, tensor<28x14x28x7xf32>) outs(%arg2: tensor<28x14x28x7xf32>) -> tensor<28x14x28x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x14x28x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x14x28x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 82368
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x130x112x7xf32>, tensor<15x130x112x7xf32>) outs(%arg2: tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x130x112x7xf32>, tensor<15x130x112x7xf32>) outs(%arg2: tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x130x112x7xf32>, %arg1: tensor<15x130x112x7xf32>, %arg2: tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x130x112x7xf32>, tensor<15x130x112x7xf32>) outs(%arg2: tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32>\n  return %ret : tensor<15x130x112x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x130x112x7xf32>, %arg1: tensor<15x130x112x7xf32>, %arg2: tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x130x112x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x130x112x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x130x112x7xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x130x112x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x130x112x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x130x112x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x130x112x7xf32>\n    return %2 : tensor<15x130x112x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x130x112x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x130x112x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x130x112x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x130x112x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x130x112x7xf32>, tensor<15x130x112x7xf32>) outs(%arg2: tensor<15x130x112x7xf32>) -> tensor<15x130x112x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x130x112x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x130x112x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1578242
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x130x15x56xf32>, tensor<120x130x15x56xf32>) outs(%arg2: tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x130x15x56xf32>, tensor<120x130x15x56xf32>) outs(%arg2: tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x130x15x56xf32>, %arg1: tensor<120x130x15x56xf32>, %arg2: tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x130x15x56xf32>, tensor<120x130x15x56xf32>) outs(%arg2: tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32>\n  return %ret : tensor<120x130x15x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x130x15x56xf32>, %arg1: tensor<120x130x15x56xf32>, %arg2: tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x130x15x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x130x15x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x130x15x56xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x130x15x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x130x15x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x130x15x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x130x15x56xf32>\n    return %2 : tensor<120x130x15x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x130x15x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x130x15x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x130x15x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x130x15x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x130x15x56xf32>, tensor<120x130x15x56xf32>) outs(%arg2: tensor<120x130x15x56xf32>) -> tensor<120x130x15x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x130x15x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x130x15x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 16186982
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x130x28x7xf32>, tensor<14x130x28x7xf32>) outs(%arg2: tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x130x28x7xf32>, tensor<14x130x28x7xf32>) outs(%arg2: tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x130x28x7xf32>, %arg1: tensor<14x130x28x7xf32>, %arg2: tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x130x28x7xf32>, tensor<14x130x28x7xf32>) outs(%arg2: tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32>\n  return %ret : tensor<14x130x28x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x130x28x7xf32>, %arg1: tensor<14x130x28x7xf32>, %arg2: tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x130x28x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x130x28x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x130x28x7xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x130x28x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x130x28x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x130x28x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x130x28x7xf32>\n    return %2 : tensor<14x130x28x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x130x28x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x130x28x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x130x28x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x130x28x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x130x28x7xf32>, tensor<14x130x28x7xf32>) outs(%arg2: tensor<14x130x28x7xf32>) -> tensor<14x130x28x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x130x28x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x130x28x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 383126
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x228x14x130xf32>, tensor<228x228x14x130xf32>) outs(%arg2: tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x228x14x130xf32>, tensor<228x228x14x130xf32>) outs(%arg2: tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x228x14x130xf32>, %arg1: tensor<228x228x14x130xf32>, %arg2: tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x228x14x130xf32>, tensor<228x228x14x130xf32>) outs(%arg2: tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32>\n  return %ret : tensor<228x228x14x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x228x14x130xf32>, %arg1: tensor<228x228x14x130xf32>, %arg2: tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x228x14x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x228x14x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x228x14x130xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x228x14x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x228x14x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x228x14x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x228x14x130xf32>\n    return %2 : tensor<228x228x14x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x228x14x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x228x14x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x228x14x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x228x14x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x228x14x130xf32>, tensor<228x228x14x130xf32>) outs(%arg2: tensor<228x228x14x130xf32>) -> tensor<228x228x14x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x228x14x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x228x14x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 113444411
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x130x112x56xf32>, tensor<112x130x112x56xf32>) outs(%arg2: tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x130x112x56xf32>, tensor<112x130x112x56xf32>) outs(%arg2: tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x130x112x56xf32>, %arg1: tensor<112x130x112x56xf32>, %arg2: tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x130x112x56xf32>, tensor<112x130x112x56xf32>) outs(%arg2: tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32>\n  return %ret : tensor<112x130x112x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x130x112x56xf32>, %arg1: tensor<112x130x112x56xf32>, %arg2: tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x130x112x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x130x112x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x130x112x56xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x130x112x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x130x112x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x130x112x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x130x112x56xf32>\n    return %2 : tensor<112x130x112x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x130x112x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x130x112x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x130x112x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x130x112x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x130x112x56xf32>, tensor<112x130x112x56xf32>) outs(%arg2: tensor<112x130x112x56xf32>) -> tensor<112x130x112x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x130x112x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x130x112x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 107975793
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x15x112x228xf32>, tensor<240x15x112x228xf32>) outs(%arg2: tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x15x112x228xf32>, tensor<240x15x112x228xf32>) outs(%arg2: tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x15x112x228xf32>, %arg1: tensor<240x15x112x228xf32>, %arg2: tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x15x112x228xf32>, tensor<240x15x112x228xf32>) outs(%arg2: tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32>\n  return %ret : tensor<240x15x112x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x15x112x228xf32>, %arg1: tensor<240x15x112x228xf32>, %arg2: tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x15x112x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x15x112x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x15x112x228xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x15x112x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x15x112x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x15x112x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x15x112x228xf32>\n    return %2 : tensor<240x15x112x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x15x112x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x15x112x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x15x112x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x15x112x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x15x112x228xf32>, tensor<240x15x112x228xf32>) outs(%arg2: tensor<240x15x112x228xf32>) -> tensor<240x15x112x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x15x112x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x15x112x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 111911262
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x240x240x228xf32>, tensor<15x240x240x228xf32>) outs(%arg2: tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x240x240x228xf32>, tensor<15x240x240x228xf32>) outs(%arg2: tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x240x240x228xf32>, %arg1: tensor<15x240x240x228xf32>, %arg2: tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x240x240x228xf32>, tensor<15x240x240x228xf32>) outs(%arg2: tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32>\n  return %ret : tensor<15x240x240x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x240x240x228xf32>, %arg1: tensor<15x240x240x228xf32>, %arg2: tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x240x240x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x240x240x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x240x240x228xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x240x240x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x240x240x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x240x240x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x240x240x228xf32>\n    return %2 : tensor<15x240x240x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x240x240x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x240x240x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x240x240x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x240x240x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x240x240x228xf32>, tensor<15x240x240x228xf32>) outs(%arg2: tensor<15x240x240x228xf32>) -> tensor<15x240x240x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x240x240x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x240x240x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 235217298
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x130x120x7xf32>, tensor<14x130x120x7xf32>) outs(%arg2: tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x130x120x7xf32>, tensor<14x130x120x7xf32>) outs(%arg2: tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x130x120x7xf32>, %arg1: tensor<14x130x120x7xf32>, %arg2: tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x130x120x7xf32>, tensor<14x130x120x7xf32>) outs(%arg2: tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32>\n  return %ret : tensor<14x130x120x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x130x120x7xf32>, %arg1: tensor<14x130x120x7xf32>, %arg2: tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x130x120x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x130x120x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x130x120x7xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x130x120x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x130x120x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x130x120x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x130x120x7xf32>\n    return %2 : tensor<14x130x120x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x130x120x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x130x120x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x130x120x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x130x120x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x130x120x7xf32>, tensor<14x130x120x7xf32>) outs(%arg2: tensor<14x130x120x7xf32>) -> tensor<14x130x120x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x130x120x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x130x120x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1576965
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x240x130x120xf32>, tensor<56x240x130x120xf32>) outs(%arg2: tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x240x130x120xf32>, tensor<56x240x130x120xf32>) outs(%arg2: tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x240x130x120xf32>, %arg1: tensor<56x240x130x120xf32>, %arg2: tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x240x130x120xf32>, tensor<56x240x130x120xf32>) outs(%arg2: tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32>\n  return %ret : tensor<56x240x130x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x240x130x120xf32>, %arg1: tensor<56x240x130x120xf32>, %arg2: tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x240x130x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x240x130x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x240x130x120xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x240x130x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x240x130x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x240x130x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x240x130x120xf32>\n    return %2 : tensor<56x240x130x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x240x130x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x240x130x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x240x130x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x240x130x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x240x130x120xf32>, tensor<56x240x130x120xf32>) outs(%arg2: tensor<56x240x130x120xf32>) -> tensor<56x240x130x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x240x130x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x240x130x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 251610384
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x14x15x228xf32>, tensor<56x14x15x228xf32>) outs(%arg2: tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x14x15x228xf32>, tensor<56x14x15x228xf32>) outs(%arg2: tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x14x15x228xf32>, %arg1: tensor<56x14x15x228xf32>, %arg2: tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x14x15x228xf32>, tensor<56x14x15x228xf32>) outs(%arg2: tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32>\n  return %ret : tensor<56x14x15x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x14x15x228xf32>, %arg1: tensor<56x14x15x228xf32>, %arg2: tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x14x15x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x14x15x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x14x15x228xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x14x15x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x14x15x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x14x15x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x14x15x228xf32>\n    return %2 : tensor<56x14x15x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x14x15x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x14x15x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x14x15x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x14x15x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x14x15x228xf32>, tensor<56x14x15x228xf32>) outs(%arg2: tensor<56x14x15x228xf32>) -> tensor<56x14x15x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x14x15x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x14x15x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2234771
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x15x28x56xf32>, tensor<120x15x28x56xf32>) outs(%arg2: tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x15x28x56xf32>, tensor<120x15x28x56xf32>) outs(%arg2: tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x15x28x56xf32>, %arg1: tensor<120x15x28x56xf32>, %arg2: tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x15x28x56xf32>, tensor<120x15x28x56xf32>) outs(%arg2: tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32>\n  return %ret : tensor<120x15x28x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x15x28x56xf32>, %arg1: tensor<120x15x28x56xf32>, %arg2: tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x15x28x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x15x28x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x15x28x56xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x15x28x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x15x28x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x15x28x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x15x28x56xf32>\n    return %2 : tensor<120x15x28x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x15x28x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x15x28x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x15x28x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x15x28x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x15x28x56xf32>, tensor<120x15x28x56xf32>) outs(%arg2: tensor<120x15x28x56xf32>) -> tensor<120x15x28x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x15x28x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x15x28x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2459954
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x130x28x240xf32>, tensor<15x130x28x240xf32>) outs(%arg2: tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x130x28x240xf32>, tensor<15x130x28x240xf32>) outs(%arg2: tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x130x28x240xf32>, %arg1: tensor<15x130x28x240xf32>, %arg2: tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x130x28x240xf32>, tensor<15x130x28x240xf32>) outs(%arg2: tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32>\n  return %ret : tensor<15x130x28x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x130x28x240xf32>, %arg1: tensor<15x130x28x240xf32>, %arg2: tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x130x28x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x130x28x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x130x28x240xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x130x28x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x130x28x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x130x28x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x130x28x240xf32>\n    return %2 : tensor<15x130x28x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x130x28x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x130x28x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x130x28x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x130x28x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x130x28x240xf32>, tensor<15x130x28x240xf32>) outs(%arg2: tensor<15x130x28x240xf32>) -> tensor<15x130x28x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x130x28x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x130x28x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 16418411
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x56x130x240xf32>, tensor<224x56x130x240xf32>) outs(%arg2: tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x56x130x240xf32>, tensor<224x56x130x240xf32>) outs(%arg2: tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x56x130x240xf32>, %arg1: tensor<224x56x130x240xf32>, %arg2: tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x56x130x240xf32>, tensor<224x56x130x240xf32>) outs(%arg2: tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32>\n  return %ret : tensor<224x56x130x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x56x130x240xf32>, %arg1: tensor<224x56x130x240xf32>, %arg2: tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x56x130x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x56x130x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x56x130x240xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x56x130x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x56x130x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x56x130x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x56x130x240xf32>\n    return %2 : tensor<224x56x130x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x56x130x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x56x130x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x56x130x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x56x130x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x56x130x240xf32>, tensor<224x56x130x240xf32>) outs(%arg2: tensor<224x56x130x240xf32>) -> tensor<224x56x130x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x56x130x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x56x130x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 463583274
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x15x240x28xf32>, tensor<112x15x240x28xf32>) outs(%arg2: tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x15x240x28xf32>, tensor<112x15x240x28xf32>) outs(%arg2: tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x15x240x28xf32>, %arg1: tensor<112x15x240x28xf32>, %arg2: tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x15x240x28xf32>, tensor<112x15x240x28xf32>) outs(%arg2: tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32>\n  return %ret : tensor<112x15x240x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x15x240x28xf32>, %arg1: tensor<112x15x240x28xf32>, %arg2: tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x15x240x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x15x240x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x15x240x28xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x15x240x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x15x240x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x15x240x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x15x240x28xf32>\n    return %2 : tensor<112x15x240x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x15x240x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x15x240x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x15x240x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x15x240x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x15x240x28xf32>, tensor<112x15x240x28xf32>) outs(%arg2: tensor<112x15x240x28xf32>) -> tensor<112x15x240x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x15x240x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x15x240x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13858799
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x7x14x7xf32>, tensor<150x7x14x7xf32>) outs(%arg2: tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x7x14x7xf32>, tensor<150x7x14x7xf32>) outs(%arg2: tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x7x14x7xf32>, %arg1: tensor<150x7x14x7xf32>, %arg2: tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x7x14x7xf32>, tensor<150x7x14x7xf32>) outs(%arg2: tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32>\n  return %ret : tensor<150x7x14x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x7x14x7xf32>, %arg1: tensor<150x7x14x7xf32>, %arg2: tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x7x14x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x7x14x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x7x14x7xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x7x14x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x7x14x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x7x14x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x7x14x7xf32>\n    return %2 : tensor<150x7x14x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x7x14x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x7x14x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x7x14x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x7x14x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x7x14x7xf32>, tensor<150x7x14x7xf32>) outs(%arg2: tensor<150x7x14x7xf32>) -> tensor<150x7x14x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x7x14x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x7x14x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 110010
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x28x120x15xf32>, tensor<56x28x120x15xf32>) outs(%arg2: tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x28x120x15xf32>, tensor<56x28x120x15xf32>) outs(%arg2: tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x28x120x15xf32>, %arg1: tensor<56x28x120x15xf32>, %arg2: tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x28x120x15xf32>, tensor<56x28x120x15xf32>) outs(%arg2: tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32>\n  return %ret : tensor<56x28x120x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x28x120x15xf32>, %arg1: tensor<56x28x120x15xf32>, %arg2: tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x28x120x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x28x120x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x28x120x15xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x28x120x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x28x120x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x28x120x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x28x120x15xf32>\n    return %2 : tensor<56x28x120x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x28x120x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x28x120x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x28x120x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x28x120x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x28x120x15xf32>, tensor<56x28x120x15xf32>) outs(%arg2: tensor<56x28x120x15xf32>) -> tensor<56x28x120x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x28x120x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x28x120x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2689406
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x240x130x56xf32>, tensor<228x240x130x56xf32>) outs(%arg2: tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x240x130x56xf32>, tensor<228x240x130x56xf32>) outs(%arg2: tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x240x130x56xf32>, %arg1: tensor<228x240x130x56xf32>, %arg2: tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x240x130x56xf32>, tensor<228x240x130x56xf32>) outs(%arg2: tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32>\n  return %ret : tensor<228x240x130x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x240x130x56xf32>, %arg1: tensor<228x240x130x56xf32>, %arg2: tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x240x130x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x240x130x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x240x130x56xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x240x130x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x240x130x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x240x130x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x240x130x56xf32>\n    return %2 : tensor<228x240x130x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x240x130x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x240x130x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x240x130x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x240x130x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x240x130x56xf32>, tensor<228x240x130x56xf32>) outs(%arg2: tensor<228x240x130x56xf32>) -> tensor<228x240x130x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x240x130x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x240x130x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 493074136
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x56x15x112xf32>, tensor<15x56x15x112xf32>) outs(%arg2: tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x56x15x112xf32>, tensor<15x56x15x112xf32>) outs(%arg2: tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x56x15x112xf32>, %arg1: tensor<15x56x15x112xf32>, %arg2: tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x56x15x112xf32>, tensor<15x56x15x112xf32>) outs(%arg2: tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32>\n  return %ret : tensor<15x56x15x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x56x15x112xf32>, %arg1: tensor<15x56x15x112xf32>, %arg2: tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x56x15x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x56x15x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x56x15x112xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x56x15x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x56x15x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x56x15x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x56x15x112xf32>\n    return %2 : tensor<15x56x15x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x56x15x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x56x15x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x56x15x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x56x15x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x56x15x112xf32>, tensor<15x56x15x112xf32>) outs(%arg2: tensor<15x56x15x112xf32>) -> tensor<15x56x15x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x56x15x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x56x15x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1079614
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x150x228x150xf32>, tensor<112x150x228x150xf32>) outs(%arg2: tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x150x228x150xf32>, tensor<112x150x228x150xf32>) outs(%arg2: tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x150x228x150xf32>, %arg1: tensor<112x150x228x150xf32>, %arg2: tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x150x228x150xf32>, tensor<112x150x228x150xf32>) outs(%arg2: tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32>\n  return %ret : tensor<112x150x228x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x150x228x150xf32>, %arg1: tensor<112x150x228x150xf32>, %arg2: tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x150x228x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x150x228x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x150x228x150xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x150x228x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x150x228x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x150x228x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x150x228x150xf32>\n    return %2 : tensor<112x150x228x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x150x228x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x150x228x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x150x228x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x150x228x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x150x228x150xf32>, tensor<112x150x228x150xf32>) outs(%arg2: tensor<112x150x228x150xf32>) -> tensor<112x150x228x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x150x228x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x150x228x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 693556196
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x112x15x28xf32>, tensor<28x112x15x28xf32>) outs(%arg2: tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x112x15x28xf32>, tensor<28x112x15x28xf32>) outs(%arg2: tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x112x15x28xf32>, %arg1: tensor<28x112x15x28xf32>, %arg2: tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x112x15x28xf32>, tensor<28x112x15x28xf32>) outs(%arg2: tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32>\n  return %ret : tensor<28x112x15x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x112x15x28xf32>, %arg1: tensor<28x112x15x28xf32>, %arg2: tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x112x15x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x112x15x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x112x15x28xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x112x15x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x112x15x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x112x15x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x112x15x28xf32>\n    return %2 : tensor<28x112x15x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x112x15x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x112x15x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x112x15x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x112x15x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x112x15x28xf32>, tensor<28x112x15x28xf32>) outs(%arg2: tensor<28x112x15x28xf32>) -> tensor<28x112x15x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x112x15x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x112x15x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1195822
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x15x228x224xf32>, tensor<228x15x228x224xf32>) outs(%arg2: tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x15x228x224xf32>, tensor<228x15x228x224xf32>) outs(%arg2: tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x15x228x224xf32>, %arg1: tensor<228x15x228x224xf32>, %arg2: tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x15x228x224xf32>, tensor<228x15x228x224xf32>) outs(%arg2: tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32>\n  return %ret : tensor<228x15x228x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x15x228x224xf32>, %arg1: tensor<228x15x228x224xf32>, %arg2: tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x15x228x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x15x228x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x15x228x224xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x15x228x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x15x228x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x15x228x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x15x228x224xf32>\n    return %2 : tensor<228x15x228x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x15x228x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x15x228x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x15x228x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x15x228x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x15x228x224xf32>, tensor<228x15x228x224xf32>) outs(%arg2: tensor<228x15x228x224xf32>) -> tensor<228x15x228x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x15x228x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x15x228x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 206596868
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x228x15x228xf32>, tensor<15x228x15x228xf32>) outs(%arg2: tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x228x15x228xf32>, tensor<15x228x15x228xf32>) outs(%arg2: tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x228x15x228xf32>, %arg1: tensor<15x228x15x228xf32>, %arg2: tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x228x15x228xf32>, tensor<15x228x15x228xf32>) outs(%arg2: tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32>\n  return %ret : tensor<15x228x15x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x228x15x228xf32>, %arg1: tensor<15x228x15x228xf32>, %arg2: tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x228x15x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x228x15x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x228x15x228xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x228x15x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x228x15x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x228x15x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x228x15x228xf32>\n    return %2 : tensor<15x228x15x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x228x15x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x228x15x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x228x15x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x228x15x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x228x15x228xf32>, tensor<15x228x15x228xf32>) outs(%arg2: tensor<15x228x15x228xf32>) -> tensor<15x228x15x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x228x15x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x228x15x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14680737
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x150x28x130xf32>, tensor<224x150x28x130xf32>) outs(%arg2: tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x150x28x130xf32>, tensor<224x150x28x130xf32>) outs(%arg2: tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x150x28x130xf32>, %arg1: tensor<224x150x28x130xf32>, %arg2: tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x150x28x130xf32>, tensor<224x150x28x130xf32>) outs(%arg2: tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32>\n  return %ret : tensor<224x150x28x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x150x28x130xf32>, %arg1: tensor<224x150x28x130xf32>, %arg2: tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x150x28x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x150x28x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x150x28x130xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x150x28x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x150x28x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x150x28x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x150x28x130xf32>\n    return %2 : tensor<224x150x28x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x150x28x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x150x28x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x150x28x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x150x28x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x150x28x130xf32>, tensor<224x150x28x130xf32>) outs(%arg2: tensor<224x150x28x130xf32>) -> tensor<224x150x28x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x150x28x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x150x28x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 145693316
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x130x56x28xf32>, tensor<56x130x56x28xf32>) outs(%arg2: tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x130x56x28xf32>, tensor<56x130x56x28xf32>) outs(%arg2: tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x130x56x28xf32>, %arg1: tensor<56x130x56x28xf32>, %arg2: tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x130x56x28xf32>, tensor<56x130x56x28xf32>) outs(%arg2: tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32>\n  return %ret : tensor<56x130x56x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x130x56x28xf32>, %arg1: tensor<56x130x56x28xf32>, %arg2: tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x130x56x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x130x56x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x130x56x28xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x130x56x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x130x56x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x130x56x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x130x56x28xf32>\n    return %2 : tensor<56x130x56x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x130x56x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x130x56x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x130x56x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x130x56x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x130x56x28xf32>, tensor<56x130x56x28xf32>) outs(%arg2: tensor<56x130x56x28xf32>) -> tensor<56x130x56x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x130x56x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x130x56x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14646679
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x28x240x150xf32>, tensor<228x28x240x150xf32>) outs(%arg2: tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x28x240x150xf32>, tensor<228x28x240x150xf32>) outs(%arg2: tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x28x240x150xf32>, %arg1: tensor<228x28x240x150xf32>, %arg2: tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x28x240x150xf32>, tensor<228x28x240x150xf32>) outs(%arg2: tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32>\n  return %ret : tensor<228x28x240x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x28x240x150xf32>, %arg1: tensor<228x28x240x150xf32>, %arg2: tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x28x240x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x28x240x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x28x240x150xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x28x240x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x28x240x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x28x240x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x28x240x150xf32>\n    return %2 : tensor<228x28x240x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x28x240x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x28x240x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x28x240x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x28x240x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x28x240x150xf32>, tensor<228x28x240x150xf32>) outs(%arg2: tensor<228x28x240x150xf32>) -> tensor<228x28x240x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x28x240x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x28x240x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 272381817
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x130x56x130xf32>, tensor<28x130x56x130xf32>) outs(%arg2: tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x130x56x130xf32>, tensor<28x130x56x130xf32>) outs(%arg2: tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x130x56x130xf32>, %arg1: tensor<28x130x56x130xf32>, %arg2: tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x130x56x130xf32>, tensor<28x130x56x130xf32>) outs(%arg2: tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32>\n  return %ret : tensor<28x130x56x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x130x56x130xf32>, %arg1: tensor<28x130x56x130xf32>, %arg2: tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x130x56x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x130x56x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x130x56x130xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x130x56x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x130x56x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x130x56x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x130x56x130xf32>\n    return %2 : tensor<28x130x56x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x130x56x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x130x56x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x130x56x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x130x56x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x130x56x130xf32>, tensor<28x130x56x130xf32>) outs(%arg2: tensor<28x130x56x130xf32>) -> tensor<28x130x56x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x130x56x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x130x56x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 32144842
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x150x240x120xf32>, tensor<14x150x240x120xf32>) outs(%arg2: tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x150x240x120xf32>, tensor<14x150x240x120xf32>) outs(%arg2: tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x150x240x120xf32>, %arg1: tensor<14x150x240x120xf32>, %arg2: tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x150x240x120xf32>, tensor<14x150x240x120xf32>) outs(%arg2: tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32>\n  return %ret : tensor<14x150x240x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x150x240x120xf32>, %arg1: tensor<14x150x240x120xf32>, %arg2: tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x150x240x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x150x240x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x150x240x120xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x150x240x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x150x240x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x150x240x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x150x240x120xf32>\n    return %2 : tensor<14x150x240x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x150x240x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x150x240x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x150x240x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x150x240x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x150x240x120xf32>, tensor<14x150x240x120xf32>) outs(%arg2: tensor<14x150x240x120xf32>) -> tensor<14x150x240x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x150x240x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x150x240x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 72602628
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x228x228x15xf32>, tensor<15x228x228x15xf32>) outs(%arg2: tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x228x228x15xf32>, tensor<15x228x228x15xf32>) outs(%arg2: tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x228x228x15xf32>, %arg1: tensor<15x228x228x15xf32>, %arg2: tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x228x228x15xf32>, tensor<15x228x228x15xf32>) outs(%arg2: tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32>\n  return %ret : tensor<15x228x228x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x228x228x15xf32>, %arg1: tensor<15x228x228x15xf32>, %arg2: tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x228x228x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x228x228x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x228x228x15xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x228x228x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x228x228x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x228x228x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x228x228x15xf32>\n    return %2 : tensor<15x228x228x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x228x228x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x228x228x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x228x228x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x228x228x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x228x228x15xf32>, tensor<15x228x228x15xf32>) outs(%arg2: tensor<15x228x228x15xf32>) -> tensor<15x228x228x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x228x228x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x228x228x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14370963
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x120x150x28xf32>, tensor<228x120x150x28xf32>) outs(%arg2: tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x120x150x28xf32>, tensor<228x120x150x28xf32>) outs(%arg2: tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x120x150x28xf32>, %arg1: tensor<228x120x150x28xf32>, %arg2: tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x120x150x28xf32>, tensor<228x120x150x28xf32>) outs(%arg2: tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32>\n  return %ret : tensor<228x120x150x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x120x150x28xf32>, %arg1: tensor<228x120x150x28xf32>, %arg2: tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x120x150x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x120x150x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x120x150x28xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x120x150x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x120x150x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x120x150x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x120x150x28xf32>\n    return %2 : tensor<228x120x150x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x120x150x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x120x150x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x120x150x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x120x150x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x120x150x28xf32>, tensor<228x120x150x28xf32>) outs(%arg2: tensor<228x120x150x28xf32>) -> tensor<228x120x150x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x120x150x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x120x150x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 139236126
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x7x14x28xf32>, tensor<224x7x14x28xf32>) outs(%arg2: tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x7x14x28xf32>, tensor<224x7x14x28xf32>) outs(%arg2: tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x7x14x28xf32>, %arg1: tensor<224x7x14x28xf32>, %arg2: tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x7x14x28xf32>, tensor<224x7x14x28xf32>) outs(%arg2: tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32>\n  return %ret : tensor<224x7x14x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x7x14x28xf32>, %arg1: tensor<224x7x14x28xf32>, %arg2: tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x7x14x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x7x14x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x7x14x28xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x7x14x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x7x14x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x7x14x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x7x14x28xf32>\n    return %2 : tensor<224x7x14x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x7x14x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x7x14x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x7x14x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x7x14x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x7x14x28xf32>, tensor<224x7x14x28xf32>) outs(%arg2: tensor<224x7x14x28xf32>) -> tensor<224x7x14x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x7x14x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x7x14x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 561973
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x14x15x120xf32>, tensor<56x14x15x120xf32>) outs(%arg2: tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x14x15x120xf32>, tensor<56x14x15x120xf32>) outs(%arg2: tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x14x15x120xf32>, %arg1: tensor<56x14x15x120xf32>, %arg2: tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x14x15x120xf32>, tensor<56x14x15x120xf32>) outs(%arg2: tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32>\n  return %ret : tensor<56x14x15x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x14x15x120xf32>, %arg1: tensor<56x14x15x120xf32>, %arg2: tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x14x15x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x14x15x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x14x15x120xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x14x15x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x14x15x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x14x15x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x14x15x120xf32>\n    return %2 : tensor<56x14x15x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x14x15x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x14x15x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x14x15x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x14x15x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x14x15x120xf32>, tensor<56x14x15x120xf32>) outs(%arg2: tensor<56x14x15x120xf32>) -> tensor<56x14x15x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x14x15x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x14x15x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1071693
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x14x7x15xf32>, tensor<112x14x7x15xf32>) outs(%arg2: tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x14x7x15xf32>, tensor<112x14x7x15xf32>) outs(%arg2: tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x14x7x15xf32>, %arg1: tensor<112x14x7x15xf32>, %arg2: tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x14x7x15xf32>, tensor<112x14x7x15xf32>) outs(%arg2: tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32>\n  return %ret : tensor<112x14x7x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x14x7x15xf32>, %arg1: tensor<112x14x7x15xf32>, %arg2: tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x14x7x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x14x7x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x14x7x15xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x14x7x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x14x7x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x14x7x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x14x7x15xf32>\n    return %2 : tensor<112x14x7x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x14x7x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x14x7x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x14x7x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x14x7x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x14x7x15xf32>, tensor<112x14x7x15xf32>) outs(%arg2: tensor<112x14x7x15xf32>) -> tensor<112x14x7x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x14x7x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x14x7x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 157479
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x130x28x150xf32>, tensor<15x130x28x150xf32>) outs(%arg2: tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x130x28x150xf32>, tensor<15x130x28x150xf32>) outs(%arg2: tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x130x28x150xf32>, %arg1: tensor<15x130x28x150xf32>, %arg2: tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x130x28x150xf32>, tensor<15x130x28x150xf32>) outs(%arg2: tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32>\n  return %ret : tensor<15x130x28x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x130x28x150xf32>, %arg1: tensor<15x130x28x150xf32>, %arg2: tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x130x28x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x130x28x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x130x28x150xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x130x28x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x130x28x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x130x28x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x130x28x150xf32>\n    return %2 : tensor<15x130x28x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x130x28x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x130x28x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x130x28x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x130x28x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x130x28x150xf32>, tensor<15x130x28x150xf32>) outs(%arg2: tensor<15x130x28x150xf32>) -> tensor<15x130x28x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x130x28x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x130x28x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9268679
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x28x14x15xf32>, tensor<228x28x14x15xf32>) outs(%arg2: tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x28x14x15xf32>, tensor<228x28x14x15xf32>) outs(%arg2: tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x28x14x15xf32>, %arg1: tensor<228x28x14x15xf32>, %arg2: tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x28x14x15xf32>, tensor<228x28x14x15xf32>) outs(%arg2: tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32>\n  return %ret : tensor<228x28x14x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x28x14x15xf32>, %arg1: tensor<228x28x14x15xf32>, %arg2: tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x28x14x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x28x14x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x28x14x15xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x28x14x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x28x14x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x28x14x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x28x14x15xf32>\n    return %2 : tensor<228x28x14x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x28x14x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x28x14x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x28x14x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x28x14x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x28x14x15xf32>, tensor<228x28x14x15xf32>) outs(%arg2: tensor<228x28x14x15xf32>) -> tensor<228x28x14x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x28x14x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x28x14x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1297615
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x228x150x130xf32>, tensor<120x228x150x130xf32>) outs(%arg2: tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x228x150x130xf32>, tensor<120x228x150x130xf32>) outs(%arg2: tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x228x150x130xf32>, %arg1: tensor<120x228x150x130xf32>, %arg2: tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x228x150x130xf32>, tensor<120x228x150x130xf32>) outs(%arg2: tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32>\n  return %ret : tensor<120x228x150x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x228x150x130xf32>, %arg1: tensor<120x228x150x130xf32>, %arg2: tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x228x150x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x228x150x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x228x150x130xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x228x150x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x228x150x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x228x150x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x228x150x130xf32>\n    return %2 : tensor<120x228x150x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x228x150x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x228x150x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x228x150x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x228x150x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x228x150x130xf32>, tensor<120x228x150x130xf32>) outs(%arg2: tensor<120x228x150x130xf32>) -> tensor<120x228x150x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x228x150x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x228x150x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 645898274
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x7x150x14xf32>, tensor<120x7x150x14xf32>) outs(%arg2: tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x7x150x14xf32>, tensor<120x7x150x14xf32>) outs(%arg2: tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x7x150x14xf32>, %arg1: tensor<120x7x150x14xf32>, %arg2: tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x7x150x14xf32>, tensor<120x7x150x14xf32>) outs(%arg2: tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32>\n  return %ret : tensor<120x7x150x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x7x150x14xf32>, %arg1: tensor<120x7x150x14xf32>, %arg2: tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x7x150x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x7x150x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x7x150x14xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x7x150x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x7x150x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x7x150x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x7x150x14xf32>\n    return %2 : tensor<120x7x150x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x7x150x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x7x150x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x7x150x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x7x150x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x7x150x14xf32>, tensor<120x7x150x14xf32>) outs(%arg2: tensor<120x7x150x14xf32>) -> tensor<120x7x150x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x7x150x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x7x150x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1267322
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x15x7x15xf32>, tensor<228x15x7x15xf32>) outs(%arg2: tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x15x7x15xf32>, tensor<228x15x7x15xf32>) outs(%arg2: tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x15x7x15xf32>, %arg1: tensor<228x15x7x15xf32>, %arg2: tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x15x7x15xf32>, tensor<228x15x7x15xf32>) outs(%arg2: tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32>\n  return %ret : tensor<228x15x7x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x15x7x15xf32>, %arg1: tensor<228x15x7x15xf32>, %arg2: tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x15x7x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x15x7x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x15x7x15xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x15x7x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x15x7x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x15x7x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x15x7x15xf32>\n    return %2 : tensor<228x15x7x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x15x7x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x15x7x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x15x7x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x15x7x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x15x7x15xf32>, tensor<228x15x7x15xf32>) outs(%arg2: tensor<228x15x7x15xf32>) -> tensor<228x15x7x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x15x7x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x15x7x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 346175
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x130x120x224xf32>, tensor<150x130x120x224xf32>) outs(%arg2: tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x130x120x224xf32>, tensor<150x130x120x224xf32>) outs(%arg2: tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x130x120x224xf32>, %arg1: tensor<150x130x120x224xf32>, %arg2: tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x130x120x224xf32>, tensor<150x130x120x224xf32>) outs(%arg2: tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32>\n  return %ret : tensor<150x130x120x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x130x120x224xf32>, %arg1: tensor<150x130x120x224xf32>, %arg2: tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x130x120x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x130x120x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x130x120x224xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x130x120x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x130x120x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x130x120x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x130x120x224xf32>\n    return %2 : tensor<150x130x120x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x130x120x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x130x120x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x130x120x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x130x120x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x130x120x224xf32>, tensor<150x130x120x224xf32>) outs(%arg2: tensor<150x130x120x224xf32>) -> tensor<150x130x120x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x130x120x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x130x120x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 620277217
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x14x56x56xf32>, tensor<15x14x56x56xf32>) outs(%arg2: tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x14x56x56xf32>, tensor<15x14x56x56xf32>) outs(%arg2: tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x14x56x56xf32>, %arg1: tensor<15x14x56x56xf32>, %arg2: tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x14x56x56xf32>, tensor<15x14x56x56xf32>) outs(%arg2: tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32>\n  return %ret : tensor<15x14x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x14x56x56xf32>, %arg1: tensor<15x14x56x56xf32>, %arg2: tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x14x56x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x14x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x14x56x56xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x14x56x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x14x56x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x14x56x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x14x56x56xf32>\n    return %2 : tensor<15x14x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x14x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x14x56x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x14x56x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x14x56x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x14x56x56xf32>, tensor<15x14x56x56xf32>) outs(%arg2: tensor<15x14x56x56xf32>) -> tensor<15x14x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x14x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x14x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 540285
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x14x14x224xf32>, tensor<112x14x14x224xf32>) outs(%arg2: tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x14x14x224xf32>, tensor<112x14x14x224xf32>) outs(%arg2: tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x14x14x224xf32>, %arg1: tensor<112x14x14x224xf32>, %arg2: tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x14x14x224xf32>, tensor<112x14x14x224xf32>) outs(%arg2: tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32>\n  return %ret : tensor<112x14x14x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x14x14x224xf32>, %arg1: tensor<112x14x14x224xf32>, %arg2: tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x14x14x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x14x14x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x14x14x224xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x14x14x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x14x14x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x14x14x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x14x14x224xf32>\n    return %2 : tensor<112x14x14x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x14x14x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x14x14x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x14x14x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x14x14x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x14x14x224xf32>, tensor<112x14x14x224xf32>) outs(%arg2: tensor<112x14x14x224xf32>) -> tensor<112x14x14x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x14x14x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x14x14x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5496120
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x240x7x28xf32>, tensor<56x240x7x28xf32>) outs(%arg2: tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x240x7x28xf32>, tensor<56x240x7x28xf32>) outs(%arg2: tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x240x7x28xf32>, %arg1: tensor<56x240x7x28xf32>, %arg2: tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x240x7x28xf32>, tensor<56x240x7x28xf32>) outs(%arg2: tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32>\n  return %ret : tensor<56x240x7x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x240x7x28xf32>, %arg1: tensor<56x240x7x28xf32>, %arg2: tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x240x7x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x240x7x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x240x7x28xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x240x7x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x240x7x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x240x7x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x240x7x28xf32>\n    return %2 : tensor<56x240x7x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x240x7x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x240x7x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x240x7x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x240x7x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x240x7x28xf32>, tensor<56x240x7x28xf32>) outs(%arg2: tensor<56x240x7x28xf32>) -> tensor<56x240x7x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x240x7x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x240x7x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2511070
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x14x14x130xf32>, tensor<15x14x14x130xf32>) outs(%arg2: tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x14x14x130xf32>, tensor<15x14x14x130xf32>) outs(%arg2: tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x14x14x130xf32>, %arg1: tensor<15x14x14x130xf32>, %arg2: tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x14x14x130xf32>, tensor<15x14x14x130xf32>) outs(%arg2: tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32>\n  return %ret : tensor<15x14x14x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x14x14x130xf32>, %arg1: tensor<15x14x14x130xf32>, %arg2: tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x14x14x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x14x14x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x14x14x130xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x14x14x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x14x14x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x14x14x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x14x14x130xf32>\n    return %2 : tensor<15x14x14x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x14x14x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x14x14x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x14x14x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x14x14x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x14x14x130xf32>, tensor<15x14x14x130xf32>) outs(%arg2: tensor<15x14x14x130xf32>) -> tensor<15x14x14x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x14x14x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x14x14x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 322869
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x240x240x228xf32>, tensor<56x240x240x228xf32>) outs(%arg2: tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x240x240x228xf32>, tensor<56x240x240x228xf32>) outs(%arg2: tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x240x240x228xf32>, %arg1: tensor<56x240x240x228xf32>, %arg2: tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x240x240x228xf32>, tensor<56x240x240x228xf32>) outs(%arg2: tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32>\n  return %ret : tensor<56x240x240x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x240x240x228xf32>, %arg1: tensor<56x240x240x228xf32>, %arg2: tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x240x240x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x240x240x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x240x240x228xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x240x240x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x240x240x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x240x240x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x240x240x228xf32>\n    return %2 : tensor<56x240x240x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x240x240x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x240x240x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x240x240x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x240x240x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x240x240x228xf32>, tensor<56x240x240x228xf32>) outs(%arg2: tensor<56x240x240x228xf32>) -> tensor<56x240x240x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x240x240x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x240x240x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 882871359
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x120x130x112xf32>, tensor<56x120x130x112xf32>) outs(%arg2: tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x120x130x112xf32>, tensor<56x120x130x112xf32>) outs(%arg2: tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x120x130x112xf32>, %arg1: tensor<56x120x130x112xf32>, %arg2: tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x120x130x112xf32>, tensor<56x120x130x112xf32>) outs(%arg2: tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32>\n  return %ret : tensor<56x120x130x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x120x130x112xf32>, %arg1: tensor<56x120x130x112xf32>, %arg2: tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x120x130x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x120x130x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x120x130x112xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x120x130x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x120x130x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x120x130x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x120x130x112xf32>\n    return %2 : tensor<56x120x130x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x120x130x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x120x130x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x120x130x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x120x130x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x120x130x112xf32>, tensor<56x120x130x112xf32>) outs(%arg2: tensor<56x120x130x112xf32>) -> tensor<56x120x130x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x120x130x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x120x130x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 117267240
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x228x228x56xf32>, tensor<7x228x228x56xf32>) outs(%arg2: tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x228x228x56xf32>, tensor<7x228x228x56xf32>) outs(%arg2: tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x228x228x56xf32>, %arg1: tensor<7x228x228x56xf32>, %arg2: tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x228x228x56xf32>, tensor<7x228x228x56xf32>) outs(%arg2: tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32>\n  return %ret : tensor<7x228x228x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x228x228x56xf32>, %arg1: tensor<7x228x228x56xf32>, %arg2: tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x228x228x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x228x228x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x228x228x56xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x228x228x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x228x228x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x228x228x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x228x228x56xf32>\n    return %2 : tensor<7x228x228x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x228x228x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x228x228x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x228x228x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x228x228x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x228x228x56xf32>, tensor<7x228x228x56xf32>) outs(%arg2: tensor<7x228x228x56xf32>) -> tensor<7x228x228x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x228x228x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x228x228x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 24322948
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x120x130x56xf32>, tensor<120x120x130x56xf32>) outs(%arg2: tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x120x130x56xf32>, tensor<120x120x130x56xf32>) outs(%arg2: tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x120x130x56xf32>, %arg1: tensor<120x120x130x56xf32>, %arg2: tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x120x130x56xf32>, tensor<120x120x130x56xf32>) outs(%arg2: tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32>\n  return %ret : tensor<120x120x130x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x120x130x56xf32>, %arg1: tensor<120x120x130x56xf32>, %arg2: tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x120x130x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x120x130x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x120x130x56xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x120x130x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x120x130x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x120x130x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x120x130x56xf32>\n    return %2 : tensor<120x120x130x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x120x130x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x120x130x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x120x130x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x120x130x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x120x130x56xf32>, tensor<120x120x130x56xf32>) outs(%arg2: tensor<120x120x130x56xf32>) -> tensor<120x120x130x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x120x130x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x120x130x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 123917530
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x112x56x15xf32>, tensor<7x112x56x15xf32>) outs(%arg2: tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x112x56x15xf32>, tensor<7x112x56x15xf32>) outs(%arg2: tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x112x56x15xf32>, %arg1: tensor<7x112x56x15xf32>, %arg2: tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x112x56x15xf32>, tensor<7x112x56x15xf32>) outs(%arg2: tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32>\n  return %ret : tensor<7x112x56x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x112x56x15xf32>, %arg1: tensor<7x112x56x15xf32>, %arg2: tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x112x56x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x112x56x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x112x56x15xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x112x56x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x112x56x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x112x56x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x112x56x15xf32>\n    return %2 : tensor<7x112x56x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x112x56x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x112x56x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x112x56x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x112x56x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x112x56x15xf32>, tensor<7x112x56x15xf32>) outs(%arg2: tensor<7x112x56x15xf32>) -> tensor<7x112x56x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x112x56x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x112x56x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 612853
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x15x56x14xf32>, tensor<56x15x56x14xf32>) outs(%arg2: tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x15x56x14xf32>, tensor<56x15x56x14xf32>) outs(%arg2: tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x15x56x14xf32>, %arg1: tensor<56x15x56x14xf32>, %arg2: tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x15x56x14xf32>, tensor<56x15x56x14xf32>) outs(%arg2: tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32>\n  return %ret : tensor<56x15x56x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x15x56x14xf32>, %arg1: tensor<56x15x56x14xf32>, %arg2: tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x15x56x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x15x56x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x15x56x14xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x15x56x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x15x56x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x15x56x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x15x56x14xf32>\n    return %2 : tensor<56x15x56x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x15x56x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x15x56x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x15x56x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x15x56x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x15x56x14xf32>, tensor<56x15x56x14xf32>) outs(%arg2: tensor<56x15x56x14xf32>) -> tensor<56x15x56x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x15x56x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x15x56x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 618209
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x112x120x224xf32>, tensor<112x112x120x224xf32>) outs(%arg2: tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x112x120x224xf32>, tensor<112x112x120x224xf32>) outs(%arg2: tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x112x120x224xf32>, %arg1: tensor<112x112x120x224xf32>, %arg2: tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x112x120x224xf32>, tensor<112x112x120x224xf32>) outs(%arg2: tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32>\n  return %ret : tensor<112x112x120x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x112x120x224xf32>, %arg1: tensor<112x112x120x224xf32>, %arg2: tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x112x120x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x112x120x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x112x120x224xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x112x120x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x112x120x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x112x120x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x112x120x224xf32>\n    return %2 : tensor<112x112x120x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x112x120x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x112x120x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x112x120x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x112x120x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x112x120x224xf32>, tensor<112x112x120x224xf32>) outs(%arg2: tensor<112x112x120x224xf32>) -> tensor<112x112x120x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x112x120x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x112x120x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 404542822
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x28x224x14xf32>, tensor<120x28x224x14xf32>) outs(%arg2: tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x28x224x14xf32>, tensor<120x28x224x14xf32>) outs(%arg2: tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x28x224x14xf32>, %arg1: tensor<120x28x224x14xf32>, %arg2: tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x28x224x14xf32>, tensor<120x28x224x14xf32>) outs(%arg2: tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32>\n  return %ret : tensor<120x28x224x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x28x224x14xf32>, %arg1: tensor<120x28x224x14xf32>, %arg2: tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x28x224x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x28x224x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x28x224x14xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x28x224x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x28x224x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x28x224x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x28x224x14xf32>\n    return %2 : tensor<120x28x224x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x28x224x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x28x224x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x28x224x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x28x224x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x28x224x14xf32>, tensor<120x28x224x14xf32>) outs(%arg2: tensor<120x28x224x14xf32>) -> tensor<120x28x224x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x28x224x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x28x224x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12975676
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x120x112x14xf32>, tensor<228x120x112x14xf32>) outs(%arg2: tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x120x112x14xf32>, tensor<228x120x112x14xf32>) outs(%arg2: tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x120x112x14xf32>, %arg1: tensor<228x120x112x14xf32>, %arg2: tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x120x112x14xf32>, tensor<228x120x112x14xf32>) outs(%arg2: tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32>\n  return %ret : tensor<228x120x112x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x120x112x14xf32>, %arg1: tensor<228x120x112x14xf32>, %arg2: tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x120x112x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x120x112x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x120x112x14xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x120x112x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x120x112x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x120x112x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x120x112x14xf32>\n    return %2 : tensor<228x120x112x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x120x112x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x120x112x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x120x112x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x120x112x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x120x112x14xf32>, tensor<228x120x112x14xf32>) outs(%arg2: tensor<228x120x112x14xf32>) -> tensor<228x120x112x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x120x112x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x120x112x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 52151572
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x14x120x120xf32>, tensor<15x14x120x120xf32>) outs(%arg2: tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x14x120x120xf32>, tensor<15x14x120x120xf32>) outs(%arg2: tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x14x120x120xf32>, %arg1: tensor<15x14x120x120xf32>, %arg2: tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x14x120x120xf32>, tensor<15x14x120x120xf32>) outs(%arg2: tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32>\n  return %ret : tensor<15x14x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x14x120x120xf32>, %arg1: tensor<15x14x120x120xf32>, %arg2: tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x14x120x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x14x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x14x120x120xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x14x120x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x14x120x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x14x120x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x14x120x120xf32>\n    return %2 : tensor<15x14x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x14x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x14x120x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x14x120x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x14x120x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x14x120x120xf32>, tensor<15x14x120x120xf32>) outs(%arg2: tensor<15x14x120x120xf32>) -> tensor<15x14x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x14x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x14x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2694547
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x240x228x224xf32>, tensor<150x240x228x224xf32>) outs(%arg2: tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x240x228x224xf32>, tensor<150x240x228x224xf32>) outs(%arg2: tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x240x228x224xf32>, %arg1: tensor<150x240x228x224xf32>, %arg2: tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x240x228x224xf32>, tensor<150x240x228x224xf32>) outs(%arg2: tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32>\n  return %ret : tensor<150x240x228x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x240x228x224xf32>, %arg1: tensor<150x240x228x224xf32>, %arg2: tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x240x228x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x240x228x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x240x228x224xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x240x228x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x240x228x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x240x228x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x240x228x224xf32>\n    return %2 : tensor<150x240x228x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x240x228x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x240x228x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x240x228x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x240x228x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x240x228x224xf32>, tensor<150x240x228x224xf32>) outs(%arg2: tensor<150x240x228x224xf32>) -> tensor<150x240x228x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x240x228x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x240x228x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2177795240
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x56x224x56xf32>, tensor<56x56x224x56xf32>) outs(%arg2: tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x56x224x56xf32>, tensor<56x56x224x56xf32>) outs(%arg2: tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x56x224x56xf32>, %arg1: tensor<56x56x224x56xf32>, %arg2: tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x56x224x56xf32>, tensor<56x56x224x56xf32>) outs(%arg2: tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32>\n  return %ret : tensor<56x56x224x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x56x224x56xf32>, %arg1: tensor<56x56x224x56xf32>, %arg2: tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x56x224x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x56x224x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x56x224x56xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x56x224x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x56x224x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x56x224x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x56x224x56xf32>\n    return %2 : tensor<56x56x224x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x56x224x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x56x224x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x56x224x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x56x224x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x56x224x56xf32>, tensor<56x56x224x56xf32>) outs(%arg2: tensor<56x56x224x56xf32>) -> tensor<56x56x224x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x56x224x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x56x224x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 47078666
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x150x14x14xf32>, tensor<14x150x14x14xf32>) outs(%arg2: tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x150x14x14xf32>, tensor<14x150x14x14xf32>) outs(%arg2: tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x150x14x14xf32>, %arg1: tensor<14x150x14x14xf32>, %arg2: tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x150x14x14xf32>, tensor<14x150x14x14xf32>) outs(%arg2: tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32>\n  return %ret : tensor<14x150x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x150x14x14xf32>, %arg1: tensor<14x150x14x14xf32>, %arg2: tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x150x14x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x150x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x150x14x14xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x150x14x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x150x14x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x150x14x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x150x14x14xf32>\n    return %2 : tensor<14x150x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x150x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x150x14x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x150x14x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x150x14x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x150x14x14xf32>, tensor<14x150x14x14xf32>) outs(%arg2: tensor<14x150x14x14xf32>) -> tensor<14x150x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x150x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x150x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 404168
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x14x7x28xf32>, tensor<15x14x7x28xf32>) outs(%arg2: tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x14x7x28xf32>, tensor<15x14x7x28xf32>) outs(%arg2: tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x14x7x28xf32>, %arg1: tensor<15x14x7x28xf32>, %arg2: tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x14x7x28xf32>, tensor<15x14x7x28xf32>) outs(%arg2: tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32>\n  return %ret : tensor<15x14x7x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x14x7x28xf32>, %arg1: tensor<15x14x7x28xf32>, %arg2: tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x14x7x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x14x7x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x14x7x28xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x14x7x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x14x7x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x14x7x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x14x7x28xf32>\n    return %2 : tensor<15x14x7x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x14x7x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x14x7x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x14x7x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x14x7x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x14x7x28xf32>, tensor<15x14x7x28xf32>) outs(%arg2: tensor<15x14x7x28xf32>) -> tensor<15x14x7x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x14x7x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x14x7x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 38741
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x224x150x14xf32>, tensor<120x224x150x14xf32>) outs(%arg2: tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x224x150x14xf32>, tensor<120x224x150x14xf32>) outs(%arg2: tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x224x150x14xf32>, %arg1: tensor<120x224x150x14xf32>, %arg2: tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x224x150x14xf32>, tensor<120x224x150x14xf32>) outs(%arg2: tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32>\n  return %ret : tensor<120x224x150x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x224x150x14xf32>, %arg1: tensor<120x224x150x14xf32>, %arg2: tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x224x150x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x224x150x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x224x150x14xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x224x150x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x224x150x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x224x150x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x224x150x14xf32>\n    return %2 : tensor<120x224x150x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x224x150x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x224x150x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x224x150x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x224x150x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x224x150x14xf32>, tensor<120x224x150x14xf32>) outs(%arg2: tensor<120x224x150x14xf32>) -> tensor<120x224x150x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x224x150x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x224x150x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 67431412
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x28x228x56xf32>, tensor<7x28x228x56xf32>) outs(%arg2: tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x28x228x56xf32>, tensor<7x28x228x56xf32>) outs(%arg2: tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x28x228x56xf32>, %arg1: tensor<7x28x228x56xf32>, %arg2: tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x28x228x56xf32>, tensor<7x28x228x56xf32>) outs(%arg2: tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32>\n  return %ret : tensor<7x28x228x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x28x228x56xf32>, %arg1: tensor<7x28x228x56xf32>, %arg2: tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x28x228x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x28x228x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x28x228x56xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x28x228x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x28x228x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x28x228x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x28x228x56xf32>\n    return %2 : tensor<7x28x228x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x28x228x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x28x228x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x28x228x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x28x228x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x28x228x56xf32>, tensor<7x28x228x56xf32>) outs(%arg2: tensor<7x28x228x56xf32>) -> tensor<7x28x228x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x28x228x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x28x228x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2116511
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x28x28x28xf32>, tensor<28x28x28x28xf32>) outs(%arg2: tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x28x28x28xf32>, tensor<28x28x28x28xf32>) outs(%arg2: tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x28x28x28xf32>, %arg1: tensor<28x28x28x28xf32>, %arg2: tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x28x28x28xf32>, tensor<28x28x28x28xf32>) outs(%arg2: tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32>\n  return %ret : tensor<28x28x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x28x28x28xf32>, %arg1: tensor<28x28x28x28xf32>, %arg2: tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x28x28x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x28x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x28x28x28xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x28x28x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x28x28x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x28x28x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x28x28x28xf32>\n    return %2 : tensor<28x28x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x28x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x28x28x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x28x28x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x28x28x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x28x28x28xf32>, tensor<28x28x28x28xf32>) outs(%arg2: tensor<28x28x28x28xf32>) -> tensor<28x28x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x28x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x28x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 548767
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x240x240x224xf32>, tensor<15x240x240x224xf32>) outs(%arg2: tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x240x240x224xf32>, tensor<15x240x240x224xf32>) outs(%arg2: tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x240x240x224xf32>, %arg1: tensor<15x240x240x224xf32>, %arg2: tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x240x240x224xf32>, tensor<15x240x240x224xf32>) outs(%arg2: tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32>\n  return %ret : tensor<15x240x240x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x240x240x224xf32>, %arg1: tensor<15x240x240x224xf32>, %arg2: tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x240x240x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x240x240x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x240x240x224xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x240x240x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x240x240x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x240x240x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x240x240x224xf32>\n    return %2 : tensor<15x240x240x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x240x240x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x240x240x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x240x240x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x240x240x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x240x240x224xf32>, tensor<15x240x240x224xf32>) outs(%arg2: tensor<15x240x240x224xf32>) -> tensor<15x240x240x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x240x240x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x240x240x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 232197587
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x228x224x224xf32>, tensor<130x228x224x224xf32>) outs(%arg2: tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x228x224x224xf32>, tensor<130x228x224x224xf32>) outs(%arg2: tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x228x224x224xf32>, %arg1: tensor<130x228x224x224xf32>, %arg2: tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x228x224x224xf32>, tensor<130x228x224x224xf32>) outs(%arg2: tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32>\n  return %ret : tensor<130x228x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x228x224x224xf32>, %arg1: tensor<130x228x224x224xf32>, %arg2: tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x228x224x224xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x228x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x228x224x224xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 224 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x228x224x224xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x228x224x224xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x228x224x224xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x228x224x224xf32>\n    return %2 : tensor<130x228x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x228x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x228x224x224xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x228x224x224xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x228x224x224xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x228x224x224xf32>, tensor<130x228x224x224xf32>) outs(%arg2: tensor<130x228x224x224xf32>) -> tensor<130x228x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x228x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x228x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1774002309
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x112x56x7xf32>, tensor<130x112x56x7xf32>) outs(%arg2: tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x112x56x7xf32>, tensor<130x112x56x7xf32>) outs(%arg2: tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x112x56x7xf32>, %arg1: tensor<130x112x56x7xf32>, %arg2: tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x112x56x7xf32>, tensor<130x112x56x7xf32>) outs(%arg2: tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32>\n  return %ret : tensor<130x112x56x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x112x56x7xf32>, %arg1: tensor<130x112x56x7xf32>, %arg2: tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x112x56x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x112x56x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x112x56x7xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x112x56x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x112x56x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x112x56x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x112x56x7xf32>\n    return %2 : tensor<130x112x56x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x112x56x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x112x56x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x112x56x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x112x56x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x112x56x7xf32>, tensor<130x112x56x7xf32>) outs(%arg2: tensor<130x112x56x7xf32>) -> tensor<130x112x56x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x112x56x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x112x56x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6495746
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x56x130x240xf32>, tensor<56x56x130x240xf32>) outs(%arg2: tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x56x130x240xf32>, tensor<56x56x130x240xf32>) outs(%arg2: tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x56x130x240xf32>, %arg1: tensor<56x56x130x240xf32>, %arg2: tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x56x130x240xf32>, tensor<56x56x130x240xf32>) outs(%arg2: tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32>\n  return %ret : tensor<56x56x130x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x56x130x240xf32>, %arg1: tensor<56x56x130x240xf32>, %arg2: tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x56x130x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x56x130x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x56x130x240xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x56x130x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x56x130x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x56x130x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x56x130x240xf32>\n    return %2 : tensor<56x56x130x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x56x130x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x56x130x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x56x130x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x56x130x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x56x130x240xf32>, tensor<56x56x130x240xf32>) outs(%arg2: tensor<56x56x130x240xf32>) -> tensor<56x56x130x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x56x130x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x56x130x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 119027537
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x14x228x7xf32>, tensor<15x14x228x7xf32>) outs(%arg2: tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x14x228x7xf32>, tensor<15x14x228x7xf32>) outs(%arg2: tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x14x228x7xf32>, %arg1: tensor<15x14x228x7xf32>, %arg2: tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x14x228x7xf32>, tensor<15x14x228x7xf32>) outs(%arg2: tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32>\n  return %ret : tensor<15x14x228x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x14x228x7xf32>, %arg1: tensor<15x14x228x7xf32>, %arg2: tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x14x228x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x14x228x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x14x228x7xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x14x228x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x14x228x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x14x228x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x14x228x7xf32>\n    return %2 : tensor<15x14x228x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x14x228x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x14x228x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x14x228x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x14x228x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x14x228x7xf32>, tensor<15x14x228x7xf32>) outs(%arg2: tensor<15x14x228x7xf32>) -> tensor<15x14x228x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x14x228x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x14x228x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 269366
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x240x240x240xf32>, tensor<130x240x240x240xf32>) outs(%arg2: tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x240x240x240xf32>, tensor<130x240x240x240xf32>) outs(%arg2: tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x240x240x240xf32>, %arg1: tensor<130x240x240x240xf32>, %arg2: tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x240x240x240xf32>, tensor<130x240x240x240xf32>) outs(%arg2: tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32>\n  return %ret : tensor<130x240x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x240x240x240xf32>, %arg1: tensor<130x240x240x240xf32>, %arg2: tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x240x240x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x240x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x240x240x240xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x240x240x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x240x240x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x240x240x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x240x240x240xf32>\n    return %2 : tensor<130x240x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x240x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x240x240x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x240x240x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x240x240x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x240x240x240xf32>, tensor<130x240x240x240xf32>) outs(%arg2: tensor<130x240x240x240xf32>) -> tensor<130x240x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x240x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x240x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2133518951
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x112x112x240xf32>, tensor<240x112x112x240xf32>) outs(%arg2: tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x112x112x240xf32>, tensor<240x112x112x240xf32>) outs(%arg2: tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x112x112x240xf32>, %arg1: tensor<240x112x112x240xf32>, %arg2: tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x112x112x240xf32>, tensor<240x112x112x240xf32>) outs(%arg2: tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32>\n  return %ret : tensor<240x112x112x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x112x112x240xf32>, %arg1: tensor<240x112x112x240xf32>, %arg2: tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x112x112x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x112x112x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x112x112x240xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x112x112x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x112x112x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x112x112x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x112x112x240xf32>\n    return %2 : tensor<240x112x112x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x112x112x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x112x112x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x112x112x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x112x112x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x112x112x240xf32>, tensor<240x112x112x240xf32>) outs(%arg2: tensor<240x112x112x240xf32>) -> tensor<240x112x112x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x112x112x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x112x112x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 865218768
  },
  "linalg.add ins(%arg0, %arg1: tensor<120x7x15x7xf32>, tensor<120x7x15x7xf32>) outs(%arg2: tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<120x7x15x7xf32>, tensor<120x7x15x7xf32>) outs(%arg2: tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<120x7x15x7xf32>, %arg1: tensor<120x7x15x7xf32>, %arg2: tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<120x7x15x7xf32>, tensor<120x7x15x7xf32>) outs(%arg2: tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32>\n  return %ret : tensor<120x7x15x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<120x7x15x7xf32>, %arg1: tensor<120x7x15x7xf32>, %arg2: tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<120x7x15x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<120x7x15x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<120x7x15x7xf32>\n    affine.for %arg3 = 0 to 120 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<120x7x15x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<120x7x15x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<120x7x15x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<120x7x15x7xf32>\n    return %2 : tensor<120x7x15x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<120x7x15x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<120x7x15x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<120x7x15x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<120x7x15x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<120x7x15x7xf32>, tensor<120x7x15x7xf32>) outs(%arg2: tensor<120x7x15x7xf32>) -> tensor<120x7x15x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<120x7x15x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<120x7x15x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          120,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 99042
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x15x240x14xf32>, tensor<240x15x240x14xf32>) outs(%arg2: tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x15x240x14xf32>, tensor<240x15x240x14xf32>) outs(%arg2: tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x15x240x14xf32>, %arg1: tensor<240x15x240x14xf32>, %arg2: tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x15x240x14xf32>, tensor<240x15x240x14xf32>) outs(%arg2: tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32>\n  return %ret : tensor<240x15x240x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x15x240x14xf32>, %arg1: tensor<240x15x240x14xf32>, %arg2: tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x15x240x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x15x240x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x15x240x14xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x15x240x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x15x240x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x15x240x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x15x240x14xf32>\n    return %2 : tensor<240x15x240x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x15x240x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x15x240x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x15x240x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x15x240x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x15x240x14xf32>, tensor<240x15x240x14xf32>) outs(%arg2: tensor<240x15x240x14xf32>) -> tensor<240x15x240x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x15x240x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x15x240x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 15331815
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x150x120x28xf32>, tensor<240x150x120x28xf32>) outs(%arg2: tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x150x120x28xf32>, tensor<240x150x120x28xf32>) outs(%arg2: tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x150x120x28xf32>, %arg1: tensor<240x150x120x28xf32>, %arg2: tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x150x120x28xf32>, tensor<240x150x120x28xf32>) outs(%arg2: tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32>\n  return %ret : tensor<240x150x120x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x150x120x28xf32>, %arg1: tensor<240x150x120x28xf32>, %arg2: tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x150x120x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x150x120x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x150x120x28xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x150x120x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x150x120x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x150x120x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x150x120x28xf32>\n    return %2 : tensor<240x150x120x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x150x120x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x150x120x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x150x120x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x150x120x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x150x120x28xf32>, tensor<240x150x120x28xf32>) outs(%arg2: tensor<240x150x120x28xf32>) -> tensor<240x150x120x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x150x120x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x150x120x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 146061904
  },
  "linalg.add ins(%arg0, %arg1: tensor<14x228x228x56xf32>, tensor<14x228x228x56xf32>) outs(%arg2: tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<14x228x228x56xf32>, tensor<14x228x228x56xf32>) outs(%arg2: tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<14x228x228x56xf32>, %arg1: tensor<14x228x228x56xf32>, %arg2: tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<14x228x228x56xf32>, tensor<14x228x228x56xf32>) outs(%arg2: tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32>\n  return %ret : tensor<14x228x228x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<14x228x228x56xf32>, %arg1: tensor<14x228x228x56xf32>, %arg2: tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<14x228x228x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<14x228x228x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<14x228x228x56xf32>\n    affine.for %arg3 = 0 to 14 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<14x228x228x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<14x228x228x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<14x228x228x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<14x228x228x56xf32>\n    return %2 : tensor<14x228x228x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<14x228x228x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<14x228x228x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<14x228x228x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<14x228x228x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<14x228x228x56xf32>, tensor<14x228x228x56xf32>) outs(%arg2: tensor<14x228x228x56xf32>) -> tensor<14x228x228x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<14x228x228x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<14x228x228x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 48193192
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x150x14x228xf32>, tensor<224x150x14x228xf32>) outs(%arg2: tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x150x14x228xf32>, tensor<224x150x14x228xf32>) outs(%arg2: tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x150x14x228xf32>, %arg1: tensor<224x150x14x228xf32>, %arg2: tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x150x14x228xf32>, tensor<224x150x14x228xf32>) outs(%arg2: tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32>\n  return %ret : tensor<224x150x14x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x150x14x228xf32>, %arg1: tensor<224x150x14x228xf32>, %arg2: tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x150x14x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x150x14x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x150x14x228xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x150x14x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x150x14x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x150x14x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x150x14x228xf32>\n    return %2 : tensor<224x150x14x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x150x14x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x150x14x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x150x14x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x150x14x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x150x14x228xf32>, tensor<224x150x14x228xf32>) outs(%arg2: tensor<224x150x14x228xf32>) -> tensor<224x150x14x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x150x14x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x150x14x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 127903390
  },
  "linalg.add ins(%arg0, %arg1: tensor<228x112x228x14xf32>, tensor<228x112x228x14xf32>) outs(%arg2: tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<228x112x228x14xf32>, tensor<228x112x228x14xf32>) outs(%arg2: tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<228x112x228x14xf32>, %arg1: tensor<228x112x228x14xf32>, %arg2: tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<228x112x228x14xf32>, tensor<228x112x228x14xf32>) outs(%arg2: tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32>\n  return %ret : tensor<228x112x228x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<228x112x228x14xf32>, %arg1: tensor<228x112x228x14xf32>, %arg2: tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<228x112x228x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<228x112x228x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<228x112x228x14xf32>\n    affine.for %arg3 = 0 to 228 {\n      affine.for %arg4 = 0 to 112 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<228x112x228x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<228x112x228x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<228x112x228x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<228x112x228x14xf32>\n    return %2 : tensor<228x112x228x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<228x112x228x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<228x112x228x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<228x112x228x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<228x112x228x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<228x112x228x14xf32>, tensor<228x112x228x14xf32>) outs(%arg2: tensor<228x112x228x14xf32>) -> tensor<228x112x228x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<228x112x228x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<228x112x228x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          228,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 100293441
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x228x28x56xf32>, tensor<28x228x28x56xf32>) outs(%arg2: tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x228x28x56xf32>, tensor<28x228x28x56xf32>) outs(%arg2: tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x228x28x56xf32>, %arg1: tensor<28x228x28x56xf32>, %arg2: tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x228x28x56xf32>, tensor<28x228x28x56xf32>) outs(%arg2: tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32>\n  return %ret : tensor<28x228x28x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x228x28x56xf32>, %arg1: tensor<28x228x28x56xf32>, %arg2: tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x228x28x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x228x28x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x228x28x56xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x228x28x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x228x28x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x228x28x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x228x28x56xf32>\n    return %2 : tensor<28x228x28x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x228x28x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x228x28x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x228x28x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x228x28x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x228x28x56xf32>, tensor<28x228x28x56xf32>) outs(%arg2: tensor<28x228x28x56xf32>) -> tensor<28x228x28x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x228x28x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x228x28x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12407248
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x150x228x228xf32>, tensor<130x150x228x228xf32>) outs(%arg2: tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x150x228x228xf32>, tensor<130x150x228x228xf32>) outs(%arg2: tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x150x228x228xf32>, %arg1: tensor<130x150x228x228xf32>, %arg2: tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x150x228x228xf32>, tensor<130x150x228x228xf32>) outs(%arg2: tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32>\n  return %ret : tensor<130x150x228x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x150x228x228xf32>, %arg1: tensor<130x150x228x228xf32>, %arg2: tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x150x228x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x150x228x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x150x228x228xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x150x228x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x150x228x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x150x228x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x150x228x228xf32>\n    return %2 : tensor<130x150x228x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x150x228x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x150x228x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x150x228x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x150x228x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x150x228x228xf32>, tensor<130x150x228x228xf32>) outs(%arg2: tensor<130x150x228x228xf32>) -> tensor<130x150x228x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x150x228x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x150x228x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1213707128
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x120x14x112xf32>, tensor<130x120x14x112xf32>) outs(%arg2: tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x120x14x112xf32>, tensor<130x120x14x112xf32>) outs(%arg2: tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x120x14x112xf32>, %arg1: tensor<130x120x14x112xf32>, %arg2: tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x120x14x112xf32>, tensor<130x120x14x112xf32>) outs(%arg2: tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32>\n  return %ret : tensor<130x120x14x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x120x14x112xf32>, %arg1: tensor<130x120x14x112xf32>, %arg2: tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x120x14x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x120x14x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x120x14x112xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x120x14x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x120x14x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x120x14x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x120x14x112xf32>\n    return %2 : tensor<130x120x14x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x120x14x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x120x14x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x120x14x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x120x14x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x120x14x112xf32>, tensor<130x120x14x112xf32>) outs(%arg2: tensor<130x120x14x112xf32>) -> tensor<130x120x14x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x120x14x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x120x14x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 30638348
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x228x112x120xf32>, tensor<224x228x112x120xf32>) outs(%arg2: tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x228x112x120xf32>, tensor<224x228x112x120xf32>) outs(%arg2: tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x228x112x120xf32>, %arg1: tensor<224x228x112x120xf32>, %arg2: tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x228x112x120xf32>, tensor<224x228x112x120xf32>) outs(%arg2: tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32>\n  return %ret : tensor<224x228x112x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x228x112x120xf32>, %arg1: tensor<224x228x112x120xf32>, %arg2: tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x228x112x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x228x112x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x228x112x120xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x228x112x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x228x112x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x228x112x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x228x112x120xf32>\n    return %2 : tensor<224x228x112x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x228x112x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x228x112x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x228x112x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x228x112x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x228x112x120xf32>, tensor<224x228x112x120xf32>) outs(%arg2: tensor<224x228x112x120xf32>) -> tensor<224x228x112x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x228x112x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x228x112x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 834710056
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x14x14x7xf32>, tensor<7x14x14x7xf32>) outs(%arg2: tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x14x14x7xf32>, tensor<7x14x14x7xf32>) outs(%arg2: tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x14x14x7xf32>, %arg1: tensor<7x14x14x7xf32>, %arg2: tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x14x14x7xf32>, tensor<7x14x14x7xf32>) outs(%arg2: tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32>\n  return %ret : tensor<7x14x14x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x14x14x7xf32>, %arg1: tensor<7x14x14x7xf32>, %arg2: tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x14x14x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x14x14x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x14x14x7xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x14x14x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x14x14x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x14x14x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x14x14x7xf32>\n    return %2 : tensor<7x14x14x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x14x14x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x14x14x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x14x14x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x14x14x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x14x14x7xf32>, tensor<7x14x14x7xf32>) outs(%arg2: tensor<7x14x14x7xf32>) -> tensor<7x14x14x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x14x14x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x14x14x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 10381
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x130x120x120xf32>, tensor<15x130x120x120xf32>) outs(%arg2: tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x130x120x120xf32>, tensor<15x130x120x120xf32>) outs(%arg2: tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x130x120x120xf32>, %arg1: tensor<15x130x120x120xf32>, %arg2: tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x130x120x120xf32>, tensor<15x130x120x120xf32>) outs(%arg2: tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32>\n  return %ret : tensor<15x130x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x130x120x120xf32>, %arg1: tensor<15x130x120x120xf32>, %arg2: tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x130x120x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x130x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x130x120x120xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x130x120x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x130x120x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x130x120x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x130x120x120xf32>\n    return %2 : tensor<15x130x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x130x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x130x120x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x130x120x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x130x120x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x130x120x120xf32>, tensor<15x130x120x120xf32>) outs(%arg2: tensor<15x130x120x120xf32>) -> tensor<15x130x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x130x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x130x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 33642124
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x150x130x14xf32>, tensor<130x150x130x14xf32>) outs(%arg2: tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x150x130x14xf32>, tensor<130x150x130x14xf32>) outs(%arg2: tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x150x130x14xf32>, %arg1: tensor<130x150x130x14xf32>, %arg2: tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x150x130x14xf32>, tensor<130x150x130x14xf32>) outs(%arg2: tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32>\n  return %ret : tensor<130x150x130x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x150x130x14xf32>, %arg1: tensor<130x150x130x14xf32>, %arg2: tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x150x130x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x150x130x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x150x130x14xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x150x130x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x150x130x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x150x130x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x150x130x14xf32>\n    return %2 : tensor<130x150x130x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x150x130x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x150x130x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x150x130x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x150x130x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x150x130x14xf32>, tensor<130x150x130x14xf32>) outs(%arg2: tensor<130x150x130x14xf32>) -> tensor<130x150x130x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x150x130x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x150x130x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 43489280
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x224x150x150xf32>, tensor<224x224x150x150xf32>) outs(%arg2: tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x224x150x150xf32>, tensor<224x224x150x150xf32>) outs(%arg2: tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x224x150x150xf32>, %arg1: tensor<224x224x150x150xf32>, %arg2: tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x224x150x150xf32>, tensor<224x224x150x150xf32>) outs(%arg2: tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32>\n  return %ret : tensor<224x224x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x224x150x150xf32>, %arg1: tensor<224x224x150x150xf32>, %arg2: tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x224x150x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x224x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x224x150x150xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x224x150x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x224x150x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x224x150x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x224x150x150xf32>\n    return %2 : tensor<224x224x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x224x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x224x150x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x224x150x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x224x150x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x224x150x150xf32>, tensor<224x224x150x150xf32>) outs(%arg2: tensor<224x224x150x150xf32>) -> tensor<224x224x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x224x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x224x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1351015009
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x240x28x14xf32>, tensor<7x240x28x14xf32>) outs(%arg2: tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x240x28x14xf32>, tensor<7x240x28x14xf32>) outs(%arg2: tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x240x28x14xf32>, %arg1: tensor<7x240x28x14xf32>, %arg2: tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x240x28x14xf32>, tensor<7x240x28x14xf32>) outs(%arg2: tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32>\n  return %ret : tensor<7x240x28x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x240x28x14xf32>, %arg1: tensor<7x240x28x14xf32>, %arg2: tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x240x28x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x240x28x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x240x28x14xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x240x28x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x240x28x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x240x28x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x240x28x14xf32>\n    return %2 : tensor<7x240x28x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x240x28x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x240x28x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x240x28x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x240x28x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x240x28x14xf32>, tensor<7x240x28x14xf32>) outs(%arg2: tensor<7x240x28x14xf32>) -> tensor<7x240x28x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x240x28x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x240x28x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 624588
  },
  "linalg.add ins(%arg0, %arg1: tensor<15x130x112x56xf32>, tensor<15x130x112x56xf32>) outs(%arg2: tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<15x130x112x56xf32>, tensor<15x130x112x56xf32>) outs(%arg2: tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<15x130x112x56xf32>, %arg1: tensor<15x130x112x56xf32>, %arg2: tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<15x130x112x56xf32>, tensor<15x130x112x56xf32>) outs(%arg2: tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32>\n  return %ret : tensor<15x130x112x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<15x130x112x56xf32>, %arg1: tensor<15x130x112x56xf32>, %arg2: tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<15x130x112x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<15x130x112x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<15x130x112x56xf32>\n    affine.for %arg3 = 0 to 15 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<15x130x112x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<15x130x112x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<15x130x112x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<15x130x112x56xf32>\n    return %2 : tensor<15x130x112x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<15x130x112x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<15x130x112x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<15x130x112x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<15x130x112x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<15x130x112x56xf32>, tensor<15x130x112x56xf32>) outs(%arg2: tensor<15x130x112x56xf32>) -> tensor<15x130x112x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<15x130x112x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<15x130x112x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          15,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 15124195
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x56x15x112xf32>, tensor<150x56x15x112xf32>) outs(%arg2: tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x56x15x112xf32>, tensor<150x56x15x112xf32>) outs(%arg2: tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x56x15x112xf32>, %arg1: tensor<150x56x15x112xf32>, %arg2: tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x56x15x112xf32>, tensor<150x56x15x112xf32>) outs(%arg2: tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32>\n  return %ret : tensor<150x56x15x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x56x15x112xf32>, %arg1: tensor<150x56x15x112xf32>, %arg2: tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x56x15x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x56x15x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x56x15x112xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x56x15x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x56x15x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x56x15x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x56x15x112xf32>\n    return %2 : tensor<150x56x15x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x56x15x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x56x15x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x56x15x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x56x15x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x56x15x112xf32>, tensor<150x56x15x112xf32>) outs(%arg2: tensor<150x56x15x112xf32>) -> tensor<150x56x15x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x56x15x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x56x15x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 17774670
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x130x56x14xf32>, tensor<240x130x56x14xf32>) outs(%arg2: tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x130x56x14xf32>, tensor<240x130x56x14xf32>) outs(%arg2: tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x130x56x14xf32>, %arg1: tensor<240x130x56x14xf32>, %arg2: tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x130x56x14xf32>, tensor<240x130x56x14xf32>) outs(%arg2: tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32>\n  return %ret : tensor<240x130x56x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x130x56x14xf32>, %arg1: tensor<240x130x56x14xf32>, %arg2: tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x130x56x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x130x56x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x130x56x14xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x130x56x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x130x56x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x130x56x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x130x56x14xf32>\n    return %2 : tensor<240x130x56x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x130x56x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x130x56x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x130x56x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x130x56x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x130x56x14xf32>, tensor<240x130x56x14xf32>) outs(%arg2: tensor<240x130x56x14xf32>) -> tensor<240x130x56x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x130x56x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x130x56x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 30386266
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x7x15x14xf32>, tensor<224x7x15x14xf32>) outs(%arg2: tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x7x15x14xf32>, tensor<224x7x15x14xf32>) outs(%arg2: tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x7x15x14xf32>, %arg1: tensor<224x7x15x14xf32>, %arg2: tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x7x15x14xf32>, tensor<224x7x15x14xf32>) outs(%arg2: tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32>\n  return %ret : tensor<224x7x15x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x7x15x14xf32>, %arg1: tensor<224x7x15x14xf32>, %arg2: tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x7x15x14xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x7x15x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x7x15x14xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 14 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x7x15x14xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x7x15x14xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x7x15x14xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x7x15x14xf32>\n    return %2 : tensor<224x7x15x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x7x15x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x7x15x14xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x7x15x14xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x7x15x14xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x7x15x14xf32>, tensor<224x7x15x14xf32>) outs(%arg2: tensor<224x7x15x14xf32>) -> tensor<224x7x15x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x7x15x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x7x15x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 322708
  },
  "linalg.add ins(%arg0, %arg1: tensor<7x120x130x7xf32>, tensor<7x120x130x7xf32>) outs(%arg2: tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<7x120x130x7xf32>, tensor<7x120x130x7xf32>) outs(%arg2: tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<7x120x130x7xf32>, %arg1: tensor<7x120x130x7xf32>, %arg2: tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<7x120x130x7xf32>, tensor<7x120x130x7xf32>) outs(%arg2: tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32>\n  return %ret : tensor<7x120x130x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<7x120x130x7xf32>, %arg1: tensor<7x120x130x7xf32>, %arg2: tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<7x120x130x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<7x120x130x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<7x120x130x7xf32>\n    affine.for %arg3 = 0 to 7 {\n      affine.for %arg4 = 0 to 120 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 7 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<7x120x130x7xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<7x120x130x7xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<7x120x130x7xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<7x120x130x7xf32>\n    return %2 : tensor<7x120x130x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<7x120x130x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<7x120x130x7xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<7x120x130x7xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<7x120x130x7xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<7x120x130x7xf32>, tensor<7x120x130x7xf32>) outs(%arg2: tensor<7x120x130x7xf32>) -> tensor<7x120x130x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<7x120x130x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<7x120x130x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          7,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 607541
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x150x228x120xf32>, tensor<112x150x228x120xf32>) outs(%arg2: tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x150x228x120xf32>, tensor<112x150x228x120xf32>) outs(%arg2: tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x150x228x120xf32>, %arg1: tensor<112x150x228x120xf32>, %arg2: tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x150x228x120xf32>, tensor<112x150x228x120xf32>) outs(%arg2: tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32>\n  return %ret : tensor<112x150x228x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x150x228x120xf32>, %arg1: tensor<112x150x228x120xf32>, %arg2: tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x150x228x120xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x150x228x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x150x228x120xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 150 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 120 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x150x228x120xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x150x228x120xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x150x228x120xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x150x228x120xf32>\n    return %2 : tensor<112x150x228x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x150x228x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x150x228x120xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x150x228x120xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x150x228x120xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x150x228x120xf32>, tensor<112x150x228x120xf32>) outs(%arg2: tensor<112x150x228x120xf32>) -> tensor<112x150x228x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x150x228x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x150x228x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 547417533
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x7x28x240xf32>, tensor<130x7x28x240xf32>) outs(%arg2: tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x7x28x240xf32>, tensor<130x7x28x240xf32>) outs(%arg2: tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x7x28x240xf32>, %arg1: tensor<130x7x28x240xf32>, %arg2: tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x7x28x240xf32>, tensor<130x7x28x240xf32>) outs(%arg2: tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32>\n  return %ret : tensor<130x7x28x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x7x28x240xf32>, %arg1: tensor<130x7x28x240xf32>, %arg2: tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x7x28x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x7x28x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x7x28x240xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x7x28x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x7x28x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x7x28x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x7x28x240xf32>\n    return %2 : tensor<130x7x28x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x7x28x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x7x28x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x7x28x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x7x28x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x7x28x240xf32>, tensor<130x7x28x240xf32>) outs(%arg2: tensor<130x7x28x240xf32>) -> tensor<130x7x28x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x7x28x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x7x28x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6828203
  },
  "linalg.add ins(%arg0, %arg1: tensor<56x7x224x15xf32>, tensor<56x7x224x15xf32>) outs(%arg2: tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<56x7x224x15xf32>, tensor<56x7x224x15xf32>) outs(%arg2: tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<56x7x224x15xf32>, %arg1: tensor<56x7x224x15xf32>, %arg2: tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<56x7x224x15xf32>, tensor<56x7x224x15xf32>) outs(%arg2: tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32>\n  return %ret : tensor<56x7x224x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<56x7x224x15xf32>, %arg1: tensor<56x7x224x15xf32>, %arg2: tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<56x7x224x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<56x7x224x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<56x7x224x15xf32>\n    affine.for %arg3 = 0 to 56 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<56x7x224x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<56x7x224x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<56x7x224x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<56x7x224x15xf32>\n    return %2 : tensor<56x7x224x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<56x7x224x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<56x7x224x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<56x7x224x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<56x7x224x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<56x7x224x15xf32>, tensor<56x7x224x15xf32>) outs(%arg2: tensor<56x7x224x15xf32>) -> tensor<56x7x224x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<56x7x224x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<56x7x224x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          56,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 932679
  },
  "linalg.add ins(%arg0, %arg1: tensor<224x14x14x28xf32>, tensor<224x14x14x28xf32>) outs(%arg2: tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<224x14x14x28xf32>, tensor<224x14x14x28xf32>) outs(%arg2: tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<224x14x14x28xf32>, %arg1: tensor<224x14x14x28xf32>, %arg2: tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<224x14x14x28xf32>, tensor<224x14x14x28xf32>) outs(%arg2: tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32>\n  return %ret : tensor<224x14x14x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<224x14x14x28xf32>, %arg1: tensor<224x14x14x28xf32>, %arg2: tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<224x14x14x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<224x14x14x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<224x14x14x28xf32>\n    affine.for %arg3 = 0 to 224 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<224x14x14x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<224x14x14x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<224x14x14x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<224x14x14x28xf32>\n    return %2 : tensor<224x14x14x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<224x14x14x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<224x14x14x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<224x14x14x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<224x14x14x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<224x14x14x28xf32>, tensor<224x14x14x28xf32>) outs(%arg2: tensor<224x14x14x28xf32>) -> tensor<224x14x14x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<224x14x14x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<224x14x14x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          224,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1116668
  },
  "linalg.add ins(%arg0, %arg1: tensor<112x28x56x56xf32>, tensor<112x28x56x56xf32>) outs(%arg2: tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<112x28x56x56xf32>, tensor<112x28x56x56xf32>) outs(%arg2: tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<112x28x56x56xf32>, %arg1: tensor<112x28x56x56xf32>, %arg2: tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<112x28x56x56xf32>, tensor<112x28x56x56xf32>) outs(%arg2: tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32>\n  return %ret : tensor<112x28x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<112x28x56x56xf32>, %arg1: tensor<112x28x56x56xf32>, %arg2: tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<112x28x56x56xf32>\n    %1 = bufferization.to_memref %arg0 : memref<112x28x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<112x28x56x56xf32>\n    affine.for %arg3 = 0 to 112 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 56 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<112x28x56x56xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<112x28x56x56xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<112x28x56x56xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<112x28x56x56xf32>\n    return %2 : tensor<112x28x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<112x28x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<112x28x56x56xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<112x28x56x56xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<112x28x56x56xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<112x28x56x56xf32>, tensor<112x28x56x56xf32>) outs(%arg2: tensor<112x28x56x56xf32>) -> tensor<112x28x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<112x28x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<112x28x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          112,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12108899
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x228x7x228xf32>, tensor<240x228x7x228xf32>) outs(%arg2: tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x228x7x228xf32>, tensor<240x228x7x228xf32>) outs(%arg2: tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x228x7x228xf32>, %arg1: tensor<240x228x7x228xf32>, %arg2: tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x228x7x228xf32>, tensor<240x228x7x228xf32>) outs(%arg2: tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32>\n  return %ret : tensor<240x228x7x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x228x7x228xf32>, %arg1: tensor<240x228x7x228xf32>, %arg2: tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x228x7x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x228x7x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x228x7x228xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 228 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x228x7x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x228x7x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x228x7x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x228x7x228xf32>\n    return %2 : tensor<240x228x7x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x228x7x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x228x7x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x228x7x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x228x7x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x228x7x228xf32>, tensor<240x228x7x228xf32>) outs(%arg2: tensor<240x228x7x228xf32>) -> tensor<240x228x7x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x228x7x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x228x7x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 104673086
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x224x56x28xf32>, tensor<28x224x56x28xf32>) outs(%arg2: tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x224x56x28xf32>, tensor<28x224x56x28xf32>) outs(%arg2: tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x224x56x28xf32>, %arg1: tensor<28x224x56x28xf32>, %arg2: tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x224x56x28xf32>, tensor<28x224x56x28xf32>) outs(%arg2: tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32>\n  return %ret : tensor<28x224x56x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x224x56x28xf32>, %arg1: tensor<28x224x56x28xf32>, %arg2: tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x224x56x28xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x224x56x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x224x56x28xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 28 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x224x56x28xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x224x56x28xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x224x56x28xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x224x56x28xf32>\n    return %2 : tensor<28x224x56x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x224x56x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x224x56x28xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x224x56x28xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x224x56x28xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x224x56x28xf32>, tensor<28x224x56x28xf32>) outs(%arg2: tensor<28x224x56x28xf32>) -> tensor<28x224x56x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x224x56x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x224x56x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12295155
  },
  "linalg.add ins(%arg0, %arg1: tensor<28x28x240x228xf32>, tensor<28x28x240x228xf32>) outs(%arg2: tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<28x28x240x228xf32>, tensor<28x28x240x228xf32>) outs(%arg2: tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<28x28x240x228xf32>, %arg1: tensor<28x28x240x228xf32>, %arg2: tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<28x28x240x228xf32>, tensor<28x28x240x228xf32>) outs(%arg2: tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32>\n  return %ret : tensor<28x28x240x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<28x28x240x228xf32>, %arg1: tensor<28x28x240x228xf32>, %arg2: tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<28x28x240x228xf32>\n    %1 = bufferization.to_memref %arg0 : memref<28x28x240x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<28x28x240x228xf32>\n    affine.for %arg3 = 0 to 28 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 228 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<28x28x240x228xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<28x28x240x228xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<28x28x240x228xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<28x28x240x228xf32>\n    return %2 : tensor<28x28x240x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<28x28x240x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<28x28x240x228xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<28x28x240x228xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<28x28x240x228xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<28x28x240x228xf32>, tensor<28x28x240x228xf32>) outs(%arg2: tensor<28x28x240x228xf32>) -> tensor<28x28x240x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<28x28x240x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<28x28x240x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          28,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 51553564
  },
  "linalg.add ins(%arg0, %arg1: tensor<150x28x120x15xf32>, tensor<150x28x120x15xf32>) outs(%arg2: tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<150x28x120x15xf32>, tensor<150x28x120x15xf32>) outs(%arg2: tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<150x28x120x15xf32>, %arg1: tensor<150x28x120x15xf32>, %arg2: tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<150x28x120x15xf32>, tensor<150x28x120x15xf32>) outs(%arg2: tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32>\n  return %ret : tensor<150x28x120x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<150x28x120x15xf32>, %arg1: tensor<150x28x120x15xf32>, %arg2: tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<150x28x120x15xf32>\n    %1 = bufferization.to_memref %arg0 : memref<150x28x120x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<150x28x120x15xf32>\n    affine.for %arg3 = 0 to 150 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 15 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<150x28x120x15xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<150x28x120x15xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<150x28x120x15xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<150x28x120x15xf32>\n    return %2 : tensor<150x28x120x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<150x28x120x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<150x28x120x15xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<150x28x120x15xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<150x28x120x15xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<150x28x120x15xf32>, tensor<150x28x120x15xf32>) outs(%arg2: tensor<150x28x120x15xf32>) -> tensor<150x28x120x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<150x28x120x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<150x28x120x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          150,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8704013
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x240x56x150xf32>, tensor<130x240x56x150xf32>) outs(%arg2: tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x240x56x150xf32>, tensor<130x240x56x150xf32>) outs(%arg2: tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x240x56x150xf32>, %arg1: tensor<130x240x56x150xf32>, %arg2: tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x240x56x150xf32>, tensor<130x240x56x150xf32>) outs(%arg2: tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32>\n  return %ret : tensor<130x240x56x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x240x56x150xf32>, %arg1: tensor<130x240x56x150xf32>, %arg2: tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x240x56x150xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x240x56x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x240x56x150xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 150 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x240x56x150xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x240x56x150xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x240x56x150xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x240x56x150xf32>\n    return %2 : tensor<130x240x56x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x240x56x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x240x56x150xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x240x56x150xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x240x56x150xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x240x56x150xf32>, tensor<130x240x56x150xf32>) outs(%arg2: tensor<130x240x56x150xf32>) -> tensor<130x240x56x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x240x56x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x240x56x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 312424846
  },
  "linalg.add ins(%arg0, %arg1: tensor<240x224x130x130xf32>, tensor<240x224x130x130xf32>) outs(%arg2: tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<240x224x130x130xf32>, tensor<240x224x130x130xf32>) outs(%arg2: tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<240x224x130x130xf32>, %arg1: tensor<240x224x130x130xf32>, %arg2: tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<240x224x130x130xf32>, tensor<240x224x130x130xf32>) outs(%arg2: tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32>\n  return %ret : tensor<240x224x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<240x224x130x130xf32>, %arg1: tensor<240x224x130x130xf32>, %arg2: tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x224x130x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<240x224x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<240x224x130x130xf32>\n    affine.for %arg3 = 0 to 240 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<240x224x130x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<240x224x130x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<240x224x130x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<240x224x130x130xf32>\n    return %2 : tensor<240x224x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<240x224x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<240x224x130x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<240x224x130x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<240x224x130x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<240x224x130x130xf32>, tensor<240x224x130x130xf32>) outs(%arg2: tensor<240x224x130x130xf32>) -> tensor<240x224x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<240x224x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<240x224x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1081218337
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x130x14x130xf32>, tensor<130x130x14x130xf32>) outs(%arg2: tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x130x14x130xf32>, tensor<130x130x14x130xf32>) outs(%arg2: tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x130x14x130xf32>, %arg1: tensor<130x130x14x130xf32>, %arg2: tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x130x14x130xf32>, tensor<130x130x14x130xf32>) outs(%arg2: tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32>\n  return %ret : tensor<130x130x14x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x130x14x130xf32>, %arg1: tensor<130x130x14x130xf32>, %arg2: tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x130x14x130xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x130x14x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x130x14x130xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 130 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 130 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x130x14x130xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x130x14x130xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x130x14x130xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x130x14x130xf32>\n    return %2 : tensor<130x130x14x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x130x14x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x130x14x130xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x130x14x130xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x130x14x130xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x130x14x130xf32>, tensor<130x130x14x130xf32>) outs(%arg2: tensor<130x130x14x130xf32>) -> tensor<130x130x14x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x130x14x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x130x14x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 36955198
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x15x56x240xf32>, tensor<130x15x56x240xf32>) outs(%arg2: tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x15x56x240xf32>, tensor<130x15x56x240xf32>) outs(%arg2: tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x15x56x240xf32>, %arg1: tensor<130x15x56x240xf32>, %arg2: tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x15x56x240xf32>, tensor<130x15x56x240xf32>) outs(%arg2: tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32>\n  return %ret : tensor<130x15x56x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x15x56x240xf32>, %arg1: tensor<130x15x56x240xf32>, %arg2: tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x15x56x240xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x15x56x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x15x56x240xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 240 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x15x56x240xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x15x56x240xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x15x56x240xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x15x56x240xf32>\n    return %2 : tensor<130x15x56x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x15x56x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x15x56x240xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x15x56x240xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x15x56x240xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x15x56x240xf32>, tensor<130x15x56x240xf32>) outs(%arg2: tensor<130x15x56x240xf32>) -> tensor<130x15x56x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x15x56x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x15x56x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31426441
  },
  "linalg.add ins(%arg0, %arg1: tensor<130x224x120x112xf32>, tensor<130x224x120x112xf32>) outs(%arg2: tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<130x224x120x112xf32>, tensor<130x224x120x112xf32>) outs(%arg2: tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<130x224x120x112xf32>, %arg1: tensor<130x224x120x112xf32>, %arg2: tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<130x224x120x112xf32>, tensor<130x224x120x112xf32>) outs(%arg2: tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32>\n  return %ret : tensor<130x224x120x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<130x224x120x112xf32>, %arg1: tensor<130x224x120x112xf32>, %arg2: tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<130x224x120x112xf32>\n    %1 = bufferization.to_memref %arg0 : memref<130x224x120x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<130x224x120x112xf32>\n    affine.for %arg3 = 0 to 130 {\n      affine.for %arg4 = 0 to 224 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 112 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<130x224x120x112xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<130x224x120x112xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<130x224x120x112xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<130x224x120x112xf32>\n    return %2 : tensor<130x224x120x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<130x224x120x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<130x224x120x112xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<130x224x120x112xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<130x224x120x112xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<130x224x120x112xf32>, tensor<130x224x120x112xf32>) outs(%arg2: tensor<130x224x120x112xf32>) -> tensor<130x224x120x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<130x224x120x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<130x224x120x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          130,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 473814871
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 28112693
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 384928382
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<3072x2048xf32>) -> tensor<3072x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>\n  return %ret : tensor<3072x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<3072x2048xf32>) -> tensor<3072x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x2048xf32>\n    memref.copy %2, %alloc : memref<3072x2048xf32> to memref<3072x2048xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x2048xf32>\n    return %3 : tensor<3072x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2903731689
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1536xf32>, %arg2: tensor<512x1536xf32>) -> tensor<512x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n  return %ret : tensor<512x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1536xf32>, %arg2: tensor<512x1536xf32>) -> tensor<512x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1536xf32>\n    memref.copy %2, %alloc : memref<512x1536xf32> to memref<512x1536xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1536xf32>\n    return %3 : tensor<512x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1530497807
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1020412985
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1555464459
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x768xf32>, %arg2: tensor<256x768xf32>) -> tensor<256x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n  return %ret : tensor<256x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x768xf32>, %arg2: tensor<256x768xf32>) -> tensor<256x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x768xf32>\n    memref.copy %2, %alloc : memref<256x768xf32> to memref<256x768xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x768xf32>\n    return %3 : tensor<256x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2329172744
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n  return %ret : tensor<512x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x2048xf32>\n    memref.copy %2, %alloc : memref<512x2048xf32> to memref<512x2048xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x2048xf32>\n    return %3 : tensor<512x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8289615737
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1032350420
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 62302921
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 384428623
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<1024x2048xf32>) -> tensor<1024x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n  return %ret : tensor<1024x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<1024x2048xf32>) -> tensor<1024x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x2048xf32>\n    memref.copy %2, %alloc : memref<1024x2048xf32> to memref<1024x2048xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x2048xf32>\n    return %3 : tensor<1024x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 967887843
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<3072x1536xf32>) -> tensor<3072x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n  return %ret : tensor<3072x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<3072x1536xf32>) -> tensor<3072x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x1536xf32>\n    memref.copy %2, %alloc : memref<3072x1536xf32> to memref<3072x1536xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x1536xf32>\n    return %3 : tensor<3072x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2149245607
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n  return %ret : tensor<256x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x2048xf32>\n    memref.copy %2, %alloc : memref<256x2048xf32> to memref<256x2048xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x2048xf32>\n    return %3 : tensor<256x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x2048xf32>) -> tensor<768x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1542699956
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n  return %ret : tensor<256x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1536xf32>\n    memref.copy %2, %alloc : memref<256x1536xf32> to memref<256x1536xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1536xf32>\n    return %3 : tensor<256x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 178172577
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x512xf32>, %arg1: tensor<512x768xf32>, %arg2: tensor<1536x768xf32>) -> tensor<1536x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n  return %ret : tensor<1536x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x512xf32>, %arg1: tensor<512x768xf32>, %arg2: tensor<1536x768xf32>) -> tensor<1536x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x768xf32>\n    memref.copy %2, %alloc : memref<1536x768xf32> to memref<1536x768xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x768xf32>\n    return %3 : tensor<1536x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2299363888
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<2048x768xf32>) -> tensor<2048x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n  return %ret : tensor<2048x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<2048x768xf32>) -> tensor<2048x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x768xf32>\n    memref.copy %2, %alloc : memref<2048x768xf32> to memref<2048x768xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x768xf32>\n    return %3 : tensor<2048x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4618852853
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n  return %ret : tensor<1536x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x256xf32>\n    memref.copy %2, %alloc : memref<1536x256xf32> to memref<1536x256xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x256xf32>\n    return %3 : tensor<1536x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 370414548
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n  return %ret : tensor<1536x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x256xf32>\n    memref.copy %2, %alloc : memref<1536x256xf32> to memref<1536x256xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x256xf32>\n    return %3 : tensor<1536x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 169047661
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n  return %ret : tensor<256x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x2048xf32>\n    memref.copy %2, %alloc : memref<256x2048xf32> to memref<256x2048xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x2048xf32>\n    return %3 : tensor<256x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 241842261
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n  return %ret : tensor<2048x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x256xf32>\n    memref.copy %2, %alloc : memref<2048x256xf32> to memref<2048x256xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x256xf32>\n    return %3 : tensor<2048x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 225535156
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n  return %ret : tensor<1536x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x128xf32>\n    memref.copy %2, %alloc : memref<1536x128xf32> to memref<1536x128xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x128xf32>\n    return %3 : tensor<1536x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 572973012
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x768xf32>, %arg2: tensor<768x768xf32>) -> tensor<768x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n  return %ret : tensor<768x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x768xf32>, %arg2: tensor<768x768xf32>) -> tensor<768x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x768xf32>\n    memref.copy %2, %alloc : memref<768x768xf32> to memref<768x768xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x768xf32>\n    return %3 : tensor<768x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2316573259
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 63763586
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 128554636
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n  return %ret : tensor<128x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1536xf32>\n    memref.copy %2, %alloc : memref<128x1536xf32> to memref<128x1536xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1536xf32>\n    return %3 : tensor<128x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x768xf32>) -> tensor<128x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 578487241
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<1536x512xf32>) -> tensor<1536x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n  return %ret : tensor<1536x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<1536x512xf32>) -> tensor<1536x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x512xf32>\n    memref.copy %2, %alloc : memref<1536x512xf32> to memref<1536x512xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x512xf32>\n    return %3 : tensor<1536x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 752172679
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 59152526
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n  return %ret : tensor<1536x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x256xf32>\n    memref.copy %2, %alloc : memref<1536x256xf32> to memref<1536x256xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x256xf32>\n    return %3 : tensor<1536x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1541821775
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<768x1024xf32>) -> tensor<768x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n  return %ret : tensor<768x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<768x1024xf32>) -> tensor<768x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x1024xf32>\n    memref.copy %2, %alloc : memref<768x1024xf32> to memref<768x1024xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x1024xf32>\n    return %3 : tensor<768x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3093051170
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4144447178
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n  return %ret : tensor<256x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x2048xf32>\n    memref.copy %2, %alloc : memref<256x2048xf32> to memref<256x2048xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x2048xf32>\n    return %3 : tensor<256x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3106434894
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n  return %ret : tensor<512x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x2048xf32>\n    memref.copy %2, %alloc : memref<512x2048xf32> to memref<512x2048xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x2048xf32>\n    return %3 : tensor<512x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6204582886
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<512x1536xf32>) -> tensor<512x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n  return %ret : tensor<512x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<512x1536xf32>) -> tensor<512x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1536xf32>\n    memref.copy %2, %alloc : memref<512x1536xf32> to memref<512x1536xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1536xf32>\n    return %3 : tensor<512x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 353204468
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<1536x512xf32>) -> tensor<1536x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n  return %ret : tensor<1536x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<1536x512xf32>) -> tensor<1536x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x512xf32>\n    memref.copy %2, %alloc : memref<1536x512xf32> to memref<1536x512xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x512xf32>\n    return %3 : tensor<1536x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4648739643
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 59223182
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 381620135
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 127578316
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n  return %ret : tensor<512x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x768xf32>\n    memref.copy %2, %alloc : memref<512x768xf32> to memref<512x768xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x768xf32>\n    return %3 : tensor<512x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2323363712
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n  return %ret : tensor<512x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x2048xf32>\n    memref.copy %2, %alloc : memref<512x2048xf32> to memref<512x2048xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x2048xf32>\n    return %3 : tensor<512x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 482960984
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n  return %ret : tensor<2048x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x256xf32>\n    memref.copy %2, %alloc : memref<2048x256xf32> to memref<2048x256xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x256xf32>\n    return %3 : tensor<2048x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 493851103
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1536xf32>, %arg1: tensor<1536x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1536xf32>, %arg1: tensor<1536x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 776329808
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n  return %ret : tensor<2048x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x512xf32>\n    memref.copy %2, %alloc : memref<2048x512xf32> to memref<2048x512xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x512xf32>\n    return %3 : tensor<2048x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6209554157
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7050494
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<2048x1024xf32>) -> tensor<2048x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n  return %ret : tensor<2048x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<2048x1024xf32>) -> tensor<2048x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x1024xf32>\n    memref.copy %2, %alloc : memref<2048x1024xf32> to memref<2048x1024xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x1024xf32>\n    return %3 : tensor<2048x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2005839977
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x3072xf32>, %arg2: tensor<128x3072xf32>) -> tensor<128x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n  return %ret : tensor<128x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x3072xf32>, %arg2: tensor<128x3072xf32>) -> tensor<128x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x3072xf32>\n    memref.copy %2, %alloc : memref<128x3072xf32> to memref<128x3072xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x3072xf32>\n    return %3 : tensor<128x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x768xf32>) -> tensor<128x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x3072xf32>) -> tensor<768x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1157787755
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 255100390
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n  return %ret : tensor<768x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x512xf32>\n    memref.copy %2, %alloc : memref<768x512xf32> to memref<768x512xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x512xf32>\n    return %3 : tensor<768x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 181397330
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 514059677
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<3072x512xf32>) -> tensor<3072x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n  return %ret : tensor<3072x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<3072x512xf32>) -> tensor<3072x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x512xf32>\n    memref.copy %2, %alloc : memref<3072x512xf32> to memref<3072x512xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x512xf32>\n    return %3 : tensor<3072x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6175339403
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<3072x256xf32>) -> tensor<3072x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n  return %ret : tensor<3072x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<3072x256xf32>) -> tensor<3072x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x256xf32>\n    memref.copy %2, %alloc : memref<3072x256xf32> to memref<3072x256xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x256xf32>\n    return %3 : tensor<3072x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 337860827
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<768x128xf32>) -> tensor<768x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n  return %ret : tensor<768x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<768x128xf32>) -> tensor<768x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x128xf32>\n    memref.copy %2, %alloc : memref<768x128xf32> to memref<768x128xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x128xf32>\n    return %3 : tensor<768x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x2048xf32>) -> tensor<768x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 768858441
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x3072xf32>, %arg1: tensor<3072x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n  return %ret : tensor<1024x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x3072xf32>, %arg1: tensor<3072x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x768xf32>\n    memref.copy %2, %alloc : memref<1024x768xf32> to memref<1024x768xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x768xf32>\n    return %3 : tensor<1024x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x3072xf32>) -> tensor<1024x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9316704088
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<768x256xf32>) -> tensor<768x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n  return %ret : tensor<768x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<768x256xf32>) -> tensor<768x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x256xf32>\n    memref.copy %2, %alloc : memref<768x256xf32> to memref<768x256xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x256xf32>\n    return %3 : tensor<768x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 770768551
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x3072xf32>, %arg2: tensor<128x3072xf32>) -> tensor<128x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n  return %ret : tensor<128x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<512x3072xf32>, %arg2: tensor<128x3072xf32>) -> tensor<128x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x3072xf32>\n    memref.copy %2, %alloc : memref<128x3072xf32> to memref<128x3072xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x3072xf32>\n    return %3 : tensor<128x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x512xf32>, tensor<512x3072xf32>) outs(%arg2 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 766733631
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x768xf32>, %arg1: tensor<768x1024xf32>, %arg2: tensor<1536x1024xf32>) -> tensor<1536x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n  return %ret : tensor<1536x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x768xf32>, %arg1: tensor<768x1024xf32>, %arg2: tensor<1536x1024xf32>) -> tensor<1536x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x1024xf32>\n    memref.copy %2, %alloc : memref<1536x1024xf32> to memref<1536x1024xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x1024xf32>\n    return %3 : tensor<1536x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4614797475
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n  return %ret : tensor<1536x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x256xf32>\n    memref.copy %2, %alloc : memref<1536x256xf32> to memref<1536x256xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x256xf32>\n    return %3 : tensor<1536x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 763774468
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<768x256xf32>) -> tensor<768x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n  return %ret : tensor<768x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<768x256xf32>) -> tensor<768x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x256xf32>\n    memref.copy %2, %alloc : memref<768x256xf32> to memref<768x256xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x256xf32>\n    return %3 : tensor<768x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 183235344
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n  return %ret : tensor<2048x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x256xf32>\n    memref.copy %2, %alloc : memref<2048x256xf32> to memref<2048x256xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x256xf32>\n    return %3 : tensor<2048x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3092293668
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 249233454
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    memref.copy %2, %alloc : memref<128x512xf32> to memref<128x512xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %3 : tensor<128x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 386618198
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 385444897
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n  return %ret : tensor<2048x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x128xf32>\n    memref.copy %2, %alloc : memref<2048x128xf32> to memref<2048x128xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x128xf32>\n    return %3 : tensor<2048x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 502581090
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3104591517
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 246199680
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<3072x128xf32>) -> tensor<3072x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n  return %ret : tensor<3072x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<3072x128xf32>) -> tensor<3072x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x128xf32>\n    memref.copy %2, %alloc : memref<3072x128xf32> to memref<3072x128xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x128xf32>\n    return %3 : tensor<3072x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2305431543
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<1536x768xf32>) -> tensor<1536x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n  return %ret : tensor<1536x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<1536x768xf32>) -> tensor<1536x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x768xf32>\n    memref.copy %2, %alloc : memref<1536x768xf32> to memref<1536x768xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x768xf32>\n    return %3 : tensor<1536x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1121759317
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x768xf32>) -> tensor<128x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 96259371
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<2048x1024xf32>) -> tensor<2048x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n  return %ret : tensor<2048x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<2048x1024xf32>) -> tensor<2048x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x1024xf32>\n    memref.copy %2, %alloc : memref<2048x1024xf32> to memref<2048x1024xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x1024xf32>\n    return %3 : tensor<2048x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8261642902
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1029340263
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8296878412
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1020695935
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2073823873
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x3072xf32>, %arg1: tensor<3072x1024xf32>, %arg2: tensor<768x1024xf32>) -> tensor<768x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n  return %ret : tensor<768x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x3072xf32>, %arg1: tensor<3072x1024xf32>, %arg2: tensor<768x1024xf32>) -> tensor<768x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x1024xf32>\n    memref.copy %2, %alloc : memref<768x1024xf32> to memref<768x1024xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x1024xf32>\n    return %3 : tensor<768x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x3072xf32>) -> tensor<768x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9343633831
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 775234090
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<768x128xf32>) -> tensor<768x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n  return %ret : tensor<768x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<768x128xf32>) -> tensor<768x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x128xf32>\n    memref.copy %2, %alloc : memref<768x128xf32> to memref<768x128xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x128xf32>\n    return %3 : tensor<768x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 576311891
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x3072xf32>, %arg1: tensor<3072x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x3072xf32>, %arg1: tensor<3072x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x3072xf32>) -> tensor<1024x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x3072xf32>, tensor<3072x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12453820563
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n  return %ret : tensor<768x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x512xf32>\n    memref.copy %2, %alloc : memref<768x512xf32> to memref<768x512xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x512xf32>\n    return %3 : tensor<768x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1155069866
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<3072x1024xf32>) -> tensor<3072x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>\n  return %ret : tensor<3072x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<3072x1024xf32>) -> tensor<3072x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x1024xf32>\n    memref.copy %2, %alloc : memref<3072x1024xf32> to memref<3072x1024xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x1024xf32>\n    return %3 : tensor<3072x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<3072x1024xf32>) -> tensor<3072x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6121570480
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x2048xf32>, %arg1: tensor<2048x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n  return %ret : tensor<2048x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x2048xf32>, %arg1: tensor<2048x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x512xf32>\n    memref.copy %2, %alloc : memref<2048x512xf32> to memref<2048x512xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x512xf32>\n    return %3 : tensor<2048x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8271881885
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1536xf32>, %arg1: tensor<1536x2048xf32>, %arg2: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n  return %ret : tensor<128x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1536xf32>, %arg1: tensor<1536x2048xf32>, %arg2: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x2048xf32>\n    memref.copy %2, %alloc : memref<128x2048xf32> to memref<128x2048xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x2048xf32>\n    return %3 : tensor<128x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1536xf32>, tensor<1536x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1550924054
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n  return %ret : tensor<512x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<512x128xf32>) -> tensor<512x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x128xf32>\n    memref.copy %2, %alloc : memref<512x128xf32> to memref<512x128xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x128xf32>\n    return %3 : tensor<512x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<512x128xf32>) -> tensor<512x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 255548241
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n  return %ret : tensor<2048x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<2048x256xf32>) -> tensor<2048x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x256xf32>\n    memref.copy %2, %alloc : memref<2048x256xf32> to memref<2048x256xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x256xf32>\n    return %3 : tensor<2048x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1537364181
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x2048xf32>) outs(%arg2 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x2048xf32>) outs(%arg2 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x2048xf32>, %arg2: tensor<2048x2048xf32>) -> tensor<2048x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x2048xf32>) outs(%arg2 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>\n  return %ret : tensor<2048x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x2048xf32>, %arg2: tensor<2048x2048xf32>) -> tensor<2048x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x2048xf32>\n    memref.copy %2, %alloc : memref<2048x2048xf32> to memref<2048x2048xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x2048xf32>\n    return %3 : tensor<2048x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x2048xf32>) outs(%arg2 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8178853024
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x3072xf32>, %arg1: tensor<3072x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n  return %ret : tensor<512x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x3072xf32>, %arg1: tensor<3072x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x768xf32>\n    memref.copy %2, %alloc : memref<512x768xf32> to memref<512x768xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x768xf32>\n    return %3 : tensor<512x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4658845721
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n  return %ret : tensor<2048x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x512xf32>\n    memref.copy %2, %alloc : memref<2048x512xf32> to memref<2048x512xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x512xf32>\n    return %3 : tensor<2048x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3078187276
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x1536xf32>, %arg2: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n  return %ret : tensor<256x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<3072x1536xf32>, %arg2: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1536xf32>\n    memref.copy %2, %alloc : memref<256x1536xf32> to memref<256x1536xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1536xf32>\n    return %3 : tensor<256x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4991378845
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 254974153
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2041285106
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n  return %ret : tensor<256x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x3072xf32>\n    memref.copy %2, %alloc : memref<256x3072xf32> to memref<256x3072xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x3072xf32>\n    return %3 : tensor<256x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x3072xf32>) -> tensor<2048x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6220603464
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n  return %ret : tensor<256x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x3072xf32>\n    memref.copy %2, %alloc : memref<256x3072xf32> to memref<256x3072xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x3072xf32>\n    return %3 : tensor<256x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x3072xf32>) -> tensor<1024x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3094816904
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<3072x512xf32>) -> tensor<3072x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n  return %ret : tensor<3072x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<3072x512xf32>) -> tensor<3072x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x512xf32>\n    memref.copy %2, %alloc : memref<3072x512xf32> to memref<3072x512xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x512xf32>\n    return %3 : tensor<3072x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<3072x512xf32>) -> tensor<3072x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9308425867
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 509107829
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n  return %ret : tensor<1536x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x128xf32>\n    memref.copy %2, %alloc : memref<1536x128xf32> to memref<1536x128xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x128xf32>\n    return %3 : tensor<1536x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 765899928
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 258023192
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1536xf32>, %arg2: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n  return %ret : tensor<256x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1536xf32>, %arg2: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1536xf32>\n    memref.copy %2, %alloc : memref<256x1536xf32> to memref<256x1536xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1536xf32>\n    return %3 : tensor<256x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1546476183
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 127348562
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3098611229
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x768xf32>, %arg1: tensor<768x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n  return %ret : tensor<512x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x768xf32>, %arg1: tensor<768x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1024xf32>\n    memref.copy %2, %alloc : memref<512x1024xf32> to memref<512x1024xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1024xf32>\n    return %3 : tensor<512x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1545601664
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x3072xf32>, %arg2: tensor<512x3072xf32>) -> tensor<512x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n  return %ret : tensor<512x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x3072xf32>, %arg2: tensor<512x3072xf32>) -> tensor<512x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x3072xf32>\n    memref.copy %2, %alloc : memref<512x3072xf32> to memref<512x3072xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x3072xf32>\n    return %3 : tensor<512x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9299524077
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<768x2048xf32>) -> tensor<768x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<768x2048xf32>) -> tensor<768x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x768xf32>, %arg1: tensor<768x2048xf32>, %arg2: tensor<768x2048xf32>) -> tensor<768x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<768x2048xf32>) -> tensor<768x2048xf32>\n  return %ret : tensor<768x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x768xf32>, %arg1: tensor<768x2048xf32>, %arg2: tensor<768x2048xf32>) -> tensor<768x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x2048xf32>\n    memref.copy %2, %alloc : memref<768x2048xf32> to memref<768x2048xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x2048xf32>\n    return %3 : tensor<768x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x2048xf32>) -> tensor<768x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x2048xf32>) -> tensor<768x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x768xf32>, tensor<768x2048xf32>) outs(%arg2 : tensor<768x2048xf32>) -> tensor<768x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4624866820
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1037433925
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n  return %ret : tensor<512x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1024xf32>, %arg1: tensor<1024x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x2048xf32>\n    memref.copy %2, %alloc : memref<512x2048xf32> to memref<512x2048xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x2048xf32>\n    return %3 : tensor<512x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4135810346
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x3072xf32>, %arg2: tensor<1536x3072xf32>) -> tensor<1536x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n  return %ret : tensor<1536x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x3072xf32>, %arg2: tensor<1536x3072xf32>) -> tensor<1536x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x3072xf32>\n    memref.copy %2, %alloc : memref<1536x3072xf32> to memref<1536x3072xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x3072xf32>\n    return %3 : tensor<1536x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2176936552
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x1536xf32>, %arg2: tensor<512x1536xf32>) -> tensor<512x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n  return %ret : tensor<512x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x1536xf32>, %arg1: tensor<1536x1536xf32>, %arg2: tensor<512x1536xf32>) -> tensor<512x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x1536xf32>\n    memref.copy %2, %alloc : memref<512x1536xf32> to memref<512x1536xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x1536xf32>\n    return %3 : tensor<512x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x1536xf32>, tensor<1536x1536xf32>) outs(%arg2 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4698531138
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x768xf32>, %arg2: tensor<2048x768xf32>) -> tensor<2048x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n  return %ret : tensor<2048x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x768xf32>, %arg2: tensor<2048x768xf32>) -> tensor<2048x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x768xf32>\n    memref.copy %2, %alloc : memref<2048x768xf32> to memref<2048x768xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x768xf32>\n    return %3 : tensor<2048x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3065281114
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<3072x1536xf32>) -> tensor<3072x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n  return %ret : tensor<3072x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<3072x1536xf32>) -> tensor<3072x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x1536xf32>\n    memref.copy %2, %alloc : memref<3072x1536xf32> to memref<3072x1536xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x1536xf32>\n    return %3 : tensor<3072x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4512564601
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n  return %ret : tensor<2048x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x128xf32>\n    memref.copy %2, %alloc : memref<2048x128xf32> to memref<2048x128xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x128xf32>\n    return %3 : tensor<2048x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1020339797
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n  return %ret : tensor<128x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1536xf32>\n    memref.copy %2, %alloc : memref<128x1536xf32> to memref<128x1536xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1536xf32>\n    return %3 : tensor<128x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1582968867
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n  return %ret : tensor<768x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x512xf32>\n    memref.copy %2, %alloc : memref<768x512xf32> to memref<768x512xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x512xf32>\n    return %3 : tensor<768x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1544474683
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x512xf32>, %arg1: tensor<512x768xf32>, %arg2: tensor<768x768xf32>) -> tensor<768x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n  return %ret : tensor<768x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x512xf32>, %arg1: tensor<512x768xf32>, %arg2: tensor<768x768xf32>) -> tensor<768x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x768xf32>\n    memref.copy %2, %alloc : memref<768x768xf32> to memref<768x768xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x768xf32>\n    return %3 : tensor<768x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1150255310
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 192081240
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1536xf32>, %arg1: tensor<1536x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n  return %ret : tensor<1024x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1536xf32>, %arg1: tensor<1536x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x768xf32>\n    memref.copy %2, %alloc : memref<1024x768xf32> to memref<1024x768xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x768xf32>\n    return %3 : tensor<1024x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1536xf32>, tensor<1536x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4643984105
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n  return %ret : tensor<1024x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1024xf32>\n    memref.copy %2, %alloc : memref<1024x1024xf32> to memref<1024x1024xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1024xf32>\n    return %3 : tensor<1024x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1003045292
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<1536x1536xf32>) -> tensor<1536x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n  return %ret : tensor<1536x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<1536x1536xf32>) -> tensor<1536x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x1536xf32>\n    memref.copy %2, %alloc : memref<1536x1536xf32> to memref<1536x1536xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x1536xf32>\n    return %3 : tensor<1536x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2250567020
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<1536x2048xf32>) -> tensor<1536x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>\n  return %ret : tensor<1536x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x2048xf32>, %arg2: tensor<1536x2048xf32>) -> tensor<1536x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x2048xf32>\n    memref.copy %2, %alloc : memref<1536x2048xf32> to memref<1536x2048xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x2048xf32>\n    return %3 : tensor<1536x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x2048xf32>) outs(%arg2 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1447770701
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<2048x1536xf32>) -> tensor<2048x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n  return %ret : tensor<2048x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<2048x1536xf32>) -> tensor<2048x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x1536xf32>\n    memref.copy %2, %alloc : memref<2048x1536xf32> to memref<2048x1536xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x1536xf32>\n    return %3 : tensor<2048x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3008006271
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n  return %ret : tensor<1536x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<1536x256xf32>) -> tensor<1536x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x256xf32>\n    memref.copy %2, %alloc : memref<1536x256xf32> to memref<1536x256xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x256xf32>\n    return %3 : tensor<1536x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2316867252
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 30537036
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n  return %ret : tensor<128x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1536xf32>\n    memref.copy %2, %alloc : memref<128x1536xf32> to memref<128x1536xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1536xf32>\n    return %3 : tensor<128x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 89235170
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 192421938
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n  return %ret : tensor<1536x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x1536xf32>, %arg1: tensor<1536x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x128xf32>\n    memref.copy %2, %alloc : memref<1536x128xf32> to memref<1536x128xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x128xf32>\n    return %3 : tensor<1536x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1536xf32>, tensor<1536x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1151726051
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n  return %ret : tensor<256x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x3072xf32>\n    memref.copy %2, %alloc : memref<256x3072xf32> to memref<256x3072xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x3072xf32>\n    return %3 : tensor<256x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4660034420
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n  return %ret : tensor<1536x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<1536x128xf32>) -> tensor<1536x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x128xf32>\n    memref.copy %2, %alloc : memref<1536x128xf32> to memref<1536x128xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x128xf32>\n    return %3 : tensor<1536x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x2048xf32>) -> tensor<1536x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1538696619
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n  return %ret : tensor<2048x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x128xf32>\n    memref.copy %2, %alloc : memref<2048x128xf32> to memref<2048x128xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x128xf32>\n    return %3 : tensor<2048x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 763798209
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x1536xf32>, %arg2: tensor<768x1536xf32>) -> tensor<768x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n  return %ret : tensor<768x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1024xf32>, %arg1: tensor<1024x1536xf32>, %arg2: tensor<768x1536xf32>) -> tensor<768x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x1536xf32>\n    memref.copy %2, %alloc : memref<768x1536xf32> to memref<768x1536xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x1536xf32>\n    return %3 : tensor<768x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1024xf32>, tensor<1024x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4642580901
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x1024xf32>, %arg2: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    memref.copy %2, %alloc : memref<128x1024xf32> to memref<128x1024xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %3 : tensor<128x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x1024xf32>) outs(%arg2 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1036262844
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n  return %ret : tensor<768x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x512xf32>\n    memref.copy %2, %alloc : memref<768x512xf32> to memref<768x512xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x512xf32>\n    return %3 : tensor<768x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 375967980
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n  return %ret : tensor<2048x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x512xf32>\n    memref.copy %2, %alloc : memref<2048x512xf32> to memref<2048x512xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x512xf32>\n    return %3 : tensor<2048x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1002271000
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    memref.copy %2, %alloc : memref<128x256xf32> to memref<128x256xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %3 : tensor<128x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 128423836
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<3072x256xf32>) -> tensor<3072x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n  return %ret : tensor<3072x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<3072x256xf32>) -> tensor<3072x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x256xf32>\n    memref.copy %2, %alloc : memref<3072x256xf32> to memref<3072x256xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x256xf32>\n    return %3 : tensor<3072x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4632052784
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n  return %ret : tensor<768x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x512xf32>\n    memref.copy %2, %alloc : memref<768x512xf32> to memref<768x512xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x512xf32>\n    return %3 : tensor<768x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 764882634
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n  return %ret : tensor<2048x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<2048x128xf32>) -> tensor<2048x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x128xf32>\n    memref.copy %2, %alloc : memref<2048x128xf32> to memref<2048x128xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x128xf32>\n    return %3 : tensor<2048x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 112359733
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x1536xf32>, %arg1: tensor<1536x1024xf32>, %arg2: tensor<2048x1024xf32>) -> tensor<2048x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n  return %ret : tensor<2048x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x1536xf32>, %arg1: tensor<1536x1024xf32>, %arg2: tensor<2048x1024xf32>) -> tensor<2048x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x1024xf32>\n    memref.copy %2, %alloc : memref<2048x1024xf32> to memref<2048x1024xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x1024xf32>\n    return %3 : tensor<2048x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x1536xf32>, tensor<1536x1024xf32>) outs(%arg2 : tensor<2048x1024xf32>) -> tensor<2048x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12396925743
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x2048xf32>, %arg1: tensor<2048x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n  return %ret : tensor<1024x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x2048xf32>, %arg1: tensor<2048x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x768xf32>\n    memref.copy %2, %alloc : memref<1024x768xf32> to memref<1024x768xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x768xf32>\n    return %3 : tensor<1024x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6199274494
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n  return %ret : tensor<2048x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<2048x512xf32>) -> tensor<2048x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x512xf32>\n    memref.copy %2, %alloc : memref<2048x512xf32> to memref<2048x512xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x512xf32>\n    return %3 : tensor<2048x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 468684876
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x3072xf32>, %arg1: tensor<3072x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n  return %ret : tensor<128x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x3072xf32>, %arg1: tensor<3072x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1536xf32>\n    memref.copy %2, %alloc : memref<128x1536xf32> to memref<128x1536xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1536xf32>\n    return %3 : tensor<128x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x1536xf32>) -> tensor<3072x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2334551418
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<768x128xf32>, %arg2: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    memref.copy %2, %alloc : memref<128x128xf32> to memref<128x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %3 : tensor<128x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x768xf32>) -> tensor<128x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x768xf32>, tensor<768x128xf32>) outs(%arg2 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 47798110
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1536x512xf32>) -> tensor<1536x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n  return %ret : tensor<1536x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1536x512xf32>) -> tensor<1536x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x512xf32>\n    memref.copy %2, %alloc : memref<1536x512xf32> to memref<1536x512xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x512xf32>\n    return %3 : tensor<1536x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 355656435
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n  return %ret : tensor<128x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1536xf32>\n    memref.copy %2, %alloc : memref<128x1536xf32> to memref<128x1536xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x1536xf32>\n    return %3 : tensor<128x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 187757089
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n  return %ret : tensor<512x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x512xf32>, %arg2: tensor<512x512xf32>) -> tensor<512x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x512xf32>\n    memref.copy %2, %alloc : memref<512x512xf32> to memref<512x512xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x512xf32>\n    return %3 : tensor<512x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x512xf32>) outs(%arg2 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 510158551
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<1536x1024xf32>) -> tensor<1536x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n  return %ret : tensor<1536x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<1536x1024xf32>) -> tensor<1536x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x1024xf32>\n    memref.copy %2, %alloc : memref<1536x1024xf32> to memref<1536x1024xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x1024xf32>\n    return %3 : tensor<1536x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1536x1024xf32>) -> tensor<1536x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6192589992
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n  return %ret : tensor<1024x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<1024x768xf32>) -> tensor<1024x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x768xf32>\n    memref.copy %2, %alloc : memref<1024x768xf32> to memref<1024x768xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x768xf32>\n    return %3 : tensor<1024x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 747742177
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<3072x768xf32>) -> tensor<3072x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n  return %ret : tensor<3072x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<3072x768xf32>) -> tensor<3072x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x768xf32>\n    memref.copy %2, %alloc : memref<3072x768xf32> to memref<3072x768xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x768xf32>\n    return %3 : tensor<3072x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2242705480
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<768x128xf32>) -> tensor<768x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n  return %ret : tensor<768x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<768x128xf32>) -> tensor<768x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x128xf32>\n    memref.copy %2, %alloc : memref<768x128xf32> to memref<768x128xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x128xf32>\n    return %3 : tensor<768x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 42303815
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<1024x1536xf32>) -> tensor<1024x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n  return %ret : tensor<1024x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x256xf32>, %arg1: tensor<256x1536xf32>, %arg2: tensor<1024x1536xf32>) -> tensor<1024x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1536xf32>\n    memref.copy %2, %alloc : memref<1024x1536xf32> to memref<1024x1536xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1536xf32>\n    return %3 : tensor<1024x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x256xf32>, tensor<256x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1506211411
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<768x1024xf32>) -> tensor<768x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n  return %ret : tensor<768x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x1024xf32>, %arg2: tensor<768x1024xf32>) -> tensor<768x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x1024xf32>\n    memref.copy %2, %alloc : memref<768x1024xf32> to memref<768x1024xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x1024xf32>\n    return %3 : tensor<768x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1024xf32>) outs(%arg2 : tensor<768x1024xf32>) -> tensor<768x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 361921651
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x2048xf32>, %arg2: tensor<1024x2048xf32>) -> tensor<1024x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n  return %ret : tensor<1024x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x2048xf32>, %arg2: tensor<1024x2048xf32>) -> tensor<1024x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x2048xf32>\n    memref.copy %2, %alloc : memref<1024x2048xf32> to memref<1024x2048xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x2048xf32>\n    return %3 : tensor<1024x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x2048xf32>) outs(%arg2 : tensor<1024x2048xf32>) -> tensor<1024x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8250366662
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<3072x128xf32>) -> tensor<3072x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n  return %ret : tensor<3072x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<3072x128xf32>) -> tensor<3072x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x128xf32>\n    memref.copy %2, %alloc : memref<3072x128xf32> to memref<3072x128xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x128xf32>\n    return %3 : tensor<3072x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<3072x128xf32>) -> tensor<3072x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 360704963
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n  return %ret : tensor<512x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x512xf32>, %arg1: tensor<512x256xf32>, %arg2: tensor<512x256xf32>) -> tensor<512x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x256xf32>\n    memref.copy %2, %alloc : memref<512x256xf32> to memref<512x256xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x256xf32>\n    return %3 : tensor<512x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x512xf32>) -> tensor<512x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x512xf32>, tensor<512x256xf32>) outs(%arg2 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 254643017
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<768x256xf32>) -> tensor<768x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n  return %ret : tensor<768x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<768x256xf32>) -> tensor<768x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x256xf32>\n    memref.copy %2, %alloc : memref<768x256xf32> to memref<768x256xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x256xf32>\n    return %3 : tensor<768x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1159643862
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x256xf32>) -> tensor<1536x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 386740193
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 250800841
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x768xf32>, %arg1: tensor<768x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1540497931
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n  return %ret : tensor<512x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x768xf32>\n    memref.copy %2, %alloc : memref<512x768xf32> to memref<512x768xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x768xf32>\n    return %3 : tensor<512x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1154884335
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x3072xf32>, %arg1: tensor<3072x2048xf32>, %arg2: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n  return %ret : tensor<128x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x3072xf32>, %arg1: tensor<3072x2048xf32>, %arg2: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x2048xf32>\n    memref.copy %2, %alloc : memref<128x2048xf32> to memref<128x2048xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x2048xf32>\n    return %3 : tensor<128x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3115300720
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n  return %ret : tensor<1024x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x128xf32>, %arg1: tensor<128x512xf32>, %arg2: tensor<1024x512xf32>) -> tensor<1024x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x512xf32>\n    memref.copy %2, %alloc : memref<1024x512xf32> to memref<1024x512xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x512xf32>\n    return %3 : tensor<1024x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x128xf32>, tensor<128x512xf32>) outs(%arg2 : tensor<1024x512xf32>) -> tensor<1024x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 232661638
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x768xf32>, %arg1: tensor<768x1536xf32>, %arg2: tensor<1024x1536xf32>) -> tensor<1024x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n  return %ret : tensor<1024x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x768xf32>, %arg1: tensor<768x1536xf32>, %arg2: tensor<1024x1536xf32>) -> tensor<1024x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x1536xf32>\n    memref.copy %2, %alloc : memref<1024x1536xf32> to memref<1024x1536xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x1536xf32>\n    return %3 : tensor<1024x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x768xf32>) -> tensor<1024x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x768xf32>, tensor<768x1536xf32>) outs(%arg2 : tensor<1024x1536xf32>) -> tensor<1024x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4624458679
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<768x1536xf32>) -> tensor<768x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n  return %ret : tensor<768x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<768x1536xf32>) -> tensor<768x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x1536xf32>\n    memref.copy %2, %alloc : memref<768x1536xf32> to memref<768x1536xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x1536xf32>\n    return %3 : tensor<768x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x128xf32>) -> tensor<768x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 530484074
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x768xf32>, %arg1: tensor<768x3072xf32>, %arg2: tensor<1536x3072xf32>) -> tensor<1536x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n  return %ret : tensor<1536x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x768xf32>, %arg1: tensor<768x3072xf32>, %arg2: tensor<1536x3072xf32>) -> tensor<1536x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x3072xf32>\n    memref.copy %2, %alloc : memref<1536x3072xf32> to memref<1536x3072xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x3072xf32>\n    return %3 : tensor<1536x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x768xf32>) -> tensor<1536x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x3072xf32>) -> tensor<768x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<1536x3072xf32>) -> tensor<1536x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13888414109
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x3072xf32>, %arg1: tensor<3072x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n  return %ret : tensor<512x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x3072xf32>, %arg1: tensor<3072x2048xf32>, %arg2: tensor<512x2048xf32>) -> tensor<512x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<3072x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x3072xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x2048xf32>\n    memref.copy %2, %alloc : memref<512x2048xf32> to memref<512x2048xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 3072 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x3072xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<3072x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x2048xf32>\n    return %3 : tensor<512x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x3072xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<3072x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x3072xf32>, tensor<3072x2048xf32>) outs(%arg2 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12462147202
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x1536xf32>, %arg2: tensor<2048x1536xf32>) -> tensor<2048x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n  return %ret : tensor<2048x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<2048x512xf32>, %arg1: tensor<512x1536xf32>, %arg2: tensor<2048x1536xf32>) -> tensor<2048x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<2048x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<2048x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2048x1536xf32>\n    memref.copy %2, %alloc : memref<2048x1536xf32> to memref<2048x1536xf32>\n    affine.for %arg3 = 0 to 2048 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<2048x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<2048x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<2048x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<2048x1536xf32>\n    return %3 : tensor<2048x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<2048x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<2048x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<2048x512xf32>) -> tensor<2048x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1536xf32>) -> tensor<512x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<2048x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<2048x512xf32>, tensor<512x1536xf32>) outs(%arg2 : tensor<2048x1536xf32>) -> tensor<2048x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<2048x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<2048x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          2048,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6138934973
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x2048xf32>, %arg1: tensor<2048x256xf32>, %arg2: tensor<3072x256xf32>) -> tensor<3072x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n  return %ret : tensor<3072x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x2048xf32>, %arg1: tensor<2048x256xf32>, %arg2: tensor<3072x256xf32>) -> tensor<3072x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x256xf32>\n    memref.copy %2, %alloc : memref<3072x256xf32> to memref<3072x256xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x256xf32>\n    return %3 : tensor<3072x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x2048xf32>) -> tensor<3072x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x256xf32>) -> tensor<2048x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x2048xf32>, tensor<2048x256xf32>) outs(%arg2 : tensor<3072x256xf32>) -> tensor<3072x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6193226959
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x2048xf32>, %arg2: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n  return %ret : tensor<128x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<2048x2048xf32>, %arg2: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x2048xf32>\n    memref.copy %2, %alloc : memref<128x2048xf32> to memref<128x2048xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<128x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<128x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<128x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x2048xf32>\n    return %3 : tensor<128x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<128x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2072845065
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n  return %ret : tensor<1024x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x256xf32>, %arg2: tensor<1024x256xf32>) -> tensor<1024x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x256xf32>\n    memref.copy %2, %alloc : memref<1024x256xf32> to memref<1024x256xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x256xf32>\n    return %3 : tensor<1024x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x256xf32>) outs(%arg2 : tensor<1024x256xf32>) -> tensor<1024x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1027870365
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n  return %ret : tensor<768x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x1536xf32>, %arg1: tensor<1536x512xf32>, %arg2: tensor<768x512xf32>) -> tensor<768x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x512xf32>\n    memref.copy %2, %alloc : memref<768x512xf32> to memref<768x512xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x512xf32>\n    return %3 : tensor<768x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x1536xf32>) -> tensor<768x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x512xf32>) -> tensor<1536x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x1536xf32>, tensor<1536x512xf32>) outs(%arg2 : tensor<768x512xf32>) -> tensor<768x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2324350131
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<256x768xf32>) -> tensor<256x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n  return %ret : tensor<256x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<256x768xf32>) -> tensor<256x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x768xf32>\n    memref.copy %2, %alloc : memref<256x768xf32> to memref<256x768xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x768xf32>\n    return %3 : tensor<256x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 186869173
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n  return %ret : tensor<512x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x2048xf32>, %arg1: tensor<2048x768xf32>, %arg2: tensor<512x768xf32>) -> tensor<512x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x768xf32>\n    memref.copy %2, %alloc : memref<512x768xf32> to memref<512x768xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x768xf32>\n    return %3 : tensor<512x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x2048xf32>) -> tensor<512x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x768xf32>) -> tensor<2048x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x2048xf32>, tensor<2048x768xf32>) outs(%arg2 : tensor<512x768xf32>) -> tensor<512x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3102652097
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<3072x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<3072x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<3072x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<3072x768xf32>) -> tensor<3072x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<3072x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n  return %ret : tensor<3072x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<3072x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<3072x768xf32>) -> tensor<3072x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<3072x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<3072x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<3072x768xf32>\n    memref.copy %2, %alloc : memref<3072x768xf32> to memref<3072x768xf32>\n    affine.for %arg3 = 0 to 3072 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<3072x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<3072x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<3072x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<3072x768xf32>\n    return %3 : tensor<3072x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<3072x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<3072x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<3072x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<3072x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<3072x768xf32>) -> tensor<3072x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<3072x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<3072x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          3072,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6933287788
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<1536x1536xf32>) -> tensor<1536x1536xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n  return %ret : tensor<1536x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1536x128xf32>, %arg1: tensor<128x1536xf32>, %arg2: tensor<1536x1536xf32>) -> tensor<1536x1536xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x1536xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1536x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1536x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1536x1536xf32>\n    memref.copy %2, %alloc : memref<1536x1536xf32> to memref<1536x1536xf32>\n    affine.for %arg3 = 0 to 1536 {\n      affine.for %arg4 = 0 to 1536 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1536x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x1536xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1536x1536xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1536x1536xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1536x1536xf32>\n    return %3 : tensor<1536x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1536x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1536x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1536x128xf32>) -> tensor<1536x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1536x1536xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1536x128xf32>, tensor<128x1536xf32>) outs(%arg2 : tensor<1536x1536xf32>) -> tensor<1536x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1536x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1536x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1536,
          1
        ],
        [
          "%arg4",
          0,
          1536,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1074547320
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<768x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<768x768xf32>) -> tensor<768x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n  return %ret : tensor<768x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<768x256xf32>, %arg1: tensor<256x768xf32>, %arg2: tensor<768x768xf32>) -> tensor<768x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<768x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<768x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<768x768xf32>\n    memref.copy %2, %alloc : memref<768x768xf32> to memref<768x768xf32>\n    affine.for %arg3 = 0 to 768 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<768x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<768x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<768x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<768x768xf32>\n    return %3 : tensor<768x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<768x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<768x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<768x256xf32>) -> tensor<768x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<768x256xf32>, tensor<256x768xf32>) outs(%arg2 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<768x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<768x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          768,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 559159103
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x3072xf32>, %arg2: tensor<512x3072xf32>) -> tensor<512x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n  return %ret : tensor<512x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<512x256xf32>, %arg1: tensor<256x3072xf32>, %arg2: tensor<512x3072xf32>) -> tensor<512x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<512x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<512x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<512x3072xf32>\n    memref.copy %2, %alloc : memref<512x3072xf32> to memref<512x3072xf32>\n    affine.for %arg3 = 0 to 512 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<512x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<512x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<512x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<512x3072xf32>\n    return %3 : tensor<512x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<512x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<512x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<512x256xf32>) -> tensor<512x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<512x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x3072xf32>) outs(%arg2 : tensor<512x3072xf32>) -> tensor<512x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<512x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<512x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1504780550
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14031997
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x128xf32>) -> tensor<2048x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 256569681
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n  return %ret : tensor<1024x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: tensor<1024x128xf32>) -> tensor<1024x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<1024x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<1024x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<1024x128xf32>\n    memref.copy %2, %alloc : memref<1024x128xf32> to memref<1024x128xf32>\n    affine.for %arg3 = 0 to 1024 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<1024x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<1024x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<1024x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<1024x128xf32>\n    return %3 : tensor<1024x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<1024x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<1024x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x128xf32>) outs(%arg2 : tensor<1024x128xf32>) -> tensor<1024x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<1024x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<1024x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          1024,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 510751348
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x7xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x7xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x7x7xf32>, %filter: tensor<32x128x1x1xf32>, %init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x7xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>\n  return %ret : tensor<128x32x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x7x7xf32>, %arg1: tensor<32x128x1x1xf32>, %arg2: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x4x4xf32>\n    memref.copy %2, %alloc : memref<128x32x4x4xf32> to memref<128x32x4x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x128x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32x4x4xf32>\n    return %3 : tensor<128x32x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x7x7xf32>) -> tensor<128x128x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x1x1xf32>) -> tensor<32x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x7xf32>, tensor<32x128x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 27831312
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x14x14xf32>, tensor<256x48x3x3xf32>) outs (%init: tensor<256x256x6x6xf32>) -> tensor<256x256x6x6xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x14x14xf32>, tensor<256x48x3x3xf32>) outs (%init: tensor<256x256x6x6xf32>) -> tensor<256x256x6x6xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x14x14xf32>, %filter: tensor<256x48x3x3xf32>, %init: tensor<256x256x6x6xf32>) -> tensor<256x256x6x6xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x14x14xf32>, tensor<256x48x3x3xf32>) outs (%init: tensor<256x256x6x6xf32>) -> tensor<256x256x6x6xf32>\n  return %ret : tensor<256x256x6x6xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x14x14xf32>, %arg1: tensor<256x48x3x3xf32>, %arg2: tensor<256x256x6x6xf32>) -> tensor<256x256x6x6xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x48x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x48x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256x6x6xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x6x6xf32>\n    memref.copy %2, %alloc : memref<256x256x6x6xf32> to memref<256x256x6x6xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 6 {\n          affine.for %arg6 = 0 to 6 {\n            affine.for %arg7 = 0 to 48 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x48x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x48x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x6x6xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x6x6xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256x6x6xf32>\n    return %3 : tensor<256x256x6x6xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x6x6xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x14x14xf32>) -> tensor<256x48x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x48x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x48x3x3xf32>) -> tensor<256x48x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x6x6xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x6x6xf32>) -> tensor<256x256x6x6xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x14x14xf32>, tensor<256x48x3x3xf32>) outs (%init: tensor<256x256x6x6xf32>) -> tensor<256x256x6x6xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x6x6xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x6x6xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          6,
          1
        ],
        [
          "%arg6",
          0,
          6,
          1
        ],
        [
          "%arg7",
          0,
          48,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3818459880
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<128x256x1x1xf32>) outs (%init: tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<128x256x1x1xf32>) outs (%init: tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x14x14xf32>, %filter: tensor<128x256x1x1xf32>, %init: tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<128x256x1x1xf32>) outs (%init: tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32>\n  return %ret : tensor<256x128x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x14x14xf32>, %arg1: tensor<128x256x1x1xf32>, %arg2: tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x7x7xf32>\n    memref.copy %2, %alloc : memref<256x128x7x7xf32> to memref<256x128x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x256x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128x7x7xf32>\n    return %3 : tensor<256x128x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x256x1x1xf32>) -> tensor<128x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<128x256x1x1xf32>) outs (%init: tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1465308371
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x64x15x15xf32>, %filter: tensor<64x64x3x3xf32>, %init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n  return %ret : tensor<128x64x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x64x15x15xf32>, %arg1: tensor<64x64x3x3xf32>, %arg2: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x7x7xf32>\n    memref.copy %2, %alloc : memref<128x64x7x7xf32> to memref<128x64x7x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x64x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64x7x7xf32>\n    return %3 : tensor<128x64x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x64x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x64x15x15xf32>) -> tensor<128x64x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x64x3x3xf32>) -> tensor<64x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 866965152
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x56xf32>, tensor<384x96x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x56xf32>, tensor<384x96x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x56x56xf32>, %filter: tensor<384x96x1x1xf32>, %init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x56xf32>, tensor<384x96x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>\n  return %ret : tensor<128x384x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x56x56xf32>, %arg1: tensor<384x96x1x1xf32>, %arg2: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<384x96x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x96x56x56xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x384x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x28x28xf32>\n    memref.copy %2, %alloc : memref<128x384x28x28xf32> to memref<128x384x28x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x96x56x56xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<384x96x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x384x28x28xf32>\n    return %3 : tensor<128x384x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x56x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x56x56xf32>) -> tensor<128x96x56x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<384x96x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<384x96x1x1xf32>) -> tensor<384x96x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x56xf32>, tensor<384x96x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 11859507478
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x28x28xf32>, %filter: tensor<256x32x1x1xf32>, %init: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>\n  return %ret : tensor<128x256x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x28x28xf32>, %arg1: tensor<256x32x1x1xf32>, %arg2: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x28x28xf32>\n    memref.copy %2, %alloc : memref<128x256x28x28xf32> to memref<128x256x28x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x32x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256x28x28xf32>\n    return %3 : tensor<128x256x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x28x28xf32>) -> tensor<128x32x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x32x1x1xf32>) -> tensor<256x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<256x32x1x1xf32>) outs (%init: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1898131795
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<256x288x4x4xf32>) -> tensor<256x288x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<256x288x4x4xf32>) -> tensor<256x288x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x7x7xf32>, %filter: tensor<288x288x1x1xf32>, %init: tensor<256x288x4x4xf32>) -> tensor<256x288x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<256x288x4x4xf32>) -> tensor<256x288x4x4xf32>\n  return %ret : tensor<256x288x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x7x7xf32>, %arg1: tensor<288x288x1x1xf32>, %arg2: tensor<256x288x4x4xf32>) -> tensor<256x288x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<288x288x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x288x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x288x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x4x4xf32>\n    memref.copy %2, %alloc : memref<256x288x4x4xf32> to memref<256x288x4x4xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 288 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x288x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<288x288x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x288x4x4xf32>\n    return %3 : tensor<256x288x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x7x7xf32>) -> tensor<256x288x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<288x288x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<288x288x1x1xf32>) -> tensor<288x288x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x4x4xf32>) -> tensor<256x288x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<256x288x4x4xf32>) -> tensor<256x288x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          288,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1215453721
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x15x15xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x15x15xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x15x15xf32>, %filter: tensor<64x384x7x7xf32>, %init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x15x15xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>\n  return %ret : tensor<128x64x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x15x15xf32>, %arg1: tensor<64x384x7x7xf32>, %arg2: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x384x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x384x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x5x5xf32>\n    memref.copy %2, %alloc : memref<128x64x5x5xf32> to memref<128x64x5x5xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 384 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x384x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x384x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64x5x5xf32>\n    return %3 : tensor<128x64x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x15x15xf32>) -> tensor<128x384x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x384x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x384x7x7xf32>) -> tensor<64x384x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x15x15xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          384,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14569652353
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x14x14xf32>, tensor<384x32x1x1xf32>) outs (%init: tensor<256x384x14x14xf32>) -> tensor<256x384x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x14x14xf32>, tensor<384x32x1x1xf32>) outs (%init: tensor<256x384x14x14xf32>) -> tensor<256x384x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x14x14xf32>, %filter: tensor<384x32x1x1xf32>, %init: tensor<256x384x14x14xf32>) -> tensor<256x384x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x14x14xf32>, tensor<384x32x1x1xf32>) outs (%init: tensor<256x384x14x14xf32>) -> tensor<256x384x14x14xf32>\n  return %ret : tensor<256x384x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x14x14xf32>, %arg1: tensor<384x32x1x1xf32>, %arg2: tensor<256x384x14x14xf32>) -> tensor<256x384x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<384x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x384x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x14x14xf32>\n    memref.copy %2, %alloc : memref<256x384x14x14xf32> to memref<256x384x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<384x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x384x14x14xf32>\n    return %3 : tensor<256x384x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x14x14xf32>) -> tensor<256x32x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<384x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<384x32x1x1xf32>) -> tensor<384x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x14x14xf32>) -> tensor<256x384x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x14x14xf32>, tensor<384x32x1x1xf32>) outs (%init: tensor<256x384x14x14xf32>) -> tensor<256x384x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1402679142
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x14xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x4x4xf32>) -> tensor<128x64x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x14xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x4x4xf32>) -> tensor<128x64x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x14x14xf32>, %filter: tensor<64x384x7x7xf32>, %init: tensor<128x64x4x4xf32>) -> tensor<128x64x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x14xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x4x4xf32>) -> tensor<128x64x4x4xf32>\n  return %ret : tensor<128x64x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x14x14xf32>, %arg1: tensor<64x384x7x7xf32>, %arg2: tensor<128x64x4x4xf32>) -> tensor<128x64x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x384x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x384x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x4x4xf32>\n    memref.copy %2, %alloc : memref<128x64x4x4xf32> to memref<128x64x4x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 384 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x384x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x384x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64x4x4xf32>\n    return %3 : tensor<128x64x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x14x14xf32>) -> tensor<128x384x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x384x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x384x7x7xf32>) -> tensor<64x384x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x4x4xf32>) -> tensor<128x64x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x14xf32>, tensor<64x384x7x7xf32>) outs (%init: tensor<128x64x4x4xf32>) -> tensor<128x64x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          384,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9330002945
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<96x384x1x1xf32>) outs (%init: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<96x384x1x1xf32>) outs (%init: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x28x28xf32>, %filter: tensor<96x384x1x1xf32>, %init: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<96x384x1x1xf32>) outs (%init: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32>\n  return %ret : tensor<256x96x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x28x28xf32>, %arg1: tensor<96x384x1x1xf32>, %arg2: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x384x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x384x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x96x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x14x14xf32>\n    memref.copy %2, %alloc : memref<256x96x14x14xf32> to memref<256x96x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 384 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x384x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x384x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x96x14x14xf32>\n    return %3 : tensor<256x96x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x28x28xf32>) -> tensor<256x384x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x384x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x384x1x1xf32>) -> tensor<96x384x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<96x384x1x1xf32>) outs (%init: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          384,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6805393862
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x15x15xf32>, tensor<96x192x7x7xf32>) outs (%init: tensor<128x96x5x5xf32>) -> tensor<128x96x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x15x15xf32>, tensor<96x192x7x7xf32>) outs (%init: tensor<128x96x5x5xf32>) -> tensor<128x96x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x15x15xf32>, %filter: tensor<96x192x7x7xf32>, %init: tensor<128x96x5x5xf32>) -> tensor<128x96x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x15x15xf32>, tensor<96x192x7x7xf32>) outs (%init: tensor<128x96x5x5xf32>) -> tensor<128x96x5x5xf32>\n  return %ret : tensor<128x96x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x15x15xf32>, %arg1: tensor<96x192x7x7xf32>, %arg2: tensor<128x96x5x5xf32>) -> tensor<128x96x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x192x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x192x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x96x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x5x5xf32>\n    memref.copy %2, %alloc : memref<128x96x5x5xf32> to memref<128x96x5x5xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 192 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x192x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x192x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x96x5x5xf32>\n    return %3 : tensor<128x96x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x15x15xf32>) -> tensor<128x192x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x192x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x192x7x7xf32>) -> tensor<96x192x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x5x5xf32>) -> tensor<128x96x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x15x15xf32>, tensor<96x192x7x7xf32>) outs (%init: tensor<128x96x5x5xf32>) -> tensor<128x96x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          192,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 10932900555
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x28x28xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<128x64x14x14xf32>) -> tensor<128x64x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x28x28xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<128x64x14x14xf32>) -> tensor<128x64x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x28x28xf32>, %filter: tensor<64x128x1x1xf32>, %init: tensor<128x64x14x14xf32>) -> tensor<128x64x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x28x28xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<128x64x14x14xf32>) -> tensor<128x64x14x14xf32>\n  return %ret : tensor<128x64x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x28x28xf32>, %arg1: tensor<64x128x1x1xf32>, %arg2: tensor<128x64x14x14xf32>) -> tensor<128x64x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x14x14xf32>\n    memref.copy %2, %alloc : memref<128x64x14x14xf32> to memref<128x64x14x14xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x128x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64x14x14xf32>\n    return %3 : tensor<128x64x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x28x28xf32>) -> tensor<128x128x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x128x1x1xf32>) -> tensor<64x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x14x14xf32>) -> tensor<128x64x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x28x28xf32>, tensor<64x128x1x1xf32>) outs (%init: tensor<128x64x14x14xf32>) -> tensor<128x64x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 692700524
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<48x48x1x1xf32>) outs (%init: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<48x48x1x1xf32>) outs (%init: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x15x15xf32>, %filter: tensor<48x48x1x1xf32>, %init: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<48x48x1x1xf32>) outs (%init: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>\n  return %ret : tensor<128x48x15x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x15x15xf32>, %arg1: tensor<48x48x1x1xf32>, %arg2: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<48x48x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x48x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x48x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x15x15xf32>\n    memref.copy %2, %alloc : memref<128x48x15x15xf32> to memref<128x48x15x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 48 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x48x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<48x48x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x48x15x15xf32>\n    return %3 : tensor<128x48x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<48x48x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<48x48x1x1xf32>) -> tensor<48x48x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<48x48x1x1xf32>) outs (%init: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          48,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 167978298
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x7xf32>, tensor<128x48x3x3xf32>) outs (%init: tensor<256x128x5x5xf32>) -> tensor<256x128x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x7xf32>, tensor<128x48x3x3xf32>) outs (%init: tensor<256x128x5x5xf32>) -> tensor<256x128x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x7x7xf32>, %filter: tensor<128x48x3x3xf32>, %init: tensor<256x128x5x5xf32>) -> tensor<256x128x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x7xf32>, tensor<128x48x3x3xf32>) outs (%init: tensor<256x128x5x5xf32>) -> tensor<256x128x5x5xf32>\n  return %ret : tensor<256x128x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x7x7xf32>, %arg1: tensor<128x48x3x3xf32>, %arg2: tensor<256x128x5x5xf32>) -> tensor<256x128x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x48x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x48x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x5x5xf32>\n    memref.copy %2, %alloc : memref<256x128x5x5xf32> to memref<256x128x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 48 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x48x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x48x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128x5x5xf32>\n    return %3 : tensor<256x128x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x7x7xf32>) -> tensor<256x48x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x48x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x48x3x3xf32>) -> tensor<128x48x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x5x5xf32>) -> tensor<256x128x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x7xf32>, tensor<128x48x3x3xf32>) outs (%init: tensor<256x128x5x5xf32>) -> tensor<256x128x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          48,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1325220285
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x7xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<128x288x3x3xf32>) -> tensor<128x288x3x3xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x7xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<128x288x3x3xf32>) -> tensor<128x288x3x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x7x7xf32>, %filter: tensor<288x32x3x3xf32>, %init: tensor<128x288x3x3xf32>) -> tensor<128x288x3x3xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x7xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<128x288x3x3xf32>) -> tensor<128x288x3x3xf32>\n  return %ret : tensor<128x288x3x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x7x7xf32>, %arg1: tensor<288x32x3x3xf32>, %arg2: tensor<128x288x3x3xf32>) -> tensor<128x288x3x3xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<288x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x288x3x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x3x3xf32>\n    memref.copy %2, %alloc : memref<128x288x3x3xf32> to memref<128x288x3x3xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x32x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<288x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x3x3xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x3x3xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x288x3x3xf32>\n    return %3 : tensor<128x288x3x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x3x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x7x7xf32>) -> tensor<128x32x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<288x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<288x32x3x3xf32>) -> tensor<288x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x3x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x3x3xf32>) -> tensor<128x288x3x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x7xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<128x288x3x3xf32>) -> tensor<128x288x3x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x3x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x3x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 355482519
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<512x192x1x1xf32>) outs (%init: tensor<256x512x4x4xf32>) -> tensor<256x512x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<512x192x1x1xf32>) outs (%init: tensor<256x512x4x4xf32>) -> tensor<256x512x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x192x7x7xf32>, %filter: tensor<512x192x1x1xf32>, %init: tensor<256x512x4x4xf32>) -> tensor<256x512x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<512x192x1x1xf32>) outs (%init: tensor<256x512x4x4xf32>) -> tensor<256x512x4x4xf32>\n  return %ret : tensor<256x512x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x192x7x7xf32>, %arg1: tensor<512x192x1x1xf32>, %arg2: tensor<256x512x4x4xf32>) -> tensor<256x512x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x192x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x192x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x4x4xf32>\n    memref.copy %2, %alloc : memref<256x512x4x4xf32> to memref<256x512x4x4xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 192 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x192x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x192x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512x4x4xf32>\n    return %3 : tensor<256x512x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x192x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x192x7x7xf32>) -> tensor<256x192x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x192x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x192x1x1xf32>) -> tensor<512x192x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x4x4xf32>) -> tensor<256x512x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<512x192x1x1xf32>) outs (%init: tensor<256x512x4x4xf32>) -> tensor<256x512x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          192,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1401207299
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<128x48x1x1xf32>) outs (%init: tensor<128x128x65x65xf32>) -> tensor<128x128x65x65xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<128x48x1x1xf32>) outs (%init: tensor<128x128x65x65xf32>) -> tensor<128x128x65x65xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x130x130xf32>, %filter: tensor<128x48x1x1xf32>, %init: tensor<128x128x65x65xf32>) -> tensor<128x128x65x65xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<128x48x1x1xf32>) outs (%init: tensor<128x128x65x65xf32>) -> tensor<128x128x65x65xf32>\n  return %ret : tensor<128x128x65x65xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x130x130xf32>, %arg1: tensor<128x48x1x1xf32>, %arg2: tensor<128x128x65x65xf32>) -> tensor<128x128x65x65xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x48x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x48x130x130xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128x65x65xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x65x65xf32>\n    memref.copy %2, %alloc : memref<128x128x65x65xf32> to memref<128x128x65x65xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 65 {\n          affine.for %arg6 = 0 to 65 {\n            affine.for %arg7 = 0 to 48 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x48x130x130xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x48x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x65x65xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x65x65xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128x65x65xf32>\n    return %3 : tensor<128x128x65x65xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x65x65xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x130x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x130x130xf32>) -> tensor<128x48x130x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x48x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x48x1x1xf32>) -> tensor<128x48x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x65x65xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x65x65xf32>) -> tensor<128x128x65x65xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<128x48x1x1xf32>) outs (%init: tensor<128x128x65x65xf32>) -> tensor<128x128x65x65xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x65x65xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x65x65xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          65,
          1
        ],
        [
          "%arg6",
          0,
          65,
          1
        ],
        [
          "%arg7",
          0,
          48,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9059710777
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<96x32x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<96x32x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x15x15xf32>, %filter: tensor<96x32x3x3xf32>, %init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<96x32x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n  return %ret : tensor<256x96x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x15x15xf32>, %arg1: tensor<96x32x3x3xf32>, %arg2: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x96x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x7x7xf32>\n    memref.copy %2, %alloc : memref<256x96x7x7xf32> to memref<256x96x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x96x7x7xf32>\n    return %3 : tensor<256x96x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x15x15xf32>) -> tensor<256x32x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x32x3x3xf32>) -> tensor<96x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<96x32x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1292046112
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<384x48x3x3xf32>) outs (%init: tensor<128x384x13x13xf32>) -> tensor<128x384x13x13xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<384x48x3x3xf32>) outs (%init: tensor<128x384x13x13xf32>) -> tensor<128x384x13x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x15x15xf32>, %filter: tensor<384x48x3x3xf32>, %init: tensor<128x384x13x13xf32>) -> tensor<128x384x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<384x48x3x3xf32>) outs (%init: tensor<128x384x13x13xf32>) -> tensor<128x384x13x13xf32>\n  return %ret : tensor<128x384x13x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x15x15xf32>, %arg1: tensor<384x48x3x3xf32>, %arg2: tensor<128x384x13x13xf32>) -> tensor<128x384x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<384x48x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x48x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x384x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x13x13xf32>\n    memref.copy %2, %alloc : memref<128x384x13x13xf32> to memref<128x384x13x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 48 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x48x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<384x48x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x384x13x13xf32>\n    return %3 : tensor<128x384x13x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<384x48x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<384x48x3x3xf32>) -> tensor<384x48x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x13x13xf32>) -> tensor<128x384x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x15x15xf32>, tensor<384x48x3x3xf32>) outs (%init: tensor<128x384x13x13xf32>) -> tensor<128x384x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x13x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          48,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13442203253
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<256x288x13x13xf32>) -> tensor<256x288x13x13xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<256x288x13x13xf32>) -> tensor<256x288x13x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x15x15xf32>, %filter: tensor<288x32x3x3xf32>, %init: tensor<256x288x13x13xf32>) -> tensor<256x288x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<256x288x13x13xf32>) -> tensor<256x288x13x13xf32>\n  return %ret : tensor<256x288x13x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x15x15xf32>, %arg1: tensor<288x32x3x3xf32>, %arg2: tensor<256x288x13x13xf32>) -> tensor<256x288x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<288x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x288x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x13x13xf32>\n    memref.copy %2, %alloc : memref<256x288x13x13xf32> to memref<256x288x13x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<288x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x288x13x13xf32>\n    return %3 : tensor<256x288x13x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x15x15xf32>) -> tensor<256x32x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<288x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<288x32x3x3xf32>) -> tensor<288x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x13x13xf32>) -> tensor<256x288x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<288x32x3x3xf32>) outs (%init: tensor<256x288x13x13xf32>) -> tensor<256x288x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x13x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13371381748
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x7xf32>, tensor<96x384x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x7xf32>, tensor<96x384x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x7x7xf32>, %filter: tensor<96x384x3x3xf32>, %init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x7xf32>, tensor<96x384x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>\n  return %ret : tensor<256x96x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x7x7xf32>, %arg1: tensor<96x384x3x3xf32>, %arg2: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x384x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x384x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x96x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x5x5xf32>\n    memref.copy %2, %alloc : memref<256x96x5x5xf32> to memref<256x96x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 384 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x384x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x384x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x96x5x5xf32>\n    return %3 : tensor<256x96x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x7x7xf32>) -> tensor<256x384x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x384x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x384x3x3xf32>) -> tensor<96x384x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x7xf32>, tensor<96x384x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          384,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8034862387
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x28x28xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x28x28xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x28x28xf32>, %filter: tensor<96x256x1x1xf32>, %init: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x28x28xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32>\n  return %ret : tensor<128x96x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x28x28xf32>, %arg1: tensor<96x256x1x1xf32>, %arg2: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x96x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x28x28xf32>\n    memref.copy %2, %alloc : memref<128x96x28x28xf32> to memref<128x96x28x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x96x28x28xf32>\n    return %3 : tensor<128x96x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x256x1x1xf32>) -> tensor<96x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x28x28xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8845908035
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<64x240x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<64x240x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x7x7xf32>, %filter: tensor<64x240x3x3xf32>, %init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<64x240x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>\n  return %ret : tensor<256x64x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x7x7xf32>, %arg1: tensor<64x240x3x3xf32>, %arg2: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x240x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x240x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x5x5xf32>\n    memref.copy %2, %alloc : memref<256x64x5x5xf32> to memref<256x64x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 240 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x240x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x240x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x5x5xf32>\n    return %3 : tensor<256x64x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x7x7xf32>) -> tensor<256x240x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x240x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x240x3x3xf32>) -> tensor<64x240x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<64x240x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          240,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3339305954
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<240x256x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<240x256x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x14x14xf32>, %filter: tensor<240x256x1x1xf32>, %init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<240x256x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>\n  return %ret : tensor<128x240x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x14x14xf32>, %arg1: tensor<240x256x1x1xf32>, %arg2: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x240x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x14x14xf32>\n    memref.copy %2, %alloc : memref<128x240x14x14xf32> to memref<128x240x14x14xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<240x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x240x14x14xf32>\n    return %3 : tensor<128x240x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x14x14xf32>) -> tensor<128x256x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<240x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<240x256x1x1xf32>) -> tensor<240x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<240x256x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5473989776
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x7x7xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x7x7xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x7x7xf32>, %filter: tensor<32x256x1x1xf32>, %init: tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x7x7xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>\n  return %ret : tensor<256x32x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x7x7xf32>, %arg1: tensor<32x256x1x1xf32>, %arg2: tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x7x7xf32>\n    memref.copy %2, %alloc : memref<256x32x7x7xf32> to memref<256x32x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x256x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x7x7xf32>\n    return %3 : tensor<256x32x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x7x7xf32>) -> tensor<256x256x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x256x1x1xf32>) -> tensor<32x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x7x7xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 365595256
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x15xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x15xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x15x15xf32>, %filter: tensor<96x256x1x1xf32>, %init: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x15xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>\n  return %ret : tensor<128x96x15x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x15x15xf32>, %arg1: tensor<96x256x1x1xf32>, %arg2: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x96x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x15x15xf32>\n    memref.copy %2, %alloc : memref<128x96x15x15xf32> to memref<128x96x15x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x15x15xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x15x15xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x96x15x15xf32>\n    return %3 : tensor<128x96x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x15x15xf32>) -> tensor<128x256x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x256x1x1xf32>) -> tensor<96x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x15x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x15xf32>, tensor<96x256x1x1xf32>) outs (%init: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2519061290
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<192x256x3x3xf32>) outs (%init: tensor<128x192x3x3xf32>) -> tensor<128x192x3x3xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<192x256x3x3xf32>) outs (%init: tensor<128x192x3x3xf32>) -> tensor<128x192x3x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x7x7xf32>, %filter: tensor<192x256x3x3xf32>, %init: tensor<128x192x3x3xf32>) -> tensor<128x192x3x3xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<192x256x3x3xf32>) outs (%init: tensor<128x192x3x3xf32>) -> tensor<128x192x3x3xf32>\n  return %ret : tensor<128x192x3x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x7x7xf32>, %arg1: tensor<192x256x3x3xf32>, %arg2: tensor<128x192x3x3xf32>) -> tensor<128x192x3x3xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<192x256x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x192x3x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x3x3xf32>\n    memref.copy %2, %alloc : memref<128x192x3x3xf32> to memref<128x192x3x3xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<192x256x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x3x3xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x3x3xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x192x3x3xf32>\n    return %3 : tensor<128x192x3x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x3x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x7x7xf32>) -> tensor<128x256x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<192x256x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<192x256x3x3xf32>) -> tensor<192x256x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x3x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x3x3xf32>) -> tensor<128x192x3x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<192x256x3x3xf32>) outs (%init: tensor<128x192x3x3xf32>) -> tensor<128x192x3x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x3x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x3x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1924424682
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x28xf32>, tensor<48x240x3x3xf32>) outs (%init: tensor<128x48x13x13xf32>) -> tensor<128x48x13x13xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x28xf32>, tensor<48x240x3x3xf32>) outs (%init: tensor<128x48x13x13xf32>) -> tensor<128x48x13x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x28x28xf32>, %filter: tensor<48x240x3x3xf32>, %init: tensor<128x48x13x13xf32>) -> tensor<128x48x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x28xf32>, tensor<48x240x3x3xf32>) outs (%init: tensor<128x48x13x13xf32>) -> tensor<128x48x13x13xf32>\n  return %ret : tensor<128x48x13x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x28x28xf32>, %arg1: tensor<48x240x3x3xf32>, %arg2: tensor<128x48x13x13xf32>) -> tensor<128x48x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<48x240x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x240x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x48x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x13x13xf32>\n    memref.copy %2, %alloc : memref<128x48x13x13xf32> to memref<128x48x13x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 240 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x240x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<48x240x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x48x13x13xf32>\n    return %3 : tensor<128x48x13x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x28x28xf32>) -> tensor<128x240x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<48x240x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<48x240x3x3xf32>) -> tensor<48x240x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x13x13xf32>) -> tensor<128x48x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x28xf32>, tensor<48x240x3x3xf32>) outs (%init: tensor<128x48x13x13xf32>) -> tensor<128x48x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x13x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          240,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8497660888
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<96x96x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<96x96x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x15x15xf32>, %filter: tensor<96x96x3x3xf32>, %init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<96x96x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n  return %ret : tensor<256x96x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x15x15xf32>, %arg1: tensor<96x96x3x3xf32>, %arg2: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x96x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x96x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x96x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x7x7xf32>\n    memref.copy %2, %alloc : memref<256x96x7x7xf32> to memref<256x96x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x96x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x96x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x96x7x7xf32>\n    return %3 : tensor<256x96x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x15x15xf32>) -> tensor<256x96x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x96x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x96x3x3xf32>) -> tensor<96x96x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<96x96x3x3xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3918028121
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x28xf32>, tensor<384x48x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x28xf32>, tensor<384x48x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x28x28xf32>, %filter: tensor<384x48x1x1xf32>, %init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x28xf32>, tensor<384x48x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>\n  return %ret : tensor<128x384x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x28x28xf32>, %arg1: tensor<384x48x1x1xf32>, %arg2: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<384x48x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x48x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x384x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x28x28xf32>\n    memref.copy %2, %alloc : memref<128x384x28x28xf32> to memref<128x384x28x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 48 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x48x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<384x48x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x384x28x28xf32>\n    return %3 : tensor<128x384x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x28x28xf32>) -> tensor<128x48x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<384x48x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<384x48x1x1xf32>) -> tensor<384x48x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x28xf32>, tensor<384x48x1x1xf32>) outs (%init: tensor<128x384x28x28xf32>) -> tensor<128x384x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          48,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4844855708
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<240x32x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<240x32x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x28x28xf32>, %filter: tensor<240x32x1x1xf32>, %init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<240x32x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>\n  return %ret : tensor<128x240x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x28x28xf32>, %arg1: tensor<240x32x1x1xf32>, %arg2: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x240x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x14x14xf32>\n    memref.copy %2, %alloc : memref<128x240x14x14xf32> to memref<128x240x14x14xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x32x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<240x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x240x14x14xf32>\n    return %3 : tensor<128x240x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x28x28xf32>) -> tensor<128x32x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<240x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<240x32x1x1xf32>) -> tensor<240x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x28x28xf32>, tensor<240x32x1x1xf32>) outs (%init: tensor<128x240x14x14xf32>) -> tensor<128x240x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 443260283
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x15xf32>, tensor<48x512x3x3xf32>) outs (%init: tensor<128x48x7x7xf32>) -> tensor<128x48x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x15xf32>, tensor<48x512x3x3xf32>) outs (%init: tensor<128x48x7x7xf32>) -> tensor<128x48x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x15x15xf32>, %filter: tensor<48x512x3x3xf32>, %init: tensor<128x48x7x7xf32>) -> tensor<128x48x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x15xf32>, tensor<48x512x3x3xf32>) outs (%init: tensor<128x48x7x7xf32>) -> tensor<128x48x7x7xf32>\n  return %ret : tensor<128x48x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x15x15xf32>, %arg1: tensor<48x512x3x3xf32>, %arg2: tensor<128x48x7x7xf32>) -> tensor<128x48x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<48x512x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x48x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x7x7xf32>\n    memref.copy %2, %alloc : memref<128x48x7x7xf32> to memref<128x48x7x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x512x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<48x512x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x48x7x7xf32>\n    return %3 : tensor<128x48x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x15x15xf32>) -> tensor<128x512x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<48x512x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<48x512x3x3xf32>) -> tensor<48x512x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x7x7xf32>) -> tensor<128x48x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x15xf32>, tensor<48x512x3x3xf32>) outs (%init: tensor<128x48x7x7xf32>) -> tensor<128x48x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5269628237
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<512x288x1x1xf32>) outs (%init: tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<512x288x1x1xf32>) outs (%init: tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x7x7xf32>, %filter: tensor<512x288x1x1xf32>, %init: tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<512x288x1x1xf32>) outs (%init: tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>\n  return %ret : tensor<256x512x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x7x7xf32>, %arg1: tensor<512x288x1x1xf32>, %arg2: tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x288x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x288x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x7x7xf32>\n    memref.copy %2, %alloc : memref<256x512x7x7xf32> to memref<256x512x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 288 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x288x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x288x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512x7x7xf32>\n    return %3 : tensor<256x512x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x7x7xf32>) -> tensor<256x288x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x288x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x288x1x1xf32>) -> tensor<512x288x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<512x288x1x1xf32>) outs (%init: tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          288,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6613202769
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x15x15xf32>, %filter: tensor<64x96x3x3xf32>, %init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n  return %ret : tensor<128x64x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x15x15xf32>, %arg1: tensor<64x96x3x3xf32>, %arg2: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x96x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x96x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x7x7xf32>\n    memref.copy %2, %alloc : memref<128x64x7x7xf32> to memref<128x64x7x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x96x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x96x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64x7x7xf32>\n    return %3 : tensor<128x64x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x96x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x96x3x3xf32>) -> tensor<64x96x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1306183637
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x14x14xf32>, tensor<48x96x1x1xf32>) outs (%init: tensor<128x48x14x14xf32>) -> tensor<128x48x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x14x14xf32>, tensor<48x96x1x1xf32>) outs (%init: tensor<128x48x14x14xf32>) -> tensor<128x48x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x14x14xf32>, %filter: tensor<48x96x1x1xf32>, %init: tensor<128x48x14x14xf32>) -> tensor<128x48x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x14x14xf32>, tensor<48x96x1x1xf32>) outs (%init: tensor<128x48x14x14xf32>) -> tensor<128x48x14x14xf32>\n  return %ret : tensor<128x48x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x14x14xf32>, %arg1: tensor<48x96x1x1xf32>, %arg2: tensor<128x48x14x14xf32>) -> tensor<128x48x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<48x96x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x96x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x48x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x14x14xf32>\n    memref.copy %2, %alloc : memref<128x48x14x14xf32> to memref<128x48x14x14xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x96x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<48x96x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x48x14x14xf32>\n    return %3 : tensor<128x48x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x14x14xf32>) -> tensor<128x96x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<48x96x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<48x96x1x1xf32>) -> tensor<48x96x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x14x14xf32>) -> tensor<128x48x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x14x14xf32>, tensor<48x96x1x1xf32>) outs (%init: tensor<128x48x14x14xf32>) -> tensor<128x48x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 366632862
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<256x64x3x3xf32>) -> tensor<256x64x3x3xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<256x64x3x3xf32>) -> tensor<256x64x3x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x7x7xf32>, %filter: tensor<64x512x3x3xf32>, %init: tensor<256x64x3x3xf32>) -> tensor<256x64x3x3xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<256x64x3x3xf32>) -> tensor<256x64x3x3xf32>\n  return %ret : tensor<256x64x3x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x7x7xf32>, %arg1: tensor<64x512x3x3xf32>, %arg2: tensor<256x64x3x3xf32>) -> tensor<256x64x3x3xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x3x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x3x3xf32>\n    memref.copy %2, %alloc : memref<256x64x3x3xf32> to memref<256x64x3x3xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x512x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x512x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x3x3xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x3x3xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x3x3xf32>\n    return %3 : tensor<256x64x3x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x3x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x512x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x512x3x3xf32>) -> tensor<64x512x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x3x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x3x3xf32>) -> tensor<256x64x3x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<256x64x3x3xf32>) -> tensor<256x64x3x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x3x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x3x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2570458214
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<240x512x1x1xf32>) outs (%init: tensor<128x240x7x7xf32>) -> tensor<128x240x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<240x512x1x1xf32>) outs (%init: tensor<128x240x7x7xf32>) -> tensor<128x240x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x7x7xf32>, %filter: tensor<240x512x1x1xf32>, %init: tensor<128x240x7x7xf32>) -> tensor<128x240x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<240x512x1x1xf32>) outs (%init: tensor<128x240x7x7xf32>) -> tensor<128x240x7x7xf32>\n  return %ret : tensor<128x240x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x7x7xf32>, %arg1: tensor<240x512x1x1xf32>, %arg2: tensor<128x240x7x7xf32>) -> tensor<128x240x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x512x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x240x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x7x7xf32>\n    memref.copy %2, %alloc : memref<128x240x7x7xf32> to memref<128x240x7x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x512x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<240x512x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x240x7x7xf32>\n    return %3 : tensor<128x240x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x7x7xf32>) -> tensor<128x512x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<240x512x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<240x512x1x1xf32>) -> tensor<240x512x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x7x7xf32>) -> tensor<128x240x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<240x512x1x1xf32>) outs (%init: tensor<128x240x7x7xf32>) -> tensor<128x240x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2832988816
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<128x256x7x7xf32>) outs (%init: tensor<128x128x4x4xf32>) -> tensor<128x128x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<128x256x7x7xf32>) outs (%init: tensor<128x128x4x4xf32>) -> tensor<128x128x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x14x14xf32>, %filter: tensor<128x256x7x7xf32>, %init: tensor<128x128x4x4xf32>) -> tensor<128x128x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<128x256x7x7xf32>) outs (%init: tensor<128x128x4x4xf32>) -> tensor<128x128x4x4xf32>\n  return %ret : tensor<128x128x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x14x14xf32>, %arg1: tensor<128x256x7x7xf32>, %arg2: tensor<128x128x4x4xf32>) -> tensor<128x128x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x4x4xf32>\n    memref.copy %2, %alloc : memref<128x128x4x4xf32> to memref<128x128x4x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x256x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128x4x4xf32>\n    return %3 : tensor<128x128x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x14x14xf32>) -> tensor<128x256x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x256x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x256x7x7xf32>) -> tensor<128x256x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x4x4xf32>) -> tensor<128x128x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x14xf32>, tensor<128x256x7x7xf32>) outs (%init: tensor<128x128x4x4xf32>) -> tensor<128x128x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12446318705
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<288x192x3x3xf32>) outs (%init: tensor<256x288x3x3xf32>) -> tensor<256x288x3x3xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<288x192x3x3xf32>) outs (%init: tensor<256x288x3x3xf32>) -> tensor<256x288x3x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x192x7x7xf32>, %filter: tensor<288x192x3x3xf32>, %init: tensor<256x288x3x3xf32>) -> tensor<256x288x3x3xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<288x192x3x3xf32>) outs (%init: tensor<256x288x3x3xf32>) -> tensor<256x288x3x3xf32>\n  return %ret : tensor<256x288x3x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x192x7x7xf32>, %arg1: tensor<288x192x3x3xf32>, %arg2: tensor<256x288x3x3xf32>) -> tensor<256x288x3x3xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<288x192x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x192x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x288x3x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x3x3xf32>\n    memref.copy %2, %alloc : memref<256x288x3x3xf32> to memref<256x288x3x3xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 192 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x192x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<288x192x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x3x3xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x3x3xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x288x3x3xf32>\n    return %3 : tensor<256x288x3x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x3x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x192x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x192x7x7xf32>) -> tensor<256x192x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<288x192x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<288x192x3x3xf32>) -> tensor<288x192x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x3x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x3x3xf32>) -> tensor<256x288x3x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x7x7xf32>, tensor<288x192x3x3xf32>) outs (%init: tensor<256x288x3x3xf32>) -> tensor<256x288x3x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x3x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x3x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          192,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4330618754
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<48x96x7x7xf32>) outs (%init: tensor<128x48x5x5xf32>) -> tensor<128x48x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<48x96x7x7xf32>) outs (%init: tensor<128x48x5x5xf32>) -> tensor<128x48x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x15x15xf32>, %filter: tensor<48x96x7x7xf32>, %init: tensor<128x48x5x5xf32>) -> tensor<128x48x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<48x96x7x7xf32>) outs (%init: tensor<128x48x5x5xf32>) -> tensor<128x48x5x5xf32>\n  return %ret : tensor<128x48x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x15x15xf32>, %arg1: tensor<48x96x7x7xf32>, %arg2: tensor<128x48x5x5xf32>) -> tensor<128x48x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<48x96x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x96x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x48x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x5x5xf32>\n    memref.copy %2, %alloc : memref<128x48x5x5xf32> to memref<128x48x5x5xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x96x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<48x96x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x48x5x5xf32>\n    return %3 : tensor<128x48x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<48x96x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<48x96x7x7xf32>) -> tensor<48x96x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x5x5xf32>) -> tensor<128x48x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x15x15xf32>, tensor<48x96x7x7xf32>) outs (%init: tensor<128x48x5x5xf32>) -> tensor<128x48x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2730775135
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x7x7xf32>, %filter: tensor<256x256x1x1xf32>, %init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>\n  return %ret : tensor<128x256x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x7x7xf32>, %arg1: tensor<256x256x1x1xf32>, %arg2: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x4x4xf32>\n    memref.copy %2, %alloc : memref<128x256x4x4xf32> to memref<128x256x4x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256x4x4xf32>\n    return %3 : tensor<128x256x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x7x7xf32>) -> tensor<128x256x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x256x1x1xf32>) -> tensor<256x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<256x256x1x1xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 477587977
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<256x128x7x7xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<256x128x7x7xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x14x14xf32>, %filter: tensor<256x128x7x7xf32>, %init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<256x128x7x7xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>\n  return %ret : tensor<128x256x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x14x14xf32>, %arg1: tensor<256x128x7x7xf32>, %arg2: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x256x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x4x4xf32>\n    memref.copy %2, %alloc : memref<128x256x4x4xf32> to memref<128x256x4x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x128x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x128x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x256x4x4xf32>\n    return %3 : tensor<128x256x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x14x14xf32>) -> tensor<128x128x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x128x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<256x128x7x7xf32>) outs (%init: tensor<128x256x4x4xf32>) -> tensor<128x256x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12437972833
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<240x240x3x3xf32>) outs (%init: tensor<256x240x5x5xf32>) -> tensor<256x240x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<240x240x3x3xf32>) outs (%init: tensor<256x240x5x5xf32>) -> tensor<256x240x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x7x7xf32>, %filter: tensor<240x240x3x3xf32>, %init: tensor<256x240x5x5xf32>) -> tensor<256x240x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<240x240x3x3xf32>) outs (%init: tensor<256x240x5x5xf32>) -> tensor<256x240x5x5xf32>\n  return %ret : tensor<256x240x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x7x7xf32>, %arg1: tensor<240x240x3x3xf32>, %arg2: tensor<256x240x5x5xf32>) -> tensor<256x240x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x240x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x240x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x240x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x5x5xf32>\n    memref.copy %2, %alloc : memref<256x240x5x5xf32> to memref<256x240x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 240 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x240x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<240x240x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x240x5x5xf32>\n    return %3 : tensor<256x240x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x7x7xf32>) -> tensor<256x240x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<240x240x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<240x240x3x3xf32>) -> tensor<240x240x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x5x5xf32>) -> tensor<256x240x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x7xf32>, tensor<240x240x3x3xf32>) outs (%init: tensor<256x240x5x5xf32>) -> tensor<256x240x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          240,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12538311632
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<384x64x3x3xf32>) outs (%init: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<384x64x3x3xf32>) outs (%init: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x64x15x15xf32>, %filter: tensor<384x64x3x3xf32>, %init: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<384x64x3x3xf32>) outs (%init: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32>\n  return %ret : tensor<128x384x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x64x15x15xf32>, %arg1: tensor<384x64x3x3xf32>, %arg2: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<384x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x64x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x384x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x7x7xf32>\n    memref.copy %2, %alloc : memref<128x384x7x7xf32> to memref<128x384x7x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x64x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<384x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x384x7x7xf32>\n    return %3 : tensor<128x384x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x64x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x64x15x15xf32>) -> tensor<128x64x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<384x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<384x64x3x3xf32>) -> tensor<384x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x15x15xf32>, tensor<384x64x3x3xf32>) outs (%init: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5207031166
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<240x512x3x3xf32>) outs (%init: tensor<256x240x3x3xf32>) -> tensor<256x240x3x3xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<240x512x3x3xf32>) outs (%init: tensor<256x240x3x3xf32>) -> tensor<256x240x3x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x7x7xf32>, %filter: tensor<240x512x3x3xf32>, %init: tensor<256x240x3x3xf32>) -> tensor<256x240x3x3xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<240x512x3x3xf32>) outs (%init: tensor<256x240x3x3xf32>) -> tensor<256x240x3x3xf32>\n  return %ret : tensor<256x240x3x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x7x7xf32>, %arg1: tensor<240x512x3x3xf32>, %arg2: tensor<256x240x3x3xf32>) -> tensor<256x240x3x3xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x512x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x240x3x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x3x3xf32>\n    memref.copy %2, %alloc : memref<256x240x3x3xf32> to memref<256x240x3x3xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x512x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<240x512x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x3x3xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x3x3xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x240x3x3xf32>\n    return %3 : tensor<256x240x3x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x3x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<240x512x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<240x512x3x3xf32>) -> tensor<240x512x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x3x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x3x3xf32>) -> tensor<256x240x3x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<240x512x3x3xf32>) outs (%init: tensor<256x240x3x3xf32>) -> tensor<256x240x3x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x3x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x3x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9644833159
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<64x288x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<64x288x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x7x7xf32>, %filter: tensor<64x288x1x1xf32>, %init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<64x288x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n  return %ret : tensor<256x64x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x7x7xf32>, %arg1: tensor<64x288x1x1xf32>, %arg2: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x288x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x288x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x7x7xf32>\n    memref.copy %2, %alloc : memref<256x64x7x7xf32> to memref<256x64x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 288 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x288x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x288x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x7x7xf32>\n    return %3 : tensor<256x64x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x7x7xf32>) -> tensor<256x288x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x288x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x288x1x1xf32>) -> tensor<64x288x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x7x7xf32>, tensor<64x288x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          288,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 827538050
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x7x7xf32>, %filter: tensor<64x512x3x3xf32>, %init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>\n  return %ret : tensor<128x64x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x7x7xf32>, %arg1: tensor<64x512x3x3xf32>, %arg2: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x512x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x5x5xf32>\n    memref.copy %2, %alloc : memref<128x64x5x5xf32> to memref<128x64x5x5xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x512x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x512x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64x5x5xf32>\n    return %3 : tensor<128x64x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x7x7xf32>) -> tensor<128x512x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x512x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x512x3x3xf32>) -> tensor<64x512x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<64x512x3x3xf32>) outs (%init: tensor<128x64x5x5xf32>) -> tensor<128x64x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3569451542
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x7xf32>, tensor<96x64x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x7xf32>, tensor<96x64x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x7x7xf32>, %filter: tensor<96x64x3x3xf32>, %init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x7xf32>, tensor<96x64x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>\n  return %ret : tensor<256x96x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x7x7xf32>, %arg1: tensor<96x64x3x3xf32>, %arg2: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x96x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x5x5xf32>\n    memref.copy %2, %alloc : memref<256x96x5x5xf32> to memref<256x96x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x64x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x96x5x5xf32>\n    return %3 : tensor<256x96x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x64x3x3xf32>) -> tensor<96x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x7xf32>, tensor<96x64x3x3xf32>) outs (%init: tensor<256x96x5x5xf32>) -> tensor<256x96x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1328485877
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x15xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x15xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x15x15xf32>, %filter: tensor<512x64x1x1xf32>, %init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x15xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n  return %ret : tensor<256x512x8x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x15x15xf32>, %arg1: tensor<512x64x1x1xf32>, %arg2: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512x8x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x8x8xf32>\n    memref.copy %2, %alloc : memref<256x512x8x8xf32> to memref<256x512x8x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x64x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512x8x8xf32>\n    return %3 : tensor<256x512x8x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x8x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x15x15xf32>) -> tensor<256x64x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x64x1x1xf32>) -> tensor<512x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x8x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x15xf32>, tensor<512x64x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x8x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x8x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1529671221
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<96x96x1x1xf32>) outs (%init: tensor<256x96x4x4xf32>) -> tensor<256x96x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<96x96x1x1xf32>) outs (%init: tensor<256x96x4x4xf32>) -> tensor<256x96x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x7x7xf32>, %filter: tensor<96x96x1x1xf32>, %init: tensor<256x96x4x4xf32>) -> tensor<256x96x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<96x96x1x1xf32>) outs (%init: tensor<256x96x4x4xf32>) -> tensor<256x96x4x4xf32>\n  return %ret : tensor<256x96x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x7x7xf32>, %arg1: tensor<96x96x1x1xf32>, %arg2: tensor<256x96x4x4xf32>) -> tensor<256x96x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x96x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x96x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x96x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x4x4xf32>\n    memref.copy %2, %alloc : memref<256x96x4x4xf32> to memref<256x96x4x4xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x96x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x96x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x96x4x4xf32>\n    return %3 : tensor<256x96x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x96x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x96x1x1xf32>) -> tensor<96x96x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x4x4xf32>) -> tensor<256x96x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<96x96x1x1xf32>) outs (%init: tensor<256x96x4x4xf32>) -> tensor<256x96x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 120093427
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x14x14xf32>, %filter: tensor<64x256x1x1xf32>, %init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n  return %ret : tensor<256x64x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x14x14xf32>, %arg1: tensor<64x256x1x1xf32>, %arg2: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x7x7xf32>\n    memref.copy %2, %alloc : memref<256x64x7x7xf32> to memref<256x64x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x256x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x7x7xf32>\n    return %3 : tensor<256x64x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x256x1x1xf32>) -> tensor<64x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<64x256x1x1xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 736356223
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<512x96x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<512x96x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x15x15xf32>, %filter: tensor<512x96x1x1xf32>, %init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<512x96x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n  return %ret : tensor<256x512x8x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x15x15xf32>, %arg1: tensor<512x96x1x1xf32>, %arg2: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x96x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x96x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512x8x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x8x8xf32>\n    memref.copy %2, %alloc : memref<256x512x8x8xf32> to memref<256x512x8x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x96x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x96x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512x8x8xf32>\n    return %3 : tensor<256x512x8x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x8x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x15x15xf32>) -> tensor<256x96x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x96x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x96x1x1xf32>) -> tensor<512x96x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x8x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x15xf32>, tensor<512x96x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x8x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x8x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2549479307
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x28xf32>, tensor<64x64x1x1xf32>) outs (%init: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x28xf32>, tensor<64x64x1x1xf32>) outs (%init: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x28x28xf32>, %filter: tensor<64x64x1x1xf32>, %init: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x28xf32>, tensor<64x64x1x1xf32>) outs (%init: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32>\n  return %ret : tensor<256x64x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x28x28xf32>, %arg1: tensor<64x64x1x1xf32>, %arg2: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x14x14xf32>\n    memref.copy %2, %alloc : memref<256x64x14x14xf32> to memref<256x64x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x64x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x14x14xf32>\n    return %3 : tensor<256x64x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x28x28xf32>) -> tensor<256x64x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x64x1x1xf32>) -> tensor<64x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x28xf32>, tensor<64x64x1x1xf32>) outs (%init: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 591221246
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x120x120xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<128x32x60x60xf32>) -> tensor<128x32x60x60xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x120x120xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<128x32x60x60xf32>) -> tensor<128x32x60x60xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x120x120xf32>, %filter: tensor<32x256x1x1xf32>, %init: tensor<128x32x60x60xf32>) -> tensor<128x32x60x60xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x120x120xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<128x32x60x60xf32>) -> tensor<128x32x60x60xf32>\n  return %ret : tensor<128x32x60x60xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x120x120xf32>, %arg1: tensor<32x256x1x1xf32>, %arg2: tensor<128x32x60x60xf32>) -> tensor<128x32x60x60xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x120x120xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32x60x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x60x60xf32>\n    memref.copy %2, %alloc : memref<128x32x60x60xf32> to memref<128x32x60x60xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x120x120xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x60x60xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x60x60xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32x60x60xf32>\n    return %3 : tensor<128x32x60x60xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x60x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x120x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x120x120xf32>) -> tensor<128x256x120x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x256x1x1xf32>) -> tensor<32x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x60x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x60x60xf32>) -> tensor<128x32x60x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x120x120xf32>, tensor<32x256x1x1xf32>) outs (%init: tensor<128x32x60x60xf32>) -> tensor<128x32x60x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x60x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x60x60xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          60,
          1
        ],
        [
          "%arg6",
          0,
          60,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13668000723
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<512x32x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<512x32x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x15x15xf32>, %filter: tensor<512x32x1x1xf32>, %init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<512x32x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n  return %ret : tensor<256x512x8x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x15x15xf32>, %arg1: tensor<512x32x1x1xf32>, %arg2: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x32x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512x8x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x8x8xf32>\n    memref.copy %2, %alloc : memref<256x512x8x8xf32> to memref<256x512x8x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x32x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512x8x8xf32>\n    return %3 : tensor<256x512x8x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x8x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x15x15xf32>) -> tensor<256x32x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x32x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x32x1x1xf32>) -> tensor<512x32x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x8x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x15xf32>, tensor<512x32x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x8x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x8x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 613103630
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x28xf32>, tensor<64x32x3x3xf32>) outs (%init: tensor<256x64x13x13xf32>) -> tensor<256x64x13x13xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x28xf32>, tensor<64x32x3x3xf32>) outs (%init: tensor<256x64x13x13xf32>) -> tensor<256x64x13x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x28x28xf32>, %filter: tensor<64x32x3x3xf32>, %init: tensor<256x64x13x13xf32>) -> tensor<256x64x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x28xf32>, tensor<64x32x3x3xf32>) outs (%init: tensor<256x64x13x13xf32>) -> tensor<256x64x13x13xf32>\n  return %ret : tensor<256x64x13x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x28x28xf32>, %arg1: tensor<64x32x3x3xf32>, %arg2: tensor<256x64x13x13xf32>) -> tensor<256x64x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x13x13xf32>\n    memref.copy %2, %alloc : memref<256x64x13x13xf32> to memref<256x64x13x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x13x13xf32>\n    return %3 : tensor<256x64x13x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x28x28xf32>) -> tensor<256x32x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x32x3x3xf32>) -> tensor<64x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x13x13xf32>) -> tensor<256x64x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x28xf32>, tensor<64x32x3x3xf32>) outs (%init: tensor<256x64x13x13xf32>) -> tensor<256x64x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x13x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2973342603
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x15xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<128x128x13x13xf32>) -> tensor<128x128x13x13xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x15xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<128x128x13x13xf32>) -> tensor<128x128x13x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x15x15xf32>, %filter: tensor<128x128x3x3xf32>, %init: tensor<128x128x13x13xf32>) -> tensor<128x128x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x15xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<128x128x13x13xf32>) -> tensor<128x128x13x13xf32>\n  return %ret : tensor<128x128x13x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x15x15xf32>, %arg1: tensor<128x128x3x3xf32>, %arg2: tensor<128x128x13x13xf32>) -> tensor<128x128x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x128x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x13x13xf32>\n    memref.copy %2, %alloc : memref<128x128x13x13xf32> to memref<128x128x13x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x128x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x128x13x13xf32>\n    return %3 : tensor<128x128x13x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x15x15xf32>) -> tensor<128x128x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x128x3x3xf32>) -> tensor<128x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x13x13xf32>) -> tensor<128x128x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x15xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<128x128x13x13xf32>) -> tensor<128x128x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x13x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12033272992
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<96x512x1x1xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<96x512x1x1xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x7x7xf32>, %filter: tensor<96x512x1x1xf32>, %init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<96x512x1x1xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n  return %ret : tensor<256x96x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x7x7xf32>, %arg1: tensor<96x512x1x1xf32>, %arg2: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x512x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x96x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x7x7xf32>\n    memref.copy %2, %alloc : memref<256x96x7x7xf32> to memref<256x96x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x512x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x512x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x96x7x7xf32>\n    return %3 : tensor<256x96x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x7x7xf32>) -> tensor<256x512x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x512x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x512x1x1xf32>) -> tensor<96x512x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x7xf32>, tensor<96x512x1x1xf32>) outs (%init: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2268036821
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<64x48x1x1xf32>) outs (%init: tensor<128x64x65x65xf32>) -> tensor<128x64x65x65xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<64x48x1x1xf32>) outs (%init: tensor<128x64x65x65xf32>) -> tensor<128x64x65x65xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x130x130xf32>, %filter: tensor<64x48x1x1xf32>, %init: tensor<128x64x65x65xf32>) -> tensor<128x64x65x65xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<64x48x1x1xf32>) outs (%init: tensor<128x64x65x65xf32>) -> tensor<128x64x65x65xf32>\n  return %ret : tensor<128x64x65x65xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x130x130xf32>, %arg1: tensor<64x48x1x1xf32>, %arg2: tensor<128x64x65x65xf32>) -> tensor<128x64x65x65xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x48x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x48x130x130xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x64x65x65xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x65x65xf32>\n    memref.copy %2, %alloc : memref<128x64x65x65xf32> to memref<128x64x65x65xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 65 {\n          affine.for %arg6 = 0 to 65 {\n            affine.for %arg7 = 0 to 48 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x48x130x130xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x48x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x65x65xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x65x65xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x64x65x65xf32>\n    return %3 : tensor<128x64x65x65xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x65x65xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x130x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x130x130xf32>) -> tensor<128x48x130x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x48x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x48x1x1xf32>) -> tensor<64x48x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x65x65xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x65x65xf32>) -> tensor<128x64x65x65xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x130xf32>, tensor<64x48x1x1xf32>) outs (%init: tensor<128x64x65x65xf32>) -> tensor<128x64x65x65xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x65x65xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x65x65xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          65,
          1
        ],
        [
          "%arg6",
          0,
          65,
          1
        ],
        [
          "%arg7",
          0,
          48,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4582847613
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x7x7xf32>, %filter: tensor<288x288x1x1xf32>, %init: tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32>\n  return %ret : tensor<128x288x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x7x7xf32>, %arg1: tensor<288x288x1x1xf32>, %arg2: tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<288x288x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x288x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x288x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x7x7xf32>\n    memref.copy %2, %alloc : memref<128x288x7x7xf32> to memref<128x288x7x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 288 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x288x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<288x288x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x288x7x7xf32>\n    return %3 : tensor<128x288x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<288x288x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<288x288x1x1xf32>) -> tensor<288x288x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<288x288x1x1xf32>) outs (%init: tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          288,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1860910731
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x1x1xf32>) outs (%init: tensor<256x64x8x8xf32>) -> tensor<256x64x8x8xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x1x1xf32>) outs (%init: tensor<256x64x8x8xf32>) -> tensor<256x64x8x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x192x15x15xf32>, %filter: tensor<64x192x1x1xf32>, %init: tensor<256x64x8x8xf32>) -> tensor<256x64x8x8xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x1x1xf32>) outs (%init: tensor<256x64x8x8xf32>) -> tensor<256x64x8x8xf32>\n  return %ret : tensor<256x64x8x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x192x15x15xf32>, %arg1: tensor<64x192x1x1xf32>, %arg2: tensor<256x64x8x8xf32>) -> tensor<256x64x8x8xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x192x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x192x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x8x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x8x8xf32>\n    memref.copy %2, %alloc : memref<256x64x8x8xf32> to memref<256x64x8x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 192 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x192x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x192x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x8x8xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x8x8xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x8x8xf32>\n    return %3 : tensor<256x64x8x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x8x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x192x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x192x15x15xf32>) -> tensor<256x192x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x192x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x192x1x1xf32>) -> tensor<64x192x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x8x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x8x8xf32>) -> tensor<256x64x8x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x1x1xf32>) outs (%init: tensor<256x64x8x8xf32>) -> tensor<256x64x8x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x8x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x8x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          192,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 705150908
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x3x3xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x3x3xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x192x15x15xf32>, %filter: tensor<64x192x3x3xf32>, %init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x3x3xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n  return %ret : tensor<256x64x7x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x192x15x15xf32>, %arg1: tensor<64x192x3x3xf32>, %arg2: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x192x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x192x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x7x7xf32>\n    memref.copy %2, %alloc : memref<256x64x7x7xf32> to memref<256x64x7x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 192 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x192x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x192x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x7xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x7xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x7x7xf32>\n    return %3 : tensor<256x64x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x192x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x192x15x15xf32>) -> tensor<256x192x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x192x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x192x3x3xf32>) -> tensor<64x192x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x7x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x15x15xf32>, tensor<64x192x3x3xf32>) outs (%init: tensor<256x64x7x7xf32>) -> tensor<256x64x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          192,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5247238748
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x15xf32>, tensor<512x240x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x15xf32>, tensor<512x240x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x15x15xf32>, %filter: tensor<512x240x1x1xf32>, %init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x15xf32>, tensor<512x240x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n  return %ret : tensor<256x512x8x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x15x15xf32>, %arg1: tensor<512x240x1x1xf32>, %arg2: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x240x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x240x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512x8x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x8x8xf32>\n    memref.copy %2, %alloc : memref<256x512x8x8xf32> to memref<256x512x8x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 240 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x240x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x240x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x8xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512x8x8xf32>\n    return %3 : tensor<256x512x8x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x8x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x15x15xf32>) -> tensor<256x240x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x240x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x240x1x1xf32>) -> tensor<512x240x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x8x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x15xf32>, tensor<512x240x1x1xf32>) outs (%init: tensor<256x512x8x8xf32>) -> tensor<256x512x8x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x8x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x8x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          240,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7133239237
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<96x128x3x3xf32>) outs (%init: tensor<128x96x6x6xf32>) -> tensor<128x96x6x6xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<96x128x3x3xf32>) outs (%init: tensor<128x96x6x6xf32>) -> tensor<128x96x6x6xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x14x14xf32>, %filter: tensor<96x128x3x3xf32>, %init: tensor<128x96x6x6xf32>) -> tensor<128x96x6x6xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<96x128x3x3xf32>) outs (%init: tensor<128x96x6x6xf32>) -> tensor<128x96x6x6xf32>\n  return %ret : tensor<128x96x6x6xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x14x14xf32>, %arg1: tensor<96x128x3x3xf32>, %arg2: tensor<128x96x6x6xf32>) -> tensor<128x96x6x6xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<96x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x128x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x96x6x6xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x6x6xf32>\n    memref.copy %2, %alloc : memref<128x96x6x6xf32> to memref<128x96x6x6xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 6 {\n          affine.for %arg6 = 0 to 6 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x128x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<96x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x6x6xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x6x6xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x96x6x6xf32>\n    return %3 : tensor<128x96x6x6xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x6x6xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x14x14xf32>) -> tensor<128x128x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<96x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<96x128x3x3xf32>) -> tensor<96x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x6x6xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x6x6xf32>) -> tensor<128x96x6x6xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x14xf32>, tensor<96x128x3x3xf32>) outs (%init: tensor<128x96x6x6xf32>) -> tensor<128x96x6x6xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x6x6xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x6x6xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          6,
          1
        ],
        [
          "%arg6",
          0,
          6,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1925980279
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<256x256x5x5xf32>) -> tensor<256x256x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<256x256x5x5xf32>) -> tensor<256x256x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x7x7xf32>, %filter: tensor<256x32x3x3xf32>, %init: tensor<256x256x5x5xf32>) -> tensor<256x256x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<256x256x5x5xf32>) -> tensor<256x256x5x5xf32>\n  return %ret : tensor<256x256x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x7x7xf32>, %arg1: tensor<256x32x3x3xf32>, %arg2: tensor<256x256x5x5xf32>) -> tensor<256x256x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x5x5xf32>\n    memref.copy %2, %alloc : memref<256x256x5x5xf32> to memref<256x256x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256x5x5xf32>\n    return %3 : tensor<256x256x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x32x3x3xf32>) -> tensor<256x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x5x5xf32>) -> tensor<256x256x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<256x32x3x3xf32>) outs (%init: tensor<256x256x5x5xf32>) -> tensor<256x256x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1757794193
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<288x256x3x3xf32>) outs (%init: tensor<128x288x5x5xf32>) -> tensor<128x288x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<288x256x3x3xf32>) outs (%init: tensor<128x288x5x5xf32>) -> tensor<128x288x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x7x7xf32>, %filter: tensor<288x256x3x3xf32>, %init: tensor<128x288x5x5xf32>) -> tensor<128x288x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<288x256x3x3xf32>) outs (%init: tensor<128x288x5x5xf32>) -> tensor<128x288x5x5xf32>\n  return %ret : tensor<128x288x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x7x7xf32>, %arg1: tensor<288x256x3x3xf32>, %arg2: tensor<128x288x5x5xf32>) -> tensor<128x288x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<288x256x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x256x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x288x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x5x5xf32>\n    memref.copy %2, %alloc : memref<128x288x5x5xf32> to memref<128x288x5x5xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x256x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<288x256x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x288x5x5xf32>\n    return %3 : tensor<128x288x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x7x7xf32>) -> tensor<128x256x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<288x256x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<288x256x3x3xf32>) -> tensor<288x256x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x5x5xf32>) -> tensor<128x288x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x7xf32>, tensor<288x256x3x3xf32>) outs (%init: tensor<128x288x5x5xf32>) -> tensor<128x288x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8027719723
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<192x384x1x1xf32>) outs (%init: tensor<256x192x14x14xf32>) -> tensor<256x192x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<192x384x1x1xf32>) outs (%init: tensor<256x192x14x14xf32>) -> tensor<256x192x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x28x28xf32>, %filter: tensor<192x384x1x1xf32>, %init: tensor<256x192x14x14xf32>) -> tensor<256x192x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<192x384x1x1xf32>) outs (%init: tensor<256x192x14x14xf32>) -> tensor<256x192x14x14xf32>\n  return %ret : tensor<256x192x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x28x28xf32>, %arg1: tensor<192x384x1x1xf32>, %arg2: tensor<256x192x14x14xf32>) -> tensor<256x192x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<192x384x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x384x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x192x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x14x14xf32>\n    memref.copy %2, %alloc : memref<256x192x14x14xf32> to memref<256x192x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 384 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x384x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<192x384x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x192x14x14xf32>\n    return %3 : tensor<256x192x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x28x28xf32>) -> tensor<256x384x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<192x384x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<192x384x1x1xf32>) -> tensor<192x384x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x192x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x192x14x14xf32>) -> tensor<256x192x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x28x28xf32>, tensor<192x384x1x1xf32>) outs (%init: tensor<256x192x14x14xf32>) -> tensor<256x192x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          384,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13584966215
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<128x32x3x3xf32>) outs (%init: tensor<256x128x3x3xf32>) -> tensor<256x128x3x3xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<128x32x3x3xf32>) outs (%init: tensor<256x128x3x3xf32>) -> tensor<256x128x3x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x7x7xf32>, %filter: tensor<128x32x3x3xf32>, %init: tensor<256x128x3x3xf32>) -> tensor<256x128x3x3xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<128x32x3x3xf32>) outs (%init: tensor<256x128x3x3xf32>) -> tensor<256x128x3x3xf32>\n  return %ret : tensor<256x128x3x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x7x7xf32>, %arg1: tensor<128x32x3x3xf32>, %arg2: tensor<256x128x3x3xf32>) -> tensor<256x128x3x3xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128x3x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x3x3xf32>\n    memref.copy %2, %alloc : memref<256x128x3x3xf32> to memref<256x128x3x3xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x3x3xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x3x3xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128x3x3xf32>\n    return %3 : tensor<256x128x3x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x3x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x32x3x3xf32>) -> tensor<128x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x3x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x3x3xf32>) -> tensor<256x128x3x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x7xf32>, tensor<128x32x3x3xf32>) outs (%init: tensor<256x128x3x3xf32>) -> tensor<256x128x3x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x3x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x3x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 316873547
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x15xf32>, tensor<240x32x3x3xf32>) outs (%init: tensor<128x240x13x13xf32>) -> tensor<128x240x13x13xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x15xf32>, tensor<240x32x3x3xf32>) outs (%init: tensor<128x240x13x13xf32>) -> tensor<128x240x13x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x15x15xf32>, %filter: tensor<240x32x3x3xf32>, %init: tensor<128x240x13x13xf32>) -> tensor<128x240x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x15xf32>, tensor<240x32x3x3xf32>) outs (%init: tensor<128x240x13x13xf32>) -> tensor<128x240x13x13xf32>\n  return %ret : tensor<128x240x13x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x15x15xf32>, %arg1: tensor<240x32x3x3xf32>, %arg2: tensor<128x240x13x13xf32>) -> tensor<128x240x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<240x32x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x32x15x15xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x240x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x13x13xf32>\n    memref.copy %2, %alloc : memref<128x240x13x13xf32> to memref<128x240x13x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x32x15x15xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<240x32x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x240x13x13xf32>\n    return %3 : tensor<128x240x13x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x15x15xf32>) -> tensor<128x32x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<240x32x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<240x32x3x3xf32>) -> tensor<240x32x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x13x13xf32>) -> tensor<128x240x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x15xf32>, tensor<240x32x3x3xf32>) outs (%init: tensor<128x240x13x13xf32>) -> tensor<128x240x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x13x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5575065888
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x7x7xf32>, %filter: tensor<64x96x3x3xf32>, %init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>\n  return %ret : tensor<256x64x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x7x7xf32>, %arg1: tensor<64x96x3x3xf32>, %arg2: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x96x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x96x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x5x5xf32>\n    memref.copy %2, %alloc : memref<256x64x5x5xf32> to memref<256x64x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 96 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x96x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x96x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x5x5xf32>\n    return %3 : tensor<256x64x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x96x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x96x3x3xf32>) -> tensor<64x96x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x7xf32>, tensor<64x96x3x3xf32>) outs (%init: tensor<256x64x5x5xf32>) -> tensor<256x64x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          96,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1332468935
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<32x512x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<32x512x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x7x7xf32>, %filter: tensor<32x512x1x1xf32>, %init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<32x512x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>\n  return %ret : tensor<128x32x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x7x7xf32>, %arg1: tensor<32x512x1x1xf32>, %arg2: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x512x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<128x512x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<128x32x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x4x4xf32>\n    memref.copy %2, %alloc : memref<128x32x4x4xf32> to memref<128x32x4x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<128x512x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x512x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x4x4xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x4x4xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<128x32x4x4xf32>\n    return %3 : tensor<128x32x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x7x7xf32>) -> tensor<128x512x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x512x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x512x1x1xf32>) -> tensor<32x512x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x7xf32>, tensor<32x512x1x1xf32>) outs (%init: tensor<128x32x4x4xf32>) -> tensor<128x32x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 124061191
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x111x74xf32>) -> tensor<128x288x111x74xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x111x74xf32>) -> tensor<128x288x111x74xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x224x150xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x288x111x74xf32>) -> tensor<128x288x111x74xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x111x74xf32>) -> tensor<128x288x111x74xf32>\n  return %ret : tensor<128x288x111x74xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x224x150xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x288x111x74xf32>) -> tensor<128x288x111x74xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x224x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x111x74xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x111x74xf32>\n    memref.copy %1, %alloc : memref<128x288x111x74xf32> to memref<128x288x111x74xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 111 {\n          affine.for %arg6 = 0 to 74 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x224x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x111x74xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x111x74xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x111x74xf32>\n    return %2 : tensor<128x288x111x74xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x111x74xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x224x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x224x150xf32>) -> tensor<128x288x224x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x111x74xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x111x74xf32>) -> tensor<128x288x111x74xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x111x74xf32>) -> tensor<128x288x111x74xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x111x74xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x111x74xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          111,
          1
        ],
        [
          "%arg6",
          0,
          74,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6516521741
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x7x150xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32>\n  return %ret : tensor<128x240x7x150xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x7x150xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x7x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x7x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x7x150xf32>\n    memref.copy %1, %alloc : memref<128x240x7x150xf32> to memref<128x240x7x150xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 150 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x7x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x7x150xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x7x150xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x7x150xf32>\n    return %2 : tensor<128x240x7x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x7x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x7x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x7x150xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x150xf32>) -> tensor<128x240x7x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x7x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x7x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 48576104
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x112x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32>\n  return %ret : tensor<128x96x112x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x112x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x112x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x112x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x112x15xf32>\n    memref.copy %1, %alloc : memref<128x96x112x15xf32> to memref<128x96x112x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x112x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x112x15xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x112x15xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x112x15xf32>\n    return %2 : tensor<128x96x112x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x112x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x112x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x112x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x112x15xf32>) -> tensor<128x96x112x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x112x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x112x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31514071
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x56x28xf32>) -> tensor<256x128x56x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x56x28xf32>) -> tensor<256x128x56x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x112x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x128x56x28xf32>) -> tensor<256x128x56x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x56x28xf32>) -> tensor<256x128x56x28xf32>\n  return %ret : tensor<256x128x56x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x112x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x128x56x28xf32>) -> tensor<256x128x56x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x112x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x56x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x56x28xf32>\n    memref.copy %1, %alloc : memref<256x128x56x28xf32> to memref<256x128x56x28xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x112x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x56x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x56x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x56x28xf32>\n    return %2 : tensor<256x128x56x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x56x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x112x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x112x56xf32>) -> tensor<256x128x112x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x56x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x56x28xf32>) -> tensor<256x128x56x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x56x28xf32>) -> tensor<256x128x56x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x56x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x56x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 116021066
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x56x28xf32>) -> tensor<128x288x56x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x56x28xf32>) -> tensor<128x288x56x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x112x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x288x56x28xf32>) -> tensor<128x288x56x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x56x28xf32>) -> tensor<128x288x56x28xf32>\n  return %ret : tensor<128x288x56x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x112x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x288x56x28xf32>) -> tensor<128x288x56x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x112x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x56x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x56x28xf32>\n    memref.copy %1, %alloc : memref<128x288x56x28xf32> to memref<128x288x56x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x112x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x56x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x56x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x56x28xf32>\n    return %2 : tensor<128x288x56x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x56x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x112x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x112x56xf32>) -> tensor<128x288x112x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x56x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x56x28xf32>) -> tensor<128x288x56x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x112x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x56x28xf32>) -> tensor<128x288x56x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x56x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x56x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 130544064
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x75xf32>) -> tensor<128x128x112x75xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x75xf32>) -> tensor<128x128x112x75xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x224x150xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x128x112x75xf32>) -> tensor<128x128x112x75xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x75xf32>) -> tensor<128x128x112x75xf32>\n  return %ret : tensor<128x128x112x75xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x224x150xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x128x112x75xf32>) -> tensor<128x128x112x75xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x224x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x112x75xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x112x75xf32>\n    memref.copy %1, %alloc : memref<128x128x112x75xf32> to memref<128x128x112x75xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 75 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x224x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x112x75xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x112x75xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x112x75xf32>\n    return %2 : tensor<128x128x112x75xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x112x75xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x224x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x224x150xf32>) -> tensor<128x128x224x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x112x75xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x112x75xf32>) -> tensor<128x128x112x75xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x75xf32>) -> tensor<128x128x112x75xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x112x75xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x112x75xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          75,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 316856535
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x150x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32>\n  return %ret : tensor<128x512x150x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x150x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x150x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x150x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x150x15xf32>\n    memref.copy %1, %alloc : memref<128x512x150x15xf32> to memref<128x512x150x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x150x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x150x15xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x150x15xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x150x15xf32>\n    return %2 : tensor<128x512x150x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x150x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x150x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x150x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x150x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x150x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 224887806
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x28x112xf32>) -> tensor<256x384x28x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x28x112xf32>) -> tensor<256x384x28x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x56x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x384x28x112xf32>) -> tensor<256x384x28x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x28x112xf32>) -> tensor<256x384x28x112xf32>\n  return %ret : tensor<256x384x28x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x56x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x384x28x112xf32>) -> tensor<256x384x28x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x384x56x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x384x28x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x28x112xf32>\n    memref.copy %1, %alloc : memref<256x384x28x112xf32> to memref<256x384x28x112xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x384x56x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x28x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x28x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x384x28x112xf32>\n    return %2 : tensor<256x384x28x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x28x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x56x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x56x224xf32>) -> tensor<256x384x56x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x28x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x28x112xf32>) -> tensor<256x384x28x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x28x112xf32>) -> tensor<256x384x28x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x28x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x28x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 718535265
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x5x226xf32>) -> tensor<128x256x5x226xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x5x226xf32>) -> tensor<128x256x5x226xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x7x228xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x256x5x226xf32>) -> tensor<128x256x5x226xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x5x226xf32>) -> tensor<128x256x5x226xf32>\n  return %ret : tensor<128x256x5x226xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x7x228xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x256x5x226xf32>) -> tensor<128x256x5x226xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x7x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x5x226xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x5x226xf32>\n    memref.copy %1, %alloc : memref<128x256x5x226xf32> to memref<128x256x5x226xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 226 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x7x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x5x226xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x5x226xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x5x226xf32>\n    return %2 : tensor<128x256x5x226xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x5x226xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x7x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x7x228xf32>) -> tensor<128x256x7x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x5x226xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x5x226xf32>) -> tensor<128x256x5x226xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x5x226xf32>) -> tensor<128x256x5x226xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x5x226xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x5x226xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          226,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 800059762
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x224x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x109x62xf32>) -> tensor<128x32x109x62xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x224x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x109x62xf32>) -> tensor<128x32x109x62xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x224x130xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x32x109x62xf32>) -> tensor<128x32x109x62xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x224x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x109x62xf32>) -> tensor<128x32x109x62xf32>\n  return %ret : tensor<128x32x109x62xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x224x130xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x32x109x62xf32>) -> tensor<128x32x109x62xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x224x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x109x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x109x62xf32>\n    memref.copy %1, %alloc : memref<128x32x109x62xf32> to memref<128x32x109x62xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 109 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x224x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x109x62xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x109x62xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x109x62xf32>\n    return %2 : tensor<128x32x109x62xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x109x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x224x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x224x130xf32>) -> tensor<128x32x224x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x109x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x109x62xf32>) -> tensor<128x32x109x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x224x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x109x62xf32>) -> tensor<128x32x109x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x109x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x109x62xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          109,
          1
        ],
        [
          "%arg6",
          0,
          62,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5412548026
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x228x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x226x5xf32>) -> tensor<256x64x226x5xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x228x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x226x5xf32>) -> tensor<256x64x226x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x228x7xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x226x5xf32>) -> tensor<256x64x226x5xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x228x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x226x5xf32>) -> tensor<256x64x226x5xf32>\n  return %ret : tensor<256x64x226x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x228x7xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x226x5xf32>) -> tensor<256x64x226x5xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x228x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x226x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x226x5xf32>\n    memref.copy %1, %alloc : memref<256x64x226x5xf32> to memref<256x64x226x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 226 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x228x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x226x5xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x226x5xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x226x5xf32>\n    return %2 : tensor<256x64x226x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x226x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x228x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x228x7xf32>) -> tensor<256x64x228x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x226x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x226x5xf32>) -> tensor<256x64x226x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x228x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x226x5xf32>) -> tensor<256x64x226x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x226x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x226x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          226,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 400137918
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x56x7xf32>) -> tensor<128x256x56x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x56x7xf32>) -> tensor<128x256x56x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x112x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x256x56x7xf32>) -> tensor<128x256x56x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x56x7xf32>) -> tensor<128x256x56x7xf32>\n  return %ret : tensor<128x256x56x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x112x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x256x56x7xf32>) -> tensor<128x256x56x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x112x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x56x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x56x7xf32>\n    memref.copy %1, %alloc : memref<128x256x56x7xf32> to memref<128x256x56x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x112x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x56x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x56x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x56x7xf32>\n    return %2 : tensor<128x256x56x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x56x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x112x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x112x14xf32>) -> tensor<128x256x112x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x56x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x56x7xf32>) -> tensor<128x256x56x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x56x7xf32>) -> tensor<128x256x56x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x56x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x56x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 28887046
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x113x55xf32>) -> tensor<128x256x113x55xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x113x55xf32>) -> tensor<128x256x113x55xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x228x112xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x256x113x55xf32>) -> tensor<128x256x113x55xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x113x55xf32>) -> tensor<128x256x113x55xf32>\n  return %ret : tensor<128x256x113x55xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x228x112xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x256x113x55xf32>) -> tensor<128x256x113x55xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x228x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x113x55xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x113x55xf32>\n    memref.copy %1, %alloc : memref<128x256x113x55xf32> to memref<128x256x113x55xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 113 {\n          affine.for %arg6 = 0 to 55 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x228x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x113x55xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x113x55xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x113x55xf32>\n    return %2 : tensor<128x256x113x55xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x113x55xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x228x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x228x112xf32>) -> tensor<128x256x228x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x113x55xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x113x55xf32>) -> tensor<128x256x113x55xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x113x55xf32>) -> tensor<128x256x113x55xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x113x55xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x113x55xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          113,
          1
        ],
        [
          "%arg6",
          0,
          55,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4393296035
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x112x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32>\n  return %ret : tensor<128x512x112x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x112x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x112x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x112x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x112x14xf32>\n    memref.copy %1, %alloc : memref<128x512x112x14xf32> to memref<128x512x112x14xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x112x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x112x14xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x112x14xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x112x14xf32>\n    return %2 : tensor<128x512x112x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x112x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x112x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x112x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x112x14xf32>) -> tensor<128x512x112x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x112x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x112x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 156993330
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x9x144xf32>) -> tensor<256x64x9x144xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x9x144xf32>) -> tensor<256x64x9x144xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x15x150xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x64x9x144xf32>) -> tensor<256x64x9x144xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x9x144xf32>) -> tensor<256x64x9x144xf32>\n  return %ret : tensor<256x64x9x144xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x15x150xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x64x9x144xf32>) -> tensor<256x64x9x144xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x15x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x9x144xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x9x144xf32>\n    memref.copy %1, %alloc : memref<256x64x9x144xf32> to memref<256x64x9x144xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 9 {\n          affine.for %arg6 = 0 to 144 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x15x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x9x144xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x9x144xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x9x144xf32>\n    return %2 : tensor<256x64x9x144xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x9x144xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x15x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x15x150xf32>) -> tensor<256x64x15x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x9x144xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x9x144xf32>) -> tensor<256x64x9x144xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x9x144xf32>) -> tensor<256x64x9x144xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x9x144xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x9x144xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          9,
          1
        ],
        [
          "%arg6",
          0,
          144,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4148509535
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x74x7xf32>) -> tensor<128x512x74x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x74x7xf32>) -> tensor<128x512x74x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x150x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x512x74x7xf32>) -> tensor<128x512x74x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x74x7xf32>) -> tensor<128x512x74x7xf32>\n  return %ret : tensor<128x512x74x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x150x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x512x74x7xf32>) -> tensor<128x512x74x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x150x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x74x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x74x7xf32>\n    memref.copy %1, %alloc : memref<128x512x74x7xf32> to memref<128x512x74x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 74 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x150x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x74x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x74x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x74x7xf32>\n    return %2 : tensor<128x512x74x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x74x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x150x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x150x15xf32>) -> tensor<128x512x150x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x74x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x74x7xf32>) -> tensor<128x512x74x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x74x7xf32>) -> tensor<128x512x74x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x74x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x74x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          74,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 776358911
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x238x26xf32>) -> tensor<128x32x238x26xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x238x26xf32>) -> tensor<128x32x238x26xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x240x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x32x238x26xf32>) -> tensor<128x32x238x26xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x238x26xf32>) -> tensor<128x32x238x26xf32>\n  return %ret : tensor<128x32x238x26xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x240x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x32x238x26xf32>) -> tensor<128x32x238x26xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x240x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x238x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x238x26xf32>\n    memref.copy %1, %alloc : memref<128x32x238x26xf32> to memref<128x32x238x26xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x240x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x238x26xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x238x26xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x238x26xf32>\n    return %2 : tensor<128x32x238x26xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x238x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x240x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x240x28xf32>) -> tensor<128x32x240x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x238x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x238x26xf32>) -> tensor<128x32x238x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x238x26xf32>) -> tensor<128x32x238x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x238x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x238x26xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          26,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 554719690
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x130x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32>\n  return %ret : tensor<128x48x130x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x130x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x130x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x130x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x130x15xf32>\n    memref.copy %1, %alloc : memref<128x48x130x15xf32> to memref<128x48x130x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x130x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x130x15xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x130x15xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x130x15xf32>\n    return %2 : tensor<128x48x130x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x130x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x130x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x130x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x15xf32>) -> tensor<128x48x130x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x130x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x130x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 18342367
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x124x22xf32>) -> tensor<128x192x124x22xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x124x22xf32>) -> tensor<128x192x124x22xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x130x28xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x192x124x22xf32>) -> tensor<128x192x124x22xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x124x22xf32>) -> tensor<128x192x124x22xf32>\n  return %ret : tensor<128x192x124x22xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x130x28xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x192x124x22xf32>) -> tensor<128x192x124x22xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x130x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x124x22xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x124x22xf32>\n    memref.copy %1, %alloc : memref<128x192x124x22xf32> to memref<128x192x124x22xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 124 {\n          affine.for %arg6 = 0 to 22 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x130x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x124x22xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x124x22xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x124x22xf32>\n    return %2 : tensor<128x192x124x22xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x124x22xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x130x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x130x28xf32>) -> tensor<128x192x130x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x124x22xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x124x22xf32>) -> tensor<128x192x124x22xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x124x22xf32>) -> tensor<128x192x124x22xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x124x22xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x124x22xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          124,
          1
        ],
        [
          "%arg6",
          0,
          22,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13111294147
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x148x13xf32>) -> tensor<128x96x148x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x148x13xf32>) -> tensor<128x96x148x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x150x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x96x148x13xf32>) -> tensor<128x96x148x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x148x13xf32>) -> tensor<128x96x148x13xf32>\n  return %ret : tensor<128x96x148x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x150x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x96x148x13xf32>) -> tensor<128x96x148x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x150x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x148x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x148x13xf32>\n    memref.copy %1, %alloc : memref<128x96x148x13xf32> to memref<128x96x148x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 148 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x150x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x148x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x148x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x148x13xf32>\n    return %2 : tensor<128x96x148x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x148x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x150x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x150x15xf32>) -> tensor<128x96x150x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x148x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x148x13xf32>) -> tensor<128x96x148x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x148x13xf32>) -> tensor<128x96x148x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x148x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x148x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          148,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 523564865
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x5x226xf32>) -> tensor<128x128x5x226xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x5x226xf32>) -> tensor<128x128x5x226xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x7x228xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x128x5x226xf32>) -> tensor<128x128x5x226xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x5x226xf32>) -> tensor<128x128x5x226xf32>\n  return %ret : tensor<128x128x5x226xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x7x228xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x128x5x226xf32>) -> tensor<128x128x5x226xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x7x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x5x226xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x5x226xf32>\n    memref.copy %1, %alloc : memref<128x128x5x226xf32> to memref<128x128x5x226xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 226 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x7x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x5x226xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x5x226xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x5x226xf32>\n    return %2 : tensor<128x128x5x226xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x5x226xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x7x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x7x228xf32>) -> tensor<128x128x7x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x5x226xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x5x226xf32>) -> tensor<128x128x5x226xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x5x226xf32>) -> tensor<128x128x5x226xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x5x226xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x5x226xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          226,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 400280555
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x384x4x5xf32>) -> tensor<128x384x4x5xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x384x4x5xf32>) -> tensor<128x384x4x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x14x15xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x384x4x5xf32>) -> tensor<128x384x4x5xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x384x4x5xf32>) -> tensor<128x384x4x5xf32>\n  return %ret : tensor<128x384x4x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x14x15xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x384x4x5xf32>) -> tensor<128x384x4x5xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x384x14x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x384x4x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x4x5xf32>\n    memref.copy %1, %alloc : memref<128x384x4x5xf32> to memref<128x384x4x5xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x384x14x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x4x5xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x4x5xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x384x4x5xf32>\n    return %2 : tensor<128x384x4x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x4x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x14x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x14x15xf32>) -> tensor<128x384x14x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x4x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x4x5xf32>) -> tensor<128x384x4x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x384x4x5xf32>) -> tensor<128x384x4x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x4x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x4x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 194313263
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x111x25xf32>) -> tensor<128x96x111x25xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x111x25xf32>) -> tensor<128x96x111x25xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x228x56xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x96x111x25xf32>) -> tensor<128x96x111x25xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x111x25xf32>) -> tensor<128x96x111x25xf32>\n  return %ret : tensor<128x96x111x25xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x228x56xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x96x111x25xf32>) -> tensor<128x96x111x25xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x228x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x111x25xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x111x25xf32>\n    memref.copy %1, %alloc : memref<128x96x111x25xf32> to memref<128x96x111x25xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 111 {\n          affine.for %arg6 = 0 to 25 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x228x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x111x25xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x111x25xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x111x25xf32>\n    return %2 : tensor<128x96x111x25xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x111x25xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x228x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x228x56xf32>) -> tensor<128x96x228x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x111x25xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x111x25xf32>) -> tensor<128x96x111x25xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x111x25xf32>) -> tensor<128x96x111x25xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x111x25xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x111x25xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          111,
          1
        ],
        [
          "%arg6",
          0,
          25,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6671192213
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x9x50xf32>) -> tensor<128x288x9x50xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x9x50xf32>) -> tensor<128x288x9x50xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x15x56xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x288x9x50xf32>) -> tensor<128x288x9x50xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x9x50xf32>) -> tensor<128x288x9x50xf32>\n  return %ret : tensor<128x288x9x50xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x15x56xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x288x9x50xf32>) -> tensor<128x288x9x50xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x15x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x9x50xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x9x50xf32>\n    memref.copy %1, %alloc : memref<128x288x9x50xf32> to memref<128x288x9x50xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 9 {\n          affine.for %arg6 = 0 to 50 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x15x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x9x50xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x9x50xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x9x50xf32>\n    return %2 : tensor<128x288x9x50xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x9x50xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x15x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x15x56xf32>) -> tensor<128x288x15x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x9x50xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x9x50xf32>) -> tensor<128x288x9x50xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x9x50xf32>) -> tensor<128x288x9x50xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x9x50xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x9x50xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          9,
          1
        ],
        [
          "%arg6",
          0,
          50,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3242543126
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x12x54xf32>) -> tensor<128x512x12x54xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x12x54xf32>) -> tensor<128x512x12x54xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x14x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x512x12x54xf32>) -> tensor<128x512x12x54xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x12x54xf32>) -> tensor<128x512x12x54xf32>\n  return %ret : tensor<128x512x12x54xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x14x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x512x12x54xf32>) -> tensor<128x512x12x54xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x14x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x12x54xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x12x54xf32>\n    memref.copy %1, %alloc : memref<128x512x12x54xf32> to memref<128x512x12x54xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 12 {\n          affine.for %arg6 = 0 to 54 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x14x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x12x54xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x12x54xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x12x54xf32>\n    return %2 : tensor<128x512x12x54xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x12x54xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x14x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x14x56xf32>) -> tensor<128x512x14x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x12x54xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x12x54xf32>) -> tensor<128x512x12x54xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x12x54xf32>) -> tensor<128x512x12x54xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x12x54xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x12x54xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          12,
          1
        ],
        [
          "%arg6",
          0,
          54,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 920130361
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x3x7xf32>) -> tensor<256x512x3x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x3x7xf32>) -> tensor<256x512x3x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x7x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x512x3x7xf32>) -> tensor<256x512x3x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x3x7xf32>) -> tensor<256x512x3x7xf32>\n  return %ret : tensor<256x512x3x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x7x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x512x3x7xf32>) -> tensor<256x512x3x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x512x7x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x512x3x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x3x7xf32>\n    memref.copy %1, %alloc : memref<256x512x3x7xf32> to memref<256x512x3x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x512x7x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x3x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x3x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x512x3x7xf32>\n    return %2 : tensor<256x512x3x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x3x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x7x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x7x15xf32>) -> tensor<256x512x7x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x3x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x3x7xf32>) -> tensor<256x512x3x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x3x7xf32>) -> tensor<256x512x3x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x3x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x3x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 64458750
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x56x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x54x238xf32>) -> tensor<256x32x54x238xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x56x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x54x238xf32>) -> tensor<256x32x54x238xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x56x240xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x32x54x238xf32>) -> tensor<256x32x54x238xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x56x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x54x238xf32>) -> tensor<256x32x54x238xf32>\n  return %ret : tensor<256x32x54x238xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x56x240xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x32x54x238xf32>) -> tensor<256x32x54x238xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x56x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x54x238xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x54x238xf32>\n    memref.copy %1, %alloc : memref<256x32x54x238xf32> to memref<256x32x54x238xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 54 {\n          affine.for %arg6 = 0 to 238 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x56x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x54x238xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x54x238xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x54x238xf32>\n    return %2 : tensor<256x32x54x238xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x54x238xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x56x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x56x240xf32>) -> tensor<256x32x56x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x54x238xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x54x238xf32>) -> tensor<256x32x54x238xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x56x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x54x238xf32>) -> tensor<256x32x54x238xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x54x238xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x54x238xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          54,
          1
        ],
        [
          "%arg6",
          0,
          238,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2270559551
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x7x112xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32>\n  return %ret : tensor<256x64x7x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x7x112xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x7x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x7x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x7x112xf32>\n    memref.copy %1, %alloc : memref<256x64x7x112xf32> to memref<256x64x7x112xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x7x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x7x112xf32>\n    return %2 : tensor<256x64x7x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x7x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x7x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x7x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x7x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x7x112xf32>) -> tensor<256x64x7x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x7x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x7x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 19637353
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x15x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x13x118xf32>) -> tensor<256x288x13x118xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x15x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x13x118xf32>) -> tensor<256x288x13x118xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x15x120xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x288x13x118xf32>) -> tensor<256x288x13x118xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x15x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x13x118xf32>) -> tensor<256x288x13x118xf32>\n  return %ret : tensor<256x288x13x118xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x15x120xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x288x13x118xf32>) -> tensor<256x288x13x118xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x288x15x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x288x13x118xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x13x118xf32>\n    memref.copy %1, %alloc : memref<256x288x13x118xf32> to memref<256x288x13x118xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 118 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x288x15x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x13x118xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x13x118xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x288x13x118xf32>\n    return %2 : tensor<256x288x13x118xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x13x118xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x15x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x15x120xf32>) -> tensor<256x288x15x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x13x118xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x13x118xf32>) -> tensor<256x288x13x118xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x15x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x13x118xf32>) -> tensor<256x288x13x118xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x13x118xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x13x118xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          118,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2439786864
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x25x4xf32>) -> tensor<128x96x25x4xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x25x4xf32>) -> tensor<128x96x25x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x56x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x96x25x4xf32>) -> tensor<128x96x25x4xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x25x4xf32>) -> tensor<128x96x25x4xf32>\n  return %ret : tensor<128x96x25x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x56x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x96x25x4xf32>) -> tensor<128x96x25x4xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x56x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x25x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x25x4xf32>\n    memref.copy %1, %alloc : memref<128x96x25x4xf32> to memref<128x96x25x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 25 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x56x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x25x4xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x25x4xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x25x4xf32>\n    return %2 : tensor<128x96x25x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x25x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x56x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x56x14xf32>) -> tensor<128x96x56x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x25x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x25x4xf32>) -> tensor<128x96x25x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x96x25x4xf32>) -> tensor<128x96x25x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x25x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x25x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          25,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 242706205
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x8x120xf32>) -> tensor<256x32x8x120xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x8x120xf32>) -> tensor<256x32x8x120xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x15x240xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x32x8x120xf32>) -> tensor<256x32x8x120xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x8x120xf32>) -> tensor<256x32x8x120xf32>\n  return %ret : tensor<256x32x8x120xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x15x240xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x32x8x120xf32>) -> tensor<256x32x8x120xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x15x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x8x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x8x120xf32>\n    memref.copy %1, %alloc : memref<256x32x8x120xf32> to memref<256x32x8x120xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 120 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x15x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x8x120xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x8x120xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x8x120xf32>\n    return %2 : tensor<256x32x8x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x8x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x15x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x15x240xf32>) -> tensor<256x32x15x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x8x120xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x8x120xf32>) -> tensor<256x32x8x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x15x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x8x120xf32>) -> tensor<256x32x8x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x8x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x8x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 17609579
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x228x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32>\n  return %ret : tensor<128x192x228x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x228x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x228x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x228x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x228x7xf32>\n    memref.copy %1, %alloc : memref<128x192x228x7xf32> to memref<128x192x228x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x228x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x228x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x228x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x228x7xf32>\n    return %2 : tensor<128x192x228x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x228x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x228x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x228x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x228x7xf32>) -> tensor<128x192x228x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x228x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x228x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 65597434
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x240x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x234x8xf32>) -> tensor<128x192x234x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x240x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x234x8xf32>) -> tensor<128x192x234x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x240x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x192x234x8xf32>) -> tensor<128x192x234x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x240x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x234x8xf32>) -> tensor<128x192x234x8xf32>\n  return %ret : tensor<128x192x234x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x240x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x192x234x8xf32>) -> tensor<128x192x234x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x240x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x234x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x234x8xf32>\n    memref.copy %1, %alloc : memref<128x192x234x8xf32> to memref<128x192x234x8xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 234 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x240x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x234x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x234x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x234x8xf32>\n    return %2 : tensor<128x192x234x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x234x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x240x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x240x14xf32>) -> tensor<128x192x240x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x234x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x234x8xf32>) -> tensor<128x192x234x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x240x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x192x234x8xf32>) -> tensor<128x192x234x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x234x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x234x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          234,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9025688179
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x56x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x27x3xf32>) -> tensor<256x128x27x3xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x56x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x27x3xf32>) -> tensor<256x128x27x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x56x7xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x128x27x3xf32>) -> tensor<256x128x27x3xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x56x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x27x3xf32>) -> tensor<256x128x27x3xf32>\n  return %ret : tensor<256x128x27x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x56x7xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x128x27x3xf32>) -> tensor<256x128x27x3xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x56x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x27x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x27x3xf32>\n    memref.copy %1, %alloc : memref<256x128x27x3xf32> to memref<256x128x27x3xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 27 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x56x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x27x3xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x27x3xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x27x3xf32>\n    return %2 : tensor<256x128x27x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x27x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x56x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x56x7xf32>) -> tensor<256x128x56x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x27x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x27x3xf32>) -> tensor<256x128x27x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x56x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x27x3xf32>) -> tensor<256x128x27x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x27x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x27x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          27,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 69195276
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x65xf32>) -> tensor<128x288x4x65xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x65xf32>) -> tensor<128x288x4x65xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x7x130xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x288x4x65xf32>) -> tensor<128x288x4x65xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x65xf32>) -> tensor<128x288x4x65xf32>\n  return %ret : tensor<128x288x4x65xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x7x130xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x288x4x65xf32>) -> tensor<128x288x4x65xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x7x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x4x65xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x4x65xf32>\n    memref.copy %1, %alloc : memref<128x288x4x65xf32> to memref<128x288x4x65xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 65 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x7x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x4x65xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x4x65xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x4x65xf32>\n    return %2 : tensor<128x288x4x65xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x4x65xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x7x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x7x130xf32>) -> tensor<128x288x7x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x4x65xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x4x65xf32>) -> tensor<128x288x4x65xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x65xf32>) -> tensor<128x288x4x65xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x4x65xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x4x65xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          65,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 20358098
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x64xf32>) -> tensor<128x256x7x64xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x64xf32>) -> tensor<128x256x7x64xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x15x130xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x256x7x64xf32>) -> tensor<128x256x7x64xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x64xf32>) -> tensor<128x256x7x64xf32>\n  return %ret : tensor<128x256x7x64xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x15x130xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x256x7x64xf32>) -> tensor<128x256x7x64xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x15x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x7x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x7x64xf32>\n    memref.copy %1, %alloc : memref<128x256x7x64xf32> to memref<128x256x7x64xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x15x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x7x64xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x7x64xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x7x64xf32>\n    return %2 : tensor<128x256x7x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x7x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x15x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x15x130xf32>) -> tensor<128x256x15x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x7x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x7x64xf32>) -> tensor<128x256x7x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x64xf32>) -> tensor<128x256x7x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x7x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x7x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          64,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 317716488
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x4x75xf32>) -> tensor<128x384x4x75xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x4x75xf32>) -> tensor<128x384x4x75xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x7x150xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x384x4x75xf32>) -> tensor<128x384x4x75xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x4x75xf32>) -> tensor<128x384x4x75xf32>\n  return %ret : tensor<128x384x4x75xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x7x150xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x384x4x75xf32>) -> tensor<128x384x4x75xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x384x7x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x384x4x75xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x4x75xf32>\n    memref.copy %1, %alloc : memref<128x384x4x75xf32> to memref<128x384x4x75xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 75 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x384x7x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x4x75xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x4x75xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x384x4x75xf32>\n    return %2 : tensor<128x384x4x75xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x4x75xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x7x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x7x150xf32>) -> tensor<128x384x7x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x4x75xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x4x75xf32>) -> tensor<128x384x4x75xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x4x75xf32>) -> tensor<128x384x4x75xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x4x75xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x4x75xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          75,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31439264
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x238x13xf32>) -> tensor<128x96x238x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x238x13xf32>) -> tensor<128x96x238x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x240x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x96x238x13xf32>) -> tensor<128x96x238x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x238x13xf32>) -> tensor<128x96x238x13xf32>\n  return %ret : tensor<128x96x238x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x240x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x96x238x13xf32>) -> tensor<128x96x238x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x240x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x238x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x238x13xf32>\n    memref.copy %1, %alloc : memref<128x96x238x13xf32> to memref<128x96x238x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x240x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x238x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x238x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x238x13xf32>\n    return %2 : tensor<128x96x238x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x238x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x240x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x240x15xf32>) -> tensor<128x96x240x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x238x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x238x13xf32>) -> tensor<128x96x238x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x238x13xf32>) -> tensor<128x96x238x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x238x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x238x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 842150303
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x3x111xf32>) -> tensor<256x128x3x111xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x3x111xf32>) -> tensor<256x128x3x111xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x7x224xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x128x3x111xf32>) -> tensor<256x128x3x111xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x3x111xf32>) -> tensor<256x128x3x111xf32>\n  return %ret : tensor<256x128x3x111xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x7x224xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x128x3x111xf32>) -> tensor<256x128x3x111xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x7x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x3x111xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x3x111xf32>\n    memref.copy %1, %alloc : memref<256x128x3x111xf32> to memref<256x128x3x111xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 111 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x7x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x3x111xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x3x111xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x3x111xf32>\n    return %2 : tensor<256x128x3x111xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x3x111xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x7x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x7x224xf32>) -> tensor<256x128x7x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x3x111xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x3x111xf32>) -> tensor<256x128x3x111xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x3x111xf32>) -> tensor<256x128x3x111xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x3x111xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x3x111xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          111,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 239533449
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x15x28xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x15x28xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x15x28xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x15x28xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32>\n  return %ret : tensor<256x128x15x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x15x28xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x15x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x15x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x15x28xf32>\n    memref.copy %1, %alloc : memref<256x128x15x28xf32> to memref<256x128x15x28xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x15x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x15x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x15x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x15x28xf32>\n    return %2 : tensor<256x128x15x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x15x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x15x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x15x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x15x28xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x15x28xf32>) -> tensor<256x128x15x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x15x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x15x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 20683276
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x14x28xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32>\n  return %ret : tensor<128x256x14x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x14x28xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x14x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x14x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x14x28xf32>\n    memref.copy %1, %alloc : memref<128x256x14x28xf32> to memref<128x256x14x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x14x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x14x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x14x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x14x28xf32>\n    return %2 : tensor<128x256x14x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x14x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x14x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x14x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x14x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x14x28xf32>) -> tensor<128x256x14x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x14x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x14x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 19261953
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x224x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32>\n  return %ret : tensor<256x256x224x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x224x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x256x224x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x256x224x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x224x56xf32>\n    memref.copy %1, %alloc : memref<256x256x224x56xf32> to memref<256x256x224x56xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x256x224x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x224x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x224x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x256x224x56xf32>\n    return %2 : tensor<256x256x224x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x224x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x224x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x224x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x224x56xf32>) -> tensor<256x256x224x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x224x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x224x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1303857586
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x65x28xf32>) -> tensor<128x192x65x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x65x28xf32>) -> tensor<128x192x65x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x130x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x192x65x28xf32>) -> tensor<128x192x65x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x65x28xf32>) -> tensor<128x192x65x28xf32>\n  return %ret : tensor<128x192x65x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x130x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x192x65x28xf32>) -> tensor<128x192x65x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x130x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x65x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x65x28xf32>\n    memref.copy %1, %alloc : memref<128x192x65x28xf32> to memref<128x192x65x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 65 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x130x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x65x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x65x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x65x28xf32>\n    return %2 : tensor<128x192x65x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x65x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x130x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x130x56xf32>) -> tensor<128x192x130x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x65x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x65x28xf32>) -> tensor<128x192x65x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x65x28xf32>) -> tensor<128x192x65x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x65x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x65x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          65,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 101562227
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x7x240xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32>\n  return %ret : tensor<128x288x7x240xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x7x240xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x7x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x7x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x7x240xf32>\n    memref.copy %1, %alloc : memref<128x288x7x240xf32> to memref<128x288x7x240xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 240 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x7x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x7x240xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x7x240xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x7x240xf32>\n    return %2 : tensor<128x288x7x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x7x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x7x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x7x240xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x7x240xf32>) -> tensor<128x288x7x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x7x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x7x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 90907209
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x28x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x26x148xf32>) -> tensor<128x288x26x148xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x28x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x26x148xf32>) -> tensor<128x288x26x148xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x28x150xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x288x26x148xf32>) -> tensor<128x288x26x148xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x28x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x26x148xf32>) -> tensor<128x288x26x148xf32>\n  return %ret : tensor<128x288x26x148xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x28x150xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x288x26x148xf32>) -> tensor<128x288x26x148xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x28x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x26x148xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x26x148xf32>\n    memref.copy %1, %alloc : memref<128x288x26x148xf32> to memref<128x288x26x148xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 148 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x28x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x26x148xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x26x148xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x26x148xf32>\n    return %2 : tensor<128x288x26x148xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x26x148xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x28x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x28x150xf32>) -> tensor<128x288x28x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x26x148xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x26x148xf32>) -> tensor<128x288x26x148xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x28x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x26x148xf32>) -> tensor<128x288x26x148xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x26x148xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x26x148xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          26,
          1
        ],
        [
          "%arg6",
          0,
          148,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3062719662
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x55x13xf32>) -> tensor<128x96x55x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x55x13xf32>) -> tensor<128x96x55x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x112x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x96x55x13xf32>) -> tensor<128x96x55x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x55x13xf32>) -> tensor<128x96x55x13xf32>\n  return %ret : tensor<128x96x55x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x112x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x96x55x13xf32>) -> tensor<128x96x55x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x112x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x55x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x55x13xf32>\n    memref.copy %1, %alloc : memref<128x96x55x13xf32> to memref<128x96x55x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 55 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x112x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x55x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x55x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x55x13xf32>\n    return %2 : tensor<128x96x55x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x55x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x112x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x112x28xf32>) -> tensor<128x96x112x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x55x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x55x13xf32>) -> tensor<128x96x55x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x96x55x13xf32>) -> tensor<128x96x55x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x55x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x55x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          55,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 193888224
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x6xf32>) -> tensor<256x48x74x6xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x6xf32>) -> tensor<256x48x74x6xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x150x14xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x48x74x6xf32>) -> tensor<256x48x74x6xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x6xf32>) -> tensor<256x48x74x6xf32>\n  return %ret : tensor<256x48x74x6xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x150x14xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x48x74x6xf32>) -> tensor<256x48x74x6xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x48x150x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x48x74x6xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x74x6xf32>\n    memref.copy %1, %alloc : memref<256x48x74x6xf32> to memref<256x48x74x6xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 74 {\n          affine.for %arg6 = 0 to 6 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x48x150x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x74x6xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x74x6xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x48x74x6xf32>\n    return %2 : tensor<256x48x74x6xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x74x6xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x150x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x150x14xf32>) -> tensor<256x48x150x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x48x74x6xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x48x74x6xf32>) -> tensor<256x48x74x6xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x6xf32>) -> tensor<256x48x74x6xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x74x6xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x74x6xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          74,
          1
        ],
        [
          "%arg6",
          0,
          6,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 116396584
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x4x57xf32>) -> tensor<128x512x4x57xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x4x57xf32>) -> tensor<128x512x4x57xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x14x120xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x512x4x57xf32>) -> tensor<128x512x4x57xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x4x57xf32>) -> tensor<128x512x4x57xf32>\n  return %ret : tensor<128x512x4x57xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x14x120xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x512x4x57xf32>) -> tensor<128x512x4x57xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x14x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x4x57xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x4x57xf32>\n    memref.copy %1, %alloc : memref<128x512x4x57xf32> to memref<128x512x4x57xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 57 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x14x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x4x57xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x4x57xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x4x57xf32>\n    return %2 : tensor<128x512x4x57xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x4x57xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x14x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x14x120xf32>) -> tensor<128x512x14x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x4x57xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x4x57xf32>) -> tensor<128x512x4x57xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x4x57xf32>) -> tensor<128x512x4x57xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x4x57xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x4x57xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          57,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2931179393
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x112x150xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32>\n  return %ret : tensor<128x240x112x150xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x112x150xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x112x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x112x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x112x150xf32>\n    memref.copy %1, %alloc : memref<128x240x112x150xf32> to memref<128x240x112x150xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 150 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x112x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x112x150xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x112x150xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x112x150xf32>\n    return %2 : tensor<128x240x112x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x112x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x112x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x112x150xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x150xf32>) -> tensor<128x240x112x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x112x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x112x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          150,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 802606953
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x240x54x54xf32>) -> tensor<128x240x54x54xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x240x54x54xf32>) -> tensor<128x240x54x54xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x56x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x240x54x54xf32>) -> tensor<128x240x54x54xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x240x54x54xf32>) -> tensor<128x240x54x54xf32>\n  return %ret : tensor<128x240x54x54xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x56x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x240x54x54xf32>) -> tensor<128x240x54x54xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x56x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x54x54xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x54x54xf32>\n    memref.copy %1, %alloc : memref<128x240x54x54xf32> to memref<128x240x54x54xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 54 {\n          affine.for %arg6 = 0 to 54 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x56x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x54x54xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x54x54xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x54x54xf32>\n    return %2 : tensor<128x240x54x54xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x54x54xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x56x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x56x56xf32>) -> tensor<128x240x56x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x54x54xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x54x54xf32>) -> tensor<128x240x54x54xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x240x54x54xf32>) -> tensor<128x240x54x54xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x54x54xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x54x54xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          54,
          1
        ],
        [
          "%arg6",
          0,
          54,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1938134835
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x7x240xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32>\n  return %ret : tensor<256x48x7x240xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x7x240xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x48x7x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x48x7x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x7x240xf32>\n    memref.copy %1, %alloc : memref<256x48x7x240xf32> to memref<256x48x7x240xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 240 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x48x7x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x7x240xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x7x240xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x48x7x240xf32>\n    return %2 : tensor<256x48x7x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x7x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x7x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x48x7x240xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<1x1xf32>) outs (%init: tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x7x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x7x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          240,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 30287824
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x119x3xf32>) -> tensor<128x288x119x3xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x119x3xf32>) -> tensor<128x288x119x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x240x7xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x288x119x3xf32>) -> tensor<128x288x119x3xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x119x3xf32>) -> tensor<128x288x119x3xf32>\n  return %ret : tensor<128x288x119x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x240x7xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x288x119x3xf32>) -> tensor<128x288x119x3xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x240x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x119x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x119x3xf32>\n    memref.copy %1, %alloc : memref<128x288x119x3xf32> to memref<128x288x119x3xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 119 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x240x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x119x3xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x119x3xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x119x3xf32>\n    return %2 : tensor<128x288x119x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x119x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x240x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x240x7xf32>) -> tensor<128x288x240x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x119x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x119x3xf32>) -> tensor<128x288x119x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x119x3xf32>) -> tensor<128x288x119x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x119x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x119x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          119,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 284820586
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x4xf32>) -> tensor<256x384x5x4xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x4xf32>) -> tensor<256x384x5x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x15x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x384x5x4xf32>) -> tensor<256x384x5x4xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x4xf32>) -> tensor<256x384x5x4xf32>\n  return %ret : tensor<256x384x5x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x15x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x384x5x4xf32>) -> tensor<256x384x5x4xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x384x15x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x384x5x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x5x4xf32>\n    memref.copy %1, %alloc : memref<256x384x5x4xf32> to memref<256x384x5x4xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x384x15x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x5x4xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x5x4xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x384x5x4xf32>\n    return %2 : tensor<256x384x5x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x5x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x15x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x15x14xf32>) -> tensor<256x384x15x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x5x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x5x4xf32>) -> tensor<256x384x5x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x4xf32>) -> tensor<256x384x5x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x5x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x5x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 389037201
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x53x57xf32>) -> tensor<128x32x53x57xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x53x57xf32>) -> tensor<128x32x53x57xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x112x120xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x32x53x57xf32>) -> tensor<128x32x53x57xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x53x57xf32>) -> tensor<128x32x53x57xf32>\n  return %ret : tensor<128x32x53x57xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x112x120xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x32x53x57xf32>) -> tensor<128x32x53x57xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x112x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x53x57xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x53x57xf32>\n    memref.copy %1, %alloc : memref<128x32x53x57xf32> to memref<128x32x53x57xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 53 {\n          affine.for %arg6 = 0 to 57 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x112x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x53x57xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x53x57xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x53x57xf32>\n    return %2 : tensor<128x32x53x57xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x53x57xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x112x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x112x120xf32>) -> tensor<128x32x112x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x53x57xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x53x57xf32>) -> tensor<128x32x53x57xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x53x57xf32>) -> tensor<128x32x53x57xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x53x57xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x53x57xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          53,
          1
        ],
        [
          "%arg6",
          0,
          57,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2416602563
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x14x8xf32>) -> tensor<256x32x14x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x14x8xf32>) -> tensor<256x32x14x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x28x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x32x14x8xf32>) -> tensor<256x32x14x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x14x8xf32>) -> tensor<256x32x14x8xf32>\n  return %ret : tensor<256x32x14x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x28x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x32x14x8xf32>) -> tensor<256x32x14x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x28x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x14x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x14x8xf32>\n    memref.copy %1, %alloc : memref<256x32x14x8xf32> to memref<256x32x14x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x28x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x14x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x14x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x14x8xf32>\n    return %2 : tensor<256x32x14x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x14x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x28x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x28x15xf32>) -> tensor<256x32x28x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x14x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x14x8xf32>) -> tensor<256x32x14x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x14x8xf32>) -> tensor<256x32x14x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x14x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x14x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1650672
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x60xf32>) -> tensor<128x512x56x60xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x60xf32>) -> tensor<128x512x56x60xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x112x120xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x512x56x60xf32>) -> tensor<128x512x56x60xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x60xf32>) -> tensor<128x512x56x60xf32>\n  return %ret : tensor<128x512x56x60xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x112x120xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x512x56x60xf32>) -> tensor<128x512x56x60xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x112x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x56x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x56x60xf32>\n    memref.copy %1, %alloc : memref<128x512x56x60xf32> to memref<128x512x56x60xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x112x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x56x60xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x56x60xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x56x60xf32>\n    return %2 : tensor<128x512x56x60xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x56x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x112x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x112x120xf32>) -> tensor<128x512x112x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x56x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x56x60xf32>) -> tensor<128x512x56x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x60xf32>) -> tensor<128x512x56x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x56x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x56x60xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          60,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 499718144
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x112x240xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x53x117xf32>) -> tensor<128x48x53x117xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x112x240xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x53x117xf32>) -> tensor<128x48x53x117xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x112x240xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x48x53x117xf32>) -> tensor<128x48x53x117xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x112x240xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x53x117xf32>) -> tensor<128x48x53x117xf32>\n  return %ret : tensor<128x48x53x117xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x112x240xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x48x53x117xf32>) -> tensor<128x48x53x117xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x112x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x53x117xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x53x117xf32>\n    memref.copy %1, %alloc : memref<128x48x53x117xf32> to memref<128x48x53x117xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 53 {\n          affine.for %arg6 = 0 to 117 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x112x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x53x117xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x53x117xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x53x117xf32>\n    return %2 : tensor<128x48x53x117xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x53x117xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x112x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x112x240xf32>) -> tensor<128x48x112x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x53x117xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x53x117xf32>) -> tensor<128x48x53x117xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x112x240xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x53x117xf32>) -> tensor<128x48x53x117xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x53x117xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x53x117xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          53,
          1
        ],
        [
          "%arg6",
          0,
          117,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7442924886
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x13x110xf32>) -> tensor<128x128x13x110xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x13x110xf32>) -> tensor<128x128x13x110xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x15x112xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x128x13x110xf32>) -> tensor<128x128x13x110xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x13x110xf32>) -> tensor<128x128x13x110xf32>\n  return %ret : tensor<128x128x13x110xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x15x112xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x128x13x110xf32>) -> tensor<128x128x13x110xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x15x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x13x110xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x13x110xf32>\n    memref.copy %1, %alloc : memref<128x128x13x110xf32> to memref<128x128x13x110xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 110 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x15x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x13x110xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x13x110xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x13x110xf32>\n    return %2 : tensor<128x128x13x110xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x13x110xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x15x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x15x112xf32>) -> tensor<128x128x15x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x13x110xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x13x110xf32>) -> tensor<128x128x13x110xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x13x110xf32>) -> tensor<128x128x13x110xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x13x110xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x13x110xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          110,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 505556709
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x150x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x72x11xf32>) -> tensor<256x64x72x11xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x150x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x72x11xf32>) -> tensor<256x64x72x11xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x150x28xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x64x72x11xf32>) -> tensor<256x64x72x11xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x150x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x72x11xf32>) -> tensor<256x64x72x11xf32>\n  return %ret : tensor<256x64x72x11xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x150x28xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x64x72x11xf32>) -> tensor<256x64x72x11xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x150x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x72x11xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x72x11xf32>\n    memref.copy %1, %alloc : memref<256x64x72x11xf32> to memref<256x64x72x11xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 72 {\n          affine.for %arg6 = 0 to 11 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x150x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x72x11xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x72x11xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x72x11xf32>\n    return %2 : tensor<256x64x72x11xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x72x11xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x150x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x150x28xf32>) -> tensor<256x64x150x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x72x11xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x72x11xf32>) -> tensor<256x64x72x11xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x150x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x72x11xf32>) -> tensor<256x64x72x11xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x72x11xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x72x11xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          72,
          1
        ],
        [
          "%arg6",
          0,
          11,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2541841148
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x130x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x65x4xf32>) -> tensor<128x64x65x4xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x130x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x65x4xf32>) -> tensor<128x64x65x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x64x130x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x64x65x4xf32>) -> tensor<128x64x65x4xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x130x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x65x4xf32>) -> tensor<128x64x65x4xf32>\n  return %ret : tensor<128x64x65x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x64x130x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x64x65x4xf32>) -> tensor<128x64x65x4xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x64x130x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x64x65x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x65x4xf32>\n    memref.copy %1, %alloc : memref<128x64x65x4xf32> to memref<128x64x65x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 65 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x64x130x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x65x4xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x65x4xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x64x65x4xf32>\n    return %2 : tensor<128x64x65x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x65x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x64x130x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x64x130x7xf32>) -> tensor<128x64x130x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x65x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x65x4xf32>) -> tensor<128x64x65x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x130x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x65x4xf32>) -> tensor<128x64x65x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x65x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x65x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          65,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4511170
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x112x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x53x62xf32>) -> tensor<128x128x53x62xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x112x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x53x62xf32>) -> tensor<128x128x53x62xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x112x130xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x128x53x62xf32>) -> tensor<128x128x53x62xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x112x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x53x62xf32>) -> tensor<128x128x53x62xf32>\n  return %ret : tensor<128x128x53x62xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x112x130xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x128x53x62xf32>) -> tensor<128x128x53x62xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x112x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x53x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x53x62xf32>\n    memref.copy %1, %alloc : memref<128x128x53x62xf32> to memref<128x128x53x62xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 53 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x112x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x53x62xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x53x62xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x53x62xf32>\n    return %2 : tensor<128x128x53x62xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x53x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x112x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x112x130xf32>) -> tensor<128x128x112x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x53x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x53x62xf32>) -> tensor<128x128x53x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x112x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x53x62xf32>) -> tensor<128x128x53x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x53x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x53x62xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          53,
          1
        ],
        [
          "%arg6",
          0,
          62,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 10514738600
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x238x5xf32>) -> tensor<128x256x238x5xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x238x5xf32>) -> tensor<128x256x238x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x240x7xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x256x238x5xf32>) -> tensor<128x256x238x5xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x238x5xf32>) -> tensor<128x256x238x5xf32>\n  return %ret : tensor<128x256x238x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x240x7xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x256x238x5xf32>) -> tensor<128x256x238x5xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x240x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x238x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x238x5xf32>\n    memref.copy %1, %alloc : memref<128x256x238x5xf32> to memref<128x256x238x5xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x240x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x238x5xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x238x5xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x238x5xf32>\n    return %2 : tensor<128x256x238x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x238x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x240x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x240x7xf32>) -> tensor<128x256x240x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x238x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x238x5xf32>) -> tensor<128x256x238x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x238x5xf32>) -> tensor<128x256x238x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x238x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x238x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 841939574
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x120x114xf32>) -> tensor<128x96x120x114xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x120x114xf32>) -> tensor<128x96x120x114xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x240x228xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x96x120x114xf32>) -> tensor<128x96x120x114xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x120x114xf32>) -> tensor<128x96x120x114xf32>\n  return %ret : tensor<128x96x120x114xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x240x228xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x96x120x114xf32>) -> tensor<128x96x120x114xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x240x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x120x114xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x120x114xf32>\n    memref.copy %1, %alloc : memref<128x96x120x114xf32> to memref<128x96x120x114xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 114 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x240x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x120x114xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x120x114xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x120x114xf32>\n    return %2 : tensor<128x96x120x114xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x120x114xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x240x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x240x228xf32>) -> tensor<128x96x240x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x120x114xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x120x114xf32>) -> tensor<128x96x120x114xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x240x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x120x114xf32>) -> tensor<128x96x120x114xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x120x114xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x120x114xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          114,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 387205164
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x27x7xf32>) -> tensor<128x512x27x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x27x7xf32>) -> tensor<128x512x27x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x56x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x512x27x7xf32>) -> tensor<128x512x27x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x27x7xf32>) -> tensor<128x512x27x7xf32>\n  return %ret : tensor<128x512x27x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x56x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x512x27x7xf32>) -> tensor<128x512x27x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x56x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x27x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x27x7xf32>\n    memref.copy %1, %alloc : memref<128x512x27x7xf32> to memref<128x512x27x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 27 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x56x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x27x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x27x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x27x7xf32>\n    return %2 : tensor<128x512x27x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x27x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x56x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x56x15xf32>) -> tensor<128x512x56x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x27x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x27x7xf32>) -> tensor<128x512x27x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x27x7xf32>) -> tensor<128x512x27x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x27x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x27x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          27,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 283464103
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x8x112xf32>) -> tensor<128x32x8x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x8x112xf32>) -> tensor<128x32x8x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x15x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x32x8x112xf32>) -> tensor<128x32x8x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x8x112xf32>) -> tensor<128x32x8x112xf32>\n  return %ret : tensor<128x32x8x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x15x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x32x8x112xf32>) -> tensor<128x32x8x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x15x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x8x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x8x112xf32>\n    memref.copy %1, %alloc : memref<128x32x8x112xf32> to memref<128x32x8x112xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x15x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x8x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x8x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x8x112xf32>\n    return %2 : tensor<128x32x8x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x8x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x15x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x15x224xf32>) -> tensor<128x32x15x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x8x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x8x112xf32>) -> tensor<128x32x8x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x15x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x8x112xf32>) -> tensor<128x32x8x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x8x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x8x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8213617
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x75x8xf32>) -> tensor<256x256x75x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x75x8xf32>) -> tensor<256x256x75x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x150x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x256x75x8xf32>) -> tensor<256x256x75x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x75x8xf32>) -> tensor<256x256x75x8xf32>\n  return %ret : tensor<256x256x75x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x150x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x256x75x8xf32>) -> tensor<256x256x75x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x256x150x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x256x75x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x75x8xf32>\n    memref.copy %1, %alloc : memref<256x256x75x8xf32> to memref<256x256x75x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 75 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x256x150x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x75x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x75x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x256x75x8xf32>\n    return %2 : tensor<256x256x75x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x75x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x150x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x150x15xf32>) -> tensor<256x256x150x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x75x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x75x8xf32>) -> tensor<256x256x75x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x75x8xf32>) -> tensor<256x256x75x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x75x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x75x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          75,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 82532768
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x240x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x238x54xf32>) -> tensor<256x64x238x54xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x240x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x238x54xf32>) -> tensor<256x64x238x54xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x240x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x238x54xf32>) -> tensor<256x64x238x54xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x240x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x238x54xf32>) -> tensor<256x64x238x54xf32>\n  return %ret : tensor<256x64x238x54xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x240x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x238x54xf32>) -> tensor<256x64x238x54xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x240x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x238x54xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x238x54xf32>\n    memref.copy %1, %alloc : memref<256x64x238x54xf32> to memref<256x64x238x54xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 54 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x240x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x238x54xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x238x54xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x238x54xf32>\n    return %2 : tensor<256x64x238x54xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x238x54xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x240x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x240x56xf32>) -> tensor<256x64x240x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x238x54xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x238x54xf32>) -> tensor<256x64x238x54xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x240x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x238x54xf32>) -> tensor<256x64x238x54xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x238x54xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x238x54xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          54,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4552608910
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x11xf32>) -> tensor<256x240x62x11xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x11xf32>) -> tensor<256x240x62x11xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x130x28xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x240x62x11xf32>) -> tensor<256x240x62x11xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x11xf32>) -> tensor<256x240x62x11xf32>\n  return %ret : tensor<256x240x62x11xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x130x28xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x240x62x11xf32>) -> tensor<256x240x62x11xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x130x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x62x11xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x62x11xf32>\n    memref.copy %1, %alloc : memref<256x240x62x11xf32> to memref<256x240x62x11xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 11 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x130x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x62x11xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x62x11xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x62x11xf32>\n    return %2 : tensor<256x240x62x11xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x62x11xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x130x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x130x28xf32>) -> tensor<256x240x130x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x62x11xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x62x11xf32>) -> tensor<256x240x62x11xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x28xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x11xf32>) -> tensor<256x240x62x11xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x62x11xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x62x11xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          62,
          1
        ],
        [
          "%arg6",
          0,
          11,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8211271391
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x64xf32>) -> tensor<256x48x74x64xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x64xf32>) -> tensor<256x48x74x64xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x150x130xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x48x74x64xf32>) -> tensor<256x48x74x64xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x64xf32>) -> tensor<256x48x74x64xf32>\n  return %ret : tensor<256x48x74x64xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x150x130xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x48x74x64xf32>) -> tensor<256x48x74x64xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x48x150x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x48x74x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x74x64xf32>\n    memref.copy %1, %alloc : memref<256x48x74x64xf32> to memref<256x48x74x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 74 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x48x150x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x74x64xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x74x64xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x48x74x64xf32>\n    return %2 : tensor<256x48x74x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x74x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x150x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x150x130xf32>) -> tensor<256x48x150x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x48x74x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x48x74x64xf32>) -> tensor<256x48x74x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x150x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x74x64xf32>) -> tensor<256x48x74x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x74x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x74x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          74,
          1
        ],
        [
          "%arg6",
          0,
          64,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1254904864
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x27xf32>) -> tensor<128x32x64x27xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x27xf32>) -> tensor<128x32x64x27xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x130x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x32x64x27xf32>) -> tensor<128x32x64x27xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x27xf32>) -> tensor<128x32x64x27xf32>\n  return %ret : tensor<128x32x64x27xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x130x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x32x64x27xf32>) -> tensor<128x32x64x27xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x130x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x64x27xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x64x27xf32>\n    memref.copy %1, %alloc : memref<128x32x64x27xf32> to memref<128x32x64x27xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 27 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x130x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x64x27xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x64x27xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x64x27xf32>\n    return %2 : tensor<128x32x64x27xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x64x27xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x130x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x130x56xf32>) -> tensor<128x32x130x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x64x27xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x64x27xf32>) -> tensor<128x32x64x27xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x27xf32>) -> tensor<128x32x64x27xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x64x27xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x64x27xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          64,
          1
        ],
        [
          "%arg6",
          0,
          27,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 153714408
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x112x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x112x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x64x112x228xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x112x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32>\n  return %ret : tensor<128x64x112x228xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x64x112x228xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x64x112x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x64x112x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x112x228xf32>\n    memref.copy %1, %alloc : memref<128x64x112x228xf32> to memref<128x64x112x228xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 228 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x64x112x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x112x228xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x112x228xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x64x112x228xf32>\n    return %2 : tensor<128x64x112x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x112x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x64x112x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x112x228xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x112x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x228xf32>) -> tensor<128x64x112x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x112x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x112x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 305257565
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x124x9xf32>) -> tensor<128x240x124x9xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x124x9xf32>) -> tensor<128x240x124x9xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x130x15xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x240x124x9xf32>) -> tensor<128x240x124x9xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x124x9xf32>) -> tensor<128x240x124x9xf32>\n  return %ret : tensor<128x240x124x9xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x130x15xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x240x124x9xf32>) -> tensor<128x240x124x9xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x130x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x124x9xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x124x9xf32>\n    memref.copy %1, %alloc : memref<128x240x124x9xf32> to memref<128x240x124x9xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 124 {\n          affine.for %arg6 = 0 to 9 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x130x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x124x9xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x124x9xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x124x9xf32>\n    return %2 : tensor<128x240x124x9xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x124x9xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x130x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x130x15xf32>) -> tensor<128x240x130x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x124x9xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x124x9xf32>) -> tensor<128x240x124x9xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x124x9xf32>) -> tensor<128x240x124x9xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x124x9xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x124x9xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          124,
          1
        ],
        [
          "%arg6",
          0,
          9,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6716901264
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x114x65xf32>) -> tensor<256x240x114x65xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x114x65xf32>) -> tensor<256x240x114x65xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x228x130xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x240x114x65xf32>) -> tensor<256x240x114x65xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x114x65xf32>) -> tensor<256x240x114x65xf32>\n  return %ret : tensor<256x240x114x65xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x228x130xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x240x114x65xf32>) -> tensor<256x240x114x65xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x228x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x114x65xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x114x65xf32>\n    memref.copy %1, %alloc : memref<256x240x114x65xf32> to memref<256x240x114x65xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 114 {\n          affine.for %arg6 = 0 to 65 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x228x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x114x65xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x114x65xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x114x65xf32>\n    return %2 : tensor<256x240x114x65xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x114x65xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x228x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x228x130xf32>) -> tensor<256x240x228x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x114x65xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x114x65xf32>) -> tensor<256x240x114x65xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x114x65xf32>) -> tensor<256x240x114x65xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x114x65xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x114x65xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          114,
          1
        ],
        [
          "%arg6",
          0,
          65,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1105586790
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x11x25xf32>) -> tensor<128x240x11x25xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x11x25xf32>) -> tensor<128x240x11x25xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x28x56xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x240x11x25xf32>) -> tensor<128x240x11x25xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x11x25xf32>) -> tensor<128x240x11x25xf32>\n  return %ret : tensor<128x240x11x25xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x28x56xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x240x11x25xf32>) -> tensor<128x240x11x25xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x28x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x11x25xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x11x25xf32>\n    memref.copy %1, %alloc : memref<128x240x11x25xf32> to memref<128x240x11x25xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 11 {\n          affine.for %arg6 = 0 to 25 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x28x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x11x25xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x11x25xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x11x25xf32>\n    return %2 : tensor<128x240x11x25xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x11x25xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x28x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x28x56xf32>) -> tensor<128x240x28x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x11x25xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x11x25xf32>) -> tensor<128x240x11x25xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x11x25xf32>) -> tensor<128x240x11x25xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x11x25xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x11x25xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          11,
          1
        ],
        [
          "%arg6",
          0,
          25,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1653815084
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x50x8xf32>) -> tensor<128x512x50x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x50x8xf32>) -> tensor<128x512x50x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x56x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x512x50x8xf32>) -> tensor<128x512x50x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x50x8xf32>) -> tensor<128x512x50x8xf32>\n  return %ret : tensor<128x512x50x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x56x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x512x50x8xf32>) -> tensor<128x512x50x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x56x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x50x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x50x8xf32>\n    memref.copy %1, %alloc : memref<128x512x50x8xf32> to memref<128x512x50x8xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 50 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x56x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x50x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x50x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x50x8xf32>\n    return %2 : tensor<128x512x50x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x50x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x56x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x56x14xf32>) -> tensor<128x512x56x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x50x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x50x8xf32>) -> tensor<128x512x50x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x50x8xf32>) -> tensor<128x512x50x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x50x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x50x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          50,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5140473948
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x75x8xf32>) -> tensor<256x288x75x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x75x8xf32>) -> tensor<256x288x75x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x150x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x288x75x8xf32>) -> tensor<256x288x75x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x75x8xf32>) -> tensor<256x288x75x8xf32>\n  return %ret : tensor<256x288x75x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x150x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x288x75x8xf32>) -> tensor<256x288x75x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x288x150x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x288x75x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x75x8xf32>\n    memref.copy %1, %alloc : memref<256x288x75x8xf32> to memref<256x288x75x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 75 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x288x150x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x75x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x75x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x288x75x8xf32>\n    return %2 : tensor<256x288x75x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x75x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x150x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x150x15xf32>) -> tensor<256x288x150x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x75x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x75x8xf32>) -> tensor<256x288x75x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x150x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x75x8xf32>) -> tensor<256x288x75x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x75x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x75x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          75,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 92831895
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x120x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32>\n  return %ret : tensor<256x288x120x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x120x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x288x120x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x288x120x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x120x14xf32>\n    memref.copy %1, %alloc : memref<256x288x120x14xf32> to memref<256x288x120x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x288x120x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x120x14xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x120x14xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x288x120x14xf32>\n    return %2 : tensor<256x288x120x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x120x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x120x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x120x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x120x14xf32>) -> tensor<256x288x120x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x120x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x120x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 189412281
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x120x4xf32>) -> tensor<128x240x120x4xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x120x4xf32>) -> tensor<128x240x120x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x240x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x240x120x4xf32>) -> tensor<128x240x120x4xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x120x4xf32>) -> tensor<128x240x120x4xf32>\n  return %ret : tensor<128x240x120x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x240x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x240x120x4xf32>) -> tensor<128x240x120x4xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x240x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x120x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x120x4xf32>\n    memref.copy %1, %alloc : memref<128x240x120x4xf32> to memref<128x240x120x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x240x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x120x4xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x120x4xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x120x4xf32>\n    return %2 : tensor<128x240x120x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x120x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x240x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x240x7xf32>) -> tensor<128x240x240x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x120x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x120x4xf32>) -> tensor<128x240x120x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x120x4xf32>) -> tensor<128x240x120x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x120x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x120x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31755170
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x240x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x240x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x240x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x240x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32>\n  return %ret : tensor<256x512x240x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x240x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x512x240x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x512x240x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x240x15xf32>\n    memref.copy %1, %alloc : memref<256x512x240x15xf32> to memref<256x512x240x15xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x512x240x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x240x15xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x240x15xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x512x240x15xf32>\n    return %2 : tensor<256x512x240x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x240x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x240x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x240x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x240x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x240x15xf32>) -> tensor<256x512x240x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x240x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x240x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 715030036
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x5x54xf32>) -> tensor<128x48x5x54xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x5x54xf32>) -> tensor<128x48x5x54xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x7x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x48x5x54xf32>) -> tensor<128x48x5x54xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x5x54xf32>) -> tensor<128x48x5x54xf32>\n  return %ret : tensor<128x48x5x54xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x7x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x48x5x54xf32>) -> tensor<128x48x5x54xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x7x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x5x54xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x5x54xf32>\n    memref.copy %1, %alloc : memref<128x48x5x54xf32> to memref<128x48x5x54xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 54 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x7x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x5x54xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x5x54xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x5x54xf32>\n    return %2 : tensor<128x48x5x54xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x5x54xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x7x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x7x56xf32>) -> tensor<128x48x7x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x5x54xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x5x54xf32>) -> tensor<128x48x5x54xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x5x54xf32>) -> tensor<128x48x5x54xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x5x54xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x5x54xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          54,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 35786528
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x240x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32>\n  return %ret : tensor<256x256x240x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x240x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x256x240x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x256x240x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x240x7xf32>\n    memref.copy %1, %alloc : memref<256x256x240x7xf32> to memref<256x256x240x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 240 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x256x240x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x240x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x240x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x256x240x7xf32>\n    return %2 : tensor<256x256x240x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x240x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x240x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x240x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x240x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x240x7xf32>) -> tensor<256x256x240x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x240x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x240x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 184097871
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x54x13xf32>) -> tensor<256x512x54x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x54x13xf32>) -> tensor<256x512x54x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x56x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x512x54x13xf32>) -> tensor<256x512x54x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x54x13xf32>) -> tensor<256x512x54x13xf32>\n  return %ret : tensor<256x512x54x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x56x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x512x54x13xf32>) -> tensor<256x512x54x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x512x56x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x512x54x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x54x13xf32>\n    memref.copy %1, %alloc : memref<256x512x54x13xf32> to memref<256x512x54x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 54 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x512x56x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x54x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x54x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x512x54x13xf32>\n    return %2 : tensor<256x512x54x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x54x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x56x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x56x15xf32>) -> tensor<256x512x56x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x54x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x54x13xf32>) -> tensor<256x512x54x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x56x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x54x13xf32>) -> tensor<256x512x54x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x54x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x54x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          54,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2037030718
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x112x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32>\n  return %ret : tensor<128x240x112x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x112x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x112x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x112x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x112x7xf32>\n    memref.copy %1, %alloc : memref<128x240x112x7xf32> to memref<128x240x112x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x112x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x112x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x112x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x112x7xf32>\n    return %2 : tensor<128x240x112x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x112x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x112x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x112x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x112x7xf32>) -> tensor<128x240x112x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x112x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x112x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 40542718
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x240x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x119x64xf32>) -> tensor<256x240x119x64xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x240x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x119x64xf32>) -> tensor<256x240x119x64xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x240x130xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x240x119x64xf32>) -> tensor<256x240x119x64xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x240x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x119x64xf32>) -> tensor<256x240x119x64xf32>\n  return %ret : tensor<256x240x119x64xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x240x130xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x240x119x64xf32>) -> tensor<256x240x119x64xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x240x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x119x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x119x64xf32>\n    memref.copy %1, %alloc : memref<256x240x119x64xf32> to memref<256x240x119x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 119 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x240x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x119x64xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x119x64xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x119x64xf32>\n    return %2 : tensor<256x240x119x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x119x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x240x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x240x130xf32>) -> tensor<256x240x240x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x119x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x119x64xf32>) -> tensor<256x240x119x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x240x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x119x64xf32>) -> tensor<256x240x119x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x119x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x119x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          119,
          1
        ],
        [
          "%arg6",
          0,
          64,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 10068163810
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x56x240xf32>, tensor<7x7xf32>) outs (%init: tensor<256x96x25x117xf32>) -> tensor<256x96x25x117xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x56x240xf32>, tensor<7x7xf32>) outs (%init: tensor<256x96x25x117xf32>) -> tensor<256x96x25x117xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x56x240xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x96x25x117xf32>) -> tensor<256x96x25x117xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x56x240xf32>, tensor<7x7xf32>) outs (%init: tensor<256x96x25x117xf32>) -> tensor<256x96x25x117xf32>\n  return %ret : tensor<256x96x25x117xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x56x240xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x96x25x117xf32>) -> tensor<256x96x25x117xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x56x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x25x117xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x25x117xf32>\n    memref.copy %1, %alloc : memref<256x96x25x117xf32> to memref<256x96x25x117xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 25 {\n          affine.for %arg6 = 0 to 117 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x56x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x25x117xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x25x117xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x25x117xf32>\n    return %2 : tensor<256x96x25x117xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x25x117xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x56x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x56x240xf32>) -> tensor<256x96x56x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x25x117xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x25x117xf32>) -> tensor<256x96x25x117xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x56x240xf32>, tensor<7x7xf32>) outs (%init: tensor<256x96x25x117xf32>) -> tensor<256x96x25x117xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x25x117xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x25x117xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          25,
          1
        ],
        [
          "%arg6",
          0,
          117,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14042154535
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x120x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x60x60xf32>) -> tensor<256x512x60x60xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x120x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x60x60xf32>) -> tensor<256x512x60x60xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x120x120xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x512x60x60xf32>) -> tensor<256x512x60x60xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x120x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x60x60xf32>) -> tensor<256x512x60x60xf32>\n  return %ret : tensor<256x512x60x60xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x120x120xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x512x60x60xf32>) -> tensor<256x512x60x60xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x512x120x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x512x60x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x60x60xf32>\n    memref.copy %1, %alloc : memref<256x512x60x60xf32> to memref<256x512x60x60xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x512x120x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x60x60xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x60x60xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x512x60x60xf32>\n    return %2 : tensor<256x512x60x60xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x60x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x120x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x120x120xf32>) -> tensor<256x512x120x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x60x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x60x60xf32>) -> tensor<256x512x60x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x120x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x60x60xf32>) -> tensor<256x512x60x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x60x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x60x60xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          60,
          1
        ],
        [
          "%arg6",
          0,
          60,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1067405362
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x119x3xf32>) -> tensor<128x32x119x3xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x119x3xf32>) -> tensor<128x32x119x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x240x7xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x32x119x3xf32>) -> tensor<128x32x119x3xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x119x3xf32>) -> tensor<128x32x119x3xf32>\n  return %ret : tensor<128x32x119x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x240x7xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x32x119x3xf32>) -> tensor<128x32x119x3xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x240x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x119x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x119x3xf32>\n    memref.copy %1, %alloc : memref<128x32x119x3xf32> to memref<128x32x119x3xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 119 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x240x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x119x3xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x119x3xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x119x3xf32>\n    return %2 : tensor<128x32x119x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x119x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x240x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x240x7xf32>) -> tensor<128x32x240x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x119x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x119x3xf32>) -> tensor<128x32x119x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x119x3xf32>) -> tensor<128x32x119x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x119x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x119x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          119,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31677265
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x224x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x111x111xf32>) -> tensor<256x48x111x111xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x224x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x111x111xf32>) -> tensor<256x48x111x111xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x224x224xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x48x111x111xf32>) -> tensor<256x48x111x111xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x224x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x111x111xf32>) -> tensor<256x48x111x111xf32>\n  return %ret : tensor<256x48x111x111xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x224x224xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x48x111x111xf32>) -> tensor<256x48x111x111xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x48x224x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x48x111x111xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x111x111xf32>\n    memref.copy %1, %alloc : memref<256x48x111x111xf32> to memref<256x48x111x111xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 111 {\n          affine.for %arg6 = 0 to 111 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x48x224x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x111x111xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x111x111xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x48x111x111xf32>\n    return %2 : tensor<256x48x111x111xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x111x111xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x224x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x224x224xf32>) -> tensor<256x48x224x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x48x111x111xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x48x111x111xf32>) -> tensor<256x48x111x111xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x224x224xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x111x111xf32>) -> tensor<256x48x111x111xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x111x111xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x111x111xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          111,
          1
        ],
        [
          "%arg6",
          0,
          111,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3285719559
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x14x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32>\n  return %ret : tensor<256x64x14x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x14x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x14x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x14x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x14x7xf32>\n    memref.copy %1, %alloc : memref<256x64x14x7xf32> to memref<256x64x14x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x14x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x14x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x14x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x14x7xf32>\n    return %2 : tensor<256x64x14x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x14x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x14x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x14x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x14x7xf32>) -> tensor<256x64x14x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x14x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x14x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2699871
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x114x4xf32>) -> tensor<256x128x114x4xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x114x4xf32>) -> tensor<256x128x114x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x228x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x128x114x4xf32>) -> tensor<256x128x114x4xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x114x4xf32>) -> tensor<256x128x114x4xf32>\n  return %ret : tensor<256x128x114x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x228x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x128x114x4xf32>) -> tensor<256x128x114x4xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x228x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x114x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x114x4xf32>\n    memref.copy %1, %alloc : memref<256x128x114x4xf32> to memref<256x128x114x4xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 114 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x228x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x114x4xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x114x4xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x114x4xf32>\n    return %2 : tensor<256x128x114x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x114x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x228x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x228x7xf32>) -> tensor<256x128x228x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x114x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x114x4xf32>) -> tensor<256x128x114x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x228x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x114x4xf32>) -> tensor<256x128x114x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x114x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x114x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          114,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 38514865
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x106x8xf32>) -> tensor<256x128x106x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x106x8xf32>) -> tensor<256x128x106x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x112x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x128x106x8xf32>) -> tensor<256x128x106x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x106x8xf32>) -> tensor<256x128x106x8xf32>\n  return %ret : tensor<256x128x106x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x112x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x128x106x8xf32>) -> tensor<256x128x106x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x112x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x106x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x106x8xf32>\n    memref.copy %1, %alloc : memref<256x128x106x8xf32> to memref<256x128x106x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 106 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x112x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x106x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x106x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x106x8xf32>\n    return %2 : tensor<256x128x106x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x106x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x112x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x112x14xf32>) -> tensor<256x128x112x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x106x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x106x8xf32>) -> tensor<256x128x106x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x106x8xf32>) -> tensor<256x128x106x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x106x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x106x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          106,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5450724881
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x7xf32>) -> tensor<128x288x4x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x7xf32>) -> tensor<128x288x4x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x7x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x288x4x7xf32>) -> tensor<128x288x4x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x7xf32>) -> tensor<128x288x4x7xf32>\n  return %ret : tensor<128x288x4x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x7x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x288x4x7xf32>) -> tensor<128x288x4x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x7x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x4x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x4x7xf32>\n    memref.copy %1, %alloc : memref<128x288x4x7xf32> to memref<128x288x4x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x7x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x4x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x4x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x4x7xf32>\n    return %2 : tensor<128x288x4x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x4x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x7x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x7x14xf32>) -> tensor<128x288x7x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x4x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x4x7xf32>) -> tensor<128x288x4x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x7xf32>) -> tensor<128x288x4x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x4x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x4x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1869554
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x22x114xf32>) -> tensor<128x48x22x114xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x22x114xf32>) -> tensor<128x48x22x114xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x28x120xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x48x22x114xf32>) -> tensor<128x48x22x114xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x22x114xf32>) -> tensor<128x48x22x114xf32>\n  return %ret : tensor<128x48x22x114xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x28x120xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x48x22x114xf32>) -> tensor<128x48x22x114xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x28x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x22x114xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x22x114xf32>\n    memref.copy %1, %alloc : memref<128x48x22x114xf32> to memref<128x48x22x114xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 22 {\n          affine.for %arg6 = 0 to 114 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x28x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x22x114xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x22x114xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x22x114xf32>\n    return %2 : tensor<128x48x22x114xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x22x114xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x28x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x28x120xf32>) -> tensor<128x48x28x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x22x114xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x22x114xf32>) -> tensor<128x48x22x114xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x28x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x22x114xf32>) -> tensor<128x48x22x114xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x22x114xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x22x114xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          22,
          1
        ],
        [
          "%arg6",
          0,
          114,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3008991890
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x28xf32>) -> tensor<256x96x60x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x28xf32>) -> tensor<256x96x60x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x120x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x96x60x28xf32>) -> tensor<256x96x60x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x28xf32>) -> tensor<256x96x60x28xf32>\n  return %ret : tensor<256x96x60x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x120x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x96x60x28xf32>) -> tensor<256x96x60x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x120x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x60x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x60x28xf32>\n    memref.copy %1, %alloc : memref<256x96x60x28xf32> to memref<256x96x60x28xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x120x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x60x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x60x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x60x28xf32>\n    return %2 : tensor<256x96x60x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x60x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x120x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x120x56xf32>) -> tensor<256x96x120x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x60x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x60x28xf32>) -> tensor<256x96x60x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x28xf32>) -> tensor<256x96x60x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x60x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x60x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          60,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 92038883
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x124x8xf32>) -> tensor<256x128x124x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x124x8xf32>) -> tensor<256x128x124x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x130x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x128x124x8xf32>) -> tensor<256x128x124x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x124x8xf32>) -> tensor<256x128x124x8xf32>\n  return %ret : tensor<256x128x124x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x130x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x128x124x8xf32>) -> tensor<256x128x124x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x130x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x124x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x124x8xf32>\n    memref.copy %1, %alloc : memref<256x128x124x8xf32> to memref<256x128x124x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 124 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x130x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x124x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x124x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x124x8xf32>\n    return %2 : tensor<256x128x124x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x124x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x130x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x130x14xf32>) -> tensor<256x128x130x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x124x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x124x8xf32>) -> tensor<256x128x124x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x128x124x8xf32>) -> tensor<256x128x124x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x124x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x124x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          124,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6373751318
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x55x119xf32>) -> tensor<128x512x55x119xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x55x119xf32>) -> tensor<128x512x55x119xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x112x240xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x512x55x119xf32>) -> tensor<128x512x55x119xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x55x119xf32>) -> tensor<128x512x55x119xf32>\n  return %ret : tensor<128x512x55x119xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x112x240xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x512x55x119xf32>) -> tensor<128x512x55x119xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x112x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x55x119xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x55x119xf32>\n    memref.copy %1, %alloc : memref<128x512x55x119xf32> to memref<128x512x55x119xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 55 {\n          affine.for %arg6 = 0 to 119 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x112x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x55x119xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x55x119xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x55x119xf32>\n    return %2 : tensor<128x512x55x119xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x55x119xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x112x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x112x240xf32>) -> tensor<128x512x112x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x55x119xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x55x119xf32>) -> tensor<128x512x55x119xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x55x119xf32>) -> tensor<128x512x55x119xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x55x119xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x55x119xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          55,
          1
        ],
        [
          "%arg6",
          0,
          119,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9307413979
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x14x120xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32>\n  return %ret : tensor<256x128x14x120xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x14x120xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x14x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x14x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x14x120xf32>\n    memref.copy %1, %alloc : memref<256x128x14x120xf32> to memref<256x128x14x120xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 120 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x14x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x14x120xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x14x120xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x14x120xf32>\n    return %2 : tensor<256x128x14x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x14x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x14x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x14x120xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x14x120xf32>) -> tensor<256x128x14x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x14x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x14x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 82963838
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x119xf32>) -> tensor<128x32x64x119xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x119xf32>) -> tensor<128x32x64x119xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x130x240xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x32x64x119xf32>) -> tensor<128x32x64x119xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x119xf32>) -> tensor<128x32x64x119xf32>\n  return %ret : tensor<128x32x64x119xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x130x240xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x32x64x119xf32>) -> tensor<128x32x64x119xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x130x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x64x119xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x64x119xf32>\n    memref.copy %1, %alloc : memref<128x32x64x119xf32> to memref<128x32x64x119xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 119 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x130x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x64x119xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x64x119xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x64x119xf32>\n    return %2 : tensor<128x32x64x119xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x64x119xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x130x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x130x240xf32>) -> tensor<128x32x130x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x64x119xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x64x119xf32>) -> tensor<128x32x64x119xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x130x240xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x64x119xf32>) -> tensor<128x32x64x119xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x64x119xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x64x119xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          64,
          1
        ],
        [
          "%arg6",
          0,
          119,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 677654217
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x113x55xf32>) -> tensor<256x240x113x55xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x113x55xf32>) -> tensor<256x240x113x55xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x228x112xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x240x113x55xf32>) -> tensor<256x240x113x55xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x113x55xf32>) -> tensor<256x240x113x55xf32>\n  return %ret : tensor<256x240x113x55xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x228x112xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x240x113x55xf32>) -> tensor<256x240x113x55xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x228x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x113x55xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x113x55xf32>\n    memref.copy %1, %alloc : memref<256x240x113x55xf32> to memref<256x240x113x55xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 113 {\n          affine.for %arg6 = 0 to 55 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x228x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x113x55xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x113x55xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x113x55xf32>\n    return %2 : tensor<256x240x113x55xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x113x55xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x228x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x228x112xf32>) -> tensor<256x240x228x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x113x55xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x113x55xf32>) -> tensor<256x240x113x55xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x228x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x113x55xf32>) -> tensor<256x240x113x55xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x113x55xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x113x55xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          113,
          1
        ],
        [
          "%arg6",
          0,
          55,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8251473668
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x60x7xf32>) -> tensor<256x384x60x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x60x7xf32>) -> tensor<256x384x60x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x120x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x384x60x7xf32>) -> tensor<256x384x60x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x60x7xf32>) -> tensor<256x384x60x7xf32>\n  return %ret : tensor<256x384x60x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x120x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x384x60x7xf32>) -> tensor<256x384x60x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x384x120x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x384x60x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x60x7xf32>\n    memref.copy %1, %alloc : memref<256x384x60x7xf32> to memref<256x384x60x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x384x120x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x60x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x60x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x384x60x7xf32>\n    return %2 : tensor<256x384x60x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x60x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x120x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x120x14xf32>) -> tensor<256x384x120x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x60x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x60x7xf32>) -> tensor<256x384x60x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x60x7xf32>) -> tensor<256x384x60x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x60x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x60x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          60,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 90984609
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x3x7xf32>) -> tensor<256x384x3x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x3x7xf32>) -> tensor<256x384x3x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x7x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x384x3x7xf32>) -> tensor<256x384x3x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x3x7xf32>) -> tensor<256x384x3x7xf32>\n  return %ret : tensor<256x384x3x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x7x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x384x3x7xf32>) -> tensor<256x384x3x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x384x7x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x384x3x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x3x7xf32>\n    memref.copy %1, %alloc : memref<256x384x3x7xf32> to memref<256x384x3x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x384x7x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x3x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x3x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x384x3x7xf32>\n    return %2 : tensor<256x384x3x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x3x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x7x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x7x15xf32>) -> tensor<256x384x7x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x3x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x3x7xf32>) -> tensor<256x384x3x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x7x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x3x7xf32>) -> tensor<256x384x3x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x3x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x3x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 48286666
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x3x119xf32>) -> tensor<256x32x3x119xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x3x119xf32>) -> tensor<256x32x3x119xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x7x240xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x32x3x119xf32>) -> tensor<256x32x3x119xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x3x119xf32>) -> tensor<256x32x3x119xf32>\n  return %ret : tensor<256x32x3x119xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x7x240xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x32x3x119xf32>) -> tensor<256x32x3x119xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x7x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x3x119xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x3x119xf32>\n    memref.copy %1, %alloc : memref<256x32x3x119xf32> to memref<256x32x3x119xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 119 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x7x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x3x119xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x3x119xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x3x119xf32>\n    return %2 : tensor<256x32x3x119xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x3x119xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x7x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x7x240xf32>) -> tensor<256x32x7x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x3x119xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x3x119xf32>) -> tensor<256x32x3x119xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x3x119xf32>) -> tensor<256x32x3x119xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x3x119xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x3x119xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          119,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 63943457
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x240x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x238x12xf32>) -> tensor<128x48x238x12xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x240x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x238x12xf32>) -> tensor<128x48x238x12xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x240x14xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x48x238x12xf32>) -> tensor<128x48x238x12xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x240x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x238x12xf32>) -> tensor<128x48x238x12xf32>\n  return %ret : tensor<128x48x238x12xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x240x14xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x48x238x12xf32>) -> tensor<128x48x238x12xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x240x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x238x12xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x238x12xf32>\n    memref.copy %1, %alloc : memref<128x48x238x12xf32> to memref<128x48x238x12xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 12 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x240x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x238x12xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x238x12xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x238x12xf32>\n    return %2 : tensor<128x48x238x12xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x238x12xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x240x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x240x14xf32>) -> tensor<128x48x240x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x238x12xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x238x12xf32>) -> tensor<128x48x238x12xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x240x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x48x238x12xf32>) -> tensor<128x48x238x12xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x238x12xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x238x12xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          12,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 384877921
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x15x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32>\n  return %ret : tensor<256x96x15x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x15x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x15x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x15x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x15x14xf32>\n    memref.copy %1, %alloc : memref<256x96x15x14xf32> to memref<256x96x15x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x15x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x15x14xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x15x14xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x15x14xf32>\n    return %2 : tensor<256x96x15x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x15x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x15x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x15x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x15x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x15x14xf32>) -> tensor<256x96x15x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x15x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x15x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8059453
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x5x25xf32>) -> tensor<128x512x5x25xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x5x25xf32>) -> tensor<128x512x5x25xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x15x56xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x512x5x25xf32>) -> tensor<128x512x5x25xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x5x25xf32>) -> tensor<128x512x5x25xf32>\n  return %ret : tensor<128x512x5x25xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x15x56xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x512x5x25xf32>) -> tensor<128x512x5x25xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x15x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x5x25xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x5x25xf32>\n    memref.copy %1, %alloc : memref<128x512x5x25xf32> to memref<128x512x5x25xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 25 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x15x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x5x25xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x5x25xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x5x25xf32>\n    return %2 : tensor<128x512x5x25xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x5x25xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x15x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x15x56xf32>) -> tensor<128x512x15x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x5x25xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x5x25xf32>) -> tensor<128x512x5x25xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x5x25xf32>) -> tensor<128x512x5x25xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x5x25xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x5x25xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          25,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1605172088
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x238x13xf32>) -> tensor<256x192x238x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x238x13xf32>) -> tensor<256x192x238x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x192x240x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x192x238x13xf32>) -> tensor<256x192x238x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x238x13xf32>) -> tensor<256x192x238x13xf32>\n  return %ret : tensor<256x192x238x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x192x240x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x192x238x13xf32>) -> tensor<256x192x238x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x192x240x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x192x238x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x238x13xf32>\n    memref.copy %1, %alloc : memref<256x192x238x13xf32> to memref<256x192x238x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x192x240x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x238x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x238x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x192x238x13xf32>\n    return %2 : tensor<256x192x238x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x238x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x192x240x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x192x240x15xf32>) -> tensor<256x192x240x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x192x238x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x192x238x13xf32>) -> tensor<256x192x238x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x238x13xf32>) -> tensor<256x192x238x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x238x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x238x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3365214749
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x240x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32>\n  return %ret : tensor<128x32x120x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x240x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x240x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x120x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x120x112xf32>\n    memref.copy %1, %alloc : memref<128x32x120x112xf32> to memref<128x32x120x112xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x240x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x120x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x120x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x120x112xf32>\n    return %2 : tensor<128x32x120x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x120x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x240x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x240x224xf32>) -> tensor<128x32x240x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x120x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x240x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x120x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x120x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 126540082
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x7x228xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32>\n  return %ret : tensor<256x96x7x228xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x7x228xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x7x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x7x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x7x228xf32>\n    memref.copy %1, %alloc : memref<256x96x7x228xf32> to memref<256x96x7x228xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 228 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x7x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x228xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x228xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x7x228xf32>\n    return %2 : tensor<256x96x7x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x7x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x7x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x7x228xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x228xf32>) -> tensor<256x96x7x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x7x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x7x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 57747553
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x7x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x5x26xf32>) -> tensor<128x192x5x26xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x7x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x5x26xf32>) -> tensor<128x192x5x26xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x7x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x192x5x26xf32>) -> tensor<128x192x5x26xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x7x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x5x26xf32>) -> tensor<128x192x5x26xf32>\n  return %ret : tensor<128x192x5x26xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x7x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x192x5x26xf32>) -> tensor<128x192x5x26xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x7x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x5x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x5x26xf32>\n    memref.copy %1, %alloc : memref<128x192x5x26xf32> to memref<128x192x5x26xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x7x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x5x26xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x5x26xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x5x26xf32>\n    return %2 : tensor<128x192x5x26xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x5x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x7x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x7x28xf32>) -> tensor<128x192x7x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x5x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x5x26xf32>) -> tensor<128x192x5x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x7x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x5x26xf32>) -> tensor<128x192x5x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x5x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x5x26xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          26,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 69679277
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x224x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x111x64xf32>) -> tensor<256x240x111x64xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x224x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x111x64xf32>) -> tensor<256x240x111x64xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x224x130xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x240x111x64xf32>) -> tensor<256x240x111x64xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x224x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x111x64xf32>) -> tensor<256x240x111x64xf32>\n  return %ret : tensor<256x240x111x64xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x224x130xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x240x111x64xf32>) -> tensor<256x240x111x64xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x224x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x111x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x111x64xf32>\n    memref.copy %1, %alloc : memref<256x240x111x64xf32> to memref<256x240x111x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 111 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x224x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x111x64xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x111x64xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x111x64xf32>\n    return %2 : tensor<256x240x111x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x111x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x224x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x224x130xf32>) -> tensor<256x240x224x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x111x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x111x64xf32>) -> tensor<256x240x111x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x224x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x111x64xf32>) -> tensor<256x240x111x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x111x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x111x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          111,
          1
        ],
        [
          "%arg6",
          0,
          64,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9402706590
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x8x9xf32>) -> tensor<256x240x8x9xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x8x9xf32>) -> tensor<256x240x8x9xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x14x15xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x240x8x9xf32>) -> tensor<256x240x8x9xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x8x9xf32>) -> tensor<256x240x8x9xf32>\n  return %ret : tensor<256x240x8x9xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x14x15xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x240x8x9xf32>) -> tensor<256x240x8x9xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x14x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x8x9xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x8x9xf32>\n    memref.copy %1, %alloc : memref<256x240x8x9xf32> to memref<256x240x8x9xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 9 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x14x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x8x9xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x8x9xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x8x9xf32>\n    return %2 : tensor<256x240x8x9xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x8x9xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x14x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x14x15xf32>) -> tensor<256x240x14x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x8x9xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x8x9xf32>) -> tensor<256x240x8x9xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x8x9xf32>) -> tensor<256x240x8x9xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x8x9xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x8x9xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          9,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 867637284
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x124xf32>) -> tensor<128x32x114x124xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x124xf32>) -> tensor<128x32x114x124xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x120x130xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x32x114x124xf32>) -> tensor<128x32x114x124xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x124xf32>) -> tensor<128x32x114x124xf32>\n  return %ret : tensor<128x32x114x124xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x120x130xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x32x114x124xf32>) -> tensor<128x32x114x124xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x120x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x114x124xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x114x124xf32>\n    memref.copy %1, %alloc : memref<128x32x114x124xf32> to memref<128x32x114x124xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 114 {\n          affine.for %arg6 = 0 to 124 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x120x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x114x124xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x114x124xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x114x124xf32>\n    return %2 : tensor<128x32x114x124xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x114x124xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x120x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x120x130xf32>) -> tensor<128x32x120x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x114x124xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x114x124xf32>) -> tensor<128x32x114x124xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x130xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x124xf32>) -> tensor<128x32x114x124xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x114x124xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x114x124xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          114,
          1
        ],
        [
          "%arg6",
          0,
          124,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 11289234272
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x120xf32>) -> tensor<128x512x56x120xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x120xf32>) -> tensor<128x512x56x120xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x112x240xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x512x56x120xf32>) -> tensor<128x512x56x120xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x120xf32>) -> tensor<128x512x56x120xf32>\n  return %ret : tensor<128x512x56x120xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x112x240xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x512x56x120xf32>) -> tensor<128x512x56x120xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x112x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x56x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x56x120xf32>\n    memref.copy %1, %alloc : memref<128x512x56x120xf32> to memref<128x512x56x120xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 120 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x112x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x56x120xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x56x120xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x56x120xf32>\n    return %2 : tensor<128x512x56x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x56x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x112x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x112x240xf32>) -> tensor<128x512x112x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x56x120xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x56x120xf32>) -> tensor<128x512x56x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x112x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x56x120xf32>) -> tensor<128x512x56x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x56x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x56x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 999908895
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x56x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x28x65xf32>) -> tensor<128x288x28x65xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x56x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x28x65xf32>) -> tensor<128x288x28x65xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x56x130xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x288x28x65xf32>) -> tensor<128x288x28x65xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x56x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x28x65xf32>) -> tensor<128x288x28x65xf32>\n  return %ret : tensor<128x288x28x65xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x56x130xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x288x28x65xf32>) -> tensor<128x288x28x65xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x56x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x28x65xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x28x65xf32>\n    memref.copy %1, %alloc : memref<128x288x28x65xf32> to memref<128x288x28x65xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 65 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x56x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x28x65xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x28x65xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x28x65xf32>\n    return %2 : tensor<128x288x28x65xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x28x65xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x56x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x56x130xf32>) -> tensor<128x288x56x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x28x65xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x28x65xf32>) -> tensor<128x288x28x65xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x56x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x28x65xf32>) -> tensor<128x288x28x65xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x28x65xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x28x65xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          65,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 150327331
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x8xf32>) -> tensor<128x128x112x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x8xf32>) -> tensor<128x128x112x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x224x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x128x112x8xf32>) -> tensor<128x128x112x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x8xf32>) -> tensor<128x128x112x8xf32>\n  return %ret : tensor<128x128x112x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x224x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x128x112x8xf32>) -> tensor<128x128x112x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x224x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x112x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x112x8xf32>\n    memref.copy %1, %alloc : memref<128x128x112x8xf32> to memref<128x128x112x8xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x224x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x112x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x112x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x112x8xf32>\n    return %2 : tensor<128x128x112x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x112x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x224x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x224x15xf32>) -> tensor<128x128x224x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x112x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x112x8xf32>) -> tensor<128x128x112x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x112x8xf32>) -> tensor<128x128x112x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x112x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x112x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 30952877
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x28x120xf32>) -> tensor<128x512x28x120xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x28x120xf32>) -> tensor<128x512x28x120xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x56x240xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x512x28x120xf32>) -> tensor<128x512x28x120xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x28x120xf32>) -> tensor<128x512x28x120xf32>\n  return %ret : tensor<128x512x28x120xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x56x240xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x512x28x120xf32>) -> tensor<128x512x28x120xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x56x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x28x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x28x120xf32>\n    memref.copy %1, %alloc : memref<128x512x28x120xf32> to memref<128x512x28x120xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 120 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x56x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x28x120xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x28x120xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x28x120xf32>\n    return %2 : tensor<128x512x28x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x28x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x56x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x56x240xf32>) -> tensor<128x512x56x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x28x120xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x28x120xf32>) -> tensor<128x512x28x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x56x240xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x28x120xf32>) -> tensor<128x512x28x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x28x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x28x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 500710462
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x130x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x64x64xf32>) -> tensor<256x192x64x64xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x130x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x64x64xf32>) -> tensor<256x192x64x64xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x192x130x130xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x192x64x64xf32>) -> tensor<256x192x64x64xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x130x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x64x64xf32>) -> tensor<256x192x64x64xf32>\n  return %ret : tensor<256x192x64x64xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x192x130x130xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x192x64x64xf32>) -> tensor<256x192x64x64xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x192x130x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x192x64x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x64x64xf32>\n    memref.copy %1, %alloc : memref<256x192x64x64xf32> to memref<256x192x64x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 64 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x192x130x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x64x64xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x64x64xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x192x64x64xf32>\n    return %2 : tensor<256x192x64x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x64x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x192x130x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x192x130x130xf32>) -> tensor<256x192x130x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x192x64x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x192x64x64xf32>) -> tensor<256x192x64x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x130x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x64x64xf32>) -> tensor<256x192x64x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x64x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x64x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          64,
          1
        ],
        [
          "%arg6",
          0,
          64,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4276635534
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x64x117x53xf32>) -> tensor<128x64x117x53xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x64x117x53xf32>) -> tensor<128x64x117x53xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x64x240x112xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x64x117x53xf32>) -> tensor<128x64x117x53xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x64x117x53xf32>) -> tensor<128x64x117x53xf32>\n  return %ret : tensor<128x64x117x53xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x64x240x112xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x64x117x53xf32>) -> tensor<128x64x117x53xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x64x240x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x64x117x53xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x117x53xf32>\n    memref.copy %1, %alloc : memref<128x64x117x53xf32> to memref<128x64x117x53xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 117 {\n          affine.for %arg6 = 0 to 53 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x64x240x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x117x53xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x117x53xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x64x117x53xf32>\n    return %2 : tensor<128x64x117x53xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x117x53xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x64x240x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x64x240x112xf32>) -> tensor<128x64x240x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x117x53xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x117x53xf32>) -> tensor<128x64x117x53xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x64x117x53xf32>) -> tensor<128x64x117x53xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x117x53xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x117x53xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          117,
          1
        ],
        [
          "%arg6",
          0,
          53,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9929258588
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x27x64xf32>) -> tensor<256x384x27x64xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x27x64xf32>) -> tensor<256x384x27x64xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x56x130xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x384x27x64xf32>) -> tensor<256x384x27x64xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x27x64xf32>) -> tensor<256x384x27x64xf32>\n  return %ret : tensor<256x384x27x64xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x56x130xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x384x27x64xf32>) -> tensor<256x384x27x64xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x384x56x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x384x27x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x27x64xf32>\n    memref.copy %1, %alloc : memref<256x384x27x64xf32> to memref<256x384x27x64xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 27 {\n          affine.for %arg6 = 0 to 64 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x384x56x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x27x64xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x27x64xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x384x27x64xf32>\n    return %2 : tensor<256x384x27x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x27x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x56x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x56x130xf32>) -> tensor<256x384x56x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x27x64xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x27x64xf32>) -> tensor<256x384x27x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x56x130xf32>, tensor<3x3xf32>) outs (%init: tensor<256x384x27x64xf32>) -> tensor<256x384x27x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x27x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x27x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          27,
          1
        ],
        [
          "%arg6",
          0,
          64,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3668854990
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x150x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x144x9xf32>) -> tensor<128x240x144x9xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x150x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x144x9xf32>) -> tensor<128x240x144x9xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x150x15xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x240x144x9xf32>) -> tensor<128x240x144x9xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x150x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x144x9xf32>) -> tensor<128x240x144x9xf32>\n  return %ret : tensor<128x240x144x9xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x150x15xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x240x144x9xf32>) -> tensor<128x240x144x9xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x150x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x144x9xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x144x9xf32>\n    memref.copy %1, %alloc : memref<128x240x144x9xf32> to memref<128x240x144x9xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 144 {\n          affine.for %arg6 = 0 to 9 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x150x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x144x9xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x144x9xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x144x9xf32>\n    return %2 : tensor<128x240x144x9xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x144x9xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x150x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x150x15xf32>) -> tensor<128x240x150x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x144x9xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x144x9xf32>) -> tensor<128x240x144x9xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x150x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x144x9xf32>) -> tensor<128x240x144x9xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x144x9xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x144x9xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          144,
          1
        ],
        [
          "%arg6",
          0,
          9,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7801082610
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x150x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32>\n  return %ret : tensor<256x32x150x224xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x150x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x150x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x150x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x150x224xf32>\n    memref.copy %1, %alloc : memref<256x32x150x224xf32> to memref<256x32x150x224xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 224 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x150x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x150x224xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x150x224xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x150x224xf32>\n    return %2 : tensor<256x32x150x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x150x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x150x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x150x224xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x32x150x224xf32>) -> tensor<256x32x150x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x150x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x150x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 402649519
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x106x22xf32>) -> tensor<128x240x106x22xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x106x22xf32>) -> tensor<128x240x106x22xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x112x28xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x240x106x22xf32>) -> tensor<128x240x106x22xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x106x22xf32>) -> tensor<128x240x106x22xf32>\n  return %ret : tensor<128x240x106x22xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x112x28xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x240x106x22xf32>) -> tensor<128x240x106x22xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x112x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x106x22xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x106x22xf32>\n    memref.copy %1, %alloc : memref<128x240x106x22xf32> to memref<128x240x106x22xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 106 {\n          affine.for %arg6 = 0 to 22 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x112x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x106x22xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x106x22xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x106x22xf32>\n    return %2 : tensor<128x240x106x22xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x106x22xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x112x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x112x28xf32>) -> tensor<128x240x112x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x106x22xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x106x22xf32>) -> tensor<128x240x106x22xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x112x28xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x106x22xf32>) -> tensor<128x240x106x22xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x106x22xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x106x22xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          106,
          1
        ],
        [
          "%arg6",
          0,
          22,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 14001217501
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x26x128xf32>) -> tensor<128x512x26x128xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x26x128xf32>) -> tensor<128x512x26x128xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x28x130xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x512x26x128xf32>) -> tensor<128x512x26x128xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x26x128xf32>) -> tensor<128x512x26x128xf32>\n  return %ret : tensor<128x512x26x128xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x28x130xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x512x26x128xf32>) -> tensor<128x512x26x128xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x28x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x26x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x26x128xf32>\n    memref.copy %1, %alloc : memref<128x512x26x128xf32> to memref<128x512x26x128xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 128 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x28x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x26x128xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x26x128xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x26x128xf32>\n    return %2 : tensor<128x512x26x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x26x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x28x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x28x130xf32>) -> tensor<128x512x28x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x26x128xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x26x128xf32>) -> tensor<128x512x26x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x130xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x26x128xf32>) -> tensor<128x512x26x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x26x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x26x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          26,
          1
        ],
        [
          "%arg6",
          0,
          128,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4702297908
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x5x12xf32>) -> tensor<128x512x5x12xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x5x12xf32>) -> tensor<128x512x5x12xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x7x14xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x512x5x12xf32>) -> tensor<128x512x5x12xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x5x12xf32>) -> tensor<128x512x5x12xf32>\n  return %ret : tensor<128x512x5x12xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x7x14xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x512x5x12xf32>) -> tensor<128x512x5x12xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x7x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x5x12xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x5x12xf32>\n    memref.copy %1, %alloc : memref<128x512x5x12xf32> to memref<128x512x5x12xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 12 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x7x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x5x12xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x5x12xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x5x12xf32>\n    return %2 : tensor<128x512x5x12xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x5x12xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x7x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x7x14xf32>) -> tensor<128x512x7x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x5x12xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x5x12xf32>) -> tensor<128x512x5x12xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x7x14xf32>, tensor<3x3xf32>) outs (%init: tensor<128x512x5x12xf32>) -> tensor<128x512x5x12xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x5x12xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x5x12xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          12,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 86453960
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x13x26xf32>) -> tensor<256x240x13x26xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x13x26xf32>) -> tensor<256x240x13x26xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x15x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x240x13x26xf32>) -> tensor<256x240x13x26xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x13x26xf32>) -> tensor<256x240x13x26xf32>\n  return %ret : tensor<256x240x13x26xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x15x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x240x13x26xf32>) -> tensor<256x240x13x26xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x15x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x13x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x13x26xf32>\n    memref.copy %1, %alloc : memref<256x240x13x26xf32> to memref<256x240x13x26xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x15x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x13x26xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x13x26xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x13x26xf32>\n    return %2 : tensor<256x240x13x26xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x13x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x15x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x15x28xf32>) -> tensor<256x240x15x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x13x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x13x26xf32>) -> tensor<256x240x13x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x240x13x26xf32>) -> tensor<256x240x13x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x13x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x13x26xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          26,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 453436093
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x4x62xf32>) -> tensor<256x240x4x62xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x4x62xf32>) -> tensor<256x240x4x62xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x14x130xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x240x4x62xf32>) -> tensor<256x240x4x62xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x4x62xf32>) -> tensor<256x240x4x62xf32>\n  return %ret : tensor<256x240x4x62xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x14x130xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x240x4x62xf32>) -> tensor<256x240x4x62xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x14x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x4x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x4x62xf32>\n    memref.copy %1, %alloc : memref<256x240x4x62xf32> to memref<256x240x4x62xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x14x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x4x62xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x4x62xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x4x62xf32>\n    return %2 : tensor<256x240x4x62xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x4x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x14x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x14x130xf32>) -> tensor<256x240x14x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x4x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x4x62xf32>) -> tensor<256x240x4x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x14x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x4x62xf32>) -> tensor<256x240x4x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x4x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x4x62xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          62,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2987180747
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x150x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x150x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x150x120xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x150x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32>\n  return %ret : tensor<256x128x150x120xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x150x120xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x150x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x150x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x150x120xf32>\n    memref.copy %1, %alloc : memref<256x128x150x120xf32> to memref<256x128x150x120xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 150 {\n          affine.for %arg6 = 0 to 120 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x150x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x150x120xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x150x120xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x150x120xf32>\n    return %2 : tensor<256x128x150x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x150x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x150x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x150x120xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x150x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x150x120xf32>) -> tensor<256x128x150x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x150x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x150x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 886757671
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x55x13xf32>) -> tensor<128x32x55x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x55x13xf32>) -> tensor<128x32x55x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x112x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x32x55x13xf32>) -> tensor<128x32x55x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x55x13xf32>) -> tensor<128x32x55x13xf32>\n  return %ret : tensor<128x32x55x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x112x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x32x55x13xf32>) -> tensor<128x32x55x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x112x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x55x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x55x13xf32>\n    memref.copy %1, %alloc : memref<128x32x55x13xf32> to memref<128x32x55x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 55 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x112x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x55x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x55x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x55x13xf32>\n    return %2 : tensor<128x32x55x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x55x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x112x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x112x28xf32>) -> tensor<128x32x112x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x55x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x55x13xf32>) -> tensor<128x32x55x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x32x55x13xf32>) -> tensor<128x32x55x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x55x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x55x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          55,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 64653877
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x12x238xf32>) -> tensor<256x64x12x238xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x12x238xf32>) -> tensor<256x64x12x238xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x14x240xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x12x238xf32>) -> tensor<256x64x12x238xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x12x238xf32>) -> tensor<256x64x12x238xf32>\n  return %ret : tensor<256x64x12x238xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x14x240xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x12x238xf32>) -> tensor<256x64x12x238xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x14x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x12x238xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x12x238xf32>\n    memref.copy %1, %alloc : memref<256x64x12x238xf32> to memref<256x64x12x238xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 12 {\n          affine.for %arg6 = 0 to 238 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x14x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x12x238xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x12x238xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x12x238xf32>\n    return %2 : tensor<256x64x12x238xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x12x238xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x14x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x14x240xf32>) -> tensor<256x64x14x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x12x238xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x12x238xf32>) -> tensor<256x64x12x238xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x14x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x12x238xf32>) -> tensor<256x64x12x238xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x12x238xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x12x238xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          12,
          1
        ],
        [
          "%arg6",
          0,
          238,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1009633583
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x112x28xf32>) -> tensor<128x48x112x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x112x28xf32>) -> tensor<128x48x112x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x224x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x48x112x28xf32>) -> tensor<128x48x112x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x112x28xf32>) -> tensor<128x48x112x28xf32>\n  return %ret : tensor<128x48x112x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x224x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x48x112x28xf32>) -> tensor<128x48x112x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x224x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x112x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x112x28xf32>\n    memref.copy %1, %alloc : memref<128x48x112x28xf32> to memref<128x48x112x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x224x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x112x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x112x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x112x28xf32>\n    return %2 : tensor<128x48x112x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x112x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x224x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x224x56xf32>) -> tensor<128x48x224x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x112x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x112x28xf32>) -> tensor<128x48x112x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x224x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x112x28xf32>) -> tensor<128x48x112x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x112x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x112x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 43187446
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x7xf32>) -> tensor<256x96x60x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x7xf32>) -> tensor<256x96x60x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x120x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x96x60x7xf32>) -> tensor<256x96x60x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x7xf32>) -> tensor<256x96x60x7xf32>\n  return %ret : tensor<256x96x60x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x120x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x96x60x7xf32>) -> tensor<256x96x60x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x120x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x60x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x60x7xf32>\n    memref.copy %1, %alloc : memref<256x96x60x7xf32> to memref<256x96x60x7xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x120x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x60x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x60x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x60x7xf32>\n    return %2 : tensor<256x96x60x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x60x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x120x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x120x14xf32>) -> tensor<256x96x120x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x60x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x60x7xf32>) -> tensor<256x96x60x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x120x14xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x60x7xf32>) -> tensor<256x96x60x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x60x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x60x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          60,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 22922534
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x7x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32>\n  return %ret : tensor<128x240x7x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x7x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x7x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x7x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x7x56xf32>\n    memref.copy %1, %alloc : memref<128x240x7x56xf32> to memref<128x240x7x56xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x7x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x7x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x7x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x7x56xf32>\n    return %2 : tensor<128x240x7x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x7x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x7x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x7x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x7x56xf32>, tensor<1x1xf32>) outs (%init: tensor<128x240x7x56xf32>) -> tensor<128x240x7x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x7x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x7x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 19568821
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x4x112xf32>) -> tensor<128x32x4x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x4x112xf32>) -> tensor<128x32x4x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x7x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x32x4x112xf32>) -> tensor<128x32x4x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x4x112xf32>) -> tensor<128x32x4x112xf32>\n  return %ret : tensor<128x32x4x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x7x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x32x4x112xf32>) -> tensor<128x32x4x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x7x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x4x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x4x112xf32>\n    memref.copy %1, %alloc : memref<128x32x4x112xf32> to memref<128x32x4x112xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x7x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x4x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x4x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x4x112xf32>\n    return %2 : tensor<128x32x4x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x4x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x7x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x7x224xf32>) -> tensor<128x32x7x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x4x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x4x112xf32>) -> tensor<128x32x4x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x7x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x4x112xf32>) -> tensor<128x32x4x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x4x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x4x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3699370
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x119xf32>) -> tensor<256x48x3x119xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x119xf32>) -> tensor<256x48x3x119xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x7x240xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x48x3x119xf32>) -> tensor<256x48x3x119xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x119xf32>) -> tensor<256x48x3x119xf32>\n  return %ret : tensor<256x48x3x119xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x7x240xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x48x3x119xf32>) -> tensor<256x48x3x119xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x48x7x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x48x3x119xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x3x119xf32>\n    memref.copy %1, %alloc : memref<256x48x3x119xf32> to memref<256x48x3x119xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 119 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x48x7x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x3x119xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x3x119xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x48x3x119xf32>\n    return %2 : tensor<256x48x3x119xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x3x119xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x7x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x7x240xf32>) -> tensor<256x48x7x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x48x3x119xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x48x3x119xf32>) -> tensor<256x48x3x119xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x119xf32>) -> tensor<256x48x3x119xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x3x119xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x3x119xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          119,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 96184428
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x64x238x13xf32>) -> tensor<128x64x238x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x64x238x13xf32>) -> tensor<128x64x238x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x64x240x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x64x238x13xf32>) -> tensor<128x64x238x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x64x238x13xf32>) -> tensor<128x64x238x13xf32>\n  return %ret : tensor<128x64x238x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x64x240x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x64x238x13xf32>) -> tensor<128x64x238x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x64x240x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x64x238x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x238x13xf32>\n    memref.copy %1, %alloc : memref<128x64x238x13xf32> to memref<128x64x238x13xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x64x240x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x238x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x238x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x64x238x13xf32>\n    return %2 : tensor<128x64x238x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x238x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x64x240x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x64x240x15xf32>) -> tensor<128x64x240x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x238x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x238x13xf32>) -> tensor<128x64x238x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x240x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x64x238x13xf32>) -> tensor<128x64x238x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x238x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x238x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 560957612
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x224x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32>\n  return %ret : tensor<128x384x224x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x224x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x384x224x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x384x224x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x224x15xf32>\n    memref.copy %1, %alloc : memref<128x384x224x15xf32> to memref<128x384x224x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x384x224x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x224x15xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x224x15xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x384x224x15xf32>\n    return %2 : tensor<128x384x224x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x224x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x224x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x224x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x224x15xf32>) -> tensor<128x384x224x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x224x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x224x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 250405540
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x62x25xf32>) -> tensor<128x48x62x25xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x62x25xf32>) -> tensor<128x48x62x25xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x130x56xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x48x62x25xf32>) -> tensor<128x48x62x25xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x62x25xf32>) -> tensor<128x48x62x25xf32>\n  return %ret : tensor<128x48x62x25xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x130x56xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x48x62x25xf32>) -> tensor<128x48x62x25xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x130x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x62x25xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x62x25xf32>\n    memref.copy %1, %alloc : memref<128x48x62x25xf32> to memref<128x48x62x25xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 25 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x130x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x62x25xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x62x25xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x62x25xf32>\n    return %2 : tensor<128x48x62x25xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x62x25xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x130x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x130x56xf32>) -> tensor<128x48x130x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x62x25xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x62x25xf32>) -> tensor<128x48x62x25xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x56xf32>, tensor<7x7xf32>) outs (%init: tensor<128x48x62x25xf32>) -> tensor<128x48x62x25xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x62x25xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x62x25xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          62,
          1
        ],
        [
          "%arg6",
          0,
          25,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1862723260
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x60x56xf32>) -> tensor<256x64x60x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x60x56xf32>) -> tensor<256x64x60x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x120x112xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x64x60x56xf32>) -> tensor<256x64x60x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x60x56xf32>) -> tensor<256x64x60x56xf32>\n  return %ret : tensor<256x64x60x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x120x112xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x64x60x56xf32>) -> tensor<256x64x60x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x120x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x60x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x60x56xf32>\n    memref.copy %1, %alloc : memref<256x64x60x56xf32> to memref<256x64x60x56xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x120x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x60x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x60x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x60x56xf32>\n    return %2 : tensor<256x64x60x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x60x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x120x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x120x112xf32>) -> tensor<256x64x120x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x60x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x60x56xf32>) -> tensor<256x64x60x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<256x64x60x56xf32>) -> tensor<256x64x60x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x60x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x60x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          60,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 123893881
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x28x14xf32>) -> tensor<128x96x28x14xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x28x14xf32>) -> tensor<128x96x28x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x56x28xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x96x28x14xf32>) -> tensor<128x96x28x14xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x28x14xf32>) -> tensor<128x96x28x14xf32>\n  return %ret : tensor<128x96x28x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x56x28xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x96x28x14xf32>) -> tensor<128x96x28x14xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x56x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x28x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x28x14xf32>\n    memref.copy %1, %alloc : memref<128x96x28x14xf32> to memref<128x96x28x14xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x56x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x28x14xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x28x14xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x28x14xf32>\n    return %2 : tensor<128x96x28x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x28x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x56x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x56x28xf32>) -> tensor<128x96x56x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x28x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x28x14xf32>) -> tensor<128x96x28x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x56x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x28x14xf32>) -> tensor<128x96x28x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x28x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x28x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12595547
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x130x56xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32>\n  return %ret : tensor<256x128x130x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x130x56xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x130x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x130x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x130x56xf32>\n    memref.copy %1, %alloc : memref<256x128x130x56xf32> to memref<256x128x130x56xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x130x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x130x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x130x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x130x56xf32>\n    return %2 : tensor<256x128x130x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x130x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x130x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x130x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x130x56xf32>, tensor<1x1xf32>) outs (%init: tensor<256x128x130x56xf32>) -> tensor<256x128x130x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x130x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x130x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 377914828
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x5x54xf32>) -> tensor<256x128x5x54xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x5x54xf32>) -> tensor<256x128x5x54xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x7x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x128x5x54xf32>) -> tensor<256x128x5x54xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x5x54xf32>) -> tensor<256x128x5x54xf32>\n  return %ret : tensor<256x128x5x54xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x7x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x128x5x54xf32>) -> tensor<256x128x5x54xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x128x7x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x128x5x54xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x5x54xf32>\n    memref.copy %1, %alloc : memref<256x128x5x54xf32> to memref<256x128x5x54xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 54 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x128x7x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x5x54xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x5x54xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x128x5x54xf32>\n    return %2 : tensor<256x128x5x54xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x5x54xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x7x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x7x56xf32>) -> tensor<256x128x7x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x5x54xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x5x54xf32>) -> tensor<256x128x5x54xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x128x5x54xf32>) -> tensor<256x128x5x54xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x5x54xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x5x54xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          54,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 191765567
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x228x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x228x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x228x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x228x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32>\n  return %ret : tensor<128x32x228x224xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x228x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x228x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x228x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x228x224xf32>\n    memref.copy %1, %alloc : memref<128x32x228x224xf32> to memref<128x32x228x224xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 224 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x228x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x228x224xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x228x224xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x228x224xf32>\n    return %2 : tensor<128x32x228x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x228x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x228x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x228x224xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x228x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x228x224xf32>) -> tensor<128x32x228x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x228x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x228x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 305590066
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x110x26xf32>) -> tensor<128x192x110x26xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x110x26xf32>) -> tensor<128x192x110x26xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x112x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x192x110x26xf32>) -> tensor<128x192x110x26xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x110x26xf32>) -> tensor<128x192x110x26xf32>\n  return %ret : tensor<128x192x110x26xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x112x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x192x110x26xf32>) -> tensor<128x192x110x26xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x112x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x110x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x110x26xf32>\n    memref.copy %1, %alloc : memref<128x192x110x26xf32> to memref<128x192x110x26xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 110 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x112x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x110x26xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x110x26xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x110x26xf32>\n    return %2 : tensor<128x192x110x26xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x110x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x112x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x112x28xf32>) -> tensor<128x192x112x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x110x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x110x26xf32>) -> tensor<128x192x110x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x110x26xf32>) -> tensor<128x192x110x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x110x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x110x26xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          110,
          1
        ],
        [
          "%arg6",
          0,
          26,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1531370427
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x5xf32>) -> tensor<256x240x62x5xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x5xf32>) -> tensor<256x240x62x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x130x15xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x240x62x5xf32>) -> tensor<256x240x62x5xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x5xf32>) -> tensor<256x240x62x5xf32>\n  return %ret : tensor<256x240x62x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x130x15xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x240x62x5xf32>) -> tensor<256x240x62x5xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x130x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x62x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x62x5xf32>\n    memref.copy %1, %alloc : memref<256x240x62x5xf32> to memref<256x240x62x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x130x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x62x5xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x62x5xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x62x5xf32>\n    return %2 : tensor<256x240x62x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x62x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x130x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x130x15xf32>) -> tensor<256x240x130x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x62x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x62x5xf32>) -> tensor<256x240x62x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x130x15xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x62x5xf32>) -> tensor<256x240x62x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x62x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x62x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          62,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3745591410
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x130x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x128x110xf32>) -> tensor<256x96x128x110xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x130x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x128x110xf32>) -> tensor<256x96x128x110xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x130x112xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x96x128x110xf32>) -> tensor<256x96x128x110xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x130x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x128x110xf32>) -> tensor<256x96x128x110xf32>\n  return %ret : tensor<256x96x128x110xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x130x112xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x96x128x110xf32>) -> tensor<256x96x128x110xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x130x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x128x110xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x128x110xf32>\n    memref.copy %1, %alloc : memref<256x96x128x110xf32> to memref<256x96x128x110xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 128 {\n          affine.for %arg6 = 0 to 110 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x130x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x128x110xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x128x110xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x128x110xf32>\n    return %2 : tensor<256x96x128x110xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x128x110xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x130x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x130x112xf32>) -> tensor<256x96x130x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x128x110xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x128x110xf32>) -> tensor<256x96x128x110xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x130x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x128x110xf32>) -> tensor<256x96x128x110xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x128x110xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x128x110xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ],
        [
          "%arg6",
          0,
          110,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7467066251
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x13x238xf32>) -> tensor<256x64x13x238xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x13x238xf32>) -> tensor<256x64x13x238xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x15x240xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x13x238xf32>) -> tensor<256x64x13x238xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x13x238xf32>) -> tensor<256x64x13x238xf32>\n  return %ret : tensor<256x64x13x238xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x15x240xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x13x238xf32>) -> tensor<256x64x13x238xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x15x240xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x13x238xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x13x238xf32>\n    memref.copy %1, %alloc : memref<256x64x13x238xf32> to memref<256x64x13x238xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 238 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x15x240xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x13x238xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x13x238xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x13x238xf32>\n    return %2 : tensor<256x64x13x238xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x13x238xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x15x240xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x15x240xf32>) -> tensor<256x64x15x240xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x13x238xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x13x238xf32>) -> tensor<256x64x13x238xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x240xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x13x238xf32>) -> tensor<256x64x13x238xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x13x238xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x13x238xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          238,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1093616002
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x224x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x60xf32>) -> tensor<128x64x112x60xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x224x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x60xf32>) -> tensor<128x64x112x60xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x64x224x120xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x64x112x60xf32>) -> tensor<128x64x112x60xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x224x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x60xf32>) -> tensor<128x64x112x60xf32>\n  return %ret : tensor<128x64x112x60xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x64x224x120xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x64x112x60xf32>) -> tensor<128x64x112x60xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x64x224x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x64x112x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x112x60xf32>\n    memref.copy %1, %alloc : memref<128x64x112x60xf32> to memref<128x64x112x60xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x64x224x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x112x60xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x64x112x60xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x64x112x60xf32>\n    return %2 : tensor<128x64x112x60xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x112x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x64x224x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x64x224x120xf32>) -> tensor<128x64x224x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x64x112x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x64x112x60xf32>) -> tensor<128x64x112x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x64x224x120xf32>, tensor<1x1xf32>) outs (%init: tensor<128x64x112x60xf32>) -> tensor<128x64x112x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x112x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x112x60xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          60,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 125428568
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x56x120xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x27x59xf32>) -> tensor<128x256x27x59xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x56x120xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x27x59xf32>) -> tensor<128x256x27x59xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x56x120xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x256x27x59xf32>) -> tensor<128x256x27x59xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x56x120xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x27x59xf32>) -> tensor<128x256x27x59xf32>\n  return %ret : tensor<128x256x27x59xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x56x120xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x256x27x59xf32>) -> tensor<128x256x27x59xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x56x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x27x59xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x27x59xf32>\n    memref.copy %1, %alloc : memref<128x256x27x59xf32> to memref<128x256x27x59xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 27 {\n          affine.for %arg6 = 0 to 59 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x56x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x27x59xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x27x59xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x27x59xf32>\n    return %2 : tensor<128x256x27x59xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x27x59xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x56x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x56x120xf32>) -> tensor<128x256x56x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x27x59xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x27x59xf32>) -> tensor<128x256x27x59xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x56x120xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x27x59xf32>) -> tensor<128x256x27x59xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x27x59xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x27x59xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          27,
          1
        ],
        [
          "%arg6",
          0,
          59,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1126662024
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x150x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x72x57xf32>) -> tensor<128x128x72x57xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x150x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x72x57xf32>) -> tensor<128x128x72x57xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x150x120xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x128x72x57xf32>) -> tensor<128x128x72x57xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x150x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x72x57xf32>) -> tensor<128x128x72x57xf32>\n  return %ret : tensor<128x128x72x57xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x150x120xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x128x72x57xf32>) -> tensor<128x128x72x57xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x150x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x72x57xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x72x57xf32>\n    memref.copy %1, %alloc : memref<128x128x72x57xf32> to memref<128x128x72x57xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 72 {\n          affine.for %arg6 = 0 to 57 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x150x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x72x57xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x72x57xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x72x57xf32>\n    return %2 : tensor<128x128x72x57xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x72x57xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x150x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x150x120xf32>) -> tensor<128x128x150x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x72x57xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x72x57xf32>) -> tensor<128x128x72x57xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x150x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x72x57xf32>) -> tensor<128x128x72x57xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x72x57xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x72x57xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          72,
          1
        ],
        [
          "%arg6",
          0,
          57,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13134153995
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x4x60xf32>) -> tensor<256x240x4x60xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x4x60xf32>) -> tensor<256x240x4x60xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x7x120xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x240x4x60xf32>) -> tensor<256x240x4x60xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x4x60xf32>) -> tensor<256x240x4x60xf32>\n  return %ret : tensor<256x240x4x60xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x7x120xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x240x4x60xf32>) -> tensor<256x240x4x60xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x7x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x4x60xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x4x60xf32>\n    memref.copy %1, %alloc : memref<256x240x4x60xf32> to memref<256x240x4x60xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 60 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x7x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x4x60xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x4x60xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x4x60xf32>\n    return %2 : tensor<256x240x4x60xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x4x60xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x7x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x7x120xf32>) -> tensor<256x240x7x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x4x60xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x4x60xf32>) -> tensor<256x240x4x60xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x7x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x4x60xf32>) -> tensor<256x240x4x60xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x4x60xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x4x60xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          60,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 33321804
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x113xf32>) -> tensor<256x48x3x113xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x113xf32>) -> tensor<256x48x3x113xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x7x228xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x48x3x113xf32>) -> tensor<256x48x3x113xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x113xf32>) -> tensor<256x48x3x113xf32>\n  return %ret : tensor<256x48x3x113xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x7x228xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x48x3x113xf32>) -> tensor<256x48x3x113xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x48x7x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x48x3x113xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x3x113xf32>\n    memref.copy %1, %alloc : memref<256x48x3x113xf32> to memref<256x48x3x113xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 3 {\n          affine.for %arg6 = 0 to 113 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x48x7x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x3x113xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x3x113xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x48x3x113xf32>\n    return %2 : tensor<256x48x3x113xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x3x113xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x7x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x7x228xf32>) -> tensor<256x48x7x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x48x3x113xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x48x3x113xf32>) -> tensor<256x48x3x113xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x7x228xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x3x113xf32>) -> tensor<256x48x3x113xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x3x113xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x3x113xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          3,
          1
        ],
        [
          "%arg6",
          0,
          113,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 91438341
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x111x13xf32>) -> tensor<256x256x111x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x111x13xf32>) -> tensor<256x256x111x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x224x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x256x111x13xf32>) -> tensor<256x256x111x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x111x13xf32>) -> tensor<256x256x111x13xf32>\n  return %ret : tensor<256x256x111x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x224x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x256x111x13xf32>) -> tensor<256x256x111x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x256x224x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x256x111x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x111x13xf32>\n    memref.copy %1, %alloc : memref<256x256x111x13xf32> to memref<256x256x111x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 111 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x256x224x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x111x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x111x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x256x111x13xf32>\n    return %2 : tensor<256x256x111x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x111x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x224x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x224x28xf32>) -> tensor<256x256x224x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x111x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x111x13xf32>) -> tensor<256x256x111x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x111x13xf32>) -> tensor<256x256x111x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x111x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x111x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          111,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2087216489
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x112xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x53xf32>) -> tensor<256x384x5x53xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x112xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x53xf32>) -> tensor<256x384x5x53xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x15x112xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x384x5x53xf32>) -> tensor<256x384x5x53xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x112xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x53xf32>) -> tensor<256x384x5x53xf32>\n  return %ret : tensor<256x384x5x53xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x15x112xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x384x5x53xf32>) -> tensor<256x384x5x53xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x384x15x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x384x5x53xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x5x53xf32>\n    memref.copy %1, %alloc : memref<256x384x5x53xf32> to memref<256x384x5x53xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 53 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x384x15x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x5x53xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x5x53xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x384x5x53xf32>\n    return %2 : tensor<256x384x5x53xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x5x53xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x15x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x15x112xf32>) -> tensor<256x384x15x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x5x53xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x5x53xf32>) -> tensor<256x384x5x53xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x112xf32>, tensor<7x7xf32>) outs (%init: tensor<256x384x5x53xf32>) -> tensor<256x384x5x53xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x5x53xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x5x53xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          53,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5102935779
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x111x13xf32>) -> tensor<256x288x111x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x111x13xf32>) -> tensor<256x288x111x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x224x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x288x111x13xf32>) -> tensor<256x288x111x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x111x13xf32>) -> tensor<256x288x111x13xf32>\n  return %ret : tensor<256x288x111x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x224x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x288x111x13xf32>) -> tensor<256x288x111x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x288x224x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x288x111x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x111x13xf32>\n    memref.copy %1, %alloc : memref<256x288x111x13xf32> to memref<256x288x111x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 111 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x288x224x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x111x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x111x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x288x111x13xf32>\n    return %2 : tensor<256x288x111x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x111x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x224x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x224x28xf32>) -> tensor<256x288x224x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x111x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x111x13xf32>) -> tensor<256x288x111x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x224x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x288x111x13xf32>) -> tensor<256x288x111x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x111x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x111x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          111,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2345806033
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x25x53xf32>) -> tensor<128x128x25x53xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x25x53xf32>) -> tensor<128x128x25x53xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x56x112xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x128x25x53xf32>) -> tensor<128x128x25x53xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x25x53xf32>) -> tensor<128x128x25x53xf32>\n  return %ret : tensor<128x128x25x53xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x56x112xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x128x25x53xf32>) -> tensor<128x128x25x53xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x56x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x25x53xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x25x53xf32>\n    memref.copy %1, %alloc : memref<128x128x25x53xf32> to memref<128x128x25x53xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 25 {\n          affine.for %arg6 = 0 to 53 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x56x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x25x53xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x25x53xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x25x53xf32>\n    return %2 : tensor<128x128x25x53xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x25x53xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x56x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x56x112xf32>) -> tensor<128x128x56x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x25x53xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x25x53xf32>) -> tensor<128x128x25x53xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x112xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x25x53xf32>) -> tensor<128x128x25x53xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x25x53xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x25x53xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          25,
          1
        ],
        [
          "%arg6",
          0,
          53,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4241831018
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x7x27xf32>) -> tensor<256x64x7x27xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x7x27xf32>) -> tensor<256x64x7x27xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x15x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x7x27xf32>) -> tensor<256x64x7x27xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x7x27xf32>) -> tensor<256x64x7x27xf32>\n  return %ret : tensor<256x64x7x27xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x15x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x7x27xf32>) -> tensor<256x64x7x27xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x15x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x7x27xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x7x27xf32>\n    memref.copy %1, %alloc : memref<256x64x7x27xf32> to memref<256x64x7x27xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 27 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x15x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x27xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x7x27xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x7x27xf32>\n    return %2 : tensor<256x64x7x27xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x7x27xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x15x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x15x56xf32>) -> tensor<256x64x15x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x7x27xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x7x27xf32>) -> tensor<256x64x7x27xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x15x56xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x7x27xf32>) -> tensor<256x64x7x27xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x7x27xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x7x27xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          27,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 67418266
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x50x9xf32>) -> tensor<128x240x50x9xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x50x9xf32>) -> tensor<128x240x50x9xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x240x56x15xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x240x50x9xf32>) -> tensor<128x240x50x9xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x50x9xf32>) -> tensor<128x240x50x9xf32>\n  return %ret : tensor<128x240x50x9xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x240x56x15xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x240x50x9xf32>) -> tensor<128x240x50x9xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x240x56x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x240x50x9xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x50x9xf32>\n    memref.copy %1, %alloc : memref<128x240x50x9xf32> to memref<128x240x50x9xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 50 {\n          affine.for %arg6 = 0 to 9 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x240x56x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x50x9xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x240x50x9xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x240x50x9xf32>\n    return %2 : tensor<128x240x50x9xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x50x9xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x240x56x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x240x56x15xf32>) -> tensor<128x240x56x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x240x50x9xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x240x50x9xf32>) -> tensor<128x240x50x9xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x240x56x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x240x50x9xf32>) -> tensor<128x240x50x9xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x50x9xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x50x9xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          50,
          1
        ],
        [
          "%arg6",
          0,
          9,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2708027214
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x4xf32>) -> tensor<128x288x4x4xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x4xf32>) -> tensor<128x288x4x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x7x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x288x4x4xf32>) -> tensor<128x288x4x4xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x4xf32>) -> tensor<128x288x4x4xf32>\n  return %ret : tensor<128x288x4x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x7x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x288x4x4xf32>) -> tensor<128x288x4x4xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x7x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x4x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x4x4xf32>\n    memref.copy %1, %alloc : memref<128x288x4x4xf32> to memref<128x288x4x4xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 4 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x7x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x4x4xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x4x4xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x4x4xf32>\n    return %2 : tensor<128x288x4x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x4x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x7x7xf32>) -> tensor<128x288x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x4x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x4x4xf32>) -> tensor<128x288x4x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x7x7xf32>, tensor<1x1xf32>) outs (%init: tensor<128x288x4x4xf32>) -> tensor<128x288x4x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x4x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x4x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          4,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1148565
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x56x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x54x110xf32>) -> tensor<128x192x54x110xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x56x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x54x110xf32>) -> tensor<128x192x54x110xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x56x112xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x192x54x110xf32>) -> tensor<128x192x54x110xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x56x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x54x110xf32>) -> tensor<128x192x54x110xf32>\n  return %ret : tensor<128x192x54x110xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x56x112xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x192x54x110xf32>) -> tensor<128x192x54x110xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x56x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x54x110xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x54x110xf32>\n    memref.copy %1, %alloc : memref<128x192x54x110xf32> to memref<128x192x54x110xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 54 {\n          affine.for %arg6 = 0 to 110 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x56x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x54x110xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x54x110xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x54x110xf32>\n    return %2 : tensor<128x192x54x110xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x54x110xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x56x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x56x112xf32>) -> tensor<128x192x56x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x54x110xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x54x110xf32>) -> tensor<128x192x54x110xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x56x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x54x110xf32>) -> tensor<128x192x54x110xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x54x110xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x54x110xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          54,
          1
        ],
        [
          "%arg6",
          0,
          110,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3146889576
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x228x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x113x27xf32>) -> tensor<128x288x113x27xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x228x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x113x27xf32>) -> tensor<128x288x113x27xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x228x56xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x288x113x27xf32>) -> tensor<128x288x113x27xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x228x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x113x27xf32>) -> tensor<128x288x113x27xf32>\n  return %ret : tensor<128x288x113x27xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x228x56xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x288x113x27xf32>) -> tensor<128x288x113x27xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x228x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x113x27xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x113x27xf32>\n    memref.copy %1, %alloc : memref<128x288x113x27xf32> to memref<128x288x113x27xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 113 {\n          affine.for %arg6 = 0 to 27 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x228x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x113x27xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x113x27xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x113x27xf32>\n    return %2 : tensor<128x288x113x27xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x113x27xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x228x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x228x56xf32>) -> tensor<128x288x228x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x113x27xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x113x27xf32>) -> tensor<128x288x113x27xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x228x56xf32>, tensor<3x3xf32>) outs (%init: tensor<128x288x113x27xf32>) -> tensor<128x288x113x27xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x113x27xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x113x27xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          113,
          1
        ],
        [
          "%arg6",
          0,
          27,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2440192897
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x55x13xf32>) -> tensor<256x32x55x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x55x13xf32>) -> tensor<256x32x55x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x112x28xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x32x55x13xf32>) -> tensor<256x32x55x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x55x13xf32>) -> tensor<256x32x55x13xf32>\n  return %ret : tensor<256x32x55x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x112x28xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x32x55x13xf32>) -> tensor<256x32x55x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x112x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x55x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x55x13xf32>\n    memref.copy %1, %alloc : memref<256x32x55x13xf32> to memref<256x32x55x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 55 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x112x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x55x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x55x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x55x13xf32>\n    return %2 : tensor<256x32x55x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x55x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x112x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x112x28xf32>) -> tensor<256x32x112x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x55x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x55x13xf32>) -> tensor<256x32x55x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x112x28xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x55x13xf32>) -> tensor<256x32x55x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x55x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x55x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          55,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 129175015
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x14x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x7x112xf32>) -> tensor<128x32x7x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x14x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x7x112xf32>) -> tensor<128x32x7x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x14x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x32x7x112xf32>) -> tensor<128x32x7x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x14x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x7x112xf32>) -> tensor<128x32x7x112xf32>\n  return %ret : tensor<128x32x7x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x14x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x32x7x112xf32>) -> tensor<128x32x7x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x14x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x7x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x7x112xf32>\n    memref.copy %1, %alloc : memref<128x32x7x112xf32> to memref<128x32x7x112xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x14x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x7x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x7x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x7x112xf32>\n    return %2 : tensor<128x32x7x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x7x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x14x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x14x224xf32>) -> tensor<128x32x14x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x7x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x7x112xf32>) -> tensor<128x32x7x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x14x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x7x112xf32>) -> tensor<128x32x7x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x7x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x7x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7559167
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x130x28xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32>\n  return %ret : tensor<128x48x130x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x130x28xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x130x28xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x130x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x130x28xf32>\n    memref.copy %1, %alloc : memref<128x48x130x28xf32> to memref<128x48x130x28xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 130 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x130x28xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x130x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x130x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x130x28xf32>\n    return %2 : tensor<128x48x130x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x130x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x130x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x130x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x130x28xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x130x28xf32>) -> tensor<128x48x130x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x130x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x130x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 32859099
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x5x57xf32>) -> tensor<128x288x5x57xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x5x57xf32>) -> tensor<128x288x5x57xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x288x15x120xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x288x5x57xf32>) -> tensor<128x288x5x57xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x5x57xf32>) -> tensor<128x288x5x57xf32>\n  return %ret : tensor<128x288x5x57xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x288x15x120xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x288x5x57xf32>) -> tensor<128x288x5x57xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x288x15x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x288x5x57xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x5x57xf32>\n    memref.copy %1, %alloc : memref<128x288x5x57xf32> to memref<128x288x5x57xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 57 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x288x15x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x5x57xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x288x5x57xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x288x5x57xf32>\n    return %2 : tensor<128x288x5x57xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x5x57xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x288x15x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x288x15x120xf32>) -> tensor<128x288x15x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x288x5x57xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x288x5x57xf32>) -> tensor<128x288x5x57xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x288x15x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x288x5x57xf32>) -> tensor<128x288x5x57xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x5x57xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x5x57xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          57,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2057084825
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x106x8xf32>) -> tensor<128x32x106x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x106x8xf32>) -> tensor<128x32x106x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x112x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x32x106x8xf32>) -> tensor<128x32x106x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x106x8xf32>) -> tensor<128x32x106x8xf32>\n  return %ret : tensor<128x32x106x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x112x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x32x106x8xf32>) -> tensor<128x32x106x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x112x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x106x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x106x8xf32>\n    memref.copy %1, %alloc : memref<128x32x106x8xf32> to memref<128x32x106x8xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 106 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x112x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x106x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x106x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x106x8xf32>\n    return %2 : tensor<128x32x106x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x106x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x112x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x112x14xf32>) -> tensor<128x32x112x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x106x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x106x8xf32>) -> tensor<128x32x106x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x112x14xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x106x8xf32>) -> tensor<128x32x106x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x106x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x106x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          106,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 681130062
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x8x114xf32>) -> tensor<128x128x8x114xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x8x114xf32>) -> tensor<128x128x8x114xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x14x120xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x128x8x114xf32>) -> tensor<128x128x8x114xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x8x114xf32>) -> tensor<128x128x8x114xf32>\n  return %ret : tensor<128x128x8x114xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x14x120xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x128x8x114xf32>) -> tensor<128x128x8x114xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x14x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x8x114xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x8x114xf32>\n    memref.copy %1, %alloc : memref<128x128x8x114xf32> to memref<128x128x8x114xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 114 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x14x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x8x114xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x8x114xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x8x114xf32>\n    return %2 : tensor<128x128x8x114xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x8x114xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x14x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x14x120xf32>) -> tensor<128x128x14x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x8x114xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x8x114xf32>) -> tensor<128x128x8x114xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x120xf32>, tensor<7x7xf32>) outs (%init: tensor<128x128x8x114xf32>) -> tensor<128x128x8x114xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x8x114xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x8x114xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          114,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2919804044
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x130x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x65x112xf32>) -> tensor<256x288x65x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x130x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x65x112xf32>) -> tensor<256x288x65x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x288x130x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x288x65x112xf32>) -> tensor<256x288x65x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x130x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x65x112xf32>) -> tensor<256x288x65x112xf32>\n  return %ret : tensor<256x288x65x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x288x130x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x288x65x112xf32>) -> tensor<256x288x65x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x288x130x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x288x65x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x65x112xf32>\n    memref.copy %1, %alloc : memref<256x288x65x112xf32> to memref<256x288x65x112xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 288 {\n        affine.for %arg5 = 0 to 65 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x288x130x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x65x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x288x65x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x288x65x112xf32>\n    return %2 : tensor<256x288x65x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x65x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x288x130x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x288x130x224xf32>) -> tensor<256x288x130x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x288x65x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x288x65x112xf32>) -> tensor<256x288x65x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x288x130x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x288x65x112xf32>) -> tensor<256x288x65x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x65x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x65x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          288,
          1
        ],
        [
          "%arg5",
          0,
          65,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1237299050
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x13x110xf32>) -> tensor<256x256x13x110xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x13x110xf32>) -> tensor<256x256x13x110xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x15x112xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x256x13x110xf32>) -> tensor<256x256x13x110xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x13x110xf32>) -> tensor<256x256x13x110xf32>\n  return %ret : tensor<256x256x13x110xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x15x112xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x256x13x110xf32>) -> tensor<256x256x13x110xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x256x15x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x256x13x110xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x13x110xf32>\n    memref.copy %1, %alloc : memref<256x256x13x110xf32> to memref<256x256x13x110xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 110 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x256x15x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x13x110xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x13x110xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x256x13x110xf32>\n    return %2 : tensor<256x256x13x110xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x13x110xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x15x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x15x112xf32>) -> tensor<256x256x15x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x13x110xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x13x110xf32>) -> tensor<256x256x13x110xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x15x112xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x13x110xf32>) -> tensor<256x256x13x110xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x13x110xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x13x110xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          110,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2021799322
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x9x8xf32>) -> tensor<256x240x9x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x9x8xf32>) -> tensor<256x240x9x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x15x14xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x240x9x8xf32>) -> tensor<256x240x9x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x9x8xf32>) -> tensor<256x240x9x8xf32>\n  return %ret : tensor<256x240x9x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x15x14xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x240x9x8xf32>) -> tensor<256x240x9x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x15x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x9x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x9x8xf32>\n    memref.copy %1, %alloc : memref<256x240x9x8xf32> to memref<256x240x9x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 9 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x15x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x9x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x9x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x9x8xf32>\n    return %2 : tensor<256x240x9x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x9x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x15x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x15x14xf32>) -> tensor<256x240x15x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x9x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x9x8xf32>) -> tensor<256x240x9x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x15x14xf32>, tensor<7x7xf32>) outs (%init: tensor<256x240x9x8xf32>) -> tensor<256x240x9x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x9x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x9x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          9,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 867725942
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x56x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x54x12xf32>) -> tensor<256x48x54x12xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x56x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x54x12xf32>) -> tensor<256x48x54x12xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x48x56x14xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x48x54x12xf32>) -> tensor<256x48x54x12xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x56x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x54x12xf32>) -> tensor<256x48x54x12xf32>\n  return %ret : tensor<256x48x54x12xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x48x56x14xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x48x54x12xf32>) -> tensor<256x48x54x12xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x48x56x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x48x54x12xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x54x12xf32>\n    memref.copy %1, %alloc : memref<256x48x54x12xf32> to memref<256x48x54x12xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 54 {\n          affine.for %arg6 = 0 to 12 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x48x56x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x54x12xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x48x54x12xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x48x54x12xf32>\n    return %2 : tensor<256x48x54x12xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x54x12xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x48x56x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x48x56x14xf32>) -> tensor<256x48x56x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x48x54x12xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x48x54x12xf32>) -> tensor<256x48x54x12xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x48x56x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x48x54x12xf32>) -> tensor<256x48x54x12xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x54x12xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x54x12xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          54,
          1
        ],
        [
          "%arg6",
          0,
          12,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 174853419
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x112x120xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32>\n  return %ret : tensor<256x256x112x120xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x112x120xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x256x112x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x256x112x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x112x120xf32>\n    memref.copy %1, %alloc : memref<256x256x112x120xf32> to memref<256x256x112x120xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 120 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x256x112x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x112x120xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x112x120xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x256x112x120xf32>\n    return %2 : tensor<256x256x112x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x112x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x112x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x112x120xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x112x120xf32>, tensor<1x1xf32>) outs (%init: tensor<256x256x112x120xf32>) -> tensor<256x256x112x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x112x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x112x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          120,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1323153685
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x22x50xf32>) -> tensor<256x32x22x50xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x22x50xf32>) -> tensor<256x32x22x50xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x28x56xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x32x22x50xf32>) -> tensor<256x32x22x50xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x22x50xf32>) -> tensor<256x32x22x50xf32>\n  return %ret : tensor<256x32x22x50xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x28x56xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x32x22x50xf32>) -> tensor<256x32x22x50xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x28x56xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x22x50xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x22x50xf32>\n    memref.copy %1, %alloc : memref<256x32x22x50xf32> to memref<256x32x22x50xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 22 {\n          affine.for %arg6 = 0 to 50 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x28x56xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x22x50xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x22x50xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x22x50xf32>\n    return %2 : tensor<256x32x22x50xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x22x50xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x28x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x28x56xf32>) -> tensor<256x32x28x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x22x50xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x22x50xf32>) -> tensor<256x32x22x50xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x28x56xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x22x50xf32>) -> tensor<256x32x22x50xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x22x50xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x22x50xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          22,
          1
        ],
        [
          "%arg6",
          0,
          50,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1760531603
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x8x75xf32>) -> tensor<128x512x8x75xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x8x75xf32>) -> tensor<128x512x8x75xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x15x150xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x512x8x75xf32>) -> tensor<128x512x8x75xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x8x75xf32>) -> tensor<128x512x8x75xf32>\n  return %ret : tensor<128x512x8x75xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x15x150xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x512x8x75xf32>) -> tensor<128x512x8x75xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x15x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x8x75xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x8x75xf32>\n    memref.copy %1, %alloc : memref<128x512x8x75xf32> to memref<128x512x8x75xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 75 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x15x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x8x75xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x8x75xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x8x75xf32>\n    return %2 : tensor<128x512x8x75xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x8x75xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x15x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x15x150xf32>) -> tensor<128x512x15x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x8x75xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x8x75xf32>) -> tensor<128x512x8x75xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x15x150xf32>, tensor<1x1xf32>) outs (%init: tensor<128x512x8x75xf32>) -> tensor<128x512x8x75xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x8x75xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x8x75xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          75,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 86355015
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x119x3xf32>) -> tensor<256x32x119x3xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x119x3xf32>) -> tensor<256x32x119x3xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x240x7xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x32x119x3xf32>) -> tensor<256x32x119x3xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x119x3xf32>) -> tensor<256x32x119x3xf32>\n  return %ret : tensor<256x32x119x3xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x240x7xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x32x119x3xf32>) -> tensor<256x32x119x3xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x240x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x119x3xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x119x3xf32>\n    memref.copy %1, %alloc : memref<256x32x119x3xf32> to memref<256x32x119x3xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 119 {\n          affine.for %arg6 = 0 to 3 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x240x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x119x3xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x119x3xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x119x3xf32>\n    return %2 : tensor<256x32x119x3xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x119x3xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x240x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x240x7xf32>) -> tensor<256x32x240x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x119x3xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x119x3xf32>) -> tensor<256x32x119x3xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x240x7xf32>, tensor<3x3xf32>) outs (%init: tensor<256x32x119x3xf32>) -> tensor<256x32x119x3xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x119x3xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x119x3xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          119,
          1
        ],
        [
          "%arg6",
          0,
          3,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 63257148
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x72x72xf32>) -> tensor<256x32x72x72xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x72x72xf32>) -> tensor<256x32x72x72xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x150x150xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x32x72x72xf32>) -> tensor<256x32x72x72xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x72x72xf32>) -> tensor<256x32x72x72xf32>\n  return %ret : tensor<256x32x72x72xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x150x150xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x32x72x72xf32>) -> tensor<256x32x72x72xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x32x150x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x32x72x72xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x72x72xf32>\n    memref.copy %1, %alloc : memref<256x32x72x72xf32> to memref<256x32x72x72xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 72 {\n          affine.for %arg6 = 0 to 72 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x32x150x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x72x72xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x72x72xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x32x72x72xf32>\n    return %2 : tensor<256x32x72x72xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x72x72xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x150x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x150x150xf32>) -> tensor<256x32x150x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x72x72xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x72x72xf32>) -> tensor<256x32x72x72xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x150x150xf32>, tensor<7x7xf32>) outs (%init: tensor<256x32x72x72xf32>) -> tensor<256x32x72x72xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x72x72xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x72x72xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          72,
          1
        ],
        [
          "%arg6",
          0,
          72,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 8292115852
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x228x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x113x6xf32>) -> tensor<256x256x113x6xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x228x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x113x6xf32>) -> tensor<256x256x113x6xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x228x14xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x256x113x6xf32>) -> tensor<256x256x113x6xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x228x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x113x6xf32>) -> tensor<256x256x113x6xf32>\n  return %ret : tensor<256x256x113x6xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x228x14xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x256x113x6xf32>) -> tensor<256x256x113x6xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x256x228x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x256x113x6xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x113x6xf32>\n    memref.copy %1, %alloc : memref<256x256x113x6xf32> to memref<256x256x113x6xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 113 {\n          affine.for %arg6 = 0 to 6 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x256x228x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x113x6xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x113x6xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x256x113x6xf32>\n    return %2 : tensor<256x256x113x6xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x113x6xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x228x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x228x14xf32>) -> tensor<256x256x228x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x113x6xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x113x6xf32>) -> tensor<256x256x113x6xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x228x14xf32>, tensor<3x3xf32>) outs (%init: tensor<256x256x113x6xf32>) -> tensor<256x256x113x6xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x113x6xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x113x6xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          113,
          1
        ],
        [
          "%arg6",
          0,
          6,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 946719079
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x228x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x113x7xf32>) -> tensor<128x384x113x7xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x228x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x113x7xf32>) -> tensor<128x384x113x7xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x228x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x384x113x7xf32>) -> tensor<128x384x113x7xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x228x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x113x7xf32>) -> tensor<128x384x113x7xf32>\n  return %ret : tensor<128x384x113x7xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x228x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x384x113x7xf32>) -> tensor<128x384x113x7xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x384x228x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x384x113x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x113x7xf32>\n    memref.copy %1, %alloc : memref<128x384x113x7xf32> to memref<128x384x113x7xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 113 {\n          affine.for %arg6 = 0 to 7 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x384x228x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x113x7xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x113x7xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x384x113x7xf32>\n    return %2 : tensor<128x384x113x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x113x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x228x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x228x15xf32>) -> tensor<128x384x228x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x113x7xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x113x7xf32>) -> tensor<128x384x113x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x228x15xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x113x7xf32>) -> tensor<128x384x113x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x113x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x113x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          113,
          1
        ],
        [
          "%arg6",
          0,
          7,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 888492404
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x56x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x56x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x48x56x14xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x56x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32>\n  return %ret : tensor<128x48x56x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x48x56x14xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x48x56x14xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x48x56x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x56x14xf32>\n    memref.copy %1, %alloc : memref<128x48x56x14xf32> to memref<128x48x56x14xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 48 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x48x56x14xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x56x14xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x48x56x14xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x48x56x14xf32>\n    return %2 : tensor<128x48x56x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x56x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x48x56x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x48x56x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x48x56x14xf32>, tensor<1x1xf32>) outs (%init: tensor<128x48x56x14xf32>) -> tensor<128x48x56x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x56x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x56x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          48,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7038177
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x7x65xf32>) -> tensor<128x128x7x65xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x7x65xf32>) -> tensor<128x128x7x65xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x14x130xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x128x7x65xf32>) -> tensor<128x128x7x65xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x7x65xf32>) -> tensor<128x128x7x65xf32>\n  return %ret : tensor<128x128x7x65xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x14x130xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x128x7x65xf32>) -> tensor<128x128x7x65xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x14x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x7x65xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x7x65xf32>\n    memref.copy %1, %alloc : memref<128x128x7x65xf32> to memref<128x128x7x65xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 65 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x14x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x7x65xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x7x65xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x7x65xf32>\n    return %2 : tensor<128x128x7x65xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x7x65xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x14x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x14x130xf32>) -> tensor<128x128x14x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x7x65xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x7x65xf32>) -> tensor<128x128x7x65xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x14x130xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x7x65xf32>) -> tensor<128x128x7x65xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x7x65xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x7x65xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          65,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 17066517
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x222x148xf32>) -> tensor<256x64x222x148xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x222x148xf32>) -> tensor<256x64x222x148xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x224x150xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x222x148xf32>) -> tensor<256x64x222x148xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x222x148xf32>) -> tensor<256x64x222x148xf32>\n  return %ret : tensor<256x64x222x148xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x224x150xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x222x148xf32>) -> tensor<256x64x222x148xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x224x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x222x148xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x222x148xf32>\n    memref.copy %1, %alloc : memref<256x64x222x148xf32> to memref<256x64x222x148xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 222 {\n          affine.for %arg6 = 0 to 148 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x224x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x222x148xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x222x148xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x222x148xf32>\n    return %2 : tensor<256x64x222x148xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x222x148xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x224x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x224x150xf32>) -> tensor<256x64x224x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x222x148xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x222x148xf32>) -> tensor<256x64x222x148xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x224x150xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x222x148xf32>) -> tensor<256x64x222x148xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x222x148xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x222x148xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          222,
          1
        ],
        [
          "%arg6",
          0,
          148,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 11586254078
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x11x62xf32>) -> tensor<256x64x11x62xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x11x62xf32>) -> tensor<256x64x11x62xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x28x130xf32>, %filter: tensor<7x7xf32>, %init: tensor<256x64x11x62xf32>) -> tensor<256x64x11x62xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x11x62xf32>) -> tensor<256x64x11x62xf32>\n  return %ret : tensor<256x64x11x62xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x28x130xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<256x64x11x62xf32>) -> tensor<256x64x11x62xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x28x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x11x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x11x62xf32>\n    memref.copy %1, %alloc : memref<256x64x11x62xf32> to memref<256x64x11x62xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 11 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x28x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x11x62xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x11x62xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x11x62xf32>\n    return %2 : tensor<256x64x11x62xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x11x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x28x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x28x130xf32>) -> tensor<256x64x28x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x11x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x11x62xf32>) -> tensor<256x64x11x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x28x130xf32>, tensor<7x7xf32>) outs (%init: tensor<256x64x11x62xf32>) -> tensor<256x64x11x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x11x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x11x62xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          11,
          1
        ],
        [
          "%arg6",
          0,
          62,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2185535681
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x240x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x238x148xf32>) -> tensor<128x128x238x148xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x240x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x238x148xf32>) -> tensor<128x128x238x148xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x240x150xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x128x238x148xf32>) -> tensor<128x128x238x148xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x240x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x238x148xf32>) -> tensor<128x128x238x148xf32>\n  return %ret : tensor<128x128x238x148xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x240x150xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x128x238x148xf32>) -> tensor<128x128x238x148xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x240x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x238x148xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x238x148xf32>\n    memref.copy %1, %alloc : memref<128x128x238x148xf32> to memref<128x128x238x148xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 238 {\n          affine.for %arg6 = 0 to 148 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x240x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x238x148xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x238x148xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x238x148xf32>\n    return %2 : tensor<128x128x238x148xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x238x148xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x240x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x240x150xf32>) -> tensor<128x128x240x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x238x148xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x238x148xf32>) -> tensor<128x128x238x148xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x240x150xf32>, tensor<3x3xf32>) outs (%init: tensor<128x128x238x148xf32>) -> tensor<128x128x238x148xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x238x148xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x238x148xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          238,
          1
        ],
        [
          "%arg6",
          0,
          148,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12425701480
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x150x224xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x74x111xf32>) -> tensor<128x192x74x111xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x150x224xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x74x111xf32>) -> tensor<128x192x74x111xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x150x224xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x192x74x111xf32>) -> tensor<128x192x74x111xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x150x224xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x74x111xf32>) -> tensor<128x192x74x111xf32>\n  return %ret : tensor<128x192x74x111xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x150x224xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x192x74x111xf32>) -> tensor<128x192x74x111xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x150x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x74x111xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x74x111xf32>\n    memref.copy %1, %alloc : memref<128x192x74x111xf32> to memref<128x192x74x111xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 74 {\n          affine.for %arg6 = 0 to 111 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x150x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x74x111xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x74x111xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x74x111xf32>\n    return %2 : tensor<128x192x74x111xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x74x111xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x150x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x150x224xf32>) -> tensor<128x192x150x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x74x111xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x74x111xf32>) -> tensor<128x192x74x111xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x150x224xf32>, tensor<3x3xf32>) outs (%init: tensor<128x192x74x111xf32>) -> tensor<128x192x74x111xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x74x111xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x74x111xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          74,
          1
        ],
        [
          "%arg6",
          0,
          111,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4382024633
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x22x9xf32>) -> tensor<128x512x22x9xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x22x9xf32>) -> tensor<128x512x22x9xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x512x28x15xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x512x22x9xf32>) -> tensor<128x512x22x9xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x22x9xf32>) -> tensor<128x512x22x9xf32>\n  return %ret : tensor<128x512x22x9xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x512x28x15xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x512x22x9xf32>) -> tensor<128x512x22x9xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x512x28x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x512x22x9xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x22x9xf32>\n    memref.copy %1, %alloc : memref<128x512x22x9xf32> to memref<128x512x22x9xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 22 {\n          affine.for %arg6 = 0 to 9 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x512x28x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x22x9xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x512x22x9xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x512x22x9xf32>\n    return %2 : tensor<128x512x22x9xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x22x9xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x512x28x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x512x28x15xf32>) -> tensor<128x512x28x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x512x22x9xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x512x22x9xf32>) -> tensor<128x512x22x9xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x512x28x15xf32>, tensor<7x7xf32>) outs (%init: tensor<128x512x22x9xf32>) -> tensor<128x512x22x9xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x22x9xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x22x9xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          22,
          1
        ],
        [
          "%arg6",
          0,
          9,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2542826005
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x113xf32>) -> tensor<128x256x7x113xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x113xf32>) -> tensor<128x256x7x113xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x15x228xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x256x7x113xf32>) -> tensor<128x256x7x113xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x113xf32>) -> tensor<128x256x7x113xf32>\n  return %ret : tensor<128x256x7x113xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x15x228xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x256x7x113xf32>) -> tensor<128x256x7x113xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x15x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x7x113xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x7x113xf32>\n    memref.copy %1, %alloc : memref<128x256x7x113xf32> to memref<128x256x7x113xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 113 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x15x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x7x113xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x7x113xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x7x113xf32>\n    return %2 : tensor<128x256x7x113xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x7x113xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x15x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x15x228xf32>) -> tensor<128x256x15x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x7x113xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x7x113xf32>) -> tensor<128x256x7x113xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x15x228xf32>, tensor<3x3xf32>) outs (%init: tensor<128x256x7x113xf32>) -> tensor<128x256x7x113xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x7x113xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x7x113xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          113,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 565249446
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x7x228xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32>\n  return %ret : tensor<128x384x7x228xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x7x228xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x384x7x228xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x384x7x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x7x228xf32>\n    memref.copy %1, %alloc : memref<128x384x7x228xf32> to memref<128x384x7x228xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 228 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x384x7x228xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x7x228xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x7x228xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x384x7x228xf32>\n    return %2 : tensor<128x384x7x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x7x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x7x228xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x7x228xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x7x228xf32>, tensor<1x1xf32>) outs (%init: tensor<128x384x7x228xf32>) -> tensor<128x384x7x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x7x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x7x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          228,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 114706621
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x75x56xf32>) -> tensor<128x96x75x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x75x56xf32>) -> tensor<128x96x75x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x150x112xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x96x75x56xf32>) -> tensor<128x96x75x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x75x56xf32>) -> tensor<128x96x75x56xf32>\n  return %ret : tensor<128x96x75x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x150x112xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x96x75x56xf32>) -> tensor<128x96x75x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x150x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x75x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x75x56xf32>\n    memref.copy %1, %alloc : memref<128x96x75x56xf32> to memref<128x96x75x56xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 75 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x150x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x75x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x75x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x75x56xf32>\n    return %2 : tensor<128x96x75x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x75x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x150x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x150x112xf32>) -> tensor<128x96x150x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x75x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x75x56xf32>) -> tensor<128x96x75x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x150x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x75x56xf32>) -> tensor<128x96x75x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x75x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x75x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          75,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 116372230
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x8x8xf32>) -> tensor<256x384x8x8xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x8x8xf32>) -> tensor<256x384x8x8xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x384x15x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x384x8x8xf32>) -> tensor<256x384x8x8xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x8x8xf32>) -> tensor<256x384x8x8xf32>\n  return %ret : tensor<256x384x8x8xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x384x15x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x384x8x8xf32>) -> tensor<256x384x8x8xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x384x15x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x384x8x8xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x8x8xf32>\n    memref.copy %1, %alloc : memref<256x384x8x8xf32> to memref<256x384x8x8xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 8 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x384x15x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x8x8xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x384x8x8xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x384x8x8xf32>\n    return %2 : tensor<256x384x8x8xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x8x8xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x384x15x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x384x15x15xf32>) -> tensor<256x384x15x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x384x8x8xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x384x8x8xf32>) -> tensor<256x384x8x8xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x384x15x15xf32>, tensor<1x1xf32>) outs (%init: tensor<256x384x8x8xf32>) -> tensor<256x384x8x8xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x8x8xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x8x8xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          8,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12768295
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x120x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x120x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x240x120x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x120x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32>\n  return %ret : tensor<256x240x120x224xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x240x120x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x240x120x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x240x120x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x120x224xf32>\n    memref.copy %1, %alloc : memref<256x240x120x224xf32> to memref<256x240x120x224xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 240 {\n        affine.for %arg5 = 0 to 120 {\n          affine.for %arg6 = 0 to 224 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x240x120x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x120x224xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x240x120x224xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x240x120x224xf32>\n    return %2 : tensor<256x240x120x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x120x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x240x120x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x240x120x224xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x240x120x224xf32>, tensor<1x1xf32>) outs (%init: tensor<256x240x120x224xf32>) -> tensor<256x240x120x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x120x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x120x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ],
        [
          "%arg6",
          0,
          224,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2415246830
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x15x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x8x65xf32>) -> tensor<256x512x8x65xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x15x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x8x65xf32>) -> tensor<256x512x8x65xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x15x130xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x512x8x65xf32>) -> tensor<256x512x8x65xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x15x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x8x65xf32>) -> tensor<256x512x8x65xf32>\n  return %ret : tensor<256x512x8x65xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x15x130xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x512x8x65xf32>) -> tensor<256x512x8x65xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x512x15x130xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x512x8x65xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x8x65xf32>\n    memref.copy %1, %alloc : memref<256x512x8x65xf32> to memref<256x512x8x65xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 8 {\n          affine.for %arg6 = 0 to 65 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x512x15x130xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x65xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x8x65xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x512x8x65xf32>\n    return %2 : tensor<256x512x8x65xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x8x65xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x15x130xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x15x130xf32>) -> tensor<256x512x15x130xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x8x65xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x8x65xf32>) -> tensor<256x512x8x65xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x15x130xf32>, tensor<1x1xf32>) outs (%init: tensor<256x512x8x65xf32>) -> tensor<256x512x8x65xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x8x65xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x8x65xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          8,
          1
        ],
        [
          "%arg6",
          0,
          65,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 149470439
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x148x13xf32>) -> tensor<256x96x148x13xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x148x13xf32>) -> tensor<256x96x148x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x150x15xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x96x148x13xf32>) -> tensor<256x96x148x13xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x148x13xf32>) -> tensor<256x96x148x13xf32>\n  return %ret : tensor<256x96x148x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x150x15xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x96x148x13xf32>) -> tensor<256x96x148x13xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x150x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x148x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x148x13xf32>\n    memref.copy %1, %alloc : memref<256x96x148x13xf32> to memref<256x96x148x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 148 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x150x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x148x13xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x148x13xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x148x13xf32>\n    return %2 : tensor<256x96x148x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x148x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x150x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x150x15xf32>) -> tensor<256x96x150x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x148x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x148x13xf32>) -> tensor<256x96x148x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x150x15xf32>, tensor<3x3xf32>) outs (%init: tensor<256x96x148x13xf32>) -> tensor<256x96x148x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x148x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x148x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          148,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1046567919
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x112x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x110x110xf32>) -> tensor<128x384x110x110xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x112x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x110x110xf32>) -> tensor<128x384x110x110xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x384x112x112xf32>, %filter: tensor<3x3xf32>, %init: tensor<128x384x110x110xf32>) -> tensor<128x384x110x110xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x112x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x110x110xf32>) -> tensor<128x384x110x110xf32>\n  return %ret : tensor<128x384x110x110xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x384x112x112xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<128x384x110x110xf32>) -> tensor<128x384x110x110xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x384x112x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x384x110x110xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x110x110xf32>\n    memref.copy %1, %alloc : memref<128x384x110x110xf32> to memref<128x384x110x110xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 384 {\n        affine.for %arg5 = 0 to 110 {\n          affine.for %arg6 = 0 to 110 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x384x112x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x110x110xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x384x110x110xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x384x110x110xf32>\n    return %2 : tensor<128x384x110x110xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x110x110xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x384x112x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x384x112x112xf32>) -> tensor<128x384x112x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x384x110x110xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x384x110x110xf32>) -> tensor<128x384x110x110xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x384x112x112xf32>, tensor<3x3xf32>) outs (%init: tensor<128x384x110x110xf32>) -> tensor<128x384x110x110xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x110x110xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x110x110xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          384,
          1
        ],
        [
          "%arg5",
          0,
          110,
          1
        ],
        [
          "%arg6",
          0,
          110,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12831978620
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x96x228x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32>\n  return %ret : tensor<128x96x228x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x96x228x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x96x228x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x96x228x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x228x15xf32>\n    memref.copy %1, %alloc : memref<128x96x228x15xf32> to memref<128x96x228x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 228 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x96x228x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x228x15xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x96x228x15xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x96x228x15xf32>\n    return %2 : tensor<128x96x228x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x228x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x96x228x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x96x228x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x96x228x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x96x228x15xf32>) -> tensor<128x96x228x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x228x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x228x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 63752653
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x256x224x15xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32>\n  return %ret : tensor<128x256x224x15xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x256x224x15xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x256x224x15xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x256x224x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x224x15xf32>\n    memref.copy %1, %alloc : memref<128x256x224x15xf32> to memref<128x256x224x15xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 224 {\n          affine.for %arg6 = 0 to 15 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x256x224x15xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x224x15xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x256x224x15xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x256x224x15xf32>\n    return %2 : tensor<128x256x224x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x224x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x256x224x15xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x256x224x15xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x256x224x15xf32>, tensor<1x1xf32>) outs (%init: tensor<128x256x224x15xf32>) -> tensor<128x256x224x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x224x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x224x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ],
        [
          "%arg6",
          0,
          15,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 166714803
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x150xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x144xf32>) -> tensor<128x32x114x144xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x150xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x144xf32>) -> tensor<128x32x114x144xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x120x150xf32>, %filter: tensor<7x7xf32>, %init: tensor<128x32x114x144xf32>) -> tensor<128x32x114x144xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x150xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x144xf32>) -> tensor<128x32x114x144xf32>\n  return %ret : tensor<128x32x114x144xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x120x150xf32>, %arg1: tensor<7x7xf32>, %arg2: tensor<128x32x114x144xf32>) -> tensor<128x32x114x144xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x120x150xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x114x144xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x114x144xf32>\n    memref.copy %1, %alloc : memref<128x32x114x144xf32> to memref<128x32x114x144xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 114 {\n          affine.for %arg6 = 0 to 144 {\n            affine.for %arg7 = 0 to 7 {\n              affine.for %arg8 = 0 to 7 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x120x150xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x114x144xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x114x144xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x114x144xf32>\n    return %2 : tensor<128x32x114x144xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x114x144xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x120x150xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x120x150xf32>) -> tensor<128x32x120x150xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<7x7xf32>) -> tensor<7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x114x144xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x114x144xf32>) -> tensor<128x32x114x144xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x150xf32>, tensor<7x7xf32>) outs (%init: tensor<128x32x114x144xf32>) -> tensor<128x32x114x144xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x114x144xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x114x144xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          114,
          1
        ],
        [
          "%arg6",
          0,
          144,
          1
        ],
        [
          "%arg7",
          0,
          7,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 + %arg7",
          "%arg6 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 13118766400
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x14x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x6x59xf32>) -> tensor<256x512x6x59xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x14x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x6x59xf32>) -> tensor<256x512x6x59xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x14x120xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x512x6x59xf32>) -> tensor<256x512x6x59xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x14x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x6x59xf32>) -> tensor<256x512x6x59xf32>\n  return %ret : tensor<256x512x6x59xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x14x120xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x512x6x59xf32>) -> tensor<256x512x6x59xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x512x14x120xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x512x6x59xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x6x59xf32>\n    memref.copy %1, %alloc : memref<256x512x6x59xf32> to memref<256x512x6x59xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 6 {\n          affine.for %arg6 = 0 to 59 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x512x14x120xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x6x59xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x6x59xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x512x6x59xf32>\n    return %2 : tensor<256x512x6x59xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x6x59xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x14x120xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x14x120xf32>) -> tensor<256x512x14x120xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x6x59xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x6x59xf32>) -> tensor<256x512x6x59xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x14x120xf32>, tensor<3x3xf32>) outs (%init: tensor<256x512x6x59xf32>) -> tensor<256x512x6x59xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x6x59xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x6x59xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          6,
          1
        ],
        [
          "%arg6",
          0,
          59,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1009627984
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x28x112xf32>) -> tensor<128x128x28x112xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x28x112xf32>) -> tensor<128x128x28x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x128x56x224xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x128x28x112xf32>) -> tensor<128x128x28x112xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x28x112xf32>) -> tensor<128x128x28x112xf32>\n  return %ret : tensor<128x128x28x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x128x56x224xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x128x28x112xf32>) -> tensor<128x128x28x112xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x128x56x224xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x128x28x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x28x112xf32>\n    memref.copy %1, %alloc : memref<128x128x28x112xf32> to memref<128x128x28x112xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x128x56x224xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x28x112xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x128x28x112xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x128x28x112xf32>\n    return %2 : tensor<128x128x28x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x28x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x128x56x224xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x128x56x224xf32>) -> tensor<128x128x56x224xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x128x28x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x128x28x112xf32>) -> tensor<128x128x28x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x128x56x224xf32>, tensor<1x1xf32>) outs (%init: tensor<128x128x28x112xf32>) -> tensor<128x128x28x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x28x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x28x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 117864996
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x192x112x112xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32>\n  return %ret : tensor<128x192x56x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x192x112x112xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x192x112x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x192x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x56x56xf32>\n    memref.copy %1, %alloc : memref<128x192x56x56xf32> to memref<128x192x56x56xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x192x112x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x56x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x192x56x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x192x56x56xf32>\n    return %2 : tensor<128x192x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x192x112x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x192x112x112xf32>) -> tensor<128x192x112x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x192x56x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x192x112x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 173060218
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x60x56xf32>) -> tensor<128x32x60x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x60x56xf32>) -> tensor<128x32x60x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<128x32x120x112xf32>, %filter: tensor<1x1xf32>, %init: tensor<128x32x60x56xf32>) -> tensor<128x32x60x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x60x56xf32>) -> tensor<128x32x60x56xf32>\n  return %ret : tensor<128x32x60x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<128x32x120x112xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<128x32x60x56xf32>) -> tensor<128x32x60x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<128x32x120x112xf32>\n    %1 = bufferization.to_memref %arg2 : memref<128x32x60x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x60x56xf32>\n    memref.copy %1, %alloc : memref<128x32x60x56xf32> to memref<128x32x60x56xf32>\n    affine.for %arg3 = 0 to 128 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 60 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<128x32x120x112xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x60x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<128x32x60x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<128x32x60x56xf32>\n    return %2 : tensor<128x32x60x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x60x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<128x32x120x112xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<128x32x120x112xf32>) -> tensor<128x32x120x112xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<128x32x60x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<128x32x60x56xf32>) -> tensor<128x32x60x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<128x32x120x112xf32>, tensor<1x1xf32>) outs (%init: tensor<128x32x60x56xf32>) -> tensor<128x32x60x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x60x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x60x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          60,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31242369
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x4xf32>) -> tensor<256x96x7x4xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x4xf32>) -> tensor<256x96x7x4xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x96x14x7xf32>, %filter: tensor<1x1xf32>, %init: tensor<256x96x7x4xf32>) -> tensor<256x96x7x4xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x4xf32>) -> tensor<256x96x7x4xf32>\n  return %ret : tensor<256x96x7x4xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x96x14x7xf32>, %arg1: tensor<1x1xf32>, %arg2: tensor<256x96x7x4xf32>) -> tensor<256x96x7x4xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x96x14x7xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x96x7x4xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x7x4xf32>\n    memref.copy %1, %alloc : memref<256x96x7x4xf32> to memref<256x96x7x4xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 96 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 4 {\n            affine.for %arg7 = 0 to 1 {\n              affine.for %arg8 = 0 to 1 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x96x14x7xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x4xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x96x7x4xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x96x7x4xf32>\n    return %2 : tensor<256x96x7x4xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x7x4xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x96x14x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x96x14x7xf32>) -> tensor<256x96x14x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1x1xf32>) -> tensor<1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x96x7x4xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x96x7x4xf32>) -> tensor<256x96x7x4xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x96x14x7xf32>, tensor<1x1xf32>) outs (%init: tensor<256x96x7x4xf32>) -> tensor<256x96x7x4xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x7x4xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x7x4xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          96,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          4,
          1
        ],
        [
          "%arg7",
          0,
          1,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1199745
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x130x130xf32>) outs(%25 : tensor<128x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x130x130xf32>) outs(%25 : tensor<128x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x130x130xf32>, %25: tensor<128x192x130x130xf32>) -> tensor<128x192x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x130x130xf32>) outs(%25 : tensor<128x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x130x130xf32>\n  return %ret : tensor<128x192x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x130x130xf32>, %arg1: tensor<128x192x130x130xf32>) -> tensor<128x192x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x130x130xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x130x130xf32>\n    return %1 : tensor<128x192x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x130x130xf32>) -> tensor<128x192x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x130x130xf32>) -> tensor<128x192x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x130x130xf32>) outs(%25 : tensor<128x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 345882557
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x14x14xf32>) outs(%25 : tensor<128x384x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x14x14xf32>) outs(%25 : tensor<128x384x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x384x14x14xf32>, %25: tensor<128x384x14x14xf32>) -> tensor<128x384x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x14x14xf32>) outs(%25 : tensor<128x384x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x14x14xf32>\n  return %ret : tensor<128x384x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x384x14x14xf32>, %arg1: tensor<128x384x14x14xf32>) -> tensor<128x384x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x384x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x14x14xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x384x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x384x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x384x14x14xf32>\n    return %1 : tensor<128x384x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x384x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x384x14x14xf32>) -> tensor<128x384x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x384x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x384x14x14xf32>) -> tensor<128x384x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x14x14xf32>) outs(%25 : tensor<128x384x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7840215
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x14x14xf32>) outs(%25 : tensor<128x192x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x14x14xf32>) outs(%25 : tensor<128x192x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x14x14xf32>, %25: tensor<128x192x14x14xf32>) -> tensor<128x192x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x14x14xf32>) outs(%25 : tensor<128x192x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x14x14xf32>\n  return %ret : tensor<128x192x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x14x14xf32>, %arg1: tensor<128x192x14x14xf32>) -> tensor<128x192x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x14x14xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x14x14xf32>\n    return %1 : tensor<128x192x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x14x14xf32>) -> tensor<128x192x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x14x14xf32>) -> tensor<128x192x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x14x14xf32>) outs(%25 : tensor<128x192x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3675221
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x130x130xf32>) outs(%25 : tensor<128x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x130x130xf32>) outs(%25 : tensor<128x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x256x130x130xf32>, %25: tensor<128x256x130x130xf32>) -> tensor<128x256x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x130x130xf32>) outs(%25 : tensor<128x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x130x130xf32>\n  return %ret : tensor<128x256x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256x130x130xf32>, %arg1: tensor<128x256x130x130xf32>) -> tensor<128x256x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x256x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x130x130xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x256x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x256x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x256x130x130xf32>\n    return %1 : tensor<128x256x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x256x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x256x130x130xf32>) -> tensor<128x256x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x256x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x256x130x130xf32>) -> tensor<128x256x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x130x130xf32>) outs(%25 : tensor<128x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 485539139
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x56x56xf32>) outs(%25 : tensor<128x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x56x56xf32>) outs(%25 : tensor<128x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x48x56x56xf32>, %25: tensor<128x48x56x56xf32>) -> tensor<128x48x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x56x56xf32>) outs(%25 : tensor<128x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x56x56xf32>\n  return %ret : tensor<128x48x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x48x56x56xf32>, %arg1: tensor<128x48x56x56xf32>) -> tensor<128x48x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x48x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x56x56xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 48 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x48x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x48x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x48x56x56xf32>\n    return %1 : tensor<128x48x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x48x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x48x56x56xf32>) -> tensor<128x48x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x48x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x48x56x56xf32>) -> tensor<128x48x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x56x56xf32>) outs(%25 : tensor<128x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          48,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 16730524
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1024xf32>) outs(%35 : tensor<128x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1024xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1024xf32>) outs(%35 : tensor<128x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1024xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x1024xf32>, %35: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1024xf32>) outs(%35 : tensor<128x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1024xf32>\n  return %ret : tensor<128x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1024xf32>, %arg1: tensor<128x1024xf32>) -> tensor<128x1024xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1024xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 1024 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x1024xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x1024xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x1024xf32>\n    return %1 : tensor<128x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x1024xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x1024xf32>) -> tensor<128x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1024xf32>) outs(%35 : tensor<128x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 100476
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x14x14xf32>) outs(%25 : tensor<256x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x14x14xf32>) outs(%25 : tensor<256x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x512x14x14xf32>, %25: tensor<256x512x14x14xf32>) -> tensor<256x512x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x14x14xf32>) outs(%25 : tensor<256x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x14x14xf32>\n  return %ret : tensor<256x512x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512x14x14xf32>, %arg1: tensor<256x512x14x14xf32>) -> tensor<256x512x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x512x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x14x14xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x512x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x512x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x512x14x14xf32>\n    return %1 : tensor<256x512x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x512x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x512x14x14xf32>) -> tensor<256x512x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x512x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x512x14x14xf32>) -> tensor<256x512x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x14x14xf32>) outs(%25 : tensor<256x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 21310216
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x3072xf32>) outs(%35 : tensor<256x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x3072xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x3072xf32>) outs(%35 : tensor<256x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x3072xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x3072xf32>, %35: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x3072xf32>) outs(%35 : tensor<256x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x3072xf32>\n  return %ret : tensor<256x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x3072xf32>, %arg1: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x3072xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 3072 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x3072xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x3072xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x3072xf32>\n    return %1 : tensor<256x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x3072xf32>) outs(%35 : tensor<256x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 602550
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x240x240xf32>) outs(%25 : tensor<128x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x240x240xf32>) outs(%25 : tensor<128x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x384x240x240xf32>, %25: tensor<128x384x240x240xf32>) -> tensor<128x384x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x240x240xf32>) outs(%25 : tensor<128x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x240x240xf32>\n  return %ret : tensor<128x384x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x384x240x240xf32>, %arg1: tensor<128x384x240x240xf32>) -> tensor<128x384x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x384x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x240x240xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x384x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x384x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x384x240x240xf32>\n    return %1 : tensor<128x384x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x384x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x384x240x240xf32>) -> tensor<128x384x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x384x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x384x240x240xf32>) -> tensor<128x384x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x240x240xf32>) outs(%25 : tensor<128x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2591579652
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x224x224xf32>) outs(%25 : tensor<128x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x224x224xf32>) outs(%25 : tensor<128x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x128x224x224xf32>, %25: tensor<128x128x224x224xf32>) -> tensor<128x128x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x224x224xf32>) outs(%25 : tensor<128x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x224x224xf32>\n  return %ret : tensor<128x128x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128x224x224xf32>, %arg1: tensor<128x128x224x224xf32>) -> tensor<128x128x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x128x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x224x224xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x128x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x128x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x128x224x224xf32>\n    return %1 : tensor<128x128x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x128x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x128x224x224xf32>) -> tensor<128x128x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x128x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x128x224x224xf32>) -> tensor<128x128x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x224x224xf32>) outs(%25 : tensor<128x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 744803265
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x28x28xf32>) outs(%25 : tensor<256x240x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x28x28xf32>) outs(%25 : tensor<256x240x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x240x28x28xf32>, %25: tensor<256x240x28x28xf32>) -> tensor<256x240x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x28x28xf32>) outs(%25 : tensor<256x240x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x28x28xf32>\n  return %ret : tensor<256x240x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x240x28x28xf32>, %arg1: tensor<256x240x28x28xf32>) -> tensor<256x240x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x240x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x28x28xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x240x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x240x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x240x28x28xf32>\n    return %1 : tensor<256x240x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x240x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x240x28x28xf32>) -> tensor<256x240x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x240x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x240x28x28xf32>) -> tensor<256x240x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x28x28xf32>) outs(%25 : tensor<256x240x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 37527599
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x768xf32>) outs(%35 : tensor<128x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x768xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x768xf32>) outs(%35 : tensor<128x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x768xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x768xf32>, %35: tensor<128x768xf32>) -> tensor<128x768xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x768xf32>) outs(%35 : tensor<128x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x768xf32>\n  return %ret : tensor<128x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x768xf32>, %arg1: tensor<128x768xf32>) -> tensor<128x768xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x768xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 768 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x768xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x768xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x768xf32>\n    return %1 : tensor<128x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x768xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x768xf32>) -> tensor<128x768xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x768xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x768xf32>) -> tensor<128x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x768xf32>) outs(%35 : tensor<128x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 75732.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x120x120xf32>) outs(%25 : tensor<256x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x120x120xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x120x120xf32>) outs(%25 : tensor<256x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x120x120xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x192x120x120xf32>, %25: tensor<256x192x120x120xf32>) -> tensor<256x192x120x120xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x120x120xf32>) outs(%25 : tensor<256x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x120x120xf32>\n  return %ret : tensor<256x192x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x192x120x120xf32>, %arg1: tensor<256x192x120x120xf32>) -> tensor<256x192x120x120xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x192x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x120x120xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 120 {\n          affine.for %arg5 = 0 to 120 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x192x120x120xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x192x120x120xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x192x120x120xf32>\n    return %1 : tensor<256x192x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x192x120x120xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x192x120x120xf32>) -> tensor<256x192x120x120xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x192x120x120xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x192x120x120xf32>) -> tensor<256x192x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x120x120xf32>) outs(%25 : tensor<256x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 582537039
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x120x120xf32>) outs(%25 : tensor<128x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x120x120xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x120x120xf32>) outs(%25 : tensor<128x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x120x120xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x120x120xf32>, %25: tensor<128x192x120x120xf32>) -> tensor<128x192x120x120xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x120x120xf32>) outs(%25 : tensor<128x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x120x120xf32>\n  return %ret : tensor<128x192x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x120x120xf32>, %arg1: tensor<128x192x120x120xf32>) -> tensor<128x192x120x120xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x120x120xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 120 {\n          affine.for %arg5 = 0 to 120 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x120x120xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x120x120xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x120x120xf32>\n    return %1 : tensor<128x192x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x120x120xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x120x120xf32>) -> tensor<128x192x120x120xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x120x120xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x120x120xf32>) -> tensor<128x192x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x120x120xf32>) outs(%25 : tensor<128x192x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 293397103
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x3072xf32>) outs(%35 : tensor<128x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x3072xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x3072xf32>) outs(%35 : tensor<128x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x3072xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x3072xf32>, %35: tensor<128x3072xf32>) -> tensor<128x3072xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x3072xf32>) outs(%35 : tensor<128x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x3072xf32>\n  return %ret : tensor<128x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x3072xf32>, %arg1: tensor<128x3072xf32>) -> tensor<128x3072xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x3072xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 3072 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x3072xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x3072xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x3072xf32>\n    return %1 : tensor<128x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x3072xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x3072xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x3072xf32>) -> tensor<128x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x3072xf32>) outs(%35 : tensor<128x3072xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          3072,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 299133
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1536xf32>) outs(%35 : tensor<256x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1536xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1536xf32>) outs(%35 : tensor<256x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1536xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x1536xf32>, %35: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1536xf32>) outs(%35 : tensor<256x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1536xf32>\n  return %ret : tensor<256x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<256x1536xf32>) -> tensor<256x1536xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1536xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 1536 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x1536xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x1536xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x1536xf32>\n    return %1 : tensor<256x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1536xf32>) outs(%35 : tensor<256x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 299736
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x224x224xf32>) outs(%25 : tensor<256x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x224x224xf32>) outs(%25 : tensor<256x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x224x224xf32>, %25: tensor<256x384x224x224xf32>) -> tensor<256x384x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x224x224xf32>) outs(%25 : tensor<256x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x224x224xf32>\n  return %ret : tensor<256x384x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x224x224xf32>, %arg1: tensor<256x384x224x224xf32>) -> tensor<256x384x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x224x224xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x224x224xf32>\n    return %1 : tensor<256x384x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x224x224xf32>) -> tensor<256x384x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x224x224xf32>) -> tensor<256x384x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x224x224xf32>) outs(%25 : tensor<256x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4513269683
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x112x112xf32>) outs(%25 : tensor<256x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x112x112xf32>) outs(%25 : tensor<256x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x64x112x112xf32>, %25: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x112x112xf32>) outs(%25 : tensor<256x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x112x112xf32>\n  return %ret : tensor<256x64x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64x112x112xf32>, %arg1: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x64x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x112x112xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x64x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x64x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x64x112x112xf32>\n    return %1 : tensor<256x64x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x64x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x64x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x112x112xf32>) outs(%25 : tensor<256x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 170164201
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x512xf32>) outs(%35 : tensor<128x512xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x512xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x512xf32>) outs(%35 : tensor<128x512xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x512xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x512xf32>, %35: tensor<128x512xf32>) -> tensor<128x512xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x512xf32>) outs(%35 : tensor<128x512xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x512xf32>\n  return %ret : tensor<128x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512xf32>, %arg1: tensor<128x512xf32>) -> tensor<128x512xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 512 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x512xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x512xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x512xf32>\n    return %1 : tensor<128x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x512xf32>) -> tensor<128x512xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x512xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x512xf32>) -> tensor<128x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x512xf32>) outs(%35 : tensor<128x512xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 51028.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x224x224xf32>) outs(%25 : tensor<128x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x224x224xf32>) outs(%25 : tensor<128x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x224x224xf32>, %25: tensor<128x96x224x224xf32>) -> tensor<128x96x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x224x224xf32>) outs(%25 : tensor<128x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x224x224xf32>\n  return %ret : tensor<128x96x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x224x224xf32>, %arg1: tensor<128x96x224x224xf32>) -> tensor<128x96x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x224x224xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x224x224xf32>\n    return %1 : tensor<128x96x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x224x224xf32>) -> tensor<128x96x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x224x224xf32>) -> tensor<128x96x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x224x224xf32>) outs(%25 : tensor<128x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 536121876
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x768xf32>) outs(%35 : tensor<256x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x768xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x768xf32>) outs(%35 : tensor<256x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x768xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x768xf32>, %35: tensor<256x768xf32>) -> tensor<256x768xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x768xf32>) outs(%35 : tensor<256x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x768xf32>\n  return %ret : tensor<256x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<256x768xf32>) -> tensor<256x768xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x768xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 768 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x768xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x768xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x768xf32>\n    return %1 : tensor<256x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x768xf32>) -> tensor<256x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x768xf32>) outs(%35 : tensor<256x768xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 150688
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x112x112xf32>) outs(%25 : tensor<128x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x112x112xf32>) outs(%25 : tensor<128x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x112x112xf32>, %25: tensor<128x96x112x112xf32>) -> tensor<128x96x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x112x112xf32>) outs(%25 : tensor<128x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x112x112xf32>\n  return %ret : tensor<128x96x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x112x112xf32>, %arg1: tensor<128x96x112x112xf32>) -> tensor<128x96x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x112x112xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x112x112xf32>\n    return %1 : tensor<128x96x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x112x112xf32>) -> tensor<128x96x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x112x112xf32>) -> tensor<128x96x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x112x112xf32>) outs(%25 : tensor<128x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 127778868
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x14x14xf32>) outs(%25 : tensor<256x240x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x14x14xf32>) outs(%25 : tensor<256x240x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x240x14x14xf32>, %25: tensor<256x240x14x14xf32>) -> tensor<256x240x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x14x14xf32>) outs(%25 : tensor<256x240x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x14x14xf32>\n  return %ret : tensor<256x240x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x240x14x14xf32>, %arg1: tensor<256x240x14x14xf32>) -> tensor<256x240x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x240x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x14x14xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x240x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x240x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x240x14x14xf32>\n    return %1 : tensor<256x240x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x240x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x240x14x14xf32>) -> tensor<256x240x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x240x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x240x14x14xf32>) -> tensor<256x240x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x14x14xf32>) outs(%25 : tensor<256x240x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9901954
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x28x28xf32>) outs(%25 : tensor<128x96x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x28x28xf32>) outs(%25 : tensor<128x96x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x28x28xf32>, %25: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x28x28xf32>) outs(%25 : tensor<128x96x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x28x28xf32>\n  return %ret : tensor<128x96x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x28x28xf32>, %arg1: tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x28x28xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x28x28xf32>\n    return %1 : tensor<128x96x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x28x28xf32>) -> tensor<128x96x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x28x28xf32>) outs(%25 : tensor<128x96x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7330281
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1024xf32>) outs(%35 : tensor<256x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1024xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1024xf32>) outs(%35 : tensor<256x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1024xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x1024xf32>, %35: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1024xf32>) outs(%35 : tensor<256x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 1024 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x1024xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x1024xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %1 : tensor<256x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1024xf32>) outs(%35 : tensor<256x1024xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 185323
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x128xf32>) outs(%35 : tensor<128x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x128xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x128xf32>) outs(%35 : tensor<128x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x128xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x128xf32>, %35: tensor<128x128xf32>) -> tensor<128x128xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x128xf32>) outs(%35 : tensor<128x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x128xf32>\n  return %ret : tensor<128x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128xf32>, %arg1: tensor<128x128xf32>) -> tensor<128x128xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 128 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x128xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x128xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x128xf32>\n    return %1 : tensor<128x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x128xf32>) -> tensor<128x128xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x128xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x128xf32>) -> tensor<128x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x128xf32>) outs(%35 : tensor<128x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 12564
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x120x120xf32>) outs(%25 : tensor<128x96x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x120x120xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x120x120xf32>) outs(%25 : tensor<128x96x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x120x120xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x120x120xf32>, %25: tensor<128x96x120x120xf32>) -> tensor<128x96x120x120xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x120x120xf32>) outs(%25 : tensor<128x96x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x120x120xf32>\n  return %ret : tensor<128x96x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x120x120xf32>, %arg1: tensor<128x96x120x120xf32>) -> tensor<128x96x120x120xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x120x120xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 120 {\n          affine.for %arg5 = 0 to 120 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x120x120xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x120x120xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x120x120xf32>\n    return %1 : tensor<128x96x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x120x120xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x120x120xf32>) -> tensor<128x96x120x120xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x120x120xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x120x120xf32>) -> tensor<128x96x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x120x120xf32>) outs(%25 : tensor<128x96x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 145907879
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x7x7xf32>) outs(%25 : tensor<256x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x7x7xf32>) outs(%25 : tensor<256x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x96x7x7xf32>, %25: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x7x7xf32>) outs(%25 : tensor<256x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x7x7xf32>\n  return %ret : tensor<256x96x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x96x7x7xf32>, %arg1: tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x96x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x7x7xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x96x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x96x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x96x7x7xf32>\n    return %1 : tensor<256x96x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x96x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x96x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x96x7x7xf32>) -> tensor<256x96x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x7x7xf32>) outs(%25 : tensor<256x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 962626
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x130x130xf32>) outs(%25 : tensor<256x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x130x130xf32>) outs(%25 : tensor<256x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x256x130x130xf32>, %25: tensor<256x256x130x130xf32>) -> tensor<256x256x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x130x130xf32>) outs(%25 : tensor<256x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x130x130xf32>\n  return %ret : tensor<256x256x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256x130x130xf32>, %arg1: tensor<256x256x130x130xf32>) -> tensor<256x256x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x256x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x130x130xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x256x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x256x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x256x130x130xf32>\n    return %1 : tensor<256x256x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x256x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x256x130x130xf32>) -> tensor<256x256x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x256x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x256x130x130xf32>) -> tensor<256x256x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x130x130xf32>) outs(%25 : tensor<256x256x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 965598149
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1536xf32>) outs(%35 : tensor<128x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1536xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1536xf32>) outs(%35 : tensor<128x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1536xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x1536xf32>, %35: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1536xf32>) outs(%35 : tensor<128x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1536xf32>\n  return %ret : tensor<128x1536xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x1536xf32>, %arg1: tensor<128x1536xf32>) -> tensor<128x1536xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x1536xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x1536xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 1536 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x1536xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x1536xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x1536xf32>\n    return %1 : tensor<128x1536xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x1536xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x1536xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x1536xf32>) -> tensor<128x1536xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x1536xf32>) outs(%35 : tensor<128x1536xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x1536xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x1536xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x1536xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 150214.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x130x130xf32>) outs(%25 : tensor<256x384x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x130x130xf32>) outs(%25 : tensor<256x384x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x130x130xf32>, %25: tensor<256x384x130x130xf32>) -> tensor<256x384x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x130x130xf32>) outs(%25 : tensor<256x384x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x130x130xf32>\n  return %ret : tensor<256x384x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x130x130xf32>, %arg1: tensor<256x384x130x130xf32>) -> tensor<256x384x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x130x130xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x130x130xf32>\n    return %1 : tensor<256x384x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x130x130xf32>) -> tensor<256x384x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x130x130xf32>) -> tensor<256x384x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x130x130xf32>) outs(%25 : tensor<256x384x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1521373797
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x112x112xf32>) outs(%25 : tensor<128x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x112x112xf32>) outs(%25 : tensor<128x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x32x112x112xf32>, %25: tensor<128x32x112x112xf32>) -> tensor<128x32x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x112x112xf32>) outs(%25 : tensor<128x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x112x112xf32>\n  return %ret : tensor<128x32x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x112x112xf32>, %arg1: tensor<128x32x112x112xf32>) -> tensor<128x32x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x32x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x112x112xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x32x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x32x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x32x112x112xf32>\n    return %1 : tensor<128x32x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x32x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x32x112x112xf32>) -> tensor<128x32x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x32x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x32x112x112xf32>) -> tensor<128x32x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x112x112xf32>) outs(%25 : tensor<128x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 42604458
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x128xf32>) outs(%35 : tensor<256x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x128xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x128xf32>) outs(%35 : tensor<256x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x128xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x128xf32>, %35: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x128xf32>) outs(%35 : tensor<256x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 128 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x128xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x128xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %1 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x128xf32>) outs(%35 : tensor<256x128xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 26563
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x224x224xf32>) outs(%25 : tensor<256x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x224x224xf32>) outs(%25 : tensor<256x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x96x224x224xf32>, %25: tensor<256x96x224x224xf32>) -> tensor<256x96x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x224x224xf32>) outs(%25 : tensor<256x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x224x224xf32>\n  return %ret : tensor<256x96x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x96x224x224xf32>, %arg1: tensor<256x96x224x224xf32>) -> tensor<256x96x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x96x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x224x224xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x96x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x96x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x96x224x224xf32>\n    return %1 : tensor<256x96x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x96x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x96x224x224xf32>) -> tensor<256x96x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x96x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x96x224x224xf32>) -> tensor<256x96x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x224x224xf32>) outs(%25 : tensor<256x96x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1068224496
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x56x56xf32>) outs(%25 : tensor<128x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x56x56xf32>) outs(%25 : tensor<128x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x256x56x56xf32>, %25: tensor<128x256x56x56xf32>) -> tensor<128x256x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x56x56xf32>) outs(%25 : tensor<128x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x56x56xf32>\n  return %ret : tensor<128x256x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256x56x56xf32>, %arg1: tensor<128x256x56x56xf32>) -> tensor<128x256x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x256x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x56x56xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x256x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x256x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x256x56x56xf32>\n    return %1 : tensor<128x256x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x256x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x256x56x56xf32>) -> tensor<128x256x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x256x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x256x56x56xf32>) -> tensor<128x256x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x56x56xf32>) outs(%25 : tensor<128x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 86849445
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x7x7xf32>) outs(%25 : tensor<128x512x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x7x7xf32>) outs(%25 : tensor<128x512x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x512x7x7xf32>, %25: tensor<128x512x7x7xf32>) -> tensor<128x512x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x7x7xf32>) outs(%25 : tensor<128x512x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x7x7xf32>\n  return %ret : tensor<128x512x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512x7x7xf32>, %arg1: tensor<128x512x7x7xf32>) -> tensor<128x512x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x512x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x7x7xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x512x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x512x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x512x7x7xf32>\n    return %1 : tensor<128x512x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x512x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x512x7x7xf32>) -> tensor<128x512x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x512x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x512x7x7xf32>) -> tensor<128x512x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x7x7xf32>) outs(%25 : tensor<128x512x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2568027
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x15x15xf32>) outs(%25 : tensor<256x512x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x15x15xf32>) outs(%25 : tensor<256x512x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x512x15x15xf32>, %25: tensor<256x512x15x15xf32>) -> tensor<256x512x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x15x15xf32>) outs(%25 : tensor<256x512x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x15x15xf32>\n  return %ret : tensor<256x512x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512x15x15xf32>, %arg1: tensor<256x512x15x15xf32>) -> tensor<256x512x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x512x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x15x15xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x512x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x512x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x512x15x15xf32>\n    return %1 : tensor<256x512x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x512x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x512x15x15xf32>) -> tensor<256x512x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x512x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x512x15x15xf32>) -> tensor<256x512x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x15x15xf32>) outs(%25 : tensor<256x512x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 24277748
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x130x130xf32>) outs(%25 : tensor<256x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x130x130xf32>) outs(%25 : tensor<256x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x192x130x130xf32>, %25: tensor<256x192x130x130xf32>) -> tensor<256x192x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x130x130xf32>) outs(%25 : tensor<256x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x130x130xf32>\n  return %ret : tensor<256x192x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x192x130x130xf32>, %arg1: tensor<256x192x130x130xf32>) -> tensor<256x192x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x192x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x130x130xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x192x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x192x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x192x130x130xf32>\n    return %1 : tensor<256x192x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x192x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x192x130x130xf32>) -> tensor<256x192x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x192x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x192x130x130xf32>) -> tensor<256x192x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x130x130xf32>) outs(%25 : tensor<256x192x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 687209972
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x256xf32>) outs(%35 : tensor<128x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x256xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x256xf32>) outs(%35 : tensor<128x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x256xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x256xf32>, %35: tensor<128x256xf32>) -> tensor<128x256xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x256xf32>) outs(%35 : tensor<128x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x256xf32>\n  return %ret : tensor<128x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256xf32>, %arg1: tensor<128x256xf32>) -> tensor<128x256xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 256 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x256xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x256xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x256xf32>\n    return %1 : tensor<128x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x256xf32>) -> tensor<128x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x256xf32>) outs(%35 : tensor<128x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 26072
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x130x130xf32>) outs(%25 : tensor<256x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x130x130xf32>) outs(%25 : tensor<256x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x288x130x130xf32>, %25: tensor<256x288x130x130xf32>) -> tensor<256x288x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x130x130xf32>) outs(%25 : tensor<256x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x130x130xf32>\n  return %ret : tensor<256x288x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x288x130x130xf32>, %arg1: tensor<256x288x130x130xf32>) -> tensor<256x288x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x288x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x130x130xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x288x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x288x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x288x130x130xf32>\n    return %1 : tensor<256x288x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x288x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x288x130x130xf32>) -> tensor<256x288x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x288x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x288x130x130xf32>) -> tensor<256x288x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x130x130xf32>) outs(%25 : tensor<256x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1100057066
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x228x228xf32>) outs(%25 : tensor<256x192x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x228x228xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x228x228xf32>) outs(%25 : tensor<256x192x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x228x228xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x192x228x228xf32>, %25: tensor<256x192x228x228xf32>) -> tensor<256x192x228x228xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x228x228xf32>) outs(%25 : tensor<256x192x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x228x228xf32>\n  return %ret : tensor<256x192x228x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x192x228x228xf32>, %arg1: tensor<256x192x228x228xf32>) -> tensor<256x192x228x228xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x192x228x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x228x228xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 228 {\n          affine.for %arg5 = 0 to 228 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x192x228x228xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x192x228x228xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x192x228x228xf32>\n    return %1 : tensor<256x192x228x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x228x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x192x228x228xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x192x228x228xf32>) -> tensor<256x192x228x228xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x192x228x228xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x192x228x228xf32>) -> tensor<256x192x228x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x228x228xf32>) outs(%25 : tensor<256x192x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x228x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x228x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x228x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2325240857
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x56x56xf32>) outs(%25 : tensor<128x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x56x56xf32>) outs(%25 : tensor<128x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x56x56xf32>, %25: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x56x56xf32>) outs(%25 : tensor<128x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x56x56xf32>\n  return %ret : tensor<128x192x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x56x56xf32>, %arg1: tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x56x56xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x56x56xf32>\n    return %1 : tensor<128x192x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x56x56xf32>) -> tensor<128x192x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x56x56xf32>) outs(%25 : tensor<128x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 66436716
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x240x240xf32>) outs(%25 : tensor<128x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x240x240xf32>) outs(%25 : tensor<128x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x288x240x240xf32>, %25: tensor<128x288x240x240xf32>) -> tensor<128x288x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x240x240xf32>) outs(%25 : tensor<128x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x240x240xf32>\n  return %ret : tensor<128x288x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x288x240x240xf32>, %arg1: tensor<128x288x240x240xf32>) -> tensor<128x288x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x288x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x240x240xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x288x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x288x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x288x240x240xf32>\n    return %1 : tensor<128x288x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x288x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x288x240x240xf32>) -> tensor<128x288x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x288x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x288x240x240xf32>) -> tensor<128x288x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x240x240xf32>) outs(%25 : tensor<128x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1932699906
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x7x7xf32>) outs(%25 : tensor<128x64x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x7x7xf32>) outs(%25 : tensor<128x64x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x64x7x7xf32>, %25: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x7x7xf32>) outs(%25 : tensor<128x64x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x7x7xf32>\n  return %ret : tensor<128x64x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64x7x7xf32>, %arg1: tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x64x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x7x7xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x64x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x64x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x64x7x7xf32>\n    return %1 : tensor<128x64x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x64x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x64x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x64x7x7xf32>) -> tensor<128x64x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x7x7xf32>) outs(%25 : tensor<128x64x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 320030
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x14x14xf32>) outs(%25 : tensor<128x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x14x14xf32>) outs(%25 : tensor<128x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x256x14x14xf32>, %25: tensor<128x256x14x14xf32>) -> tensor<128x256x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x14x14xf32>) outs(%25 : tensor<128x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x14x14xf32>\n  return %ret : tensor<128x256x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256x14x14xf32>, %arg1: tensor<128x256x14x14xf32>) -> tensor<128x256x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x256x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x14x14xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x256x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x256x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x256x14x14xf32>\n    return %1 : tensor<128x256x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x256x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x256x14x14xf32>) -> tensor<128x256x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x256x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x256x14x14xf32>) -> tensor<128x256x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x14x14xf32>) outs(%25 : tensor<128x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5123443
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x150x150xf32>) outs(%25 : tensor<128x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x150x150xf32>) outs(%25 : tensor<128x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x240x150x150xf32>, %25: tensor<128x240x150x150xf32>) -> tensor<128x240x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x150x150xf32>) outs(%25 : tensor<128x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x150x150xf32>\n  return %ret : tensor<128x240x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x240x150x150xf32>, %arg1: tensor<128x240x150x150xf32>) -> tensor<128x240x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x240x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x150x150xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x240x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x240x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x240x150x150xf32>\n    return %1 : tensor<128x240x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x240x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x240x150x150xf32>) -> tensor<128x240x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x240x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x240x150x150xf32>) -> tensor<128x240x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x150x150xf32>) outs(%25 : tensor<128x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 616710357
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x224x224xf32>) outs(%25 : tensor<128x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x224x224xf32>) outs(%25 : tensor<128x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x32x224x224xf32>, %25: tensor<128x32x224x224xf32>) -> tensor<128x32x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x224x224xf32>) outs(%25 : tensor<128x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x224x224xf32>\n  return %ret : tensor<128x32x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x224x224xf32>, %arg1: tensor<128x32x224x224xf32>) -> tensor<128x32x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x32x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x224x224xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x32x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x32x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x32x224x224xf32>\n    return %1 : tensor<128x32x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x32x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x32x224x224xf32>) -> tensor<128x32x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x32x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x32x224x224xf32>) -> tensor<128x32x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x224x224xf32>) outs(%25 : tensor<128x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 164012581
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x28x28xf32>) outs(%25 : tensor<128x512x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x28x28xf32>) outs(%25 : tensor<128x512x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x512x28x28xf32>, %25: tensor<128x512x28x28xf32>) -> tensor<128x512x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x28x28xf32>) outs(%25 : tensor<128x512x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x28x28xf32>\n  return %ret : tensor<128x512x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512x28x28xf32>, %arg1: tensor<128x512x28x28xf32>) -> tensor<128x512x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x512x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x28x28xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x512x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x512x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x512x28x28xf32>\n    return %1 : tensor<128x512x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x512x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x512x28x28xf32>) -> tensor<128x512x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x512x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x512x28x28xf32>) -> tensor<128x512x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x28x28xf32>) outs(%25 : tensor<128x512x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 40506088
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x224x224xf32>) outs(%25 : tensor<128x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x224x224xf32>) outs(%25 : tensor<128x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x256x224x224xf32>, %25: tensor<128x256x224x224xf32>) -> tensor<128x256x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x224x224xf32>) outs(%25 : tensor<128x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x224x224xf32>\n  return %ret : tensor<128x256x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256x224x224xf32>, %arg1: tensor<128x256x224x224xf32>) -> tensor<128x256x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x256x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x224x224xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x256x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x256x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x256x224x224xf32>\n    return %1 : tensor<128x256x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x256x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x256x224x224xf32>) -> tensor<128x256x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x256x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x256x224x224xf32>) -> tensor<128x256x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x224x224xf32>) outs(%25 : tensor<128x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1501003811
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x150x150xf32>) outs(%25 : tensor<128x48x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x150x150xf32>) outs(%25 : tensor<128x48x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x48x150x150xf32>, %25: tensor<128x48x150x150xf32>) -> tensor<128x48x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x150x150xf32>) outs(%25 : tensor<128x48x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x150x150xf32>\n  return %ret : tensor<128x48x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x48x150x150xf32>, %arg1: tensor<128x48x150x150xf32>) -> tensor<128x48x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x48x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x150x150xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 48 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x48x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x48x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x48x150x150xf32>\n    return %1 : tensor<128x48x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x48x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x48x150x150xf32>) -> tensor<128x48x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x48x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x48x150x150xf32>) -> tensor<128x48x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x150x150xf32>) outs(%25 : tensor<128x48x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          48,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 113142340
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x7x7xf32>) outs(%25 : tensor<128x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x7x7xf32>) outs(%25 : tensor<128x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x384x7x7xf32>, %25: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x7x7xf32>) outs(%25 : tensor<128x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x7x7xf32>\n  return %ret : tensor<128x384x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x384x7x7xf32>, %arg1: tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x384x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x7x7xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x384x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x384x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x384x7x7xf32>\n    return %1 : tensor<128x384x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x384x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x384x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x384x7x7xf32>) -> tensor<128x384x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x7x7xf32>) outs(%25 : tensor<128x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1921986
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x112x112xf32>) outs(%25 : tensor<256x240x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x112x112xf32>) outs(%25 : tensor<256x240x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x240x112x112xf32>, %25: tensor<256x240x112x112xf32>) -> tensor<256x240x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x112x112xf32>) outs(%25 : tensor<256x240x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x112x112xf32>\n  return %ret : tensor<256x240x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x240x112x112xf32>, %arg1: tensor<256x240x112x112xf32>) -> tensor<256x240x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x240x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x112x112xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x240x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x240x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x240x112x112xf32>\n    return %1 : tensor<256x240x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x240x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x240x112x112xf32>) -> tensor<256x240x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x240x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x240x112x112xf32>) -> tensor<256x240x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x112x112xf32>) outs(%25 : tensor<256x240x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 635330672
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x14x14xf32>) outs(%25 : tensor<256x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x14x14xf32>) outs(%25 : tensor<256x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x32x14x14xf32>, %25: tensor<256x32x14x14xf32>) -> tensor<256x32x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x14x14xf32>) outs(%25 : tensor<256x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x14x14xf32>\n  return %ret : tensor<256x32x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32x14x14xf32>, %arg1: tensor<256x32x14x14xf32>) -> tensor<256x32x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x32x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x14x14xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x32x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x32x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x32x14x14xf32>\n    return %1 : tensor<256x32x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x32x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x32x14x14xf32>) -> tensor<256x32x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x32x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x32x14x14xf32>) -> tensor<256x32x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x14x14xf32>) outs(%25 : tensor<256x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1214370
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x56x56xf32>) outs(%25 : tensor<256x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x56x56xf32>) outs(%25 : tensor<256x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x192x56x56xf32>, %25: tensor<256x192x56x56xf32>) -> tensor<256x192x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x56x56xf32>) outs(%25 : tensor<256x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x56x56xf32>\n  return %ret : tensor<256x192x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x192x56x56xf32>, %arg1: tensor<256x192x56x56xf32>) -> tensor<256x192x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x192x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x192x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x192x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x192x56x56xf32>\n    return %1 : tensor<256x192x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x192x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x192x56x56xf32>) -> tensor<256x192x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x192x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x192x56x56xf32>) -> tensor<256x192x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x56x56xf32>) outs(%25 : tensor<256x192x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 132410627
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x120x120xf32>) outs(%25 : tensor<128x32x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x120x120xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x120x120xf32>) outs(%25 : tensor<128x32x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x120x120xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x32x120x120xf32>, %25: tensor<128x32x120x120xf32>) -> tensor<128x32x120x120xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x120x120xf32>) outs(%25 : tensor<128x32x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x120x120xf32>\n  return %ret : tensor<128x32x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x120x120xf32>, %arg1: tensor<128x32x120x120xf32>) -> tensor<128x32x120x120xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x32x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x120x120xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 120 {\n          affine.for %arg5 = 0 to 120 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x32x120x120xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x32x120x120xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x32x120x120xf32>\n    return %1 : tensor<128x32x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x32x120x120xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x32x120x120xf32>) -> tensor<128x32x120x120xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x32x120x120xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x32x120x120xf32>) -> tensor<128x32x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x120x120xf32>) outs(%25 : tensor<128x32x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 48879650
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x240x240xf32>) outs(%25 : tensor<256x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x240x240xf32>) outs(%25 : tensor<256x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x288x240x240xf32>, %25: tensor<256x288x240x240xf32>) -> tensor<256x288x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x240x240xf32>) outs(%25 : tensor<256x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x240x240xf32>\n  return %ret : tensor<256x288x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x288x240x240xf32>, %arg1: tensor<256x288x240x240xf32>) -> tensor<256x288x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x288x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x240x240xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x288x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x288x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x288x240x240xf32>\n    return %1 : tensor<256x288x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x288x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x288x240x240xf32>) -> tensor<256x288x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x288x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x288x240x240xf32>) -> tensor<256x288x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x240x240xf32>) outs(%25 : tensor<256x288x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3882374854
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x150x150xf32>) outs(%25 : tensor<128x96x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x150x150xf32>) outs(%25 : tensor<128x96x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x150x150xf32>, %25: tensor<128x96x150x150xf32>) -> tensor<128x96x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x150x150xf32>) outs(%25 : tensor<128x96x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x150x150xf32>\n  return %ret : tensor<128x96x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x150x150xf32>, %arg1: tensor<128x96x150x150xf32>) -> tensor<128x96x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x150x150xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x150x150xf32>\n    return %1 : tensor<128x96x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x150x150xf32>) -> tensor<128x96x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x150x150xf32>) -> tensor<128x96x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x150x150xf32>) outs(%25 : tensor<128x96x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 226001670
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x240x240xf32>) outs(%25 : tensor<256x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x240x240xf32>) outs(%25 : tensor<256x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x256x240x240xf32>, %25: tensor<256x256x240x240xf32>) -> tensor<256x256x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x240x240xf32>) outs(%25 : tensor<256x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x240x240xf32>\n  return %ret : tensor<256x256x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256x240x240xf32>, %arg1: tensor<256x256x240x240xf32>) -> tensor<256x256x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x256x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x240x240xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x256x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x256x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x256x240x240xf32>\n    return %1 : tensor<256x256x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x256x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x256x240x240xf32>) -> tensor<256x256x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x256x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x256x240x240xf32>) -> tensor<256x256x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x240x240xf32>) outs(%25 : tensor<256x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3447506114
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x28x28xf32>) outs(%25 : tensor<256x384x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x28x28xf32>) outs(%25 : tensor<256x384x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x28x28xf32>, %25: tensor<256x384x28x28xf32>) -> tensor<256x384x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x28x28xf32>) outs(%25 : tensor<256x384x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x28x28xf32>\n  return %ret : tensor<256x384x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x28x28xf32>, %arg1: tensor<256x384x28x28xf32>) -> tensor<256x384x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x28x28xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x28x28xf32>\n    return %1 : tensor<256x384x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x28x28xf32>) -> tensor<256x384x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x28x28xf32>) -> tensor<256x384x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x28x28xf32>) outs(%25 : tensor<256x384x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 60541331
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x112x112xf32>) outs(%25 : tensor<128x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x112x112xf32>) outs(%25 : tensor<128x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x512x112x112xf32>, %25: tensor<128x512x112x112xf32>) -> tensor<128x512x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x112x112xf32>) outs(%25 : tensor<128x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x112x112xf32>\n  return %ret : tensor<128x512x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512x112x112xf32>, %arg1: tensor<128x512x112x112xf32>) -> tensor<128x512x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x512x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x112x112xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x512x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x512x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x512x112x112xf32>\n    return %1 : tensor<128x512x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x512x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x512x112x112xf32>) -> tensor<128x512x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x512x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x512x112x112xf32>) -> tensor<128x512x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x112x112xf32>) outs(%25 : tensor<128x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 762031439
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x15x15xf32>) outs(%25 : tensor<128x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x15x15xf32>) outs(%25 : tensor<128x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x384x15x15xf32>, %25: tensor<128x384x15x15xf32>) -> tensor<128x384x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x15x15xf32>) outs(%25 : tensor<128x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x15x15xf32>\n  return %ret : tensor<128x384x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x384x15x15xf32>, %arg1: tensor<128x384x15x15xf32>) -> tensor<128x384x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x384x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x15x15xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x384x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x384x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x384x15x15xf32>\n    return %1 : tensor<128x384x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x384x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x384x15x15xf32>) -> tensor<128x384x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x384x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x384x15x15xf32>) -> tensor<128x384x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x15x15xf32>) outs(%25 : tensor<128x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 9151274
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x228x228xf32>) outs(%25 : tensor<128x32x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x228x228xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x228x228xf32>) outs(%25 : tensor<128x32x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x228x228xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x32x228x228xf32>, %25: tensor<128x32x228x228xf32>) -> tensor<128x32x228x228xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x228x228xf32>) outs(%25 : tensor<128x32x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x228x228xf32>\n  return %ret : tensor<128x32x228x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x228x228xf32>, %arg1: tensor<128x32x228x228xf32>) -> tensor<128x32x228x228xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x32x228x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x228x228xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 228 {\n          affine.for %arg5 = 0 to 228 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x32x228x228xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x32x228x228xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x32x228x228xf32>\n    return %1 : tensor<128x32x228x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x228x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x32x228x228xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x32x228x228xf32>) -> tensor<128x32x228x228xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x32x228x228xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x32x228x228xf32>) -> tensor<128x32x228x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x228x228xf32>) outs(%25 : tensor<128x32x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x228x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x228x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x228x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 169827227
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x112x112xf32>) outs(%25 : tensor<256x384x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x112x112xf32>) outs(%25 : tensor<256x384x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x112x112xf32>, %25: tensor<256x384x112x112xf32>) -> tensor<256x384x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x112x112xf32>) outs(%25 : tensor<256x384x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x112x112xf32>\n  return %ret : tensor<256x384x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x112x112xf32>, %arg1: tensor<256x384x112x112xf32>) -> tensor<256x384x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x112x112xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x112x112xf32>\n    return %1 : tensor<256x384x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x112x112xf32>) -> tensor<256x384x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x112x112xf32>) -> tensor<256x384x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x112x112xf32>) outs(%25 : tensor<256x384x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1121010997
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x15x15xf32>) outs(%25 : tensor<128x48x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x15x15xf32>) outs(%25 : tensor<128x48x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x48x15x15xf32>, %25: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x15x15xf32>) outs(%25 : tensor<128x48x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x15x15xf32>\n  return %ret : tensor<128x48x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x48x15x15xf32>, %arg1: tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x48x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x15x15xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 48 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x48x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x48x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x48x15x15xf32>\n    return %1 : tensor<128x48x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x48x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x48x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x48x15x15xf32>) -> tensor<128x48x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x15x15xf32>) outs(%25 : tensor<128x48x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          48,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1047841
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x112x112xf32>) outs(%25 : tensor<128x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x112x112xf32>) outs(%25 : tensor<128x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x64x112x112xf32>, %25: tensor<128x64x112x112xf32>) -> tensor<128x64x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x112x112xf32>) outs(%25 : tensor<128x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x112x112xf32>\n  return %ret : tensor<128x64x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64x112x112xf32>, %arg1: tensor<128x64x112x112xf32>) -> tensor<128x64x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x64x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x112x112xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x64x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x64x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x64x112x112xf32>\n    return %1 : tensor<128x64x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x64x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x64x112x112xf32>) -> tensor<128x64x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x64x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x64x112x112xf32>) -> tensor<128x64x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x112x112xf32>) outs(%25 : tensor<128x64x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 84653524
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x150x150xf32>) outs(%25 : tensor<256x512x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x150x150xf32>) outs(%25 : tensor<256x512x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x512x150x150xf32>, %25: tensor<256x512x150x150xf32>) -> tensor<256x512x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x150x150xf32>) outs(%25 : tensor<256x512x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x150x150xf32>\n  return %ret : tensor<256x512x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512x150x150xf32>, %arg1: tensor<256x512x150x150xf32>) -> tensor<256x512x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x512x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x150x150xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x512x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x512x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x512x150x150xf32>\n    return %1 : tensor<256x512x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x512x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x512x150x150xf32>) -> tensor<256x512x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x512x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x512x150x150xf32>) -> tensor<256x512x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x150x150xf32>) outs(%25 : tensor<256x512x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2728905844
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x224x224xf32>) outs(%25 : tensor<128x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x224x224xf32>) outs(%25 : tensor<128x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x384x224x224xf32>, %25: tensor<128x384x224x224xf32>) -> tensor<128x384x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x224x224xf32>) outs(%25 : tensor<128x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x224x224xf32>\n  return %ret : tensor<128x384x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x384x224x224xf32>, %arg1: tensor<128x384x224x224xf32>) -> tensor<128x384x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x384x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x384x224x224xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x384x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x384x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x384x224x224xf32>\n    return %1 : tensor<128x384x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x384x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x384x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x384x224x224xf32>) -> tensor<128x384x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x384x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x384x224x224xf32>) -> tensor<128x384x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x384x224x224xf32>) outs(%25 : tensor<128x384x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x384x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x384x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x384x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2250439989
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x14x14xf32>) outs(%25 : tensor<128x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x14x14xf32>) outs(%25 : tensor<128x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x512x14x14xf32>, %25: tensor<128x512x14x14xf32>) -> tensor<128x512x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x14x14xf32>) outs(%25 : tensor<128x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x14x14xf32>\n  return %ret : tensor<128x512x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x512x14x14xf32>, %arg1: tensor<128x512x14x14xf32>) -> tensor<128x512x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x512x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x512x14x14xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x512x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x512x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x512x14x14xf32>\n    return %1 : tensor<128x512x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x512x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x512x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x512x14x14xf32>) -> tensor<128x512x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x512x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x512x14x14xf32>) -> tensor<128x512x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x512x14x14xf32>) outs(%25 : tensor<128x512x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x512x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x512x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x512x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 10638798
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x15x15xf32>) outs(%25 : tensor<256x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x15x15xf32>) outs(%25 : tensor<256x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x64x15x15xf32>, %25: tensor<256x64x15x15xf32>) -> tensor<256x64x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x15x15xf32>) outs(%25 : tensor<256x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x15x15xf32>\n  return %ret : tensor<256x64x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64x15x15xf32>, %arg1: tensor<256x64x15x15xf32>) -> tensor<256x64x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x64x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x15x15xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x64x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x64x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x64x15x15xf32>\n    return %1 : tensor<256x64x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x64x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x64x15x15xf32>) -> tensor<256x64x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x64x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x64x15x15xf32>) -> tensor<256x64x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x15x15xf32>) outs(%25 : tensor<256x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2803846
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x28x28xf32>) outs(%25 : tensor<128x64x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x28x28xf32>) outs(%25 : tensor<128x64x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x64x28x28xf32>, %25: tensor<128x64x28x28xf32>) -> tensor<128x64x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x28x28xf32>) outs(%25 : tensor<128x64x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x28x28xf32>\n  return %ret : tensor<128x64x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64x28x28xf32>, %arg1: tensor<128x64x28x28xf32>) -> tensor<128x64x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x64x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x28x28xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x64x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x64x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x64x28x28xf32>\n    return %1 : tensor<128x64x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x64x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x64x28x28xf32>) -> tensor<128x64x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x64x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x64x28x28xf32>) -> tensor<128x64x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x28x28xf32>) outs(%25 : tensor<128x64x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5005262
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x256xf32>) outs(%35 : tensor<256x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x256xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x256xf32>) outs(%35 : tensor<256x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x256xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x256xf32>, %35: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x256xf32>) outs(%35 : tensor<256x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 256 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x256xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x256xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %1 : tensor<256x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x256xf32>) outs(%35 : tensor<256x256xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 51589.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x112x112xf32>) outs(%25 : tensor<256x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x112x112xf32>) outs(%25 : tensor<256x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x96x112x112xf32>, %25: tensor<256x96x112x112xf32>) -> tensor<256x96x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x112x112xf32>) outs(%25 : tensor<256x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x112x112xf32>\n  return %ret : tensor<256x96x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x96x112x112xf32>, %arg1: tensor<256x96x112x112xf32>) -> tensor<256x96x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x96x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x112x112xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x96x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x96x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x96x112x112xf32>\n    return %1 : tensor<256x96x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x96x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x96x112x112xf32>) -> tensor<256x96x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x96x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x96x112x112xf32>) -> tensor<256x96x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x112x112xf32>) outs(%25 : tensor<256x96x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 255614830
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x112x112xf32>) outs(%25 : tensor<128x192x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x112x112xf32>) outs(%25 : tensor<128x192x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x112x112xf32>, %25: tensor<128x192x112x112xf32>) -> tensor<128x192x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x112x112xf32>) outs(%25 : tensor<128x192x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x112x112xf32>\n  return %ret : tensor<128x192x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x112x112xf32>, %arg1: tensor<128x192x112x112xf32>) -> tensor<128x192x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x112x112xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x112x112xf32>\n    return %1 : tensor<128x192x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x112x112xf32>) -> tensor<128x192x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x112x112xf32>) -> tensor<128x192x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x112x112xf32>) outs(%25 : tensor<128x192x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 254372981
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x14x14xf32>) outs(%25 : tensor<256x64x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x14x14xf32>) outs(%25 : tensor<256x64x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x64x14x14xf32>, %25: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x14x14xf32>) outs(%25 : tensor<256x64x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x14x14xf32>\n  return %ret : tensor<256x64x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64x14x14xf32>, %arg1: tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x64x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x14x14xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x64x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x64x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x64x14x14xf32>\n    return %1 : tensor<256x64x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x64x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x64x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x64x14x14xf32>) -> tensor<256x64x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x14x14xf32>) outs(%25 : tensor<256x64x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2441446
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x28x28xf32>) outs(%25 : tensor<128x192x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x28x28xf32>) outs(%25 : tensor<128x192x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x28x28xf32>, %25: tensor<128x192x28x28xf32>) -> tensor<128x192x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x28x28xf32>) outs(%25 : tensor<128x192x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x28x28xf32>\n  return %ret : tensor<128x192x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x28x28xf32>, %arg1: tensor<128x192x28x28xf32>) -> tensor<128x192x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x28x28xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x28x28xf32>\n    return %1 : tensor<128x192x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x28x28xf32>) -> tensor<128x192x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x28x28xf32>) -> tensor<128x192x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x28x28xf32>) outs(%25 : tensor<128x192x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 15145287
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x150x150xf32>) outs(%25 : tensor<256x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x150x150xf32>) outs(%25 : tensor<256x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x240x150x150xf32>, %25: tensor<256x240x150x150xf32>) -> tensor<256x240x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x150x150xf32>) outs(%25 : tensor<256x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x150x150xf32>\n  return %ret : tensor<256x240x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x240x150x150xf32>, %arg1: tensor<256x240x150x150xf32>) -> tensor<256x240x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x240x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x150x150xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x240x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x240x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x240x150x150xf32>\n    return %1 : tensor<256x240x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x240x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x240x150x150xf32>) -> tensor<256x240x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x240x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x240x150x150xf32>) -> tensor<256x240x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x150x150xf32>) outs(%25 : tensor<256x240x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1235398459
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x7x7xf32>) outs(%25 : tensor<256x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x7x7xf32>) outs(%25 : tensor<256x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x7x7xf32>, %25: tensor<256x384x7x7xf32>) -> tensor<256x384x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x7x7xf32>) outs(%25 : tensor<256x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x7x7xf32>\n  return %ret : tensor<256x384x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x7x7xf32>, %arg1: tensor<256x384x7x7xf32>) -> tensor<256x384x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x7x7xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x7x7xf32>\n    return %1 : tensor<256x384x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x7x7xf32>) -> tensor<256x384x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x7x7xf32>) -> tensor<256x384x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x7x7xf32>) outs(%25 : tensor<256x384x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3847032
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x15x15xf32>) outs(%25 : tensor<128x240x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x15x15xf32>) outs(%25 : tensor<128x240x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x240x15x15xf32>, %25: tensor<128x240x15x15xf32>) -> tensor<128x240x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x15x15xf32>) outs(%25 : tensor<128x240x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x15x15xf32>\n  return %ret : tensor<128x240x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x240x15x15xf32>, %arg1: tensor<128x240x15x15xf32>) -> tensor<128x240x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x240x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x15x15xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x240x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x240x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x240x15x15xf32>\n    return %1 : tensor<128x240x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x240x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x240x15x15xf32>) -> tensor<128x240x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x240x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x240x15x15xf32>) -> tensor<128x240x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x15x15xf32>) outs(%25 : tensor<128x240x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5244748
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x240x240xf32>) outs(%25 : tensor<256x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x240x240xf32>) outs(%25 : tensor<256x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x32x240x240xf32>, %25: tensor<256x32x240x240xf32>) -> tensor<256x32x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x240x240xf32>) outs(%25 : tensor<256x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x240x240xf32>\n  return %ret : tensor<256x32x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32x240x240xf32>, %arg1: tensor<256x32x240x240xf32>) -> tensor<256x32x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x32x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x240x240xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x32x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x32x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x32x240x240xf32>\n    return %1 : tensor<256x32x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x32x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x32x240x240xf32>) -> tensor<256x32x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x32x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x32x240x240xf32>) -> tensor<256x32x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x240x240xf32>) outs(%25 : tensor<256x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 376465645
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x56x56xf32>) outs(%25 : tensor<256x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x56x56xf32>) outs(%25 : tensor<256x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x256x56x56xf32>, %25: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x56x56xf32>) outs(%25 : tensor<256x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x56x56xf32>\n  return %ret : tensor<256x256x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256x56x56xf32>, %arg1: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x256x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x256x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x256x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x256x56x56xf32>\n    return %1 : tensor<256x256x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x256x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x256x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x56x56xf32>) outs(%25 : tensor<256x256x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 175056997
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x120x120xf32>) outs(%25 : tensor<128x240x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x120x120xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x120x120xf32>) outs(%25 : tensor<128x240x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x120x120xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x240x120x120xf32>, %25: tensor<128x240x120x120xf32>) -> tensor<128x240x120x120xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x120x120xf32>) outs(%25 : tensor<128x240x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x120x120xf32>\n  return %ret : tensor<128x240x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x240x120x120xf32>, %arg1: tensor<128x240x120x120xf32>) -> tensor<128x240x120x120xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x240x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x120x120xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 120 {\n          affine.for %arg5 = 0 to 120 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x240x120x120xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x240x120x120xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x240x120x120xf32>\n    return %1 : tensor<128x240x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x240x120x120xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x240x120x120xf32>) -> tensor<128x240x120x120xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x240x120x120xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x240x120x120xf32>) -> tensor<128x240x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x120x120xf32>) outs(%25 : tensor<128x240x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 371252290
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x56x56xf32>) outs(%25 : tensor<256x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x56x56xf32>) outs(%25 : tensor<256x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x48x56x56xf32>, %25: tensor<256x48x56x56xf32>) -> tensor<256x48x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x56x56xf32>) outs(%25 : tensor<256x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x56x56xf32>\n  return %ret : tensor<256x48x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x48x56x56xf32>, %arg1: tensor<256x48x56x56xf32>) -> tensor<256x48x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x48x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 48 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x48x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x48x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x48x56x56xf32>\n    return %1 : tensor<256x48x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x48x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x48x56x56xf32>) -> tensor<256x48x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x48x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x48x56x56xf32>) -> tensor<256x48x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x56x56xf32>) outs(%25 : tensor<256x48x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          48,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 33298880
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x14x14xf32>) outs(%25 : tensor<256x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x14x14xf32>) outs(%25 : tensor<256x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x256x14x14xf32>, %25: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x14x14xf32>) outs(%25 : tensor<256x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x14x14xf32>\n  return %ret : tensor<256x256x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256x14x14xf32>, %arg1: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x256x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x14x14xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x256x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x256x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x256x14x14xf32>\n    return %1 : tensor<256x256x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x256x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x256x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x14x14xf32>) outs(%25 : tensor<256x256x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 10668267
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x240x240xf32>) outs(%25 : tensor<256x240x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x240x240xf32>) outs(%25 : tensor<256x240x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x240x240x240xf32>, %25: tensor<256x240x240x240xf32>) -> tensor<256x240x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x240x240xf32>) outs(%25 : tensor<256x240x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x240x240xf32>\n  return %ret : tensor<256x240x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x240x240x240xf32>, %arg1: tensor<256x240x240x240xf32>) -> tensor<256x240x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x240x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x240x240xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x240x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x240x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x240x240x240xf32>\n    return %1 : tensor<256x240x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x240x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x240x240x240xf32>) -> tensor<256x240x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x240x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x240x240x240xf32>) -> tensor<256x240x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x240x240xf32>) outs(%25 : tensor<256x240x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3239669423
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x28x28xf32>) outs(%25 : tensor<256x128x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x28x28xf32>) outs(%25 : tensor<256x128x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x128x28x28xf32>, %25: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x28x28xf32>) outs(%25 : tensor<256x128x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x28x28xf32>\n  return %ret : tensor<256x128x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128x28x28xf32>, %arg1: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x128x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x28x28xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x128x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x128x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x128x28x28xf32>\n    return %1 : tensor<256x128x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x128x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x128x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x28x28xf32>) outs(%25 : tensor<256x128x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 20169996
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x7x7xf32>) outs(%25 : tensor<128x192x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x7x7xf32>) outs(%25 : tensor<128x192x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x7x7xf32>, %25: tensor<128x192x7x7xf32>) -> tensor<128x192x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x7x7xf32>) outs(%25 : tensor<128x192x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x7x7xf32>\n  return %ret : tensor<128x192x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x7x7xf32>, %arg1: tensor<128x192x7x7xf32>) -> tensor<128x192x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x7x7xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x7x7xf32>\n    return %1 : tensor<128x192x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x7x7xf32>) -> tensor<128x192x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x7x7xf32>) -> tensor<128x192x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x7x7xf32>) outs(%25 : tensor<128x192x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 961926.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x56x56xf32>) outs(%25 : tensor<256x96x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x56x56xf32>) outs(%25 : tensor<256x96x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x96x56x56xf32>, %25: tensor<256x96x56x56xf32>) -> tensor<256x96x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x56x56xf32>) outs(%25 : tensor<256x96x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x56x56xf32>\n  return %ret : tensor<256x96x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x96x56x56xf32>, %arg1: tensor<256x96x56x56xf32>) -> tensor<256x96x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x96x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x96x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x96x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x96x56x56xf32>\n    return %1 : tensor<256x96x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x96x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x96x56x56xf32>) -> tensor<256x96x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x96x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x96x56x56xf32>) -> tensor<256x96x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x56x56xf32>) outs(%25 : tensor<256x96x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 66788779
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x130x130xf32>) outs(%25 : tensor<128x96x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x130x130xf32>) outs(%25 : tensor<128x96x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x130x130xf32>, %25: tensor<128x96x130x130xf32>) -> tensor<128x96x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x130x130xf32>) outs(%25 : tensor<128x96x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x130x130xf32>\n  return %ret : tensor<128x96x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x130x130xf32>, %arg1: tensor<128x96x130x130xf32>) -> tensor<128x96x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x130x130xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x130x130xf32>\n    return %1 : tensor<128x96x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x130x130xf32>) -> tensor<128x96x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x130x130xf32>) -> tensor<128x96x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x130x130xf32>) outs(%25 : tensor<128x96x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 171716926
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x228x228xf32>) outs(%25 : tensor<128x240x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x228x228xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x228x228xf32>) outs(%25 : tensor<128x240x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x228x228xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x240x228x228xf32>, %25: tensor<128x240x228x228xf32>) -> tensor<128x240x228x228xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x228x228xf32>) outs(%25 : tensor<128x240x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x228x228xf32>\n  return %ret : tensor<128x240x228x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x240x228x228xf32>, %arg1: tensor<128x240x228x228xf32>) -> tensor<128x240x228x228xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x240x228x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x240x228x228xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 228 {\n          affine.for %arg5 = 0 to 228 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x240x228x228xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x240x228x228xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x240x228x228xf32>\n    return %1 : tensor<128x240x228x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x240x228x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x240x228x228xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x240x228x228xf32>) -> tensor<128x240x228x228xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x240x228x228xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x240x228x228xf32>) -> tensor<128x240x228x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x240x228x228xf32>) outs(%25 : tensor<128x240x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x240x228x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x240x228x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x240x228x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1439067163
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x7x7xf32>) outs(%25 : tensor<128x128x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x7x7xf32>) outs(%25 : tensor<128x128x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x128x7x7xf32>, %25: tensor<128x128x7x7xf32>) -> tensor<128x128x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x7x7xf32>) outs(%25 : tensor<128x128x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x7x7xf32>\n  return %ret : tensor<128x128x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128x7x7xf32>, %arg1: tensor<128x128x7x7xf32>) -> tensor<128x128x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x128x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x7x7xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x128x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x128x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x128x7x7xf32>\n    return %1 : tensor<128x128x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x128x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x128x7x7xf32>) -> tensor<128x128x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x128x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x128x7x7xf32>) -> tensor<128x128x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x7x7xf32>) outs(%25 : tensor<128x128x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 641391.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x120x120xf32>) outs(%25 : tensor<128x128x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x120x120xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x120x120xf32>) outs(%25 : tensor<128x128x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x120x120xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x128x120x120xf32>, %25: tensor<128x128x120x120xf32>) -> tensor<128x128x120x120xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x120x120xf32>) outs(%25 : tensor<128x128x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x120x120xf32>\n  return %ret : tensor<128x128x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128x120x120xf32>, %arg1: tensor<128x128x120x120xf32>) -> tensor<128x128x120x120xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x128x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x120x120xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 120 {\n          affine.for %arg5 = 0 to 120 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x128x120x120xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x128x120x120xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x128x120x120xf32>\n    return %1 : tensor<128x128x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x128x120x120xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x128x120x120xf32>) -> tensor<128x128x120x120xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x128x120x120xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x128x120x120xf32>) -> tensor<128x128x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x120x120xf32>) outs(%25 : tensor<128x128x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 195336258
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x120x120xf32>) outs(%25 : tensor<128x288x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x120x120xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x120x120xf32>) outs(%25 : tensor<128x288x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x120x120xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x288x120x120xf32>, %25: tensor<128x288x120x120xf32>) -> tensor<128x288x120x120xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x120x120xf32>) outs(%25 : tensor<128x288x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x120x120xf32>\n  return %ret : tensor<128x288x120x120xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x288x120x120xf32>, %arg1: tensor<128x288x120x120xf32>) -> tensor<128x288x120x120xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x288x120x120xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x120x120xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 120 {\n          affine.for %arg5 = 0 to 120 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x288x120x120xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x288x120x120xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x288x120x120xf32>\n    return %1 : tensor<128x288x120x120xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x120x120xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x288x120x120xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x288x120x120xf32>) -> tensor<128x288x120x120xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x288x120x120xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x288x120x120xf32>) -> tensor<128x288x120x120xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x120x120xf32>) outs(%25 : tensor<128x288x120x120xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x120x120xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x120x120xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x120x120xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          120,
          1
        ],
        [
          "%arg5",
          0,
          120,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 459495910
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x240x240xf32>) outs(%25 : tensor<128x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x240x240xf32>) outs(%25 : tensor<128x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x64x240x240xf32>, %25: tensor<128x64x240x240xf32>) -> tensor<128x64x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x240x240xf32>) outs(%25 : tensor<128x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x240x240xf32>\n  return %ret : tensor<128x64x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64x240x240xf32>, %arg1: tensor<128x64x240x240xf32>) -> tensor<128x64x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x64x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x240x240xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x64x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x64x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x64x240x240xf32>\n    return %1 : tensor<128x64x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x64x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x64x240x240xf32>) -> tensor<128x64x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x64x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x64x240x240xf32>) -> tensor<128x64x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x240x240xf32>) outs(%25 : tensor<128x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 388450427
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x112x112xf32>) outs(%25 : tensor<256x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x112x112xf32>) outs(%25 : tensor<256x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x512x112x112xf32>, %25: tensor<256x512x112x112xf32>) -> tensor<256x512x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x112x112xf32>) outs(%25 : tensor<256x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x112x112xf32>\n  return %ret : tensor<256x512x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512x112x112xf32>, %arg1: tensor<256x512x112x112xf32>) -> tensor<256x512x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x512x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x112x112xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x512x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x512x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x512x112x112xf32>\n    return %1 : tensor<256x512x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x512x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x512x112x112xf32>) -> tensor<256x512x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x512x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x512x112x112xf32>) -> tensor<256x512x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x112x112xf32>) outs(%25 : tensor<256x512x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1548791068
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x14x14xf32>) outs(%25 : tensor<128x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x14x14xf32>) outs(%25 : tensor<128x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x32x14x14xf32>, %25: tensor<128x32x14x14xf32>) -> tensor<128x32x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x14x14xf32>) outs(%25 : tensor<128x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x14x14xf32>\n  return %ret : tensor<128x32x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x14x14xf32>, %arg1: tensor<128x32x14x14xf32>) -> tensor<128x32x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x32x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x14x14xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x32x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x32x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x32x14x14xf32>\n    return %1 : tensor<128x32x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x32x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x32x14x14xf32>) -> tensor<128x32x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x32x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x32x14x14xf32>) -> tensor<128x32x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x14x14xf32>) outs(%25 : tensor<128x32x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 607155.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x240x240xf32>) outs(%25 : tensor<128x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x240x240xf32>) outs(%25 : tensor<128x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x256x240x240xf32>, %25: tensor<128x256x240x240xf32>) -> tensor<128x256x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x240x240xf32>) outs(%25 : tensor<128x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x240x240xf32>\n  return %ret : tensor<128x256x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256x240x240xf32>, %arg1: tensor<128x256x240x240xf32>) -> tensor<128x256x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x256x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x240x240xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x256x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x256x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x256x240x240xf32>\n    return %1 : tensor<128x256x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x256x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x256x240x240xf32>) -> tensor<128x256x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x256x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x256x240x240xf32>) -> tensor<128x256x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x240x240xf32>) outs(%25 : tensor<128x256x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1720911957
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x15x15xf32>) outs(%25 : tensor<128x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x15x15xf32>) outs(%25 : tensor<128x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x64x15x15xf32>, %25: tensor<128x64x15x15xf32>) -> tensor<128x64x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x15x15xf32>) outs(%25 : tensor<128x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x15x15xf32>\n  return %ret : tensor<128x64x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x64x15x15xf32>, %arg1: tensor<128x64x15x15xf32>) -> tensor<128x64x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x64x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x64x15x15xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x64x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x64x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x64x15x15xf32>\n    return %1 : tensor<128x64x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x64x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x64x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x64x15x15xf32>) -> tensor<128x64x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x64x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x64x15x15xf32>) -> tensor<128x64x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x64x15x15xf32>) outs(%25 : tensor<128x64x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x64x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x64x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x64x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1396432
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x224x224xf32>) outs(%25 : tensor<256x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x224x224xf32>) outs(%25 : tensor<256x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x128x224x224xf32>, %25: tensor<256x128x224x224xf32>) -> tensor<256x128x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x224x224xf32>) outs(%25 : tensor<256x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x224x224xf32>\n  return %ret : tensor<256x128x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128x224x224xf32>, %arg1: tensor<256x128x224x224xf32>) -> tensor<256x128x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x128x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x224x224xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x128x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x128x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x128x224x224xf32>\n    return %1 : tensor<256x128x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x128x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x128x224x224xf32>) -> tensor<256x128x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x128x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x128x224x224xf32>) -> tensor<256x128x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x224x224xf32>) outs(%25 : tensor<256x128x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1488880298
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x14x14xf32>) outs(%25 : tensor<128x128x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x14x14xf32>) outs(%25 : tensor<128x128x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x128x14x14xf32>, %25: tensor<128x128x14x14xf32>) -> tensor<128x128x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x14x14xf32>) outs(%25 : tensor<128x128x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x14x14xf32>\n  return %ret : tensor<128x128x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128x14x14xf32>, %arg1: tensor<128x128x14x14xf32>) -> tensor<128x128x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x128x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x14x14xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x128x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x128x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x128x14x14xf32>\n    return %1 : tensor<128x128x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x128x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x128x14x14xf32>) -> tensor<128x128x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x128x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x128x14x14xf32>) -> tensor<128x128x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x14x14xf32>) outs(%25 : tensor<128x128x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2483525
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x7x7xf32>) outs(%25 : tensor<128x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x7x7xf32>) outs(%25 : tensor<128x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x7x7xf32>, %25: tensor<128x96x7x7xf32>) -> tensor<128x96x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x7x7xf32>) outs(%25 : tensor<128x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x7x7xf32>\n  return %ret : tensor<128x96x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x7x7xf32>, %arg1: tensor<128x96x7x7xf32>) -> tensor<128x96x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x7x7xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x7x7xf32>\n    return %1 : tensor<128x96x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x7x7xf32>) -> tensor<128x96x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x7x7xf32>) -> tensor<128x96x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x7x7xf32>) outs(%25 : tensor<128x96x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 483473.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x224x224xf32>) outs(%25 : tensor<256x288x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x224x224xf32>) outs(%25 : tensor<256x288x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x288x224x224xf32>, %25: tensor<256x288x224x224xf32>) -> tensor<256x288x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x224x224xf32>) outs(%25 : tensor<256x288x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x224x224xf32>\n  return %ret : tensor<256x288x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x288x224x224xf32>, %arg1: tensor<256x288x224x224xf32>) -> tensor<256x288x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x288x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x224x224xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x288x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x288x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x288x224x224xf32>\n    return %1 : tensor<256x288x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x288x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x288x224x224xf32>) -> tensor<256x288x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x288x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x288x224x224xf32>) -> tensor<256x288x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x224x224xf32>) outs(%25 : tensor<256x288x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3376639387
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x130x130xf32>) outs(%25 : tensor<256x240x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x130x130xf32>) outs(%25 : tensor<256x240x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x240x130x130xf32>, %25: tensor<256x240x130x130xf32>) -> tensor<256x240x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x130x130xf32>) outs(%25 : tensor<256x240x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x130x130xf32>\n  return %ret : tensor<256x240x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x240x130x130xf32>, %arg1: tensor<256x240x130x130xf32>) -> tensor<256x240x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x240x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x130x130xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x240x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x240x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x240x130x130xf32>\n    return %1 : tensor<256x240x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x240x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x240x130x130xf32>) -> tensor<256x240x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x240x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x240x130x130xf32>) -> tensor<256x240x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x130x130xf32>) outs(%25 : tensor<256x240x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 880703576
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x28x28xf32>) outs(%25 : tensor<256x48x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x28x28xf32>) outs(%25 : tensor<256x48x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x48x28x28xf32>, %25: tensor<256x48x28x28xf32>) -> tensor<256x48x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x28x28xf32>) outs(%25 : tensor<256x48x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x28x28xf32>\n  return %ret : tensor<256x48x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x48x28x28xf32>, %arg1: tensor<256x48x28x28xf32>) -> tensor<256x48x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x48x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x48x28x28xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 48 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x48x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x48x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x48x28x28xf32>\n    return %1 : tensor<256x48x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x48x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x48x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x48x28x28xf32>) -> tensor<256x48x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x48x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x48x28x28xf32>) -> tensor<256x48x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x48x28x28xf32>) outs(%25 : tensor<256x48x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x48x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x48x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x48x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          48,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 7337124
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x2048xf32>) outs(%35 : tensor<128x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x2048xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x2048xf32>) outs(%35 : tensor<128x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x2048xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<128x2048xf32>, %35: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x2048xf32>) outs(%35 : tensor<128x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x2048xf32>\n  return %ret : tensor<128x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x2048xf32>, %arg1: tensor<128x2048xf32>) -> tensor<128x2048xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x2048xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 2048 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<128x2048xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<128x2048xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x2048xf32>\n    return %1 : tensor<128x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<128x2048xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<128x2048xf32>) -> tensor<128x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<128x2048xf32>) outs(%35 : tensor<128x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<128x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 199739.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x228x228xf32>) outs(%25 : tensor<128x288x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x228x228xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x228x228xf32>) outs(%25 : tensor<128x288x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x228x228xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x288x228x228xf32>, %25: tensor<128x288x228x228xf32>) -> tensor<128x288x228x228xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x228x228xf32>) outs(%25 : tensor<128x288x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x228x228xf32>\n  return %ret : tensor<128x288x228x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x288x228x228xf32>, %arg1: tensor<128x288x228x228xf32>) -> tensor<128x288x228x228xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x288x228x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x228x228xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 228 {\n          affine.for %arg5 = 0 to 228 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x288x228x228xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x288x228x228xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x288x228x228xf32>\n    return %1 : tensor<128x288x228x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x228x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x288x228x228xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x288x228x228xf32>) -> tensor<128x288x228x228xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x288x228x228xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x288x228x228xf32>) -> tensor<128x288x228x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x228x228xf32>) outs(%25 : tensor<128x288x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x228x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x228x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x228x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1729941843
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x240x240xf32>) outs(%25 : tensor<128x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x240x240xf32>) outs(%25 : tensor<128x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x32x240x240xf32>, %25: tensor<128x32x240x240xf32>) -> tensor<128x32x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x240x240xf32>) outs(%25 : tensor<128x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x240x240xf32>\n  return %ret : tensor<128x32x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x240x240xf32>, %arg1: tensor<128x32x240x240xf32>) -> tensor<128x32x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x32x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x240x240xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x32x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x32x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x32x240x240xf32>\n    return %1 : tensor<128x32x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x32x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x32x240x240xf32>) -> tensor<128x32x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x32x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x32x240x240xf32>) -> tensor<128x32x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x240x240xf32>) outs(%25 : tensor<128x32x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 189701689
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x56x56xf32>) outs(%25 : tensor<256x288x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x56x56xf32>) outs(%25 : tensor<256x288x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x288x56x56xf32>, %25: tensor<256x288x56x56xf32>) -> tensor<256x288x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x56x56xf32>) outs(%25 : tensor<256x288x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x56x56xf32>\n  return %ret : tensor<256x288x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x288x56x56xf32>, %arg1: tensor<256x288x56x56xf32>) -> tensor<256x288x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x288x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x288x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x288x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x288x56x56xf32>\n    return %1 : tensor<256x288x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x288x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x288x56x56xf32>) -> tensor<256x288x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x288x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x288x56x56xf32>) -> tensor<256x288x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x56x56xf32>) outs(%25 : tensor<256x288x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 197137819
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x240x240xf32>) outs(%25 : tensor<256x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x240x240xf32>) outs(%25 : tensor<256x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x240x240xf32>, %25: tensor<256x384x240x240xf32>) -> tensor<256x384x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x240x240xf32>) outs(%25 : tensor<256x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x240x240xf32>\n  return %ret : tensor<256x384x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x240x240xf32>, %arg1: tensor<256x384x240x240xf32>) -> tensor<256x384x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x240x240xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x240x240xf32>\n    return %1 : tensor<256x384x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x240x240xf32>) -> tensor<256x384x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x240x240xf32>) -> tensor<256x384x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x240x240xf32>) outs(%25 : tensor<256x384x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5266212794
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x130x130xf32>) outs(%25 : tensor<128x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x130x130xf32>) outs(%25 : tensor<128x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x288x130x130xf32>, %25: tensor<128x288x130x130xf32>) -> tensor<128x288x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x130x130xf32>) outs(%25 : tensor<128x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x130x130xf32>\n  return %ret : tensor<128x288x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x288x130x130xf32>, %arg1: tensor<128x288x130x130xf32>) -> tensor<128x288x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x288x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x288x130x130xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x288x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x288x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x288x130x130xf32>\n    return %1 : tensor<128x288x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x288x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x288x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x288x130x130xf32>) -> tensor<128x288x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x288x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x288x130x130xf32>) -> tensor<128x288x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x288x130x130xf32>) outs(%25 : tensor<128x288x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x288x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x288x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x288x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 546535543
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x15x15xf32>) outs(%25 : tensor<128x192x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x15x15xf32>) outs(%25 : tensor<128x192x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x192x15x15xf32>, %25: tensor<128x192x15x15xf32>) -> tensor<128x192x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x15x15xf32>) outs(%25 : tensor<128x192x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x15x15xf32>\n  return %ret : tensor<128x192x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x192x15x15xf32>, %arg1: tensor<128x192x15x15xf32>) -> tensor<128x192x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x192x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x192x15x15xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x192x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x192x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x192x15x15xf32>\n    return %1 : tensor<128x192x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x192x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x192x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x192x15x15xf32>) -> tensor<128x192x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x192x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x192x15x15xf32>) -> tensor<128x192x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x192x15x15xf32>) outs(%25 : tensor<128x192x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x192x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x192x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x192x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4193847
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x2048xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x2048xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x2048xf32>, %35: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x2048xf32>\n  return %ret : tensor<256x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x2048xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 2048 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x2048xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x2048xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x2048xf32>\n    return %1 : tensor<256x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %46 = arith.cmpf ugt, %in, %cst_1 : f32\n            %47 = arith.select %46, %in, %cst_1 : f32\n            linalg.yield %47 : f32\n        } -> tensor<256x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 399441
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x240x240xf32>) outs(%25 : tensor<256x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x240x240xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x240x240xf32>) outs(%25 : tensor<256x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x240x240xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x64x240x240xf32>, %25: tensor<256x64x240x240xf32>) -> tensor<256x64x240x240xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x240x240xf32>) outs(%25 : tensor<256x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x240x240xf32>\n  return %ret : tensor<256x64x240x240xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64x240x240xf32>, %arg1: tensor<256x64x240x240xf32>) -> tensor<256x64x240x240xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x64x240x240xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x240x240xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 240 {\n          affine.for %arg5 = 0 to 240 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x64x240x240xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x64x240x240xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x64x240x240xf32>\n    return %1 : tensor<256x64x240x240xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x240x240xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x64x240x240xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x64x240x240xf32>) -> tensor<256x64x240x240xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x64x240x240xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x64x240x240xf32>) -> tensor<256x64x240x240xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x240x240xf32>) outs(%25 : tensor<256x64x240x240xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x240x240xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x240x240xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x240x240xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          240,
          1
        ],
        [
          "%arg5",
          0,
          240,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 771588596
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x28x28xf32>) outs(%25 : tensor<256x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x28x28xf32>) outs(%25 : tensor<256x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x32x28x28xf32>, %25: tensor<256x32x28x28xf32>) -> tensor<256x32x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x28x28xf32>) outs(%25 : tensor<256x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x28x28xf32>\n  return %ret : tensor<256x32x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32x28x28xf32>, %arg1: tensor<256x32x28x28xf32>) -> tensor<256x32x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x32x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x28x28xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x32x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x32x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x32x28x28xf32>\n    return %1 : tensor<256x32x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x32x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x32x28x28xf32>) -> tensor<256x32x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x32x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x32x28x28xf32>) -> tensor<256x32x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x28x28xf32>) outs(%25 : tensor<256x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4677425
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x28x28xf32>) outs(%25 : tensor<128x256x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x28x28xf32>) outs(%25 : tensor<128x256x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x256x28x28xf32>, %25: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x28x28xf32>) outs(%25 : tensor<128x256x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x28x28xf32>\n  return %ret : tensor<128x256x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x256x28x28xf32>, %arg1: tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x256x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x256x28x28xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x256x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x256x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x256x28x28xf32>\n    return %1 : tensor<128x256x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x256x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x256x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x256x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x256x28x28xf32>) -> tensor<128x256x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x256x28x28xf32>) outs(%25 : tensor<128x256x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x256x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x256x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x256x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 20063981
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x7x7xf32>) outs(%25 : tensor<256x240x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x7x7xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x7x7xf32>) outs(%25 : tensor<256x240x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x7x7xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x240x7x7xf32>, %25: tensor<256x240x7x7xf32>) -> tensor<256x240x7x7xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x7x7xf32>) outs(%25 : tensor<256x240x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x7x7xf32>\n  return %ret : tensor<256x240x7x7xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x240x7x7xf32>, %arg1: tensor<256x240x7x7xf32>) -> tensor<256x240x7x7xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x240x7x7xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x240x7x7xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 240 {\n        affine.for %arg4 = 0 to 7 {\n          affine.for %arg5 = 0 to 7 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x240x7x7xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x240x7x7xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x240x7x7xf32>\n    return %1 : tensor<256x240x7x7xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x240x7x7xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x240x7x7xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x240x7x7xf32>) -> tensor<256x240x7x7xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x240x7x7xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x240x7x7xf32>) -> tensor<256x240x7x7xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x240x7x7xf32>) outs(%25 : tensor<256x240x7x7xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x240x7x7xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x240x7x7xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x240x7x7xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          240,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2402506
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x56x56xf32>) outs(%25 : tensor<256x384x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x56x56xf32>) outs(%25 : tensor<256x384x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x56x56xf32>, %25: tensor<256x384x56x56xf32>) -> tensor<256x384x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x56x56xf32>) outs(%25 : tensor<256x384x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x56x56xf32>\n  return %ret : tensor<256x384x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x56x56xf32>, %arg1: tensor<256x384x56x56xf32>) -> tensor<256x384x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x56x56xf32>\n    return %1 : tensor<256x384x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x56x56xf32>) -> tensor<256x384x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x56x56xf32>) -> tensor<256x384x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x56x56xf32>) outs(%25 : tensor<256x384x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 261040031
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x112x112xf32>) outs(%25 : tensor<128x128x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x112x112xf32>) outs(%25 : tensor<128x128x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x128x112x112xf32>, %25: tensor<128x128x112x112xf32>) -> tensor<128x128x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x112x112xf32>) outs(%25 : tensor<128x128x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x112x112xf32>\n  return %ret : tensor<128x128x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128x112x112xf32>, %arg1: tensor<128x128x112x112xf32>) -> tensor<128x128x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x128x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x112x112xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x128x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x128x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x128x112x112xf32>\n    return %1 : tensor<128x128x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x128x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x128x112x112xf32>) -> tensor<128x128x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x128x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x128x112x112xf32>) -> tensor<128x128x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x112x112xf32>) outs(%25 : tensor<128x128x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 169712452
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x228x228xf32>) outs(%25 : tensor<256x64x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x228x228xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x228x228xf32>) outs(%25 : tensor<256x64x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x228x228xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x64x228x228xf32>, %25: tensor<256x64x228x228xf32>) -> tensor<256x64x228x228xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x228x228xf32>) outs(%25 : tensor<256x64x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x228x228xf32>\n  return %ret : tensor<256x64x228x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x64x228x228xf32>, %arg1: tensor<256x64x228x228xf32>) -> tensor<256x64x228x228xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x64x228x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x228x228xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 64 {\n        affine.for %arg4 = 0 to 228 {\n          affine.for %arg5 = 0 to 228 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x64x228x228xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x64x228x228xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x64x228x228xf32>\n    return %1 : tensor<256x64x228x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x228x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x64x228x228xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x64x228x228xf32>) -> tensor<256x64x228x228xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x64x228x228xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x64x228x228xf32>) -> tensor<256x64x228x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x64x228x228xf32>) outs(%25 : tensor<256x64x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x64x228x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x228x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x228x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          64,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 688366870
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x56x56xf32>) outs(%25 : tensor<256x128x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x56x56xf32>) outs(%25 : tensor<256x128x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x128x56x56xf32>, %25: tensor<256x128x56x56xf32>) -> tensor<256x128x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x56x56xf32>) outs(%25 : tensor<256x128x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x56x56xf32>\n  return %ret : tensor<256x128x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128x56x56xf32>, %arg1: tensor<256x128x56x56xf32>) -> tensor<256x128x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x128x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x128x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x128x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x128x56x56xf32>\n    return %1 : tensor<256x128x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x128x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x128x56x56xf32>) -> tensor<256x128x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x128x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x128x56x56xf32>) -> tensor<256x128x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x128x56x56xf32>) outs(%25 : tensor<256x128x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x128x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 87193888
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x14x14xf32>) outs(%25 : tensor<256x96x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x14x14xf32>) outs(%25 : tensor<256x96x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x96x14x14xf32>, %25: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x14x14xf32>) outs(%25 : tensor<256x96x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x14x14xf32>\n  return %ret : tensor<256x96x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x96x14x14xf32>, %arg1: tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x96x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x14x14xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x96x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x96x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x96x14x14xf32>\n    return %1 : tensor<256x96x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x96x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x96x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x96x14x14xf32>) -> tensor<256x96x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x14x14xf32>) outs(%25 : tensor<256x96x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3646686
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x14x14xf32>) outs(%25 : tensor<256x288x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x14x14xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x14x14xf32>) outs(%25 : tensor<256x288x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x14x14xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x288x14x14xf32>, %25: tensor<256x288x14x14xf32>) -> tensor<256x288x14x14xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x14x14xf32>) outs(%25 : tensor<256x288x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x14x14xf32>\n  return %ret : tensor<256x288x14x14xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x288x14x14xf32>, %arg1: tensor<256x288x14x14xf32>) -> tensor<256x288x14x14xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x288x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x288x14x14xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 288 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 14 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x288x14x14xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x288x14x14xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x288x14x14xf32>\n    return %1 : tensor<256x288x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x288x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x288x14x14xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x288x14x14xf32>) -> tensor<256x288x14x14xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x288x14x14xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x288x14x14xf32>) -> tensor<256x288x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x288x14x14xf32>) outs(%25 : tensor<256x288x14x14xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x288x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x288x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x288x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          288,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 11918795
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x15x15xf32>) outs(%25 : tensor<128x96x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x15x15xf32>) outs(%25 : tensor<128x96x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x96x15x15xf32>, %25: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x15x15xf32>) outs(%25 : tensor<128x96x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x15x15xf32>\n  return %ret : tensor<128x96x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x96x15x15xf32>, %arg1: tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x96x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x96x15x15xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x96x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x96x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x96x15x15xf32>\n    return %1 : tensor<128x96x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x96x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x96x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x96x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x96x15x15xf32>) -> tensor<128x96x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x96x15x15xf32>) outs(%25 : tensor<128x96x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x96x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x96x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x96x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2094711
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x150x150xf32>) outs(%25 : tensor<128x128x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x150x150xf32>) outs(%25 : tensor<128x128x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x128x150x150xf32>, %25: tensor<128x128x150x150xf32>) -> tensor<128x128x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x150x150xf32>) outs(%25 : tensor<128x128x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x150x150xf32>\n  return %ret : tensor<128x128x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x128x150x150xf32>, %arg1: tensor<128x128x150x150xf32>) -> tensor<128x128x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x128x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x128x150x150xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 128 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x128x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x128x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x128x150x150xf32>\n    return %1 : tensor<128x128x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x128x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x128x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x128x150x150xf32>) -> tensor<128x128x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x128x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x128x150x150xf32>) -> tensor<128x128x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x128x150x150xf32>) outs(%25 : tensor<128x128x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x128x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x128x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x128x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          128,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 303353493
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x224x224xf32>) outs(%25 : tensor<256x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x224x224xf32>) outs(%25 : tensor<256x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x256x224x224xf32>, %25: tensor<256x256x224x224xf32>) -> tensor<256x256x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x224x224xf32>) outs(%25 : tensor<256x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x224x224xf32>\n  return %ret : tensor<256x256x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256x224x224xf32>, %arg1: tensor<256x256x224x224xf32>) -> tensor<256x256x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x256x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x224x224xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 256 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x256x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x256x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x256x224x224xf32>\n    return %1 : tensor<256x256x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x256x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x256x224x224xf32>) -> tensor<256x256x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x256x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x256x224x224xf32>) -> tensor<256x256x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x256x224x224xf32>) outs(%25 : tensor<256x256x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x256x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3001118954
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x130x130xf32>) outs(%25 : tensor<128x48x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x130x130xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x130x130xf32>) outs(%25 : tensor<128x48x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x130x130xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x48x130x130xf32>, %25: tensor<128x48x130x130xf32>) -> tensor<128x48x130x130xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x130x130xf32>) outs(%25 : tensor<128x48x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x130x130xf32>\n  return %ret : tensor<128x48x130x130xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x48x130x130xf32>, %arg1: tensor<128x48x130x130xf32>) -> tensor<128x48x130x130xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x48x130x130xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x48x130x130xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 48 {\n        affine.for %arg4 = 0 to 130 {\n          affine.for %arg5 = 0 to 130 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x48x130x130xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x48x130x130xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x48x130x130xf32>\n    return %1 : tensor<128x48x130x130xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x48x130x130xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x48x130x130xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x48x130x130xf32>) -> tensor<128x48x130x130xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x48x130x130xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x48x130x130xf32>) -> tensor<128x48x130x130xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x48x130x130xf32>) outs(%25 : tensor<128x48x130x130xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x48x130x130xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x48x130x130xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x48x130x130xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          48,
          1
        ],
        [
          "%arg4",
          0,
          130,
          1
        ],
        [
          "%arg5",
          0,
          130,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 85763513
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x224x224xf32>) outs(%25 : tensor<256x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x224x224xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x224x224xf32>) outs(%25 : tensor<256x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x224x224xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x32x224x224xf32>, %25: tensor<256x32x224x224xf32>) -> tensor<256x32x224x224xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x224x224xf32>) outs(%25 : tensor<256x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x224x224xf32>\n  return %ret : tensor<256x32x224x224xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32x224x224xf32>, %arg1: tensor<256x32x224x224xf32>) -> tensor<256x32x224x224xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x32x224x224xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x224x224xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 224 {\n          affine.for %arg5 = 0 to 224 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x32x224x224xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x32x224x224xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x32x224x224xf32>\n    return %1 : tensor<256x32x224x224xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x224x224xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x32x224x224xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x32x224x224xf32>) -> tensor<256x32x224x224xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x32x224x224xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x32x224x224xf32>) -> tensor<256x32x224x224xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x224x224xf32>) outs(%25 : tensor<256x32x224x224xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x224x224xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x224x224xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x224x224xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          224,
          1
        ],
        [
          "%arg5",
          0,
          224,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 330816074
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x150x150xf32>) outs(%25 : tensor<256x32x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x150x150xf32>) outs(%25 : tensor<256x32x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x32x150x150xf32>, %25: tensor<256x32x150x150xf32>) -> tensor<256x32x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x150x150xf32>) outs(%25 : tensor<256x32x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x150x150xf32>\n  return %ret : tensor<256x32x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32x150x150xf32>, %arg1: tensor<256x32x150x150xf32>) -> tensor<256x32x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x32x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x150x150xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x32x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x32x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x32x150x150xf32>\n    return %1 : tensor<256x32x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x32x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x32x150x150xf32>) -> tensor<256x32x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x32x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x32x150x150xf32>) -> tensor<256x32x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x150x150xf32>) outs(%25 : tensor<256x32x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 150565058
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x228x228xf32>) outs(%25 : tensor<256x96x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x228x228xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x228x228xf32>) outs(%25 : tensor<256x96x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x228x228xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x96x228x228xf32>, %25: tensor<256x96x228x228xf32>) -> tensor<256x96x228x228xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x228x228xf32>) outs(%25 : tensor<256x96x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x228x228xf32>\n  return %ret : tensor<256x96x228x228xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x96x228x228xf32>, %arg1: tensor<256x96x228x228xf32>) -> tensor<256x96x228x228xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x96x228x228xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x96x228x228xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 96 {\n        affine.for %arg4 = 0 to 228 {\n          affine.for %arg5 = 0 to 228 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x96x228x228xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x96x228x228xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x96x228x228xf32>\n    return %1 : tensor<256x96x228x228xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x96x228x228xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x96x228x228xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x96x228x228xf32>) -> tensor<256x96x228x228xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x96x228x228xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x96x228x228xf32>) -> tensor<256x96x228x228xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x96x228x228xf32>) outs(%25 : tensor<256x96x228x228xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x96x228x228xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x96x228x228xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x96x228x228xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          96,
          1
        ],
        [
          "%arg4",
          0,
          228,
          1
        ],
        [
          "%arg5",
          0,
          228,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1097713124
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x28x28xf32>) outs(%25 : tensor<128x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x28x28xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x28x28xf32>) outs(%25 : tensor<128x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x28x28xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<128x32x28x28xf32>, %25: tensor<128x32x28x28xf32>) -> tensor<128x32x28x28xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x28x28xf32>) outs(%25 : tensor<128x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x28x28xf32>\n  return %ret : tensor<128x32x28x28xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<128x32x28x28xf32>, %arg1: tensor<128x32x28x28xf32>) -> tensor<128x32x28x28xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<128x32x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<128x32x28x28xf32>\n    affine.for %arg2 = 0 to 128 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 28 {\n          affine.for %arg5 = 0 to 28 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<128x32x28x28xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<128x32x28x28xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<128x32x28x28xf32>\n    return %1 : tensor<128x32x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<128x32x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<128x32x28x28xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<128x32x28x28xf32>) -> tensor<128x32x28x28xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<128x32x28x28xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<128x32x28x28xf32>) -> tensor<128x32x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<128x32x28x28xf32>) outs(%25 : tensor<128x32x28x28xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<128x32x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<128x32x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<128x32x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          128,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2335317
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x15x15xf32>) outs(%25 : tensor<256x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x15x15xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x15x15xf32>) outs(%25 : tensor<256x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x15x15xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x384x15x15xf32>, %25: tensor<256x384x15x15xf32>) -> tensor<256x384x15x15xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x15x15xf32>) outs(%25 : tensor<256x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x15x15xf32>\n  return %ret : tensor<256x384x15x15xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x384x15x15xf32>, %arg1: tensor<256x384x15x15xf32>) -> tensor<256x384x15x15xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x384x15x15xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x384x15x15xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 384 {\n        affine.for %arg4 = 0 to 15 {\n          affine.for %arg5 = 0 to 15 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x384x15x15xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x384x15x15xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x384x15x15xf32>\n    return %1 : tensor<256x384x15x15xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x384x15x15xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x384x15x15xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x384x15x15xf32>) -> tensor<256x384x15x15xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x384x15x15xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x384x15x15xf32>) -> tensor<256x384x15x15xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x384x15x15xf32>) outs(%25 : tensor<256x384x15x15xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x384x15x15xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x384x15x15xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x384x15x15xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          384,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 18126454
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x112x112xf32>) outs(%25 : tensor<256x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x112x112xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x112x112xf32>) outs(%25 : tensor<256x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x112x112xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x32x112x112xf32>, %25: tensor<256x32x112x112xf32>) -> tensor<256x32x112x112xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x112x112xf32>) outs(%25 : tensor<256x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x112x112xf32>\n  return %ret : tensor<256x32x112x112xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x32x112x112xf32>, %arg1: tensor<256x32x112x112xf32>) -> tensor<256x32x112x112xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x32x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x112x112xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 32 {\n        affine.for %arg4 = 0 to 112 {\n          affine.for %arg5 = 0 to 112 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x32x112x112xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x32x112x112xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x32x112x112xf32>\n    return %1 : tensor<256x32x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x32x112x112xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x32x112x112xf32>) -> tensor<256x32x112x112xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x32x112x112xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x32x112x112xf32>) -> tensor<256x32x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x32x112x112xf32>) outs(%25 : tensor<256x32x112x112xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x32x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          32,
          1
        ],
        [
          "%arg4",
          0,
          112,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 85198281
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x56x56xf32>) outs(%25 : tensor<256x512x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x56x56xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x56x56xf32>) outs(%25 : tensor<256x512x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x56x56xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x512x56x56xf32>, %25: tensor<256x512x56x56xf32>) -> tensor<256x512x56x56xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x56x56xf32>) outs(%25 : tensor<256x512x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x56x56xf32>\n  return %ret : tensor<256x512x56x56xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512x56x56xf32>, %arg1: tensor<256x512x56x56xf32>) -> tensor<256x512x56x56xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x512x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x56x56xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 512 {\n        affine.for %arg4 = 0 to 56 {\n          affine.for %arg5 = 0 to 56 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x512x56x56xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x512x56x56xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x512x56x56xf32>\n    return %1 : tensor<256x512x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x512x56x56xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x512x56x56xf32>) -> tensor<256x512x56x56xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x512x56x56xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x512x56x56xf32>) -> tensor<256x512x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x512x56x56xf32>) outs(%25 : tensor<256x512x56x56xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x512x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 347747154
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x150x150xf32>) outs(%25 : tensor<256x192x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x150x150xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x150x150xf32>) outs(%25 : tensor<256x192x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x150x150xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x192x150x150xf32>, %25: tensor<256x192x150x150xf32>) -> tensor<256x192x150x150xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x150x150xf32>) outs(%25 : tensor<256x192x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x150x150xf32>\n  return %ret : tensor<256x192x150x150xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x192x150x150xf32>, %arg1: tensor<256x192x150x150xf32>) -> tensor<256x192x150x150xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x192x150x150xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x150x150xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 192 {\n        affine.for %arg4 = 0 to 150 {\n          affine.for %arg5 = 0 to 150 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x192x150x150xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x192x150x150xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x192x150x150xf32>\n    return %1 : tensor<256x192x150x150xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n        #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x150x150xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x192x150x150xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x192x150x150xf32>) -> tensor<256x192x150x150xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x192x150x150xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x192x150x150xf32>) -> tensor<256x192x150x150xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x192x150x150xf32>) outs(%25 : tensor<256x192x150x150xf32>) {\n            ^bb0(%in: f32, %out: f32):\n            %cst_1 = arith.constant 0.000000e+00 : f32\n            %90 = arith.cmpf ugt, %in, %cst_1 : f32\n            %91 = arith.select %90, %in, %cst_1 : f32\n            linalg.yield %91 : f32\n        } -> tensor<256x192x150x150xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x150x150xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x150x150xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          192,
          1
        ],
        [
          "%arg4",
          0,
          150,
          1
        ],
        [
          "%arg5",
          0,
          150,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 942386419
  }
}