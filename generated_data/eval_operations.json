{
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n  return %ret : tensor<256x1000xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x1000xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1000xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1000xf32>\n    memref.copy %2, %alloc : memref<256x1000xf32> to memref<256x1000xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1000 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x1000xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1000xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1000xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1000xf32>\n    return %3 : tensor<256x1000xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1000xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x1000xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x1000xf32>) -> tensor<2048x1000xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1000xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1000xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1000xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1000,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2002760977
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1280xf32>, tensor<1280x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1280xf32>, tensor<1280x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1280xf32>, %arg1: tensor<1280x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1280xf32>, tensor<1280x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n  return %ret : tensor<256x1000xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1280xf32>, %arg1: tensor<1280x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1280x1000xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1280xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1000xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1000xf32>\n    memref.copy %2, %alloc : memref<256x1000xf32> to memref<256x1000xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1000 {\n        affine.for %arg5 = 0 to 1280 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1280xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1280x1000xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1000xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1000xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1000xf32>\n    return %3 : tensor<256x1000xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1000xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1280xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1280xf32>) -> tensor<256x1280xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1280x1000xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1280x1000xf32>) -> tensor<1280x1000xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1000xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1280xf32>, tensor<1280x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1000xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1000xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1000,
          1
        ],
        [
          "%arg5",
          0,
          1280,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1247334561
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n  return %ret : tensor<256x1000xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x1000xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1000xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1000xf32>\n    memref.copy %2, %alloc : memref<256x1000xf32> to memref<256x1000xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1000 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x1000xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1000xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1000xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1000xf32>\n    return %3 : tensor<256x1000xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1000xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x1000xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x1000xf32>) -> tensor<1536x1000xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1000xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1000xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1000xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1000,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1496736488
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1408xf32>, tensor<1408x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1408xf32>, tensor<1408x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1408xf32>, %arg1: tensor<1408x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1408xf32>, tensor<1408x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n  return %ret : tensor<256x1000xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1408xf32>, %arg1: tensor<1408x1000xf32>, %arg2: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1408x1000xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1408xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1000xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1000xf32>\n    memref.copy %2, %alloc : memref<256x1000xf32> to memref<256x1000xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1000 {\n        affine.for %arg5 = 0 to 1408 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1408xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1408x1000xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1000xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1000xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1000xf32>\n    return %3 : tensor<256x1000xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1000xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1408xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1408xf32>) -> tensor<256x1408xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1408x1000xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1408x1000xf32>) -> tensor<1408x1000xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1000xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1408xf32>, tensor<1408x1000xf32>) outs(%arg2 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1000xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1000xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1000,
          1
        ],
        [
          "%arg5",
          0,
          1408,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1370613807
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<256x768xf32>) -> tensor<256x768xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n  return %ret : tensor<256x768xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x768xf32>, %arg2: tensor<256x768xf32>) -> tensor<256x768xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x768xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x768xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x768xf32>\n    memref.copy %2, %alloc : memref<256x768xf32> to memref<256x768xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 768 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x768xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x768xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x768xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x768xf32>\n    return %3 : tensor<256x768xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x768xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x768xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x768xf32>) -> tensor<768x768xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x768xf32>) outs(%arg2 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x768xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x768xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          768,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 577426257
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1024xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 1024 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1024xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1024x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1024x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1030742239
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n  return %ret : tensor<256x3072xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x3072xf32>, %arg2: tensor<256x3072xf32>) -> tensor<256x3072xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x3072xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x3072xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x3072xf32>\n    memref.copy %2, %alloc : memref<256x3072xf32> to memref<256x3072xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 3072 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x3072xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x3072xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x3072xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x3072xf32>\n    return %3 : tensor<256x3072xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x3072xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x3072xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x3072xf32>) -> tensor<768x3072xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x3072xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x3072xf32>) outs(%arg2 : tensor<256x3072xf32>) -> tensor<256x3072xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x3072xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x3072xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          3072,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2313018996
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n  return %ret : tensor<256x128xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x128xf32>, %arg2: tensor<256x128xf32>) -> tensor<256x128xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x128xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128xf32>\n    memref.copy %2, %alloc : memref<256x128xf32> to memref<256x128xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x128xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x128xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x128xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128xf32>\n    return %3 : tensor<256x128xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x128xf32>) outs(%arg2 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 29970395
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x4096xf32>, tensor<4096x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x4096xf32>, tensor<4096x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x4096xf32>, %arg1: tensor<4096x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x4096xf32>, tensor<4096x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x4096xf32>, %arg1: tensor<4096x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<4096x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x4096xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 4096 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x4096xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<4096x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x4096xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x4096xf32>) -> tensor<256x4096xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<4096x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<4096x1024xf32>) -> tensor<4096x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x4096xf32>, tensor<4096x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          4096,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4163362073
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x4096xf32>) outs(%arg2 : tensor<256x4096xf32>) -> tensor<256x4096xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x4096xf32>) outs(%arg2 : tensor<256x4096xf32>) -> tensor<256x4096xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x4096xf32>, %arg2: tensor<256x4096xf32>) -> tensor<256x4096xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x4096xf32>) outs(%arg2 : tensor<256x4096xf32>) -> tensor<256x4096xf32>\n  return %ret : tensor<256x4096xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1536xf32>, %arg1: tensor<1536x4096xf32>, %arg2: tensor<256x4096xf32>) -> tensor<256x4096xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1536x4096xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x1536xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x4096xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x4096xf32>\n    memref.copy %2, %alloc : memref<256x4096xf32> to memref<256x4096xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 4096 {\n        affine.for %arg5 = 0 to 1536 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x1536xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<1536x4096xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x4096xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x4096xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x4096xf32>\n    return %3 : tensor<256x4096xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x4096xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x1536xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x1536xf32>) -> tensor<256x1536xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<1536x4096xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<1536x4096xf32>) -> tensor<1536x4096xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x4096xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x4096xf32>) -> tensor<256x4096xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x1536xf32>, tensor<1536x4096xf32>) outs(%arg2 : tensor<256x4096xf32>) -> tensor<256x4096xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x4096xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x4096xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          4096,
          1
        ],
        [
          "%arg5",
          0,
          1536,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 6208599760
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2xf32>) outs(%arg2 : tensor<256x2xf32>) -> tensor<256x2xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2xf32>) outs(%arg2 : tensor<256x2xf32>) -> tensor<256x2xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x2xf32>, %arg2: tensor<256x2xf32>) -> tensor<256x2xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2xf32>) outs(%arg2 : tensor<256x2xf32>) -> tensor<256x2xf32>\n  return %ret : tensor<256x2xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x768xf32>, %arg1: tensor<768x2xf32>, %arg2: tensor<256x2xf32>) -> tensor<256x2xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<768x2xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x768xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x2xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x2xf32>\n    memref.copy %2, %alloc : memref<256x2xf32> to memref<256x2xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 2 {\n        affine.for %arg5 = 0 to 768 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x768xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<768x2xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x2xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x2xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x2xf32>\n    return %3 : tensor<256x2xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x2xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x768xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x768xf32>) -> tensor<256x768xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<768x2xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<768x2xf32>) -> tensor<768x2xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x2xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x2xf32>) -> tensor<256x2xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x768xf32>, tensor<768x2xf32>) outs(%arg2 : tensor<256x2xf32>) -> tensor<256x2xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x2xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x2xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          2,
          1
        ],
        [
          "%arg5",
          0,
          768,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1456441
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n  return %ret : tensor<256x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<2048x2048xf32>, %arg2: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<2048x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x2048xf32>\n    memref.copy %2, %alloc : memref<256x2048xf32> to memref<256x2048xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 2048 {\n        affine.for %arg5 = 0 to 2048 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x2048xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<2048x2048xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x2048xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x2048xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x2048xf32>\n    return %3 : tensor<256x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<2048x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<2048x2048xf32>) -> tensor<2048x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x2048xf32>, tensor<2048x2048xf32>) outs(%arg2 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          2048,
          1
        ],
        [
          "%arg5",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4138642150
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n  return %ret : tensor<256x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x128xf32>, %arg1: tensor<128x256xf32>, %arg2: tensor<256x256xf32>) -> tensor<256x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256xf32>\n    memref.copy %2, %alloc : memref<256x256xf32> to memref<256x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 128 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x128xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<128x256xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x256xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x256xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256xf32>\n    return %3 : tensor<256x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x128xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x128xf32>) -> tensor<256x128xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<128x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<128x256xf32>) -> tensor<128x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x128xf32>, tensor<128x256xf32>) outs(%arg2 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          128,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 28470065
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x256xf32>, %arg1: tensor<256x512xf32>, %arg2: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    memref.copy %2, %alloc : memref<256x512xf32> to memref<256x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 256 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x256xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<256x512xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x512xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x512xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %3 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x256xf32>) -> tensor<256x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x256xf32>, tensor<256x512xf32>) outs(%arg2 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 125263854
  },
  "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>": {
    "operation": "linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n  %ret = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n  return %ret : tensor<256x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<512x1024xf32>, %arg2: tensor<256x1024xf32>) -> tensor<256x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024xf32>\n    memref.copy %2, %alloc : memref<256x1024xf32> to memref<256x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 512 {\n          %4 = affine.load %1[%arg3, %arg5] : memref<256x512xf32>\n          %5 = affine.load %0[%arg5, %arg4] : memref<512x1024xf32>\n          %6 = affine.load %alloc[%arg3, %arg4] : memref<256x1024xf32>\n          %7 = arith.mulf %4, %5 : f32\n          %8 = arith.addf %6, %7 : f32\n          affine.store %8, %alloc[%arg3, %arg4] : memref<256x1024xf32>\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024xf32>\n    return %3 : tensor<256x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<512x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<512x1024xf32>) -> tensor<512x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.matmul ins(%arg0, %arg1 : tensor<256x512xf32>, tensor<512x1024xf32>) outs(%arg2 : tensor<256x1024xf32>) -> tensor<256x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg5"
        ],
        [
          "%arg5",
          "%arg4"
        ],
        [
          "%arg3",
          "%arg4"
        ]
      ],
      "store_data": []
    },
    "execution_time": 510508285
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x114x114xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x114x114xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x114x114xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x114x114xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32>\n  return %ret : tensor<256x64x56x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x114x114xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x114x114xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x56x56xf32>\n    memref.copy %1, %alloc : memref<256x64x56x56xf32> to memref<256x64x56x56xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x114x114xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x56x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x56x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x56x56xf32>\n    return %2 : tensor<256x64x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x114x114xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x114x114xf32>) -> tensor<256x64x114x114xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x56x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x114x114xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1106323983
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x147x147xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x73x73xf32>) -> tensor<256x64x73x73xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x147x147xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x73x73xf32>) -> tensor<256x64x73x73xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x147x147xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x64x73x73xf32>) -> tensor<256x64x73x73xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x147x147xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x73x73xf32>) -> tensor<256x64x73x73xf32>\n  return %ret : tensor<256x64x73x73xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x147x147xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x64x73x73xf32>) -> tensor<256x64x73x73xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x64x147x147xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x64x73x73xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x73x73xf32>\n    memref.copy %1, %alloc : memref<256x64x73x73xf32> to memref<256x64x73x73xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 73 {\n          affine.for %arg6 = 0 to 73 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x64x147x147xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x73x73xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x73x73xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x64x73x73xf32>\n    return %2 : tensor<256x64x73x73xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x73x73xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x147x147xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x147x147xf32>) -> tensor<256x64x147x147xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x73x73xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x73x73xf32>) -> tensor<256x64x73x73xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x147x147xf32>, tensor<3x3xf32>) outs (%init: tensor<256x64x73x73xf32>) -> tensor<256x64x73x73xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x73x73xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x73x73xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          73,
          1
        ],
        [
          "%arg6",
          0,
          73,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1879374947
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x71x71xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x35x35xf32>) -> tensor<256x192x35x35xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x71x71xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x35x35xf32>) -> tensor<256x192x35x35xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x192x71x71xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x192x35x35xf32>) -> tensor<256x192x35x35xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x71x71xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x35x35xf32>) -> tensor<256x192x35x35xf32>\n  return %ret : tensor<256x192x35x35xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x192x71x71xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x192x35x35xf32>) -> tensor<256x192x35x35xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x192x71x71xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x192x35x35xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x192x35x35xf32>\n    memref.copy %1, %alloc : memref<256x192x35x35xf32> to memref<256x192x35x35xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 192 {\n        affine.for %arg5 = 0 to 35 {\n          affine.for %arg6 = 0 to 35 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x192x71x71xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x35x35xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x192x35x35xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x192x35x35xf32>\n    return %2 : tensor<256x192x35x35xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x192x35x35xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x192x71x71xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x192x71x71xf32>) -> tensor<256x192x71x71xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x192x35x35xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x192x35x35xf32>) -> tensor<256x192x35x35xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x192x71x71xf32>, tensor<3x3xf32>) outs (%init: tensor<256x192x35x35xf32>) -> tensor<256x192x35x35xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x192x35x35xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x192x35x35xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          192,
          1
        ],
        [
          "%arg5",
          0,
          35,
          1
        ],
        [
          "%arg6",
          0,
          35,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1300666420
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x42x167x167xf32>, tensor<3x3xf32>) outs (%init: tensor<256x42x83x83xf32>) -> tensor<256x42x83x83xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x42x167x167xf32>, tensor<3x3xf32>) outs (%init: tensor<256x42x83x83xf32>) -> tensor<256x42x83x83xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x42x167x167xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x42x83x83xf32>) -> tensor<256x42x83x83xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x42x167x167xf32>, tensor<3x3xf32>) outs (%init: tensor<256x42x83x83xf32>) -> tensor<256x42x83x83xf32>\n  return %ret : tensor<256x42x83x83xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x42x167x167xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x42x83x83xf32>) -> tensor<256x42x83x83xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x42x167x167xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x42x83x83xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x42x83x83xf32>\n    memref.copy %1, %alloc : memref<256x42x83x83xf32> to memref<256x42x83x83xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 42 {\n        affine.for %arg5 = 0 to 83 {\n          affine.for %arg6 = 0 to 83 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x42x167x167xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x42x83x83xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x42x83x83xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x42x83x83xf32>\n    return %2 : tensor<256x42x83x83xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x42x83x83xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x42x167x167xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x42x167x167xf32>) -> tensor<256x42x167x167xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x42x83x83xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x42x83x83xf32>) -> tensor<256x42x83x83xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x42x167x167xf32>, tensor<3x3xf32>) outs (%init: tensor<256x42x83x83xf32>) -> tensor<256x42x83x83xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x42x83x83xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x42x83x83xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          42,
          1
        ],
        [
          "%arg5",
          0,
          83,
          1
        ],
        [
          "%arg6",
          0,
          83,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1596201740
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x84x85x85xf32>, tensor<3x3xf32>) outs (%init: tensor<256x84x42x42xf32>) -> tensor<256x84x42x42xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x84x85x85xf32>, tensor<3x3xf32>) outs (%init: tensor<256x84x42x42xf32>) -> tensor<256x84x42x42xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x84x85x85xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x84x42x42xf32>) -> tensor<256x84x42x42xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x84x85x85xf32>, tensor<3x3xf32>) outs (%init: tensor<256x84x42x42xf32>) -> tensor<256x84x42x42xf32>\n  return %ret : tensor<256x84x42x42xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x84x85x85xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x84x42x42xf32>) -> tensor<256x84x42x42xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x84x85x85xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x84x42x42xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x84x42x42xf32>\n    memref.copy %1, %alloc : memref<256x84x42x42xf32> to memref<256x84x42x42xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 84 {\n        affine.for %arg5 = 0 to 42 {\n          affine.for %arg6 = 0 to 42 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x84x85x85xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x84x42x42xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x84x42x42xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x84x42x42xf32>\n    return %2 : tensor<256x84x42x42xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x84x42x42xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x84x85x85xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x84x85x85xf32>) -> tensor<256x84x85x85xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x84x42x42xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x84x42x42xf32>) -> tensor<256x84x42x42xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x84x85x85xf32>, tensor<3x3xf32>) outs (%init: tensor<256x84x42x42xf32>) -> tensor<256x84x42x42xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x84x42x42xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x84x42x42xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          84,
          1
        ],
        [
          "%arg5",
          0,
          42,
          1
        ],
        [
          "%arg6",
          0,
          42,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 817686512
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x43x43xf32>, tensor<3x3xf32>) outs (%init: tensor<256x336x21x21xf32>) -> tensor<256x336x21x21xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x43x43xf32>, tensor<3x3xf32>) outs (%init: tensor<256x336x21x21xf32>) -> tensor<256x336x21x21xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x336x43x43xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x336x21x21xf32>) -> tensor<256x336x21x21xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x43x43xf32>, tensor<3x3xf32>) outs (%init: tensor<256x336x21x21xf32>) -> tensor<256x336x21x21xf32>\n  return %ret : tensor<256x336x21x21xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x336x43x43xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x336x21x21xf32>) -> tensor<256x336x21x21xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x336x43x43xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x336x21x21xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x336x21x21xf32>\n    memref.copy %1, %alloc : memref<256x336x21x21xf32> to memref<256x336x21x21xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 336 {\n        affine.for %arg5 = 0 to 21 {\n          affine.for %arg6 = 0 to 21 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x336x43x43xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x336x21x21xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x336x21x21xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x336x21x21xf32>\n    return %2 : tensor<256x336x21x21xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x336x21x21xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x336x43x43xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x336x43x43xf32>) -> tensor<256x336x43x43xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x336x21x21xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x336x21x21xf32>) -> tensor<256x336x21x21xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x43x43xf32>, tensor<3x3xf32>) outs (%init: tensor<256x336x21x21xf32>) -> tensor<256x336x21x21xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x336x21x21xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x336x21x21xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          336,
          1
        ],
        [
          "%arg5",
          0,
          21,
          1
        ],
        [
          "%arg6",
          0,
          21,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 827613606
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x672x23x23xf32>, tensor<3x3xf32>) outs (%init: tensor<256x672x11x11xf32>) -> tensor<256x672x11x11xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x672x23x23xf32>, tensor<3x3xf32>) outs (%init: tensor<256x672x11x11xf32>) -> tensor<256x672x11x11xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x672x23x23xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x672x11x11xf32>) -> tensor<256x672x11x11xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x672x23x23xf32>, tensor<3x3xf32>) outs (%init: tensor<256x672x11x11xf32>) -> tensor<256x672x11x11xf32>\n  return %ret : tensor<256x672x11x11xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x672x23x23xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x672x11x11xf32>) -> tensor<256x672x11x11xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x672x23x23xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x672x11x11xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x672x11x11xf32>\n    memref.copy %1, %alloc : memref<256x672x11x11xf32> to memref<256x672x11x11xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 672 {\n        affine.for %arg5 = 0 to 11 {\n          affine.for %arg6 = 0 to 11 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x672x23x23xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x672x11x11xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x672x11x11xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x672x11x11xf32>\n    return %2 : tensor<256x672x11x11xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x672x11x11xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x672x23x23xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x672x23x23xf32>) -> tensor<256x672x23x23xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x672x11x11xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x672x11x11xf32>) -> tensor<256x672x11x11xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x672x23x23xf32>, tensor<3x3xf32>) outs (%init: tensor<256x672x11x11xf32>) -> tensor<256x672x11x11xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x672x11x11xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x672x11x11xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          672,
          1
        ],
        [
          "%arg5",
          0,
          11,
          1
        ],
        [
          "%arg6",
          0,
          11,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 464409341
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x11x113x113xf32>, tensor<3x3xf32>) outs (%init: tensor<256x11x56x56xf32>) -> tensor<256x11x56x56xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x11x113x113xf32>, tensor<3x3xf32>) outs (%init: tensor<256x11x56x56xf32>) -> tensor<256x11x56x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x11x113x113xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x11x56x56xf32>) -> tensor<256x11x56x56xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x11x113x113xf32>, tensor<3x3xf32>) outs (%init: tensor<256x11x56x56xf32>) -> tensor<256x11x56x56xf32>\n  return %ret : tensor<256x11x56x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x11x113x113xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x11x56x56xf32>) -> tensor<256x11x56x56xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x11x113x113xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x11x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x11x56x56xf32>\n    memref.copy %1, %alloc : memref<256x11x56x56xf32> to memref<256x11x56x56xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 11 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x11x113x113xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x11x56x56xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x11x56x56xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x11x56x56xf32>\n    return %2 : tensor<256x11x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x11x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x11x113x113xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x11x113x113xf32>) -> tensor<256x11x113x113xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x11x56x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x11x56x56xf32>) -> tensor<256x11x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x11x113x113xf32>, tensor<3x3xf32>) outs (%init: tensor<256x11x56x56xf32>) -> tensor<256x11x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x11x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x11x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          11,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 190198575
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x22x57x57xf32>, tensor<3x3xf32>) outs (%init: tensor<256x22x28x28xf32>) -> tensor<256x22x28x28xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x22x57x57xf32>, tensor<3x3xf32>) outs (%init: tensor<256x22x28x28xf32>) -> tensor<256x22x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x22x57x57xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x22x28x28xf32>) -> tensor<256x22x28x28xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x22x57x57xf32>, tensor<3x3xf32>) outs (%init: tensor<256x22x28x28xf32>) -> tensor<256x22x28x28xf32>\n  return %ret : tensor<256x22x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x22x57x57xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x22x28x28xf32>) -> tensor<256x22x28x28xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x22x57x57xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x22x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x22x28x28xf32>\n    memref.copy %1, %alloc : memref<256x22x28x28xf32> to memref<256x22x28x28xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 22 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x22x57x57xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x22x28x28xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x22x28x28xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x22x28x28xf32>\n    return %2 : tensor<256x22x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x22x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x22x57x57xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x22x57x57xf32>) -> tensor<256x22x57x57xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x22x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x22x28x28xf32>) -> tensor<256x22x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x22x57x57xf32>, tensor<3x3xf32>) outs (%init: tensor<256x22x28x28xf32>) -> tensor<256x22x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x22x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x22x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          22,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 96234278
  },
  "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x88x29x29xf32>, tensor<3x3xf32>) outs (%init: tensor<256x88x14x14xf32>) -> tensor<256x88x14x14xf32>": {
    "operation": "linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x88x29x29xf32>, tensor<3x3xf32>) outs (%init: tensor<256x88x14x14xf32>) -> tensor<256x88x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x88x29x29xf32>, %filter: tensor<3x3xf32>, %init: tensor<256x88x14x14xf32>) -> tensor<256x88x14x14xf32> {\n  %ret = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x88x29x29xf32>, tensor<3x3xf32>) outs (%init: tensor<256x88x14x14xf32>) -> tensor<256x88x14x14xf32>\n  return %ret : tensor<256x88x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x88x29x29xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<256x88x14x14xf32>) -> tensor<256x88x14x14xf32> {\n    %0 = bufferization.to_memref %arg0 : memref<256x88x29x29xf32>\n    %1 = bufferization.to_memref %arg2 : memref<256x88x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x88x14x14xf32>\n    memref.copy %1, %alloc : memref<256x88x14x14xf32> to memref<256x88x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 88 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                %3 = affine.apply #map(%arg5, %arg7)\n                %4 = affine.apply #map(%arg6, %arg8)\n                %5 = affine.load %0[%arg3, %arg4, %3, %4] : memref<256x88x29x29xf32>\n                %6 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x88x14x14xf32>\n                %7 = arith.maximumf %6, %5 : f32\n                affine.store %7, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x88x14x14xf32>\n              }\n            }\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x88x14x14xf32>\n    return %2 : tensor<256x88x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x88x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x88x29x29xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x88x29x29xf32>) -> tensor<256x88x29x29xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<3x3xf32>) -> tensor<3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x88x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x88x14x14xf32>) -> tensor<256x88x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.pooling_nchw_max {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x88x29x29xf32>, tensor<3x3xf32>) outs (%init: tensor<256x88x14x14xf32>) -> tensor<256x88x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x88x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x88x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          88,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5 * 2 + %arg7",
          "%arg6 * 2 + %arg8"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 97834762
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x14x14x1024xf32>, tensor<256x14x14x1024xf32>) outs(%arg2: tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x14x14x1024xf32>, tensor<256x14x14x1024xf32>) outs(%arg2: tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x14x14x1024xf32>, %arg1: tensor<256x14x14x1024xf32>, %arg2: tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x14x14x1024xf32>, tensor<256x14x14x1024xf32>) outs(%arg2: tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32>\n  return %ret : tensor<256x14x14x1024xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x14x14x1024xf32>, %arg1: tensor<256x14x14x1024xf32>, %arg2: tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x14x14x1024xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x14x14x1024xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x14x14x1024xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 1024 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x14x14x1024xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x14x14x1024xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x14x14x1024xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x14x14x1024xf32>\n    return %2 : tensor<256x14x14x1024xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x14x14x1024xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x14x14x1024xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x14x14x1024xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x14x14x1024xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x14x14x1024xf32>, tensor<256x14x14x1024xf32>) outs(%arg2: tensor<256x14x14x1024xf32>) -> tensor<256x14x14x1024xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x14x14x1024xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x14x14x1024xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          1024,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 61510748
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x28x28x512xf32>, tensor<256x28x28x512xf32>) outs(%arg2: tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x28x28x512xf32>, tensor<256x28x28x512xf32>) outs(%arg2: tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x28x28x512xf32>, %arg1: tensor<256x28x28x512xf32>, %arg2: tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x28x28x512xf32>, tensor<256x28x28x512xf32>) outs(%arg2: tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32>\n  return %ret : tensor<256x28x28x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x28x28x512xf32>, %arg1: tensor<256x28x28x512xf32>, %arg2: tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x28x28x512xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x28x28x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x28x28x512xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 28 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 512 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x28x28x512xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x28x28x512xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x28x28x512xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x28x28x512xf32>\n    return %2 : tensor<256x28x28x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x28x28x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x28x28x512xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x28x28x512xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x28x28x512xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x28x28x512xf32>, tensor<256x28x28x512xf32>) outs(%arg2: tensor<256x28x28x512xf32>) -> tensor<256x28x28x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x28x28x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x28x28x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          28,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 123035905
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x7x7x2048xf32>, tensor<256x7x7x2048xf32>) outs(%arg2: tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x7x7x2048xf32>, tensor<256x7x7x2048xf32>) outs(%arg2: tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x7x7x2048xf32>, %arg1: tensor<256x7x7x2048xf32>, %arg2: tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x7x7x2048xf32>, tensor<256x7x7x2048xf32>) outs(%arg2: tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32>\n  return %ret : tensor<256x7x7x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x7x7x2048xf32>, %arg1: tensor<256x7x7x2048xf32>, %arg2: tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x7x7x2048xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x7x7x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x7x7x2048xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 2048 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x7x7x2048xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x7x7x2048xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x7x7x2048xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x7x7x2048xf32>\n    return %2 : tensor<256x7x7x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x7x7x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x7x7x2048xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x7x7x2048xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x7x7x2048xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x7x7x2048xf32>, tensor<256x7x7x2048xf32>) outs(%arg2: tensor<256x7x7x2048xf32>) -> tensor<256x7x7x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x7x7x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x7x7x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 31186093
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x56x56x256xf32>, tensor<256x56x56x256xf32>) outs(%arg2: tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x56x56x256xf32>, tensor<256x56x56x256xf32>) outs(%arg2: tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x56x56x256xf32>, %arg1: tensor<256x56x56x256xf32>, %arg2: tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x56x56x256xf32>, tensor<256x56x56x256xf32>) outs(%arg2: tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32>\n  return %ret : tensor<256x56x56x256xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x56x56x256xf32>, %arg1: tensor<256x56x56x256xf32>, %arg2: tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x56x56x256xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x56x56x256xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x56x56x256xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 56 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 256 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x56x56x256xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x56x56x256xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x56x56x256xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x56x56x256xf32>\n    return %2 : tensor<256x56x56x256xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x56x56x256xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x56x56x256xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x56x56x256xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x56x56x256xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x56x56x256xf32>, tensor<256x56x56x256xf32>) outs(%arg2: tensor<256x56x56x256xf32>) -> tensor<256x56x56x256xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x56x56x256xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x56x56x256xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          56,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          256,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 245997900
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x21x21x336xf32>, tensor<256x21x21x336xf32>) outs(%arg2: tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x21x21x336xf32>, tensor<256x21x21x336xf32>) outs(%arg2: tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x21x21x336xf32>, %arg1: tensor<256x21x21x336xf32>, %arg2: tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x21x21x336xf32>, tensor<256x21x21x336xf32>) outs(%arg2: tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32>\n  return %ret : tensor<256x21x21x336xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x21x21x336xf32>, %arg1: tensor<256x21x21x336xf32>, %arg2: tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x21x21x336xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x21x21x336xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x21x21x336xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 21 {\n        affine.for %arg5 = 0 to 21 {\n          affine.for %arg6 = 0 to 336 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x21x21x336xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x21x21x336xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x21x21x336xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x21x21x336xf32>\n    return %2 : tensor<256x21x21x336xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x21x21x336xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x21x21x336xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x21x21x336xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x21x21x336xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x21x21x336xf32>, tensor<256x21x21x336xf32>) outs(%arg2: tensor<256x21x21x336xf32>) -> tensor<256x21x21x336xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x21x21x336xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x21x21x336xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          21,
          1
        ],
        [
          "%arg5",
          0,
          21,
          1
        ],
        [
          "%arg6",
          0,
          336,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 45660707
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x11x11x672xf32>, tensor<256x11x11x672xf32>) outs(%arg2: tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x11x11x672xf32>, tensor<256x11x11x672xf32>) outs(%arg2: tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x11x11x672xf32>, %arg1: tensor<256x11x11x672xf32>, %arg2: tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x11x11x672xf32>, tensor<256x11x11x672xf32>) outs(%arg2: tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32>\n  return %ret : tensor<256x11x11x672xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x11x11x672xf32>, %arg1: tensor<256x11x11x672xf32>, %arg2: tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x11x11x672xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x11x11x672xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x11x11x672xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 11 {\n        affine.for %arg5 = 0 to 11 {\n          affine.for %arg6 = 0 to 672 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x11x11x672xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x11x11x672xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x11x11x672xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x11x11x672xf32>\n    return %2 : tensor<256x11x11x672xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x11x11x672xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x11x11x672xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x11x11x672xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x11x11x672xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x11x11x672xf32>, tensor<256x11x11x672xf32>) outs(%arg2: tensor<256x11x11x672xf32>) -> tensor<256x11x11x672xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x11x11x672xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x11x11x672xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          11,
          1
        ],
        [
          "%arg5",
          0,
          11,
          1
        ],
        [
          "%arg6",
          0,
          672,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25052369
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x42x42x168xf32>, tensor<256x42x42x168xf32>) outs(%arg2: tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x42x42x168xf32>, tensor<256x42x42x168xf32>) outs(%arg2: tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x42x42x168xf32>, %arg1: tensor<256x42x42x168xf32>, %arg2: tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x42x42x168xf32>, tensor<256x42x42x168xf32>) outs(%arg2: tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32>\n  return %ret : tensor<256x42x42x168xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x42x42x168xf32>, %arg1: tensor<256x42x42x168xf32>, %arg2: tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x42x42x168xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x42x42x168xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x42x42x168xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 42 {\n        affine.for %arg5 = 0 to 42 {\n          affine.for %arg6 = 0 to 168 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x42x42x168xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x42x42x168xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x42x42x168xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x42x42x168xf32>\n    return %2 : tensor<256x42x42x168xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x42x42x168xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x42x42x168xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x42x42x168xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x42x42x168xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x42x42x168xf32>, tensor<256x42x42x168xf32>) outs(%arg2: tensor<256x42x42x168xf32>) -> tensor<256x42x42x168xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x42x42x168xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x42x42x168xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          42,
          1
        ],
        [
          "%arg5",
          0,
          42,
          1
        ],
        [
          "%arg6",
          0,
          168,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 91123638
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x15x15x304xf32>, tensor<256x15x15x304xf32>) outs(%arg2: tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x15x15x304xf32>, tensor<256x15x15x304xf32>) outs(%arg2: tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x15x15x304xf32>, %arg1: tensor<256x15x15x304xf32>, %arg2: tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x15x15x304xf32>, tensor<256x15x15x304xf32>) outs(%arg2: tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32>\n  return %ret : tensor<256x15x15x304xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x15x15x304xf32>, %arg1: tensor<256x15x15x304xf32>, %arg2: tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x15x15x304xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x15x15x304xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x15x15x304xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 15 {\n        affine.for %arg5 = 0 to 15 {\n          affine.for %arg6 = 0 to 304 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x15x15x304xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x15x15x304xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x15x15x304xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x15x15x304xf32>\n    return %2 : tensor<256x15x15x304xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x15x15x304xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x15x15x304xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x15x15x304xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x15x15x304xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x15x15x304xf32>, tensor<256x15x15x304xf32>) outs(%arg2: tensor<256x15x15x304xf32>) -> tensor<256x15x15x304xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x15x15x304xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x15x15x304xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          15,
          1
        ],
        [
          "%arg5",
          0,
          15,
          1
        ],
        [
          "%arg6",
          0,
          304,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 21061224
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x14x14x88xf32>, tensor<256x14x14x88xf32>) outs(%arg2: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x14x14x88xf32>, tensor<256x14x14x88xf32>) outs(%arg2: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x14x14x88xf32>, %arg1: tensor<256x14x14x88xf32>, %arg2: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x14x14x88xf32>, tensor<256x14x14x88xf32>) outs(%arg2: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>\n  return %ret : tensor<256x14x14x88xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x14x14x88xf32>, %arg1: tensor<256x14x14x88xf32>, %arg2: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x14x14x88xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x14x14x88xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x14x14x88xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 14 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 88 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x14x14x88xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x14x14x88xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x14x14x88xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x14x14x88xf32>\n    return %2 : tensor<256x14x14x88xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x14x14x88xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x14x14x88xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x14x14x88xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x14x14x88xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x14x14x88xf32>, tensor<256x14x14x88xf32>) outs(%arg2: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x14x14x88xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x14x14x88xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          88,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 4842591
  },
  "linalg.add ins(%arg0, %arg1: tensor<256x7x7x176xf32>, tensor<256x7x7x176xf32>) outs(%arg2: tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32>": {
    "operation": "linalg.add ins(%arg0, %arg1: tensor<256x7x7x176xf32>, tensor<256x7x7x176xf32>) outs(%arg2: tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32>",
    "wrapped_operation": "func.func @func_call(%arg0: tensor<256x7x7x176xf32>, %arg1: tensor<256x7x7x176xf32>, %arg2: tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32> {\n  %ret = linalg.add ins(%arg0, %arg1: tensor<256x7x7x176xf32>, tensor<256x7x7x176xf32>) outs(%arg2: tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32>\n  return %ret : tensor<256x7x7x176xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x7x7x176xf32>, %arg1: tensor<256x7x7x176xf32>, %arg2: tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x7x7x176xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x7x7x176xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x7x7x176xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 7 {\n        affine.for %arg5 = 0 to 7 {\n          affine.for %arg6 = 0 to 176 {\n            %3 = affine.load %1[%arg3, %arg4, %arg5, %arg6] : memref<256x7x7x176xf32>\n            %4 = affine.load %0[%arg3, %arg4, %arg5, %arg6] : memref<256x7x7x176xf32>\n            %5 = arith.addf %3, %4 : f32\n            affine.store %5, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x7x7x176xf32>\n          }\n        }\n      }\n    }\n    %2 = bufferization.to_tensor %alloc : memref<256x7x7x176xf32>\n    return %2 : tensor<256x7x7x176xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x7x7x176xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_arg0 = bufferization.alloc_tensor() : tensor<256x7x7x176xf32>\n%arg0 = linalg.fill ins(%val : f32) outs(%tmp_arg0 : tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32>\n%tmp_arg1 = bufferization.alloc_tensor() : tensor<256x7x7x176xf32>\n%arg1 = linalg.fill ins(%val : f32) outs(%tmp_arg1 : tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32>\n%tmp_arg2 = bufferization.alloc_tensor() : tensor<256x7x7x176xf32>\n%arg2 = linalg.fill ins(%val : f32) outs(%tmp_arg2 : tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.add ins(%arg0, %arg1: tensor<256x7x7x176xf32>, tensor<256x7x7x176xf32>) outs(%arg2: tensor<256x7x7x176xf32>) -> tensor<256x7x7x176xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x7x7x176xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x7x7x176xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          7,
          1
        ],
        [
          "%arg5",
          0,
          7,
          1
        ],
        [
          "%arg6",
          0,
          176,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 1922568
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x12x12xf32>) -> tensor<256x256x12x12xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x12x12xf32>) -> tensor<256x256x12x12xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x14x14xf32>, %filter: tensor<256x256x3x3xf32>, %init: tensor<256x256x12x12xf32>) -> tensor<256x256x12x12xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x12x12xf32>) -> tensor<256x256x12x12xf32>\n  return %ret : tensor<256x256x12x12xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x14x14xf32>, %arg1: tensor<256x256x3x3xf32>, %arg2: tensor<256x256x12x12xf32>) -> tensor<256x256x12x12xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256x12x12xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x12x12xf32>\n    memref.copy %2, %alloc : memref<256x256x12x12xf32> to memref<256x256x12x12xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 12 {\n          affine.for %arg6 = 0 to 12 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x256x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x256x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x12x12xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x12x12xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256x12x12xf32>\n    return %3 : tensor<256x256x12x12xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x12x12xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x256x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x256x3x3xf32>) -> tensor<256x256x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x12x12xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x12x12xf32>) -> tensor<256x256x12x12xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x12x12xf32>) -> tensor<256x256x12x12xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x12x12xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x12x12xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          12,
          1
        ],
        [
          "%arg6",
          0,
          12,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 82128340267
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<256x1024x14x14xf32>) -> tensor<256x1024x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<256x1024x14x14xf32>) -> tensor<256x1024x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x14x14xf32>, %filter: tensor<1024x256x1x1xf32>, %init: tensor<256x1024x14x14xf32>) -> tensor<256x1024x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<256x1024x14x14xf32>) -> tensor<256x1024x14x14xf32>\n  return %ret : tensor<256x1024x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x14x14xf32>, %arg1: tensor<1024x256x1x1xf32>, %arg2: tensor<256x1024x14x14xf32>) -> tensor<256x1024x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<1024x256x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x1024x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1024x14x14xf32>\n    memref.copy %2, %alloc : memref<256x1024x14x14xf32> to memref<256x1024x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 1024 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x256x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<1024x256x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x1024x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x1024x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x1024x14x14xf32>\n    return %3 : tensor<256x1024x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1024x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<1024x256x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<1024x256x1x1xf32>) -> tensor<1024x256x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x1024x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x1024x14x14xf32>) -> tensor<256x1024x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x14x14xf32>, tensor<1024x256x1x1xf32>) outs (%init: tensor<256x1024x14x14xf32>) -> tensor<256x1024x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1024x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1024x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          1024,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 46687059293
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<256x128x26x26xf32>) -> tensor<256x128x26x26xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<256x128x26x26xf32>) -> tensor<256x128x26x26xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x28x28xf32>, %filter: tensor<128x128x3x3xf32>, %init: tensor<256x128x26x26xf32>) -> tensor<256x128x26x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<256x128x26x26xf32>) -> tensor<256x128x26x26xf32>\n  return %ret : tensor<256x128x26x26xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x28x28xf32>, %arg1: tensor<128x128x3x3xf32>, %arg2: tensor<256x128x26x26xf32>) -> tensor<256x128x26x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128x26x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x26x26xf32>\n    memref.copy %2, %alloc : memref<256x128x26x26xf32> to memref<256x128x26x26xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x128x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x26x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x26x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128x26x26xf32>\n    return %3 : tensor<256x128x26x26xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x26x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x128x3x3xf32>) -> tensor<128x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x26x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x26x26xf32>) -> tensor<256x128x26x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<128x128x3x3xf32>) outs (%init: tensor<256x128x26x26xf32>) -> tensor<256x128x26x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x26x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x26x26xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          26,
          1
        ],
        [
          "%arg6",
          0,
          26,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 96255232057
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<512x128x1x1xf32>) outs (%init: tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<512x128x1x1xf32>) outs (%init: tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x28x28xf32>, %filter: tensor<512x128x1x1xf32>, %init: tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<512x128x1x1xf32>) outs (%init: tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32>\n  return %ret : tensor<256x512x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x28x28xf32>, %arg1: tensor<512x128x1x1xf32>, %arg2: tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<512x128x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x512x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512x28x28xf32>\n    memref.copy %2, %alloc : memref<256x512x28x28xf32> to memref<256x512x28x28xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 512 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x128x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<512x128x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x512x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x512x28x28xf32>\n    return %3 : tensor<256x512x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<512x128x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<512x128x1x1xf32>) -> tensor<512x128x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x512x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<512x128x1x1xf32>) outs (%init: tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          512,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 44282278285
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x28x28xf32>, tensor<128x512x1x1xf32>) outs (%init: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x28x28xf32>, tensor<128x512x1x1xf32>) outs (%init: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x512x28x28xf32>, %filter: tensor<128x512x1x1xf32>, %init: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x28x28xf32>, tensor<128x512x1x1xf32>) outs (%init: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n  return %ret : tensor<256x128x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x512x28x28xf32>, %arg1: tensor<128x512x1x1xf32>, %arg2: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<128x512x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x512x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x128x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x128x28x28xf32>\n    memref.copy %2, %alloc : memref<256x128x28x28xf32> to memref<256x128x28x28xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 128 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 512 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x512x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<128x512x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x128x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x128x28x28xf32>\n    return %3 : tensor<256x128x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x128x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x512x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x512x28x28xf32>) -> tensor<256x512x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<128x512x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<128x512x1x1xf32>) -> tensor<128x512x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x128x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x512x28x28xf32>, tensor<128x512x1x1xf32>) outs (%init: tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x128x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x128x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          128,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          512,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 48666263434
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x14xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x12x12xf32>) -> tensor<256x32x12x12xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x14xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x12x12xf32>) -> tensor<256x32x12x12xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x14x14xf32>, %filter: tensor<32x128x3x3xf32>, %init: tensor<256x32x12x12xf32>) -> tensor<256x32x12x12xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x14xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x12x12xf32>) -> tensor<256x32x12x12xf32>\n  return %ret : tensor<256x32x12x12xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x14x14xf32>, %arg1: tensor<32x128x3x3xf32>, %arg2: tensor<256x32x12x12xf32>) -> tensor<256x32x12x12xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x12x12xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x12x12xf32>\n    memref.copy %2, %alloc : memref<256x32x12x12xf32> to memref<256x32x12x12xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 12 {\n          affine.for %arg6 = 0 to 12 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x128x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x12x12xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x12x12xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x12x12xf32>\n    return %3 : tensor<256x32x12x12xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x12x12xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x14x14xf32>) -> tensor<256x128x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x3x3xf32>) -> tensor<32x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x12x12xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x12x12xf32>) -> tensor<256x32x12x12xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x14x14xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x12x12xf32>) -> tensor<256x32x12x12xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x12x12xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x12x12xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          12,
          1
        ],
        [
          "%arg6",
          0,
          12,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 5125335832
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x7xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x5x5xf32>) -> tensor<256x32x5x5xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x7xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x5x5xf32>) -> tensor<256x32x5x5xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x7x7xf32>, %filter: tensor<32x128x3x3xf32>, %init: tensor<256x32x5x5xf32>) -> tensor<256x32x5x5xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x7xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x5x5xf32>) -> tensor<256x32x5x5xf32>\n  return %ret : tensor<256x32x5x5xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x7x7xf32>, %arg1: tensor<32x128x3x3xf32>, %arg2: tensor<256x32x5x5xf32>) -> tensor<256x32x5x5xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128x7x7xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x5x5xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x5x5xf32>\n    memref.copy %2, %alloc : memref<256x32x5x5xf32> to memref<256x32x5x5xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 5 {\n          affine.for %arg6 = 0 to 5 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x128x7x7xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x5x5xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x5x5xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x5x5xf32>\n    return %3 : tensor<256x32x5x5xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x5x5xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x7x7xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x7x7xf32>) -> tensor<256x128x7x7xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x3x3xf32>) -> tensor<32x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x5x5xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x5x5xf32>) -> tensor<256x32x5x5xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x7x7xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x5x5xf32>) -> tensor<256x32x5x5xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x5x5xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x5x5xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          5,
          1
        ],
        [
          "%arg6",
          0,
          5,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 888904827
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x16x16xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x16x16xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x256x16x16xf32>, %filter: tensor<256x256x3x3xf32>, %init: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x16x16xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n  return %ret : tensor<256x256x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x256x16x16xf32>, %arg1: tensor<256x256x3x3xf32>, %arg2: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x256x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x256x16x16xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x14x14xf32>\n    memref.copy %2, %alloc : memref<256x256x14x14xf32> to memref<256x256x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 256 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x256x16x16xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x256x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256x14x14xf32>\n    return %3 : tensor<256x256x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x256x16x16xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x256x16x16xf32>) -> tensor<256x256x16x16xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x256x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x256x3x3xf32>) -> tensor<256x256x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x256x16x16xf32>, tensor<256x256x3x3xf32>) outs (%init: tensor<256x256x14x14xf32>) -> tensor<256x256x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          256,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 111931706509
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x576x14x14xf32>, tensor<576x576x1x1xf32>) outs (%init: tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x576x14x14xf32>, tensor<576x576x1x1xf32>) outs (%init: tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x576x14x14xf32>, %filter: tensor<576x576x1x1xf32>, %init: tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x576x14x14xf32>, tensor<576x576x1x1xf32>) outs (%init: tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32>\n  return %ret : tensor<256x576x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x576x14x14xf32>, %arg1: tensor<576x576x1x1xf32>, %arg2: tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<576x576x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x576x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x576x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x576x14x14xf32>\n    memref.copy %2, %alloc : memref<256x576x14x14xf32> to memref<256x576x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 576 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 576 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x576x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<576x576x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x576x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x576x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x576x14x14xf32>\n    return %3 : tensor<256x576x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x576x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x576x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<576x576x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<576x576x1x1xf32>) -> tensor<576x576x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x576x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x576x14x14xf32>, tensor<576x576x1x1xf32>) outs (%init: tensor<256x576x14x14xf32>) -> tensor<256x576x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x576x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x576x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          576,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          576,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 61465330343
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x26x26xf32>) -> tensor<256x32x26x26xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x26x26xf32>) -> tensor<256x32x26x26xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x128x28x28xf32>, %filter: tensor<32x128x3x3xf32>, %init: tensor<256x32x26x26xf32>) -> tensor<256x32x26x26xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x26x26xf32>) -> tensor<256x32x26x26xf32>\n  return %ret : tensor<256x32x26x26xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x128x28x28xf32>, %arg1: tensor<32x128x3x3xf32>, %arg2: tensor<256x32x26x26xf32>) -> tensor<256x32x26x26xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<32x128x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x128x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x32x26x26xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x32x26x26xf32>\n    memref.copy %2, %alloc : memref<256x32x26x26xf32> to memref<256x32x26x26xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 32 {\n        affine.for %arg5 = 0 to 26 {\n          affine.for %arg6 = 0 to 26 {\n            affine.for %arg7 = 0 to 128 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x128x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<32x128x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x26x26xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x32x26x26xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x32x26x26xf32>\n    return %3 : tensor<256x32x26x26xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x32x26x26xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x128x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x128x28x28xf32>) -> tensor<256x128x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<32x128x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<32x128x3x3xf32>) -> tensor<32x128x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x32x26x26xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x32x26x26xf32>) -> tensor<256x32x26x26xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x128x28x28xf32>, tensor<32x128x3x3xf32>) outs (%init: tensor<256x32x26x26xf32>) -> tensor<256x32x26x26xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x32x26x26xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x32x26x26xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          32,
          1
        ],
        [
          "%arg5",
          0,
          26,
          1
        ],
        [
          "%arg6",
          0,
          26,
          1
        ],
        [
          "%arg7",
          0,
          128,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 24063082695
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x14x14xf32>, tensor<336x336x1x1xf32>) outs (%init: tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x14x14xf32>, tensor<336x336x1x1xf32>) outs (%init: tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x336x14x14xf32>, %filter: tensor<336x336x1x1xf32>, %init: tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x14x14xf32>, tensor<336x336x1x1xf32>) outs (%init: tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32>\n  return %ret : tensor<256x336x14x14xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x336x14x14xf32>, %arg1: tensor<336x336x1x1xf32>, %arg2: tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<336x336x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x336x14x14xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x336x14x14xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x336x14x14xf32>\n    memref.copy %2, %alloc : memref<256x336x14x14xf32> to memref<256x336x14x14xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 336 {\n        affine.for %arg5 = 0 to 14 {\n          affine.for %arg6 = 0 to 14 {\n            affine.for %arg7 = 0 to 336 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x336x14x14xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<336x336x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x336x14x14xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x336x14x14xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x336x14x14xf32>\n    return %3 : tensor<256x336x14x14xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x336x14x14xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x336x14x14xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<336x336x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<336x336x1x1xf32>) -> tensor<336x336x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x336x14x14xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x336x14x14xf32>, tensor<336x336x1x1xf32>) outs (%init: tensor<256x336x14x14xf32>) -> tensor<256x336x14x14xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x336x14x14xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x336x14x14xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          336,
          1
        ],
        [
          "%arg5",
          0,
          14,
          1
        ],
        [
          "%arg6",
          0,
          14,
          1
        ],
        [
          "%arg7",
          0,
          336,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 20466985196
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<256x64x54x54xf32>) -> tensor<256x64x54x54xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<256x64x54x54xf32>) -> tensor<256x64x54x54xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x56x56xf32>, %filter: tensor<64x64x3x3xf32>, %init: tensor<256x64x54x54xf32>) -> tensor<256x64x54x54xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<256x64x54x54xf32>) -> tensor<256x64x54x54xf32>\n  return %ret : tensor<256x64x54x54xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x56x56xf32>, %arg1: tensor<64x64x3x3xf32>, %arg2: tensor<256x64x54x54xf32>) -> tensor<256x64x54x54xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64x56x56xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x54x54xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x54x54xf32>\n    memref.copy %2, %alloc : memref<256x64x54x54xf32> to memref<256x64x54x54xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 54 {\n          affine.for %arg6 = 0 to 54 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x64x56x56xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x54x54xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x54x54xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x54x54xf32>\n    return %3 : tensor<256x64x54x54xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x54x54xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x56x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x64x3x3xf32>) -> tensor<64x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x54x54xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x54x54xf32>) -> tensor<256x64x54x54xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<64x64x3x3xf32>) outs (%init: tensor<256x64x54x54xf32>) -> tensor<256x64x54x54xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x54x54xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x54x54xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          54,
          1
        ],
        [
          "%arg6",
          0,
          54,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 103390065598
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x448x28x28xf32>, tensor<448x448x1x1xf32>) outs (%init: tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x448x28x28xf32>, tensor<448x448x1x1xf32>) outs (%init: tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x448x28x28xf32>, %filter: tensor<448x448x1x1xf32>, %init: tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x448x28x28xf32>, tensor<448x448x1x1xf32>) outs (%init: tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32>\n  return %ret : tensor<256x448x28x28xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x448x28x28xf32>, %arg1: tensor<448x448x1x1xf32>, %arg2: tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<448x448x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x448x28x28xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x448x28x28xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x448x28x28xf32>\n    memref.copy %2, %alloc : memref<256x448x28x28xf32> to memref<256x448x28x28xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 448 {\n        affine.for %arg5 = 0 to 28 {\n          affine.for %arg6 = 0 to 28 {\n            affine.for %arg7 = 0 to 448 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x448x28x28xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<448x448x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x448x28x28xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x448x28x28xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x448x28x28xf32>\n    return %3 : tensor<256x448x28x28xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x448x28x28xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x448x28x28xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<448x448x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<448x448x1x1xf32>) -> tensor<448x448x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x448x28x28xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x448x28x28xf32>, tensor<448x448x1x1xf32>) outs (%init: tensor<256x448x28x28xf32>) -> tensor<256x448x28x28xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x448x28x28xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x448x28x28xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          448,
          1
        ],
        [
          "%arg5",
          0,
          28,
          1
        ],
        [
          "%arg6",
          0,
          28,
          1
        ],
        [
          "%arg7",
          0,
          448,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 148295603736
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x56x56xf32>, %filter: tensor<256x64x1x1xf32>, %init: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32>\n  return %ret : tensor<256x256x56x56xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x56x56xf32>, %arg1: tensor<256x64x1x1xf32>, %arg2: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x64x1x1xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64x56x56xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256x56x56xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x56x56xf32>\n    memref.copy %2, %alloc : memref<256x256x56x56xf32> to memref<256x256x56x56xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 56 {\n          affine.for %arg6 = 0 to 56 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 1 {\n                affine.for %arg9 = 0 to 1 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x64x56x56xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x64x1x1xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x56x56xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x56x56xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256x56x56xf32>\n    return %3 : tensor<256x256x56x56xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x56x56xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x56x56xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x56x56xf32>) -> tensor<256x64x56x56xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x64x1x1xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x64x1x1xf32>) -> tensor<256x64x1x1xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x56x56xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x56x56xf32>, tensor<256x64x1x1xf32>) outs (%init: tensor<256x256x56x56xf32>) -> tensor<256x256x56x56xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x56x56xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x56x56xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          56,
          1
        ],
        [
          "%arg6",
          0,
          56,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          1,
          1
        ],
        [
          "%arg9",
          0,
          1,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 41354533474
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x128x128xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<256x8x61x61xf32>) -> tensor<256x8x61x61xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x128x128xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<256x8x61x61xf32>) -> tensor<256x8x61x61xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x16x128x128xf32>, %filter: tensor<8x16x7x7xf32>, %init: tensor<256x8x61x61xf32>) -> tensor<256x8x61x61xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x128x128xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<256x8x61x61xf32>) -> tensor<256x8x61x61xf32>\n  return %ret : tensor<256x8x61x61xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x16x128x128xf32>, %arg1: tensor<8x16x7x7xf32>, %arg2: tensor<256x8x61x61xf32>) -> tensor<256x8x61x61xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<8x16x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x16x128x128xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x8x61x61xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x8x61x61xf32>\n    memref.copy %2, %alloc : memref<256x8x61x61xf32> to memref<256x8x61x61xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 8 {\n        affine.for %arg5 = 0 to 61 {\n          affine.for %arg6 = 0 to 61 {\n            affine.for %arg7 = 0 to 16 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x16x128x128xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<8x16x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x8x61x61xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x8x61x61xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x8x61x61xf32>\n    return %3 : tensor<256x8x61x61xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x8x61x61xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x16x128x128xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x16x128x128xf32>) -> tensor<256x16x128x128xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<8x16x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<8x16x7x7xf32>) -> tensor<8x16x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x8x61x61xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x8x61x61xf32>) -> tensor<256x8x61x61xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x16x128x128xf32>, tensor<8x16x7x7xf32>) outs (%init: tensor<256x8x61x61xf32>) -> tensor<256x8x61x61xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x8x61x61xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x8x61x61xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          8,
          1
        ],
        [
          "%arg5",
          0,
          61,
          1
        ],
        [
          "%arg6",
          0,
          61,
          1
        ],
        [
          "%arg7",
          0,
          16,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 22558694398
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x64x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<256x16x62x62xf32>) -> tensor<256x16x62x62xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x64x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<256x16x62x62xf32>) -> tensor<256x16x62x62xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x64x64x64xf32>, %filter: tensor<16x64x3x3xf32>, %init: tensor<256x16x62x62xf32>) -> tensor<256x16x62x62xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x64x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<256x16x62x62xf32>) -> tensor<256x16x62x62xf32>\n  return %ret : tensor<256x16x62x62xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x64x64x64xf32>, %arg1: tensor<16x64x3x3xf32>, %arg2: tensor<256x16x62x62xf32>) -> tensor<256x16x62x62xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<16x64x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x64x64x64xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x16x62x62xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x16x62x62xf32>\n    memref.copy %2, %alloc : memref<256x16x62x62xf32> to memref<256x16x62x62xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 16 {\n        affine.for %arg5 = 0 to 62 {\n          affine.for %arg6 = 0 to 62 {\n            affine.for %arg7 = 0 to 64 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x64x64x64xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<16x64x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x16x62x62xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x16x62x62xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x16x62x62xf32>\n    return %3 : tensor<256x16x62x62xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x16x62x62xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x64x64x64xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x64x64x64xf32>) -> tensor<256x64x64x64xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<16x64x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<16x64x3x3xf32>) -> tensor<16x64x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x16x62x62xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x16x62x62xf32>) -> tensor<256x16x62x62xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<1> : tensor<2xi64>} ins (%input, %filter: tensor<256x64x64x64xf32>, tensor<16x64x3x3xf32>) outs (%init: tensor<256x16x62x62xf32>) -> tensor<256x16x62x62xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x16x62x62xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x16x62x62xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          16,
          1
        ],
        [
          "%arg5",
          0,
          62,
          1
        ],
        [
          "%arg6",
          0,
          62,
          1
        ],
        [
          "%arg7",
          0,
          64,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 + %arg8",
          "%arg6 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 34496586857
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x32xf32>, tensor<256x32x7x7xf32>) outs (%init: tensor<256x256x13x13xf32>) -> tensor<256x256x13x13xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x32xf32>, tensor<256x32x7x7xf32>) outs (%init: tensor<256x256x13x13xf32>) -> tensor<256x256x13x13xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x32x32x32xf32>, %filter: tensor<256x32x7x7xf32>, %init: tensor<256x256x13x13xf32>) -> tensor<256x256x13x13xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x32xf32>, tensor<256x32x7x7xf32>) outs (%init: tensor<256x256x13x13xf32>) -> tensor<256x256x13x13xf32>\n  return %ret : tensor<256x256x13x13xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x32x32x32xf32>, %arg1: tensor<256x32x7x7xf32>, %arg2: tensor<256x256x13x13xf32>) -> tensor<256x256x13x13xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<256x32x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x32x32x32xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x256x13x13xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x256x13x13xf32>\n    memref.copy %2, %alloc : memref<256x256x13x13xf32> to memref<256x256x13x13xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 256 {\n        affine.for %arg5 = 0 to 13 {\n          affine.for %arg6 = 0 to 13 {\n            affine.for %arg7 = 0 to 32 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x32x32x32xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<256x32x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x13x13xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x256x13x13xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x256x13x13xf32>\n    return %3 : tensor<256x256x13x13xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x256x13x13xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x32x32x32xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x32x32x32xf32>) -> tensor<256x32x32x32xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<256x32x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<256x32x7x7xf32>) -> tensor<256x32x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x256x13x13xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x256x13x13xf32>) -> tensor<256x256x13x13xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x32x32x32xf32>, tensor<256x32x7x7xf32>) outs (%init: tensor<256x256x13x13xf32>) -> tensor<256x256x13x13xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x256x13x13xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x256x13x13xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          256,
          1
        ],
        [
          "%arg5",
          0,
          13,
          1
        ],
        [
          "%arg6",
          0,
          13,
          1
        ],
        [
          "%arg7",
          0,
          32,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 65434063249
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x230x230xf32>, tensor<64x3x7x7xf32>) outs (%init: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x230x230xf32>, tensor<64x3x7x7xf32>) outs (%init: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x3x230x230xf32>, %filter: tensor<64x3x7x7xf32>, %init: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x230x230xf32>, tensor<64x3x7x7xf32>) outs (%init: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32>\n  return %ret : tensor<256x64x112x112xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x3x230x230xf32>, %arg1: tensor<64x3x7x7xf32>, %arg2: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x3x7x7xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x3x230x230xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x112x112xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x112x112xf32>\n    memref.copy %2, %alloc : memref<256x64x112x112xf32> to memref<256x64x112x112xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 112 {\n          affine.for %arg6 = 0 to 112 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 7 {\n                affine.for %arg9 = 0 to 7 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x3x230x230xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x3x7x7xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x112x112xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x112x112xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x112x112xf32>\n    return %3 : tensor<256x64x112x112xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x112x112xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x3x230x230xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x3x230x230xf32>) -> tensor<256x3x230x230xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x3x7x7xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x3x7x7xf32>) -> tensor<64x3x7x7xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x112x112xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x230x230xf32>, tensor<64x3x7x7xf32>) outs (%init: tensor<256x64x112x112xf32>) -> tensor<256x64x112x112xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x112x112xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x112x112xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          112,
          1
        ],
        [
          "%arg6",
          0,
          112,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          7,
          1
        ],
        [
          "%arg9",
          0,
          7,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 108586801776
  },
  "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x260x260xf32>, tensor<64x3x3x3xf32>) outs (%init: tensor<256x64x129x129xf32>) -> tensor<256x64x129x129xf32>": {
    "operation": "linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x260x260xf32>, tensor<64x3x3x3xf32>) outs (%init: tensor<256x64x129x129xf32>) -> tensor<256x64x129x129xf32>",
    "wrapped_operation": "func.func @func_call(%input: tensor<256x3x260x260xf32>, %filter: tensor<64x3x3x3xf32>, %init: tensor<256x64x129x129xf32>) -> tensor<256x64x129x129xf32> {\n  %ret = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x260x260xf32>, tensor<64x3x3x3xf32>) outs (%init: tensor<256x64x129x129xf32>) -> tensor<256x64x129x129xf32>\n  return %ret : tensor<256x64x129x129xf32>\n}",
    "lowered_operation": "#map = affine_map<(d0, d1) -> (d0 * 2 + d1)>\nmodule {\n  func.func @func_call(%arg0: tensor<256x3x260x260xf32>, %arg1: tensor<64x3x3x3xf32>, %arg2: tensor<256x64x129x129xf32>) -> tensor<256x64x129x129xf32> {\n    %0 = bufferization.to_memref %arg1 : memref<64x3x3x3xf32>\n    %1 = bufferization.to_memref %arg0 : memref<256x3x260x260xf32>\n    %2 = bufferization.to_memref %arg2 : memref<256x64x129x129xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x64x129x129xf32>\n    memref.copy %2, %alloc : memref<256x64x129x129xf32> to memref<256x64x129x129xf32>\n    affine.for %arg3 = 0 to 256 {\n      affine.for %arg4 = 0 to 64 {\n        affine.for %arg5 = 0 to 129 {\n          affine.for %arg6 = 0 to 129 {\n            affine.for %arg7 = 0 to 3 {\n              affine.for %arg8 = 0 to 3 {\n                affine.for %arg9 = 0 to 3 {\n                  %4 = affine.apply #map(%arg5, %arg8)\n                  %5 = affine.apply #map(%arg6, %arg9)\n                  %6 = affine.load %1[%arg3, %arg7, %4, %5] : memref<256x3x260x260xf32>\n                  %7 = affine.load %0[%arg4, %arg7, %arg8, %arg9] : memref<64x3x3x3xf32>\n                  %8 = affine.load %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x129x129xf32>\n                  %9 = arith.mulf %6, %7 : f32\n                  %10 = arith.addf %8, %9 : f32\n                  affine.store %10, %alloc[%arg3, %arg4, %arg5, %arg6] : memref<256x64x129x129xf32>\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    %3 = bufferization.to_tensor %alloc : memref<256x64x129x129xf32>\n    return %3 : tensor<256x64x129x129xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "module attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x64x129x129xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_input = bufferization.alloc_tensor() : tensor<256x3x260x260xf32>\n%input = linalg.fill ins(%val : f32) outs(%tmp_input : tensor<256x3x260x260xf32>) -> tensor<256x3x260x260xf32>\n%tmp_filter = bufferization.alloc_tensor() : tensor<64x3x3x3xf32>\n%filter = linalg.fill ins(%val : f32) outs(%tmp_filter : tensor<64x3x3x3xf32>) -> tensor<64x3x3x3xf32>\n%tmp_init = bufferization.alloc_tensor() : tensor<256x64x129x129xf32>\n%init = linalg.fill ins(%val : f32) outs(%tmp_init : tensor<256x64x129x129xf32>) -> tensor<256x64x129x129xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.conv_2d_nchw_fchw {dilations = dense<1> : tensor<2xi64>, strides = dense<2> : tensor<2xi64>} ins (%input, %filter: tensor<256x3x260x260xf32>, tensor<64x3x3x3xf32>) outs (%init: tensor<256x64x129x129xf32>) -> tensor<256x64x129x129xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x64x129x129xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x64x129x129xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg3",
          0,
          256,
          1
        ],
        [
          "%arg4",
          0,
          64,
          1
        ],
        [
          "%arg5",
          0,
          129,
          1
        ],
        [
          "%arg6",
          0,
          129,
          1
        ],
        [
          "%arg7",
          0,
          3,
          1
        ],
        [
          "%arg8",
          0,
          3,
          1
        ],
        [
          "%arg9",
          0,
          3,
          1
        ]
      ],
      "op_count": {
        "+": 1,
        "-": 0,
        "*": 1,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg3",
          "%arg7",
          "%arg5 * 2 + %arg8",
          "%arg6 * 2 + %arg9"
        ],
        [
          "%arg4",
          "%arg7",
          "%arg8",
          "%arg9"
        ],
        [
          "%arg3",
          "%arg4",
          "%arg5",
          "%arg6"
        ]
      ],
      "store_data": []
    },
    "execution_time": 21987584276
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x2048xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x2048xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x2048xf32>, %35: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x2048xf32>\n  return %ret : tensor<256x2048xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x2048xf32>, %arg1: tensor<256x2048xf32>) -> tensor<256x2048xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x2048xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x2048xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 2048 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x2048xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x2048xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x2048xf32>\n    return %1 : tensor<256x2048xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x2048xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x2048xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x2048xf32>) -> tensor<256x2048xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x2048xf32>) outs(%35 : tensor<256x2048xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x2048xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x2048xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x2048xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          2048,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 398779.5
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x512xf32>) outs(%35 : tensor<256x512xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x512xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x512xf32>) outs(%35 : tensor<256x512xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x512xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x512xf32>, %35: tensor<256x512xf32>) -> tensor<256x512xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x512xf32>) outs(%35 : tensor<256x512xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x512xf32>\n  return %ret : tensor<256x512xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x512xf32>, %arg1: tensor<256x512xf32>) -> tensor<256x512xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x512xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x512xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 512 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x512xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x512xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x512xf32>\n    return %1 : tensor<256x512xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x512xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x512xf32>) -> tensor<256x512xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x512xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x512xf32>) -> tensor<256x512xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x512xf32>) outs(%35 : tensor<256x512xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x512xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x512xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x512xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          512,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 101208
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1000xf32>) outs(%35 : tensor<256x1000xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x1000xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1000xf32>) outs(%35 : tensor<256x1000xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x1000xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x1000xf32>, %35: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1000xf32>) outs(%35 : tensor<256x1000xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x1000xf32>\n  return %ret : tensor<256x1000xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x1000xf32>, %arg1: tensor<256x1000xf32>) -> tensor<256x1000xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x1000xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x1000xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 1000 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x1000xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x1000xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x1000xf32>\n    return %1 : tensor<256x1000xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x1000xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x1000xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x1000xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x1000xf32>) -> tensor<256x1000xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x1000xf32>) outs(%35 : tensor<256x1000xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x1000xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x1000xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x1000xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          1000,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 195511.5
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x100xf32>) outs(%35 : tensor<256x100xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x100xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x100xf32>) outs(%35 : tensor<256x100xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x100xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x100xf32>, %35: tensor<256x100xf32>) -> tensor<256x100xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x100xf32>) outs(%35 : tensor<256x100xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x100xf32>\n  return %ret : tensor<256x100xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x100xf32>, %arg1: tensor<256x100xf32>) -> tensor<256x100xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x100xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x100xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 100 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x100xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x100xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x100xf32>\n    return %1 : tensor<256x100xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x100xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x100xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x100xf32>) -> tensor<256x100xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x100xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x100xf32>) -> tensor<256x100xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x100xf32>) outs(%35 : tensor<256x100xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x100xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x100xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x100xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          100,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 19827
  },
  "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x10xf32>) outs(%35 : tensor<256x10xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x10xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x10xf32>) outs(%35 : tensor<256x10xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x10xf32>",
    "wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nfunc.func @func_call(%38: tensor<256x10xf32>, %35: tensor<256x10xf32>) -> tensor<256x10xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x10xf32>) outs(%35 : tensor<256x10xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x10xf32>\n  return %ret : tensor<256x10xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x10xf32>, %arg1: tensor<256x10xf32>) -> tensor<256x10xf32> {\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x10xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x10xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 10 {\n        %2 = affine.load %0[%arg2, %arg3] : memref<256x10xf32>\n        %3 = arith.cmpf ugt, %2, %cst : f32\n        %4 = arith.select %3, %2, %cst : f32\n        affine.store %4, %alloc[%arg2, %arg3] : memref<256x10xf32>\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x10xf32>\n    return %1 : tensor<256x10xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map2 = affine_map<(d0, d1) -> (d0, d1)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x10xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_38 = bufferization.alloc_tensor() : tensor<256x10xf32>\n%38 = linalg.fill ins(%val : f32) outs(%tmp_38 : tensor<256x10xf32>) -> tensor<256x10xf32>\n%tmp_35 = bufferization.alloc_tensor() : tensor<256x10xf32>\n%35 = linalg.fill ins(%val : f32) outs(%tmp_35 : tensor<256x10xf32>) -> tensor<256x10xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%38 : tensor<256x10xf32>) outs(%35 : tensor<256x10xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %46 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %47 = arith.select %46, %in, %cst_1 : f32\n                    linalg.yield %47 : f32\n                } -> tensor<256x10xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x10xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x10xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          10,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%arg2",
          "%arg3"
        ]
      ],
      "store_data": []
    },
    "execution_time": 2579.5
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x57x57x64xf32>) outs(%25 : tensor<256x57x57x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x57x57x64xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x57x57x64xf32>) outs(%25 : tensor<256x57x57x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x57x57x64xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x57x57x64xf32>, %25: tensor<256x57x57x64xf32>) -> tensor<256x57x57x64xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x57x57x64xf32>) outs(%25 : tensor<256x57x57x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x57x57x64xf32>\n  return %ret : tensor<256x57x57x64xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x57x57x64xf32>, %arg1: tensor<256x57x57x64xf32>) -> tensor<256x57x57x64xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x57x57x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x57x57x64xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 57 {\n        affine.for %arg4 = 0 to 57 {\n          affine.for %arg5 = 0 to 64 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x57x57x64xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x57x57x64xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x57x57x64xf32>\n    return %1 : tensor<256x57x57x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x57x57x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x57x57x64xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x57x57x64xf32>) -> tensor<256x57x57x64xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x57x57x64xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x57x57x64xf32>) -> tensor<256x57x57x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x57x57x64xf32>) outs(%25 : tensor<256x57x57x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x57x57x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x57x57x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x57x57x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          57,
          1
        ],
        [
          "%arg4",
          0,
          57,
          1
        ],
        [
          "%arg5",
          0,
          64,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 45016676
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x74x74x64xf32>) outs(%25 : tensor<256x74x74x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x74x74x64xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x74x74x64xf32>) outs(%25 : tensor<256x74x74x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x74x74x64xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x74x74x64xf32>, %25: tensor<256x74x74x64xf32>) -> tensor<256x74x74x64xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x74x74x64xf32>) outs(%25 : tensor<256x74x74x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x74x74x64xf32>\n  return %ret : tensor<256x74x74x64xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x74x74x64xf32>, %arg1: tensor<256x74x74x64xf32>) -> tensor<256x74x74x64xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x74x74x64xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x74x74x64xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 74 {\n        affine.for %arg4 = 0 to 74 {\n          affine.for %arg5 = 0 to 64 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x74x74x64xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x74x74x64xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x74x74x64xf32>\n    return %1 : tensor<256x74x74x64xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x74x74x64xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x74x74x64xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x74x74x64xf32>) -> tensor<256x74x74x64xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x74x74x64xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x74x74x64xf32>) -> tensor<256x74x74x64xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x74x74x64xf32>) outs(%25 : tensor<256x74x74x64xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x74x74x64xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x74x74x64xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x74x74x64xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          74,
          1
        ],
        [
          "%arg4",
          0,
          74,
          1
        ],
        [
          "%arg5",
          0,
          64,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 75674570
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x36x36x192xf32>) outs(%25 : tensor<256x36x36x192xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x36x36x192xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x36x36x192xf32>) outs(%25 : tensor<256x36x36x192xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x36x36x192xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x36x36x192xf32>, %25: tensor<256x36x36x192xf32>) -> tensor<256x36x36x192xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x36x36x192xf32>) outs(%25 : tensor<256x36x36x192xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x36x36x192xf32>\n  return %ret : tensor<256x36x36x192xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x36x36x192xf32>, %arg1: tensor<256x36x36x192xf32>) -> tensor<256x36x36x192xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x36x36x192xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x36x36x192xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 36 {\n        affine.for %arg4 = 0 to 36 {\n          affine.for %arg5 = 0 to 192 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x36x36x192xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x36x36x192xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x36x36x192xf32>\n    return %1 : tensor<256x36x36x192xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x36x36x192xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x36x36x192xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x36x36x192xf32>) -> tensor<256x36x36x192xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x36x36x192xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x36x36x192xf32>) -> tensor<256x36x36x192xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x36x36x192xf32>) outs(%25 : tensor<256x36x36x192xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x36x36x192xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x36x36x192xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x36x36x192xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          36,
          1
        ],
        [
          "%arg4",
          0,
          36,
          1
        ],
        [
          "%arg5",
          0,
          192,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 51477762
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x85x85x42xf32>) outs(%25 : tensor<256x85x85x42xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x85x85x42xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x85x85x42xf32>) outs(%25 : tensor<256x85x85x42xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x85x85x42xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x85x85x42xf32>, %25: tensor<256x85x85x42xf32>) -> tensor<256x85x85x42xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x85x85x42xf32>) outs(%25 : tensor<256x85x85x42xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x85x85x42xf32>\n  return %ret : tensor<256x85x85x42xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x85x85x42xf32>, %arg1: tensor<256x85x85x42xf32>) -> tensor<256x85x85x42xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x85x85x42xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x85x85x42xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 85 {\n        affine.for %arg4 = 0 to 85 {\n          affine.for %arg5 = 0 to 42 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x85x85x42xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x85x85x42xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x85x85x42xf32>\n    return %1 : tensor<256x85x85x42xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x85x85x42xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x85x85x42xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x85x85x42xf32>) -> tensor<256x85x85x42xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x85x85x42xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x85x85x42xf32>) -> tensor<256x85x85x42xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x85x85x42xf32>) outs(%25 : tensor<256x85x85x42xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x85x85x42xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x85x85x42xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x85x85x42xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          85,
          1
        ],
        [
          "%arg4",
          0,
          85,
          1
        ],
        [
          "%arg5",
          0,
          42,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 68920689
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x43x43x84xf32>) outs(%25 : tensor<256x43x43x84xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x43x43x84xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x43x43x84xf32>) outs(%25 : tensor<256x43x43x84xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x43x43x84xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x43x43x84xf32>, %25: tensor<256x43x43x84xf32>) -> tensor<256x43x43x84xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x43x43x84xf32>) outs(%25 : tensor<256x43x43x84xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x43x43x84xf32>\n  return %ret : tensor<256x43x43x84xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x43x43x84xf32>, %arg1: tensor<256x43x43x84xf32>) -> tensor<256x43x43x84xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x43x43x84xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x43x43x84xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 43 {\n        affine.for %arg4 = 0 to 43 {\n          affine.for %arg5 = 0 to 84 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x43x43x84xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x43x43x84xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x43x43x84xf32>\n    return %1 : tensor<256x43x43x84xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x43x43x84xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x43x43x84xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x43x43x84xf32>) -> tensor<256x43x43x84xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x43x43x84xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x43x43x84xf32>) -> tensor<256x43x43x84xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x43x43x84xf32>) outs(%25 : tensor<256x43x43x84xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x43x43x84xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x43x43x84xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x43x43x84xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          43,
          1
        ],
        [
          "%arg4",
          0,
          43,
          1
        ],
        [
          "%arg5",
          0,
          84,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 33345071
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x23x23x336xf32>) outs(%25 : tensor<256x23x23x336xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x23x23x336xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x23x23x336xf32>) outs(%25 : tensor<256x23x23x336xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x23x23x336xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x23x23x336xf32>, %25: tensor<256x23x23x336xf32>) -> tensor<256x23x23x336xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x23x23x336xf32>) outs(%25 : tensor<256x23x23x336xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x23x23x336xf32>\n  return %ret : tensor<256x23x23x336xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x23x23x336xf32>, %arg1: tensor<256x23x23x336xf32>) -> tensor<256x23x23x336xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x23x23x336xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x23x23x336xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 23 {\n        affine.for %arg4 = 0 to 23 {\n          affine.for %arg5 = 0 to 336 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x23x23x336xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x23x23x336xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x23x23x336xf32>\n    return %1 : tensor<256x23x23x336xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x23x23x336xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x23x23x336xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x23x23x336xf32>) -> tensor<256x23x23x336xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x23x23x336xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x23x23x336xf32>) -> tensor<256x23x23x336xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x23x23x336xf32>) outs(%25 : tensor<256x23x23x336xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x23x23x336xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x23x23x336xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x23x23x336xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          23,
          1
        ],
        [
          "%arg4",
          0,
          23,
          1
        ],
        [
          "%arg5",
          0,
          336,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 35693757
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x672xf32>) outs(%25 : tensor<256x14x14x672xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x672xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x672xf32>) outs(%25 : tensor<256x14x14x672xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x672xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x14x14x672xf32>, %25: tensor<256x14x14x672xf32>) -> tensor<256x14x14x672xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x672xf32>) outs(%25 : tensor<256x14x14x672xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x672xf32>\n  return %ret : tensor<256x14x14x672xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x14x14x672xf32>, %arg1: tensor<256x14x14x672xf32>) -> tensor<256x14x14x672xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x14x14x672xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x14x14x672xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 14 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 672 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x14x14x672xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x14x14x672xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x14x14x672xf32>\n    return %1 : tensor<256x14x14x672xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x14x14x672xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x14x14x672xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x14x14x672xf32>) -> tensor<256x14x14x672xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x14x14x672xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x14x14x672xf32>) -> tensor<256x14x14x672xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x672xf32>) outs(%25 : tensor<256x14x14x672xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x672xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x14x14x672xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x14x14x672xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          672,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 25914905
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x29x29x22xf32>) outs(%25 : tensor<256x29x29x22xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x29x29x22xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x29x29x22xf32>) outs(%25 : tensor<256x29x29x22xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x29x29x22xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x29x29x22xf32>, %25: tensor<256x29x29x22xf32>) -> tensor<256x29x29x22xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x29x29x22xf32>) outs(%25 : tensor<256x29x29x22xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x29x29x22xf32>\n  return %ret : tensor<256x29x29x22xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x29x29x22xf32>, %arg1: tensor<256x29x29x22xf32>) -> tensor<256x29x29x22xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x29x29x22xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x29x29x22xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 29 {\n        affine.for %arg4 = 0 to 29 {\n          affine.for %arg5 = 0 to 22 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x29x29x22xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x29x29x22xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x29x29x22xf32>\n    return %1 : tensor<256x29x29x22xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x29x29x22xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x29x29x22xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x29x29x22xf32>) -> tensor<256x29x29x22xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x29x29x22xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x29x29x22xf32>) -> tensor<256x29x29x22xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x29x29x22xf32>) outs(%25 : tensor<256x29x29x22xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x29x29x22xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x29x29x22xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x29x29x22xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          29,
          1
        ],
        [
          "%arg4",
          0,
          29,
          1
        ],
        [
          "%arg5",
          0,
          22,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3294533
  },
  "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x88xf32>) outs(%25 : tensor<256x14x14x88xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x88xf32>": {
    "operation": "linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x88xf32>) outs(%25 : tensor<256x14x14x88xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x88xf32>",
    "wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nfunc.func @func_call(%28: tensor<256x14x14x88xf32>, %25: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32> {\n  %ret = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x88xf32>) outs(%25 : tensor<256x14x14x88xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x88xf32>\n  return %ret : tensor<256x14x14x88xf32>\n}",
    "lowered_operation": "module {\n  func.func @func_call(%arg0: tensor<256x14x14x88xf32>, %arg1: tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32> {\n    %c0 = arith.constant 0 : index\n    %cst = arith.constant 0.000000e+00 : f32\n    %0 = bufferization.to_memref %arg0 : memref<256x14x14x88xf32>\n    %alloc = memref.alloc() {alignment = 64 : i64} : memref<256x14x14x88xf32>\n    affine.for %arg2 = 0 to 256 {\n      affine.for %arg3 = 0 to 14 {\n        affine.for %arg4 = 0 to 14 {\n          affine.for %arg5 = 0 to 88 {\n            %2 = affine.load %0[%c0, %arg3, %arg4, %arg5] : memref<256x14x14x88xf32>\n            %3 = arith.cmpf ugt, %2, %cst : f32\n            %4 = arith.select %3, %2, %cst : f32\n            affine.store %4, %alloc[%arg2, %arg3, %arg4, %arg5] : memref<256x14x14x88xf32>\n          }\n        }\n      }\n    }\n    %1 = bufferization.to_tensor %alloc : memref<256x14x14x88xf32>\n    return %1 : tensor<256x14x14x88xf32>\n  }\n}\n\n",
    "transform_wrapped_operation": "#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>\n                #map2 = affine_map<(d0, d1, d2, d3) -> (0, d1, d2, d3)>\nmodule attributes {torch.debug_module_name = \"Net\"} {\nfunc.func private @nanoTime() -> i64 attributes { llvm.emit_c_interface }\nfunc.func private @printFlops(f64)\nfunc.func private @printI64(i64)\nfunc.func private @printNewline()\nfunc.func private @printMemrefF32(tensor<*xf32>)\n\n\nfunc.func @matmul() -> tensor<256x14x14x88xf32>{\n\n%val = arith.constant 2.00000e+00 : f32\n%zero = arith.constant 0.00000e+00 : f32\n\n%tmp_28 = bufferization.alloc_tensor() : tensor<256x14x14x88xf32>\n%28 = linalg.fill ins(%val : f32) outs(%tmp_28 : tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>\n%tmp_25 = bufferization.alloc_tensor() : tensor<256x14x14x88xf32>\n%25 = linalg.fill ins(%val : f32) outs(%tmp_25 : tensor<256x14x14x88xf32>) -> tensor<256x14x14x88xf32>\n\n%t0 = func.call @nanoTime() : () -> (i64)\n\n%return_arg = linalg.generic {indexing_maps = [#map2, #map], iterator_types = [\"parallel\", \"parallel\", \"parallel\", \"parallel\"]} ins(%28 : tensor<256x14x14x88xf32>) outs(%25 : tensor<256x14x14x88xf32>) {\n                    ^bb0(%in: f32, %out: f32):\n                    %cst_1 = arith.constant 0.000000e+00 : f32\n                    %90 = arith.cmpf ugt, %in, %cst_1 : f32\n                    %91 = arith.select %90, %in, %cst_1 : f32\n                    linalg.yield %91 : f32\n                } -> tensor<256x14x14x88xf32>\n%t = func.call @nanoTime() : () -> (i64)\n%delta = arith.subi %t, %t0 : i64\n%fp = arith.uitofp %delta : i64 to f64\n// func.call @printFlops(%fp) : (f64) -> ()\nfunc.call @printI64(%delta) : (i64) -> ()\nfunc.call @printNewline() : () -> ()\n\nreturn %return_arg : tensor<256x14x14x88xf32> \n}\n\nfunc.func @main(){\n    %c1 = arith.constant 1: index\n    %c0 = arith.constant 0 : index\n    %n = arith.constant 2: index\n    scf.for %i = %c0 to %n step %c1 {\n    %outputmain = func.call @matmul() : () -> tensor<256x14x14x88xf32>\n    }\n    return\n}\n}\n",
    "loops_data": {
      "nested_loops": [
        [
          "%arg2",
          0,
          256,
          1
        ],
        [
          "%arg3",
          0,
          14,
          1
        ],
        [
          "%arg4",
          0,
          14,
          1
        ],
        [
          "%arg5",
          0,
          88,
          1
        ]
      ],
      "op_count": {
        "+": 0,
        "-": 0,
        "*": 0,
        "/": 0,
        "exp": 0
      },
      "load_data": [
        [
          "%c0",
          "%arg3",
          "%arg4",
          "%arg5"
        ]
      ],
      "store_data": []
    },
    "execution_time": 3374615
  }
}